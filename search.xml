<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python之文件处理]]></title>
    <url>%2F2019%2F01%2F27%2FPython%E4%B9%8B%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[Python之文件处理open操作open(file, mode=’r’, buffering=-1, encoding=None, errors=None, newline=None, closefd=True,opener=None) 打开一个文件，返回一个文件对象(流对象)和文件描述符。打开文件失败，则返回异常 基本使用： 创建一个文件test，然后打开它，用完关闭 123f = open('test') # file对象print(f.read()) # 读取文件f.close() # 关闭文件 123 在文件操作中，最常用的操作就是读和写 文件访问的模式有两种：文本模式和二进制模式。不同模式下，操作函数不尽相同，表现的结果也不一样 open的参数file: 打开或者创建的文件名.如果不指定路径，默认当前路径mode: 文件打开模式open函数默认是以只读文本模式打开已存在的文件 r：缺省的，表示只读打开, 不能使用写文件功能 如果使用write方法，会抛出异常 如果文件不存在，抛出FileNotFoundError异常示范代码： 123f = open('test','r')print(f.read())f.close() 123 w：表示只写打开, 如果读取文件则抛出异常 如果文件不存在，则直接创建文件 如果文件存在，则清空文件内容示范代码： 1234567f = open('test','w')f.write('123')f.close()f = open('test','r')print(f.read())f.close() 123 x：创建并写入一个新文件，不能使用读文件功能 如果文件不存在，创建文件，并且以只写方式打开 如果文件存在，抛出FileExistsErroe异常示范代码： 1234567f = open('test0','x')f.write('qwer')f.close()f = open('test1','r')print(f.read())f.close() abcd123www.python.org www.magedu.com python3 a：写入打开文件 如果文件存在，只写打开，追加内容 如果文件不存在，则创建，直写打开，追加内容示范代码： 1234567f = open('test','a')f.write('*******')f.close()f = open('test','r')print(f.read())f.close() 123******* rwxa总结： r是只读，w x a 都是只写 w x a 都可以参数新文件 w 不管文件存在与否，都会生成全新内容的文件 a 不管文件存在与否，都能在打开文件的尾部追加新内容 x 要求文件必须不存在，自己创建一个新文件，否则报错 t：文本模式 字符流，将文件的字节按照某种字符编码理解，按照字符操作。open的默认mode就是 rt b：二进制模式 字节流，将文件按照直接理解，与字符编码无关。二进制模式操作室，直接操作使用bytes类型 示范代码： 12345678910f = open('test1','rb') # 二进制只读s = f.read()print(type(s))print(s)f.close()f = open('test3','wb') # IO对象s = f.write('lpx'.encode())print(s)f.close() &lt;class &apos;bytes&apos;&gt; b&apos;abcd123www.python.org\r\nwww.magedu.com\r\n\r\npython3&apos; 3 +: 为r、w、a、x提供缺失的读或者写功能 获取文件对象依旧按照r、w、a、x 自己的特征 +号不能单独使用，可以认为它是为前面的模式字符提供增强功能 1234f = open('test3','r+',encoding='utf8')print(f.read())f.write('abcdef')f.close() lpx 文件指针上面的示范代码，已经说明了有一个指针 文件指针，指向当前字节位置mode=r，指针起始在0 mode=a，指针起始在EOF tell()：显示指针当前位置 seek(offset,[,whence]) 移动文件指针位置。offest偏移多少直接，whence从哪里开始 文本模式下 whence 0 缺省值，表示从头开始，offest只能正整数 whence 1 表示从当前位置，offest只接受0 whence 2 表示从EOF开始，offest只就收0 1234567891011121314151617181920212223242526# 文本模式f = open('test','r+')print(f.tell()) # 起始print(f.read())print(f.tell()) # EOFprint(f.seek(2,0))print(f.read())print(f.seek(0,1)) # offset 必须为 0print(f.seek(0,2)) # offset 必须为 0f.close()print('*' * 10)# 中文f = open('test4','w+')print(f.write("马哥教育"))print(f.tell())f.close()f = open('test4','r+')print(f.read(2))print(f.seek(1))print(f.tell())# print(f.read()) # UnicodeDecodeError 当前位置不足以构成中文print(f.seek(2))f.close() 0 123******* 10 2 3******* 10 10 ********** 4 8 马哥 1 1 2 文本模式总结： whence 为1表示从当前位置开始偏移 ，但是只支持偏移0，相当于原地不动，没什么用 whence 为2表示从EOF开始偏移，只支持偏移0，相当于移动文件指针到EOF seek 是按照字节偏移的 read在文本模式下是按照字符读取的 二进制模式 whence 0 缺省值，表示从头开始，offest只能正整数 whence 1 表示从当前位置，offest可正可负 whence 2 表示从EOF开始，offest可正可负 1234567891011121314151617181920212223# 二进制模式f = open('test4','rb+')print(f.tell()) # 起始print(f.read())print(f.tell()) #f.write(b'abc')print('*'* 10)print(f.seek(0)) # 起始print(f.seek(2,1)) # 从当前指针开始，先后2print(f.read())print(f.seek(-2,1)) # 从当前指针开始，先前2print('*'* 10)print(f.seek(2,2)) # 从EOF开始，向后2print(f.seek(0)) print(f.seek(-2,2)) # 从EOF开始，向前2print('*'* 10)# f.seek(-20,2) # OSErrorf.close() 0 b&apos;\xc2\xed\xb8\xe7\xbd\xcc\xd3\xfd&apos; 8 ********** 0 2 b&apos;\xb8\xe7\xbd\xcc\xd3\xfdabc&apos; 9 ********** 13 0 9 ********** 二进制模式总结： 二进制模式支持任意起点的偏移，从头、从尾、从中间位置开始 向后seek 可以越界，但是向前seek 时，不能越界，否则抛异常 buffering1 表示使用缺省大小的buffer。如果是二进制模式，使用io.DEFAULT_BUFFER_SIZE值，默认是4096或者8192。如果是文本模式，如果是终端设备，是行缓存方式，如果不是，则使用二进制模式的策略。 0 只在二进制模式使用，表示关buffer 1 只在文本模式使用，表示使用行缓冲。意思就是见到换行符就flush 大于1 用于指定buffer的大小 buffer 缓冲区缓冲区一个内存空间，一般来说是一个FIFO队列，到缓冲区满了或者达到阈值，数据才会flush到磁盘。 flush() 将缓冲区数据写入磁盘 close() 关闭前会调用flush() io.DEFAULT_BUFFER_SIZE 缺省缓冲区大小，字节 二进制模式 12345678910import iof = open('test4','w+b')print(io.DEFAULT_BUFFER_SIZE)f.write('lvpeixin.tech'.encode())f.seek(0)print(f.read())f.write('www.lvpeixin.tech'.encode())f.flush()f.close() 8192 b&apos;lvpeixin.tech&apos; 123456f = open('test4','w+b',4) # 缓冲区大小f.write(b'lpx')f.write(b'tech')f.seek(0)print(f.read())f.close() b&apos;lpxtech&apos; 文本模式buffering=1，使用行缓冲 123456f = open('test4','w+',1)f.write('lpx')f.write('lpx'*4)f.write('\n')f.write('Hello\nPython')f.close() buffering &gt; 1,使用指定大小的缓冲区 12345678f = open('test4','w+', 15)f.write("mag") f.write('edu') f.write('Hello\n') f.write('\nPython')f.write('a' * (io.DEFAULT_BUFFER_SIZE - 20)) # 设置为大于1没什么用f.write('\nwww.magedu.com/python')f.close() buffering=0这是一种特殊的二进制模式。不需要内存的buffer，可以看做是一个FIFO文件 12345678f = open('test4','wb+', 0)f.write(b"m") f.write(b"a") f.write(b"g") f.write(b"magedu"*4) f.write(b'\n')f.write(b'Hello\nPython')f.close() buffering总结 文本模式，一般都用默认缓冲区大小 二进制模式，都是一个个字节的操作，可以指定buffer的大小 一般来说，默认缓冲区大小是个比较好的选择，除非明确知道，否则不调整默认缓冲区大小 一般编程中，明确知道需要些磁盘，都会手动调用一次flush，而不是等到自动flush或者close的时候 encodeing：编码，仅文本模式使用None 表示使用缺省编码，依赖操作系统 Windows下的缺省编码是 GBK Linux下的缺省编码是 UTF-8 如下代码在不同操作系统下的文件编码都是不同 123f = open('test1','w')f.write('啊')f.close() 其它参数errors什么样的编码错误将被捕获 None和strict表示有编码错误将抛出ValueError异常；ignore表示忽略 newline 文本模式中，换行的转换。 可以为None、’’ 空串、’\r’、’\n’、’\r\n’ 读时，None表示’\r’、’\n’、’\r\n’都被转换为’\n’； ‘’表示不会自动转换通用换行符；其它合法字符表示换行符就是指定字符，就会按照指定字符分行写时， None表示’\n’都会被替换为系统缺省行分隔符os.linesep；’\n’或’’表示’\n’不替换；其它合法字符表示’\n’会被替换为指定的字符 示范代码： 12345678f = open('test','w')f.write('python\rwww.python.org\nwww.magedu.com\r\npython3')f.close()newlines = [None, '', '\n', '\r\n']for nl in newlines: f = open('test', 'r+' , newline=nl) # 缺省替换所有换行符 print(f.readlines()) f.close() [&apos;python\n&apos;, &apos;www.python.org\n&apos;, &apos;www.magedu.com\n&apos;, &apos;\n&apos;, &apos;python3&apos;] [&apos;python\r&apos;, &apos;www.python.org\r\n&apos;, &apos;www.magedu.com\r&apos;, &apos;\r\n&apos;, &apos;python3&apos;] [&apos;python\rwww.python.org\r\n&apos;, &apos;www.magedu.com\r\r\n&apos;, &apos;python3&apos;] [&apos;python\rwww.python.org\r\n&apos;, &apos;www.magedu.com\r\r\n&apos;, &apos;python3&apos;] closefd 关闭文件描述符，True表示关闭它，False会再文件关闭后保持这个描述符 fileobj.fileno() 可以查看文件描述符 文件上下文管理 对于类似于文件对象的IO对象，一般来说都需要在不使用的时候关闭、注销，以释放资源。 IO被打开的时候，会获得一个文件描述符。计算机资源是有限的，所以操作系统都会做限制。 就是为了保护计算机的资源不要被完全耗尽，计算资源是共享的，不是独占的。 file.close() 方法容易被遗忘，所以，Python引入了with语句来自动帮我们调用close()方法 12345with open('test','w+') as f: f.write("abc") # 文件只读，写入失败 # 测试f是否关闭f.closed # f的作用域 True 上下文管理; 使用with.. as 关键字 上下文管理语句块并不会开启新的作用域 with语句执行完毕后，会自动关闭文件对象 12]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[直接插入排序原理]]></title>
    <url>%2F2019%2F01%2F20%2F%E7%9B%B4%E6%8E%A5%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[直接插入排序原理： 在未排序序列中，构建一个子排序序列，直至全部数据排序完成 将待排序的数，插入到已经排序的序列中的合适的位置 增加一个哨兵位，放入待排序比较值，让它和后面已经排好序的序列做比较，找到合适的插入点简单是说： 就是在无序区中构建一个空白有序区，然后一个一个将无序区的元素拿到有序区作比较，将这些比较的元素按照从小到大或者从大到小的循序插入到有序区中 实现代码如下 12345678910111213141516lst = [1,6,5,4,2,3,9,7,8]lst = [0] + lstlength = len(lst)for i in range(2,length): lst[0] = lst[i] j = i - 1 if lst[j] &gt; lst[0]: while lst[j] &gt; lst[0]: lst[j + 1] = lst[j] lst[j] = lst[0] lst[j] = lst[0] j -= 1 lst[1:] [1, 2, 3, 4, 5, 6, 7, 8, 9] 因为在列表头部添加了一个元素用于记录待交换元素，所以应该从索引为2的元素，开始，拿来和已经排序好的序列进行比较(认为6已经在排序空间了) 由于无法判断已排序区到底排了几次，所以只能使用while循环，直到排序区的某个元素比待排序元素小时，表示在上一次插入过后，排序区已经排序完毕，这时就可以退出循环了 123456789101112131415lst = [1,6,5,4,2,3,9,7,8]length = len(lst)temp = 0for i in range(1,length): temp = lst[i] j = i - 1 if lst[j] &gt; temp: while lst[j] &gt; temp: lst[j+1],lst[j] = lst[j],temp j -= 1 if j &lt; 0: break lst [1, 2, 3, 4, 5, 6, 7, 8, 9] 总结 最好情况，正好是升序排列，比较迭代次n-1次 最差情况，正好是降序排列，比较迭代1，2，… n - 1 次即n(n-1)/2，数据移动会非常多 使用两层嵌套循环，时间复杂度为O(n^2) 属于稳定的排序算法 使用在小规模数据比较时 如果比较操作耗时大的话，可以采用二分查找来提高效率，即二分查找插入排序(由于每次比较还是要进行插入，所以优化效率不是那么高)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数参数注解和作用， 以及参数注解在业务中的应用， inspect模块的使用]]></title>
    <url>%2F2019%2F01%2F20%2F%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0%E6%B3%A8%E8%A7%A3%E5%92%8C%E4%BD%9C%E7%94%A8%EF%BC%8C%20%E4%BB%A5%E5%8F%8A%E5%8F%82%E6%95%B0%E6%B3%A8%E8%A7%A3%E5%9C%A8%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%EF%BC%8C%20inspect%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[函数参数注解和作用， 以及参数注解在业务中的应用， inspect模块的使用函数参数注解函数定义的弊端： Python是动态语言，变量随时可以被赋值，且能被赋值为不同的类型 Python不是静态编译型语言，变量的类型实在运行期间决定的 动态语言很灵活，但是这种特性也是有弊端的举例： 1234567def add(x,y): return x + yprint(add(4,5))print(add('a','b'))print(add(4,'a')) # TypeError: unsupported operand type(s) for +: 'int' and 'str' 问题： 难发现：由于不做任何的类型检查，直至运行期问题才显现出来，或者线上运行时才能暴露出现的问题 难使用：函数的使用者看到函数类型时，并不知道你的函数的设计，所以也不知道应该传入什么类型的数据 弊端的解决途径文档注释 增加文档 Documentation String 这不是一个管理，不是强制标准，但是，建议程序员一定要为函数提供说明文档 但是 函数定义更新后，函数文档未必同步更新 12345678910def add(x,y): """ :param x: :param y: :return: """ return x + yprint(help(add)) 函数注解 Annotations如何解决这种动态语言定义的弊端呢？通常使用的就是函数注解 Annotations 123456789101112def add(x:int,y:int) -&gt;int: # 函数参数、函数返回值进行注解 """ :param x: :param y: :return: """ return x + yprint(help((add)))print('*'*40)print(dir(add)) Help on function add in module __main__: add(x: int, y: int) -&gt; int :param x: :param y: :return: None **************************************** [&apos;__annotations__&apos;, &apos;__call__&apos;, &apos;__class__&apos;, &apos;__closure__&apos;, &apos;__code__&apos;, &apos;__defaults__&apos;, &apos;__delattr__&apos;, &apos;__dict__&apos;, &apos;__dir__&apos;, &apos;__doc__&apos;, &apos;__eq__&apos;, &apos;__format__&apos;, &apos;__ge__&apos;, &apos;__get__&apos;, &apos;__getattribute__&apos;, &apos;__globals__&apos;, &apos;__gt__&apos;, &apos;__hash__&apos;, &apos;__init__&apos;, &apos;__init_subclass__&apos;, &apos;__kwdefaults__&apos;, &apos;__le__&apos;, &apos;__lt__&apos;, &apos;__module__&apos;, &apos;__name__&apos;, &apos;__ne__&apos;, &apos;__new__&apos;, &apos;__qualname__&apos;, &apos;__reduce__&apos;, &apos;__reduce_ex__&apos;, &apos;__repr__&apos;, &apos;__setattr__&apos;, &apos;__sizeof__&apos;, &apos;__str__&apos;, &apos;__subclasshook__&apos;] 函数注解的属性保留由以上代码可知，函数注解都是保存在函数annotations中，函数注解到底是怎么回事呢？ Python3,5引入函数注解功能 对函数的参数进行类型注解 对函数的返回值进行类型注解 只对函数参数做一个辅助的说明，并不对函数参数进行类型检查 可以提供给第三发工具，做代码分析，发现隐藏的bug 函数注解的信息，保存在annotations属性中 根据函数注解的形式，即可知道存储在字典中的 12345678def add(x:int,y:int) -&gt;int: """ :param x: :param y: :return: """print(add.__annotations__) {&apos;x&apos;: &lt;class &apos;int&apos;&gt;, &apos;y&apos;: &lt;class &apos;int&apos;&gt;, &apos;return&apos;: &lt;class &apos;int&apos;&gt;} 函数参数类型的检查应用函数参数类型检查思路： 函数参数的检查，一定是函数外部检查 函数应该作为参数，传入到检查函数中 [装饰器] 检查函数拿到函数传入的实际参数，与形参什么对比 annotations属性是一个字典，其中包含返回值类型是声明，假设要做位置参数的判断，就无法与字典的声明对应，使用inspect模块 inspect模块提供获取对象信息的函数，可以做到对 函数和类的的类型检测 inspect模块的参数检查功能在使用inspect模块检查参数时，首先要对函数签名、签名的参数、参数中的元素要有清晰的认知，要从架构上把控他们之间的管理 签名对象：签名： 包含函数信息，如函数名、函数参数类型、命名空间等常用属性例如：‘bind’，‘bind partial’，‘empty’，‘parameters’，‘replace’，‘return_annotation’ 参数对象：签名属性的参数：包含参数属性，有序字典OrderedDict例如：‘items’，‘keys’，‘values’ 元素对象：签名属性的参数中的元素：有序字典中的value的常用属性例如：‘annotation’，‘default’，‘empty’，‘kind’，‘name’，‘replace’如果元素没有注释或者没有default默认值时，该属性就为empty 元素对象属性为字典值的属性案例： 先查看位置参数的注释，必须通过字典中key的值得到注释类型 是字典值表现形式\&lt;\Parameter “x:int”&gt;，要进步通过查看他的\&lt;\Parameter “x:int”&gt;.annotation才能得到 class int整正的数据类型 在参数核验时，如isinstance(3,int) 中int 就是class int 只有这样才能对比，而\&lt;\Parameter “x:int”&gt;在正常情况下是无法使用的，必须通过annotation将其类型解放出来才能使用举例： 12345678910import inspectdef add(x:int,y:int=6,*args,**kwargs)-&gt;int: return x + ysig = inspect.signature(add)params = sig.parametersvalues = [ x for x in params.values() ]print(values)for i,v in enumerate(values): print(values[i].annotation) [&lt;Parameter &quot;x: int&quot;&gt;, &lt;Parameter &quot;y: int = 6&quot;&gt;, &lt;Parameter &quot;*args&quot;&gt;, &lt;Parameter &quot;**kwargs&quot;&gt;] &lt;class &apos;int&apos;&gt; &lt;class &apos;int&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; signature获取签名inspect.signature(callable),获取签名（函数签名中包含了一个函数信息，包括函数名、函数参数、函数所在的类和命名空间及其他信息）举例： 12345678910111213141516171819202122232425import inspectdef add(x:int,y:int=6,*args,**kwargs)-&gt;int: return x + ysig = inspect.signature(add)params = sig.parametersprint(sig)print(params)print(sig.return_annotation)print('-'*40)print(params['y'])print(params['y'].annotation)print(params['y'].default)print('='*40)print(params['x'])print(params['x'].annotation)print(params['x'].default)print('-'*40)print(params['args'])print(params['args'].annotation)print(params['args'].default)print('='*40)print(params['kwargs'])print(params['kwargs'].annotation)print(params['kwargs'].default) (x: int, y: int = 6, *args, **kwargs) -&gt; int OrderedDict([(&apos;x&apos;, &lt;Parameter &quot;x: int&quot;&gt;), (&apos;y&apos;, &lt;Parameter &quot;y: int = 6&quot;&gt;), (&apos;args&apos;, &lt;Parameter &quot;*args&quot;&gt;), (&apos;kwargs&apos;, &lt;Parameter &quot;**kwargs&quot;&gt;)]) &lt;class &apos;int&apos;&gt; ---------------------------------------- y: int = 6 &lt;class &apos;int&apos;&gt; 6 ======================================== x: int &lt;class &apos;int&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; ---------------------------------------- *args &lt;class &apos;inspect._empty&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; ======================================== **kwargs &lt;class &apos;inspect._empty&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; 对象的判断 inspect.isfunction(add) 是否是函数 inspect.ismethod(add) 是否是类的方法 inspect.isgenerator(add) 是否是生成器对象 inspect.isgenerafunction(add) 是否是生成器函数 inspect.isclass(add) 是否是类 inspect.ismodule(inspect) 是否是模块 inspect.isbuiltin(print) 是否是内建对象 parameter参数对象 保存在元组中，是只读属性 name，参数的名字 annotation，参数的注解，可以不定义 default，参数的缺省值，可以不定义 empty，特殊的类，用来标识default 或者注释annotation属性为空 kind，实参如何绑定到形参，就是形参的类型 @ POSITIONAL_ONLY 值必须由位置参数提供 @ POSITIONAL_KEYWORD 值可以作为关键字或者位置参数提供 @ VAR_POSITIONAL 可变位置参数，相当于 args @ KEYWORD_ONLY ,keyword-only参数，相当于 或者 args 后出现的非可变关键参数 @ VAR_KEYWORD, 可变关键参数，相当于 * kwargs 案例操作： 12345678910111213141516import inspectdef add(x, y:int=7, *args, z, t = 10, **kwargs)-&gt;int: return x + ysig = inspect.signature(add)params = sig.parametersprint(params)for i,v in enumerate(params.items()): # 通过迭代有序字典的方式获取value name,param = v print() print(i+1,name,param.annotation,param.kind,param.default) print(param.default,param.empty) print('*' * 50) OrderedDict([(&apos;x&apos;, &lt;Parameter &quot;x&quot;&gt;), (&apos;y&apos;, &lt;Parameter &quot;y: int = 7&quot;&gt;), (&apos;args&apos;, &lt;Parameter &quot;*args&quot;&gt;), (&apos;z&apos;, &lt;Parameter &quot;z&quot;&gt;), (&apos;t&apos;, &lt;Parameter &quot;t=10&quot;&gt;), (&apos;kwargs&apos;, &lt;Parameter &quot;**kwargs&quot;&gt;)]) 1 x &lt;class &apos;inspect._empty&apos;&gt; POSITIONAL_OR_KEYWORD &lt;class &apos;inspect._empty&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; ************************************************** 2 y &lt;class &apos;int&apos;&gt; POSITIONAL_OR_KEYWORD 7 7 &lt;class &apos;inspect._empty&apos;&gt; ************************************************** 3 args &lt;class &apos;inspect._empty&apos;&gt; VAR_POSITIONAL &lt;class &apos;inspect._empty&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; ************************************************** 4 z &lt;class &apos;inspect._empty&apos;&gt; KEYWORD_ONLY &lt;class &apos;inspect._empty&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; ************************************************** 5 t &lt;class &apos;inspect._empty&apos;&gt; KEYWORD_ONLY 10 10 &lt;class &apos;inspect._empty&apos;&gt; ************************************************** 6 kwargs &lt;class &apos;inspect._empty&apos;&gt; VAR_KEYWORD &lt;class &apos;inspect._empty&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; &lt;class &apos;inspect._empty&apos;&gt; ************************************************** 传参检查需求： 请检查用户输入参数是否符合参数注解的要求12def add(x,y:int=7)-&gt;: return x + y 解题思路：可以通过ordereddict.annotation获取参数的注解类型，再通过isinstance(值，类型)对比 解决方法： 12345678910111213141516171819202122232425import inspectdef check(fn): def wapper(*args,**kwargs): sig = inspect.signature(fn) params = sig.parameters value = list(params.values()) # 字典的values，为的是通过value.annotation 解放注释类型 print(values) for i ,p in enumerate(args): param = values[i] if param.annotation is not param.empty and isinstance(p,values[i].annotation): print('OK') for k,v in kwargs.items(): # 获取数据类型第二种手段，直接通过 dict[key].annotation 等价于 values.annotation if params[k].annotation is not params[k].empty and isinstance(v,params[k].annotation): print('OK') func = fn(*args,**kwargs) return func return wapper@check # add = check(add)def add(x,y:int=7)-&gt;int: return x + yprint(add(3,y=4)) [&lt;Parameter &quot;x: int&quot;&gt;, &lt;Parameter &quot;y: int = 6&quot;&gt;, &lt;Parameter &quot;*args&quot;&gt;, &lt;Parameter &quot;**kwargs&quot;&gt;] OK OK 7 总结：获取具体某参数的注释：方法1. 通过字典值获取参数类型123Values = list(inpect,signature.paramters)For v in Values: print(v.annotation) 方法2：通过字典key获取参数类型1print(dict[k].annotation)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python生成器]]></title>
    <url>%2F2019%2F01%2F18%2FPython%20%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Python生成器生成器generator 的定义生成器指的是生成器对象，可以有生成器表达式得到，也可以使用yield关键字得到一个生成器函数，调用这个函数就可以得到一个生成器对象 生成器函数 生成器函数就是函数体中包含yield语句的函数，返回生成器对象 生成器对象，就是一个可迭代对象，是一个迭代器 生成器对象，是延迟计算，惰性求值的例如： 12345678910111213def inc(): for i in range(5): yield iprint(type(inc))print(type(inc()))x = inc()print((type(x)))print(next(x))for m in x: print(m,'*')for m in x: print(m,'**') &lt;class &apos;function&apos;&gt; &lt;class &apos;generator&apos;&gt; &lt;class &apos;generator&apos;&gt; 0 1 * 2 * 3 * 4 * 1234y = (i for i in range(5))print(type(y))print(next(y))print(next(y)) &lt;class &apos;generator&apos;&gt; 0 1 普通的函数调用fn(),函数会立即执行完毕，但是生成器函数可以使用next函数多次执行 生成器函数等价于生成器表达式，只不过生成器函数可以更加的复杂举例 1234567891011121314def gen(): print('line 1') yield 1 print('line 2') yield 2 print('line 3') returnnext(gen()) # line 1 next(gen()) # line 1 g = gen()print(next(g)) # line 1print(next(g)) # line 2# print(next(g)) # StopIterationprint(next(g,'End')) # 如果生成器对象中没有元素，就给个缺省值 line 1 line 1 line 1 1 line 2 2 line 3 End 在生成器函数中，使用多个yield语句，执行一次后会暂停执行，把yield表达式的值返回 再次执行会执行到下一个yield语句 return语句依然可以终止函数执行，但return语句的返回值不能被获取到 return会导致无法获取到下一个值，抛出StopIteration异常 如果函数没有显示的return语句，如果生成器函数执行到结尾，一样会抛出StopIteration异常 生成器函数的执行步骤 包含yield语句的生成器函数生成 生成器对象 时，生成器函数的函数体不会立即被执行 next（generator）会从函数的当前位置向后执行到之后碰到的第一个yoeld语句，会弹出yield的返回值，并暂停函数的执行 再次调用next（）函数，会执行两个yield之间的语句 如果没有多余的yield语句可以被执行，继续调用next（）函数，就会抛出StopIteration异常 生成器的应用场景 无限循环 123456789101112def counter(): i = 0 while True: i += 1 yield idef inc(c): return next(c)c = counter()print(inc(c))print(inc(c)) 1 2 123456789101112def counter(): i = 0 while True: i += 1 yield idef inc(): c = counter() return next(c)print(inc())print(inc())print(inc()) 1 1 1 计数器 1234567891011121314def inc(): def counter(): i = 0 while True: i += 1 yield 1 c = counter() return lambda:next(c) # lambda表达式是一个匿名函数 # return返回的是一个匿名函数foo = inc()print(foo())print(foo()) 1 1 处理递归问题 1234567891011121314def fib(): x = 0 y = 1 while True: yield y x,y = y,x+y foo = fib()for _ in range(5): print(next(foo))for _ in range(10): next(foo)print(next(foo)) 1 1 2 3 5 987 协程coroutine 协程是生成器的高级用法 比进程、线程更加轻量级 是在用户空间调度函数的一种实现 Python3 的 asyncio 就是协程实现的，已经加入到标准库了 Python3.5 使用 async、await关键字直接原生支持协程 协程调度器的实现思路 有两个生成器A、B next(A)后，A执行到了yield语句后暂停，然后执行next(B),B执行到yield语句后也暂停，然后再次调用next(A),在调用next(B)，周而复始，就实现了调度器的效果了 协程是一种非抢占式的调度 yield from举例说明 1234567def inc(): for x in range(1000): yield xfoo = inc()print(next(foo))print(next(foo))print(next(foo)) 0 1 2 等价于下面的代码 1234567def inc(): yield from range(1000) foo = inc()print(next(foo))print(next(foo))print(next(foo)) 0 1 2 yield from 是Python 3.3 才出现的新语法 yield from iterable 是 for item in iterable:tield item 形式的语法糖 可从可迭代对象中一个个获取元素例如： 1234567891011def counter(n): # 生成器，迭代器 for x in range(n): yield xdef inc(n): yield from counter(n) foo = inc(10)print(next(foo))print(next(foo))print(next(foo)) 0 1 2]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数的执行过程、递归函数、匿名函数]]></title>
    <url>%2F2019%2F01%2F16%2F%E5%87%BD%E6%95%B0%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%E3%80%81%E9%80%92%E5%BD%92%E5%87%BD%E6%95%B0%E3%80%81%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[函数的执行过程、递归函数、匿名函数函数的执行过程举例： 123456789101112131415def foo1(b,b1=3): print("foo1 called",b,b1) def foo2(c): foo3(c) print("foo2 called",c) def foo3(d): print("foo3 called",d) print("main called") foo1(100,101) foo2(200)print("main ending") main called foo1 called 100 101 foo3 called 200 foo2 called 200 main ending 以上代码执行流程： 全局帧生成foo1、foo2、foo3函数对象 主函数调用 主函数查找内建print压栈，将常量字符串压栈，调用函数，弹出栈顶 主函数中全局查找函数foo1压栈、将常量100、101压栈，调用函数foo1，创建栈帧。print函数压栈，字符串和变量吧b、b1压栈，调用函数，弹出栈顶，返回值 主函数查找foo2函数压栈、将常量200压栈，调用foo2、创建栈帧。foo3函数压栈，变量c引用压栈，调用foo3，创建栈帧。foo3完成print函数调用，返回值。 主函数中foo2调用结束后弹出栈顶，主函数继续执行print函数调用，弹出栈顶。 主函数结束调用， 返回None 递归函数递归函数的含义 函数直接或间接调用自身就是递归 递归需要有边界条件、递归前进段、递归返回段 递归一定要有边界条件 当边界条件不满足时，递归前进 当边界条件满足时，递归返回 递归函数的性能 循环稍微复杂一些，但是只要不是死循环，可以多次迭代直至算出结果。 fib函数代码极简易懂，但是只能获取最外层的函数调用，内部递归结果都是中间结果，而且给定一个n值都要进行近2n次递归，深度越深，效率越低。 递归还有深度限制，如果递归复杂，函数反复压栈，栈内存很快就会溢出 递归函数的优化 解决递归调用栈溢出的方法就是通过尾递归优化，事实上尾递归和循环的效果是一样的，所以只要把循环看成是一种特殊的尾递归函数也是可以的 尾递归是指 在函数返回的时候，调用自身本身，并且，return语句不能包含表达式。 这样编译器或者解释器就可以把尾递归优化，使递归本身无论调用多少次，都只占一个栈帧，不会出现栈溢出的情况 递归函数的总结 递归是一种很自然的表达，符合逻辑思维 递归相对运行效率低，每一次调用函数都要开辟栈帧 递归有深度限制，如果递归层次太深，函数反复压栈，栈内存很快就溢出了 如果是有限次数的递归，可以使用递归调用，或者使用循环代替，循环代码稍微复杂一些，但是只要不是死循环，可以多次迭代直至算出结果 绝大多数递归，都可以使用循环实现 即使递归代码很简洁，但是能不用则不用递归 递归函数的使用案例1. 斐波那契数列解法1：重点内容是 f(n) = f(n-1) + f(n-2) 12345def f(n): return 1 if n &lt; 3 else f(n-1)+f(n-2)for i in range(1,11): print(f(i),end=' ') 1 1 2 3 5 8 13 21 34 55 解法2：利用函数体就是关系式，return就是返回结果进行计算 123456789def f(n,x=[1],y=[0]): if n &gt; 1: x[0],y[0] = x[0] + y[0] ,x[0] print(y[0],end=' ') else: return x[0] return f(n-1,x=[x[0]],y=[y[0]])f(10) 1 1 2 3 5 8 13 21 34 55 2.求n的阶乘 123456def f(n): if n == 1: return 1 return n * f(n-1)f(5) 120 求n的阶乘尾递归法 123456def f(n,num=1): if n == 1: return num num *= n return f(n-1,num)f(5) 120 匿名函数匿名函数就是没有名字的函数,但是，如果过函数没有名字,要如何定义？ 要如何调用？ 要如何使用？ Python借助lambda表达式构建匿名函数 格式： 1234567891011# **lambda 参数列表:表达式print( lambda x: x**2 )print( (lambda x:x**2)(4) )foo = lambda x,y:(x + y)**2print( '&#123;&#125; &#123;&#125;'.format('foo(2,1):',foo(2,1)) )def foo(x,y): # 相同的效果 return (x + y) ** 2print( '&#123;&#125; &#123;&#125;'.format('foo(2,1):',foo(2,1)) ) &lt;function &lt;lambda&gt; at 0x000001EBD826E6A8&gt; 16 foo(2,1): 9 foo(2,1): 9 匿名函数的定义 匿名函数使用 lambda关键字来定义 参数列表不需要小括号 冒号是用来分割参数列表和表达式 不需要使用return，表达式的值，就是匿名函数的返回值 lambda表达式（匿名函数）只能写在一行上面 ，被称为单行函数 匿名函数的用途在高阶函数传参时，使用lambda表达式，往往能简化代码 123456print((lambda :0)())print((lambda x,y=3:x+y)(5))print((lambda x,y=3:x+y)(5,6))print((lambda x,*,y=30:x+y)(5))print((lambda x,*,y=30:x+y)(5,y=10))print((lambda *args:(x for x in args))(*range(5))) 0 8 11 35 15 &lt;generator object &lt;lambda&gt;.&lt;locals&gt;.&lt;genexpr&gt; at 0x000001EBD82AB2A0&gt;]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数的执行过程、递归函数、匿名函数]]></title>
    <url>%2F2019%2F01%2F16%2F%E8%A3%85%E9%A5%B0%E5%99%A8%EF%BC%8C%20%E8%A3%85%E9%A5%B0%E5%99%A8%E5%8E%9F%E7%90%86%EF%BC%8C%20%E8%A3%85%E9%A5%B0%E5%99%A8%E7%9A%84%E5%A5%BD%E5%A4%84%EF%BC%8C%20%E8%A3%85%E9%A5%B0%E5%99%A8%E5%B8%A6%E6%9D%A5%E7%9A%84%E5%89%AF%E4%BD%9C%E7%94%A8%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%8C%20%E5%B8%A6%E5%8F%82%E8%A3%85%E9%A5%B0%E5%99%A8%E5%8F%8A%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[装饰器， 装饰器原理， 装饰器的好处， 装饰器带来的副作用及解决方法， 带参装饰器及应用装饰器 装饰器是可调用的对象， 其参数是另一个函数（被装饰的函数） 。 装饰器可能会处理被装饰的函数， 然后把它返回， 或者将其替换成另一个函数或可调用对象 它经常用于有切面需求的场景：如 插入日志、性能测试、事物处理、缓存、权限校验等等 装饰器的推导式1 需求 一个加法函数，想要增强它的功能，能够输出被调用过以及调用的参数信息 123456789def add(x,y): return x + y# 增加信息输出功能def add(x,y): print(x,y) return x + yadd(4,5) 上面的加法函数是完成了需求，但是有以下缺点 打印语句的耦合度太高，如果有100个函数需要同样的功能，则这100个函数都需要添加相同的代码 加法函数属于业务功能，而输出信息的功能，属于非业务功能代码，不该放在业务函数加法当中 为了做到业务功能分离，我们可以利用高阶函数进行将功能函数与业务函数进行分类 1234567891011121314151617181920def add(x,y): return x + y def logger(fn): print('Call function begin') # 增强的输出 ret = fn(10,5) print('Call function end') # 增强的功能 return retprint(logger(add)) # 此时将函数add作为logger的参数传入，标准的高阶函数，此时相当于 以下函数def logger(add): print('Call function begin') ret = add(10,5) print('Call function end') return retprint(logger(add)) 遗留问题以上功能函数也就是业务函数已经实现分离，但是问题在于参数的传入，此时函数的参数是在函数体内固定死了，但是现实中的函数参数是灵活的，不可能一成不变的，因此需要对参数进行选择性传入 装饰器的推导式2 自由参数传入 为了解决自由参数的传入 在嵌套函数中，外层函数的形参对于外层函数就是本质的形参，但是对于内层函数就是实参。因此外层函数传入实参时，经过外层 args, ** kwargs贪婪模式吸收，形成tuple和dict的形式，传递给内层函数，内层函数拿到就是tuple和dict，再经过实参出入时解构 args,** kwargs。最后就将外层函数传入的实参梯队传入内层函数。 123456789# 解决只有参数的传入，原本函数如下：def logger(fn): print('Call function begin') ret = fn(10,30) print('Call function end') return retdef add(x,y): return x + y 123456789101112# 为了解决只有参数的传入def logger(fn,*args,**kwargs): print('Call function begin ') func = fn(*args,**kwargs) print('Call function end') return funcdef add(x,y): return x + ylogger(add,5,6) Call function begin Call function end 11 装饰器的推导式3 柯里化 为了将fn(x,y)变形为fn(x)(y)语法糖格式的需求，将函数进行柯里化 为了将logger(add,4,5)变形为logger(add)(5,6) 用到了闭包的概念 依据柯里化变形三步骤 函数中第一个或某一个参数提升至外层函数，并对外层函数重命名 原本命名的函数参数抛出提升，其余的变形为新命名函数的函数体 新命名函数返回值为原本之前的函数 12345678910111213# 新函数的柯里化变形def logger(fn): def _logger(*args,**kwargs): print('Call function begin') ret = fn(*args,**kwargs) print('Call function end') return ret return _loggerdef add(x,y): return x + ylogger(add)(4,5) Call function begin Call function end 9 装饰器的推导式4 语法糖 上述变形已经实现柯里化调用，但是每次需要通过增强功能函数调用 为了解决通过功能函数调用业务函数的问题，直接采用语法糖，抛弃功能函数调用业务函数，直接采用功能函数调用，这会产生对外功能函数没发生什么变化的错觉，但是功能却已经增强了 123456789101112131415def logger(fn): def _logger(*args,**kwargs): print('Call function begin') ret = fn(*args,**kwargs) print('Call function end') return ret return _logger@logger # add = logger(add) # 通过语法糖实现增强功能def add(x,y): return x + y# 语法糖 @logger === &gt; add == logger(add),因此此时add == _loggeradd(4,5) Call function begin Call function end 9 为什么要进行柯里化柯里化就是为了配合语法糖，语法糖相当于将语法糖下面的函数作为实参传递给语法糖函数原函数去哪里了 12345@logger # add = logger(add) # 通过语法糖实现增强功能def add(x,y): return x + y# 语法糖 @logger === &gt; add == logger(add),因此此时add == _logger# add(*args,**kwargs) == _logger(*args,**kwargs) 既然add已经不再是原来的 add 函数，那么增强功能函数要怎么调用 x+y 呢，此时就要用到了闭包的作用了 首先： 将函数add作为实参传递给语法糖函数，这是语法糖函数就产生了闭包，内存函数fn就已经记录下add函数了 其次： 将语法糖返回的函数覆盖现有的add函数 最后： add函数就等价于 _logger函数了， 可以通过调用 _ name 或者 _ doc _ 属性进行验证 装饰器的分类无参装饰器根据如上推导公式即可得到无参装饰器 12345678910111213def logger(fn): def _logger(*args,**kwargs): print('Call function begin') ret = fn(*args,**kwargs) print('Call function end') return ret return _logger@logger # add = logger(add)def add(x,y): return x + yadd(4,5) Call function begin Call function end 9 带参装饰器 带参装饰器它是一个函数 函数作为它的参数 返回值是一个不带参的装饰器函数 可以看做是在装饰器外层又加上一层函数，三层嵌套函数 带参装饰器的参数可以有多个，使用闭包功能进行传参 使用 @functionname(参数列表)的方式调用，等价于add = logger(参数列表)(add) 格式如下： 1234567891011121314151617181920import datetimedef logger(duration): def _logger(fn): def wapper(*args,**kwargs): print('Call logger begin') start = datetime.datetime.now() ret = fn(*args,**kwargs) delta = (datetime.datetime.now()-start).total_seconds() print('Call logger end') print('so slow') if duration &lt; delta else print('so fast') return ret return wapper return _logger@logger(5) # add = logger(5)(add)def add(x,y): return x + yadd(4,5) Call logger begin Call logger end so fast 9 返回值为装饰函数 根据带参装饰器和不带参装饰器可知，经过装饰后的函数已经不再是原本的函数了，如以上的add函数已经变成_logger函数，因此想要知道函数的具体内容只能通过查看函数的 add 属性和 doc 属性可知，原本的函数已经被装饰器属性覆盖了，是因为功能函数已经传递给装饰器函数了，但是属性尚未传递 解决思路; 可以通过传递功能函数的同时，传递属性，此时外界看来一切都没有变化，只是简单的装饰过而已，无法看到装饰器内部复杂的变化 解决方法1：在装饰器中，手动将装饰器得到的属性修改为要装饰的属性 12wrapper.__name__ = wrapped.__name__wrapper.__doc__ = wrapped.__doc__ 在装饰器中，调用修改属性函数，外界定义修改属性函数 123def property(wapped,wapper): wrapper.__name__ = wrapped.__name__ wrapper.__doc__ = wrapped.__doc__ 通过装饰器进行修改属性，但是装饰器返回的不是另一个函数，返回的就是自己，由修改属性函数柯里化，返回装饰器函数即可 123456def propety(wapped): def _propety(wapper): wrapper.__name__ = wrapped.__name__ wrapper.__doc__ = wrapped.__doc__ return wapper # 内层函数返回的一定是要返回 参数传入的装饰器函数 return propety 举例： 1234567891011121314151617181920212223242526272829303132333435363738394041import datetimeimport timedef propety(src): def _propety(dest): print(dest.__name__,) dest.__name__ = src.__name__ dest.__doc__ = src.__doc__ return dest return _propetydef logger(fn): @propety(fn) # _logger = prorety(fn)(_logger) def _logger(*args,**kwargs): print('Call logger begin') start = datetime.datetime.now() ret = fn(*args,**kwargs) delta = (datetime.datetime.now() - start).total_seconds() print(delta) print('Call logger end') return ret return _logger@logger # add = logget(add)def add(x,y): """This is add function""" time.sleep(1) return x + yprint('&#123;&#125; &#123;&#125; &#123;&#125;'.format(add(4,5),add.__name__,add.__doc__)) _logger Call logger begin 1.000784 Call logger end 9 add This is add function 装饰器的副作用有上述的案例可知，要被装饰的函数在给装饰器通过闭包传递功能时，尚未把属性传递，使得我们看到的add函数属性是_logger的属性，而不是add的属性。 解决方式1：函数思路解决问题，定义一个拷贝函数属性的函数使用函数就是调用此函数，并给函数传参，wapper表示装饰器函数，wapped表示被装饰函数，只要传入这两个参数即可 12345678910111213141516171819202122232425import datetimeimport timeimport functoolsdef logger(fn): def _logger(*args,**kwargs): """This is _logger function""" print('Call _logger begin') start = datetime.datetime.now() ret = fn(*args,**kwargs) delta = (datetime.datetime.now() - start).total_seconds() print('Call _logger end') print(delta) functools.update_wrapper(_logger,fn) # 此时调用函数属性变更函数 return ret return _logger@logger # add = logger(add)def add(x,y): """This is add function""" print('#####################') time.sleep(2) return x + yprint(' return: &#123;&#125;\n name: &#123;&#125;\n doc: &#123;&#125;'.format(add(4,5),add.__name__,add.__doc__)) Call _logger begin ##################### Call _logger end 2.000202 return: 9 name: add doc: This is add function 装饰器案例1234567891011121314151617181920212223import datetimeimport timeimport functoolsdef looger(fn): @functools.wraps(fn) # _logger = functools.wraps)(fn)(_logger) #调用装饰器进行函数属性变更 def _loogger(*args,**kwargs): """This is _logger function""" print('Call function begin') start = datetime.datetime.now() ret = fn(*args,**kwargs) delta = (datetime.datetime.now() - start).total_seconds() print(delta) return ret return _logger @logger # add = logger(add)def add(x,y): """This is add function""" time.sleep(1) return x + yprint('return:&#123;&#125; \n name:&#123;&#125; \n doc:&#123;&#125;'.format(add(4,5),add.__name__,add.__doc__)) Call _logger begin Call _logger end 1.000573 return:9 name:add doc:This is add function]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python函数、参数、可变参数、keyword-only]]></title>
    <url>%2F2019%2F01%2F15%2FPython%E5%87%BD%E6%95%B0%E3%80%81%E5%8F%82%E6%95%B0%E3%80%81%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0%E3%80%81keyword-only%2F</url>
    <content type="text"><![CDATA[Python函数、参数、可变参数、keyword-only函数 数学定义：y = f(x),y是x的函数，x是自变量。y = f（x0,x1,…,xN） Python函数： 函数是由若干语句组成的语句块、由函数名称、参数列表构成，它是组织代码的最小单元 可以完成特定的功能 函数的作用 结构化编程对代码的最基本的封装，按照功能组织一段代码 封装的目的是为了代码的复用，减少冗余代码 使代码更加简洁美观、且易读性更强 函数的分类 内建函数； 如 max(）、len(）等 库函数：如 math.ceil() 等 函数的定义使用def关键字 定义函数123def 函数名（参数列表）: 函数体（代码块） [return 返回值] 函数名就是标识符，命名要求一样 语句块必须缩进，约定4个空格 Python的函数没有return语句，函数会隐式的返回一个None值 定义中的参数列表会成为形式参数，它只是符号表达，简称形参 函数的调用 函数的定义，只是声明了一个函数，但是它不会自动执行，需要被调用才能执行 调用的方式，就是函数名加上小括号，括号内写上参数 调用时写的参数就是实际参数，是实实在在传入的值，简称实参 函数的举例123456def add(x,y): result = x+y return resultout = add(4,5)print(out) 上面只是一个函数的定义，有一个函数叫做add，接收2个参数 计算的结果，通过返回值返回 通过调用函数名add加上2个参数，返回值可使用变量接收 定义需求在调用前，也就是说调用时，已经被定义过，否则抛出NameError异常 函数是可调用的对象，callable（） 参数 函数形参的作用是实现主调函数与被调函数之间的联系，通常将函数所处理的数据，影响函数功能的因素或者函数处理的结果作为形参 参数调用时传入的参数要和定义的个数相匹配（可变参数除外） 位置参数 按照参数定义的顺序传入的参数就是位置参数如： 123def f(x,y,z): passf(1,2,3) # 1,2,3 按照位置参数的定义赋值给 x,y,z 关键字参数 使用形参的名字传入函数中，如果使用的使用形参的名字，那么传参的顺序就和定义的顺序不一样了如： 123def f(x,y,z): passf(x=1,y=2,y=3) # 按照关键字参数的定义，直接使用形参的名字进行赋值 传参案例123f(z=None, y=10, x=[1])f((1,), z=6, y=4.1)f(y=5, z=6, 1) # SyntaxError: positional argument follows keyword argument File &quot;&lt;ipython-input-3-27c4e4027067&gt;&quot;, line 3 f(y=5, z=6, 1) # ^ SyntaxError: positional argument follows keyword argument 总结： 位置参数必须在关键字参数之前传入，位置参数按照位置对应 参数默认值（缺省值） 定义形参时，可以在形参后跟上一个值如： 123456789101112def add(x=4,y=5): return x + yadd(4,5)add(x=4,y=5)add(y=4,x=5)add(4,y=5)# add(4,x=5) # got multiple values for argument 'x'add(x=5)add(y=4)add()# add(x=4,5) # positional argument follows keyword argument# add(y=4,5) # positional argument follows keyword argument 9 总结： 参数的默认值可以在未传入足够的实参时候，对没有给定的参数赋值为默认值 参数非常多的时候，并不需要用户每次都输入所有的参数，简化函数调用 位置参数必须在关键字参数之前 不能给同一个参数赋多个值 函数默认参数案例： 1234def login(host='127.0.0.1',port='8080',username='lpx',password='123456'): print('host:&#123;&#125;\nport:&#123;&#125;\nusername:&#123;&#125;\npassword:&#123;&#125;'.format(host,port,username,password)) login() host:127.0.0.1 port:8080 username:lpx password:123456 可变参数位置可变参数无可变参数出现的问题：如果实参有100个，实现这一百个数的求和 123456789def f(nums): sumnum = 0 for i in nums: sumnum += i return sumnumlst = [x for x in range(1,101)]print(f(lst))print(f(1,2,3)) 5050 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-18-c97b6b4b48cc&gt; in &lt;module&gt; 7 lst = [x for x in range(1,101)] 8 print(f(lst)) ----&gt; 9 print(f(1,2,3)) TypeError: f() takes 1 positional argument but 3 were given 说明默认一个位置形参只能接收一个实参，所以list接收了，f(1,2,3)无法接收，报错为给定参数过得多，导致连函数体都无法进入 可变参数： 12345678def add(*nums): sum = 0 print(type(nums)) for x in nums: sum += x print(sum)add(3, 6, 9) # 将多个参数封装成元组传入 &lt;class &apos;tuple&apos;&gt; 18 总结： 一个形参可以匹配多个实参 只需在形参前使用 *表示该形参为可变参数，可接收多个实参 本质上是将收集到的多个实参放在一个tuple中 可变关键字参数 在形参前使用 ** ，表示可以接收多个关键字实参 收集到的关键字实参的名称和值组成一个字典案例： 123456def showconfig(**kwargs): print('type:&#123;&#125; **kwargs:&#123;&#125;'.format( type(kwargs),kwargs )) for k,v in kwargs.items(): print(k,v) showconfig(host='127.0.0.1',port='8080',username='lpx',password='123456') type:&lt;class &apos;dict&apos;&gt; **kwargs:{&apos;host&apos;: &apos;127.0.0.1&apos;, &apos;port&apos;: &apos;8080&apos;, &apos;username&apos;: &apos;lpx&apos;, &apos;password&apos;: &apos;123456&apos;} host 127.0.0.1 port 8080 username lpx password 123456 可变参数总结 可变参数分为可变位置参数和可变关键字参数 位置可变参数在形参前使用一个星号 * 关键字可变位置参数在形参前使用两个星号 ** 位置可变参数和关键字可变参数都可以收集多个实参 位置可变参数收集到的实参形成一个tuple，关键字可变位置参数收集到的实参形成一个dict 在混合使用参数时，普通参数放在参数列表前面，关键字可变参数放在列表后面，位置可变参数行中间 keyword-only参数1234def fn(*,x): print(x)fn(x=4) 4 keyword-only参数在Python3加入 如果在一个星号参数后，或者一个位置可变参数后，出现的普通参数，实际上已经不是普通参数了，而是keyword-only参数 从语法上卡args可以看做已经截获了所有的位置参数，x不使用关键字参数就不可能拿到实参 keyword-only参数必须给赋值，若不赋值则报错 案例演示： 123456def fn(*args,x,y): print(x) print(args) fn(3,5) # TypeError: fn() missing 1 required keyword-only argument: 'x'fn(3,5,x=7,y=10) # 正确的写法 7 (3, 5) 由以上注释代码可知： args可以看做是截获了所有的位置参数，x不使用关键词传参就拿不到实参，如果x拿不到实参就会报错 keyword-only默认值 不管什么类型的位置参数，只要有默认值都会保存在函数的 defaults 属性中 1234567def fn(*args,x=1,y=2): print(args) print(x,y)fn()fn(1,2,x=3,y=4)fn.__defaults__ () 1 2 (1, 2) 3 4 能否定义fn(*kwargs,x)?根据传参方式 * kwargs 通过关键字传参，x也得通过关键字传参，x的关键词传参有可能会被关键字可变参数吸收，所以关键字可变参数不能定义在keyword-only前如： 123456# def fn(**kwargs,x): # invalid syntax 错误def fn(x,**kwargs): print(x) print(kwargs) fn(x=2,y=5,z=1) 2 {&apos;y&apos;: 5, &apos;z&apos;: 1} 函数参数定义规范 函数参数列表的一般顺序为：普通位置参数、默认（缺省值）参数、可变位置参数、keyword-only（可带缺省值）参数、可变关键字参数 代码应该简单易懂，而不是为了为难被人，尤其是在项目中不要给自己和他人挖坑，要做到复杂问题简单化 书写函数参数时，应该按照标准规范定义函数参数如： 1234def fn(x,y,z=3,*args,m=4,n,**kwargs): print(x,y,z,m,n) print(args) print(kwargs) 函数传参方式位置参数传参 def f(x,y,z) 调用使用f(1,3,5) 按照参数定义顺序传入实参 关键字参数传参 def f(x,y,z) 调用使用f(x=1,y=3,z=5) 使用形参的名字来传入实参，如果使用形参名字，那么传参的顺序就可和定义的顺序不同了 参数解构 给函数提供实参的时候，可以在集合类型前使用 * 或者 ** ，把集合类型的结构解开，提取里面的元素作为函数的实参 非字典类型使用 * 解构成位置参数 字典类型使用 ** 解构成关键字参数 提取出来的元素数目要和参数的要求匹配，也要和参数的类型匹配如： 123456def add(x,y): return x+yprint(add(*(4,5)))print(add(*[4,5]))print(add(*&#123;4,5&#125;))print(add(**&#123;'x':4,'y':5&#125;)) 9 9 9 9 传参总结函数传参的方式有两种 通过位置参数传参 通过关键字参数传参 通常位置参数在前，关键字参数在后，若采用关键字参数时，顺序可以迭代，但是位置参数传入时，顺序不能打乱]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python函数返回值、作用域、自由变量和闭包、默认值的作用域、函数销毁]]></title>
    <url>%2F2019%2F01%2F15%2FPython%E5%87%BD%E6%95%B0%E8%BF%94%E5%9B%9E%E5%80%BC%E3%80%81%E4%BD%9C%E7%94%A8%E5%9F%9F%E3%80%81%E8%87%AA%E7%94%B1%E5%8F%98%E9%87%8F%E5%92%8C%E9%97%AD%E5%8C%85%E3%80%81%E9%BB%98%E8%AE%A4%E5%80%BC%E7%9A%84%E4%BD%9C%E7%94%A8%E5%9F%9F%E3%80%81%E5%87%BD%E6%95%B0%E9%94%80%E6%AF%81%2F</url>
    <content type="text"><![CDATA[Python函数返回值、作用域、自由变量和闭包、默认值的作用域、函数销毁函数返回值举例： 123456789101112131415161718192021222324252627282930313233343536def f1(x): print(x) return x + 1def f2(x): print(x) return x + 1 print(x + 1) def f3(x): if x &gt; 3: return print('&gt; 3') else: return print('&lt; 3')def f4(x): print(x) return x + 1 return x + 2def f5(x): for i in range(x): if i &gt; 3: return print(i) else: print('&#123;&#125; is not greater than 3'.format(x))def f6(x):# return x +=1 pass f1(5)f2(5)f3(5)f4(5)f5(5) 5 5 &gt; 3 5 4 总结： Python函数使用return语句返回‘返回值’ 所有函数多有返回值，如果没有return语句，就会隐式调用return None return 语句并不一定是函数的语句块的最后一条语句 一个函数可以存在多个return语句，但是最终只有一条可以被执行。如果没有一条return语句被执行，就会隐式调用 return None 如果有必要，可以显示调用 return None，也可以简写为 return 函数的返回值必须为一个对象，这个对象可以是数字，字符串、列表、元组、字典、函数等等，但是不能返回一个表达式 如果函数执行了return语句，函数就会返回，当前被执行的return语句之后的其他语句就不会被执行 函数返回值的作用： 结束函数调用、返回值 函数对象当我们定义一个函数时，函数对象就像数学中的函数一样，具有其自身的属性举例： 12345def foo(a): x = 3 return x + aprint(foo)print(dir(foo)) &lt;function foo at 0x00000136ECAB6D90&gt; [&apos;__annotations__&apos;, &apos;__call__&apos;, &apos;__class__&apos;, &apos;__closure__&apos;, &apos;__code__&apos;, &apos;__defaults__&apos;, &apos;__delattr__&apos;, &apos;__dict__&apos;, &apos;__dir__&apos;, &apos;__doc__&apos;, &apos;__eq__&apos;, &apos;__format__&apos;, &apos;__ge__&apos;, &apos;__get__&apos;, &apos;__getattribute__&apos;, &apos;__globals__&apos;, &apos;__gt__&apos;, &apos;__hash__&apos;, &apos;__init__&apos;, &apos;__init_subclass__&apos;, &apos;__kwdefaults__&apos;, &apos;__le__&apos;, &apos;__lt__&apos;, &apos;__module__&apos;, &apos;__name__&apos;, &apos;__ne__&apos;, &apos;__new__&apos;, &apos;__qualname__&apos;, &apos;__reduce__&apos;, &apos;__reduce_ex__&apos;, &apos;__repr__&apos;, &apos;__setattr__&apos;, &apos;__sizeof__&apos;, &apos;__str__&apos;, &apos;__subclasshook__&apos;] 函数属性简单概括： code 代码 有函数就有函数体，函数体也是函数的一个属性 default 位置参数的默认值 kwdefault 关键字参数的默认值 name 函数自身的名字 call 函数是否可以被调用 函数作用域函数嵌套 在一个函数中定义另一个函数 1234567def outer(): def inner(): print('inner') print('outer') inner()outer()# inner() outer inner 函数有可见的范围，这就是作用域的概念 内部函数不能直接在外部使用，这会抛出NameError异常，因为它不可见 作用域 一个标识符的可见范围，就是这个标识符的作用域。一般就是常说的变量的作用域 举例 12345678910x = 5def f1(): print(x) # x 是全局变量，子函数没有定义 x 这里就直接调用全局变量的 xdef f2(): x = x + 1 # int' object is not callable 等号左边的x 是重新定义，但是等号右边的x没有却没有定义，导致此处报错 print(x) f1()f2() 5 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-4-e6a3b9a7c9f5&gt; in &lt;module&gt; 8 9 f1() ---&gt; 10 2() 11 TypeError: &apos;int&apos; object is not callable 全局作用域 在整个程序的运行环境中都是可见的 局部作用域 在函数、类的内部可见的 局部变量的使用范围不能超过其所在的局部作用域举例： 1234567891011121314151617181920def outer1(): o = 65 def inner(): print('inner:&#123;&#125;,chr:&#123;&#125;'.format(o,chr(o))) print('outer1:&#123;&#125;,chr:&#123;&#125;'.format(o,chr(o))) inner()def outer2(): o = 65 def inner(): o = 97 print('inner:&#123;&#125;,chr:&#123;&#125;'.format(o,chr(o))) print('outer2:&#123;&#125;,chr:&#123;&#125;'.format(o,chr(o))) inner() outer1()print('*'*20)outer2() outer1:65,chr:A inner:65,chr:A ******************** outer2:65,chr:A inner:97,chr:a 从嵌套结构的例子看来： 外层变量的作用域可以向内层函数渗透 内层函数如果定义了一个变量名与外层函数相同的变量，外层函数的变量就不会传入内层举例： 123456x = 5def fn(): y = x + 1 x += 1 # 等号左边的 x 是赋值即定义 ，等号右边的 x 却不是上层函数的x，右边的 x 和左边的 x 同一个 x 但是右边的 x 没有定义导致报错 print(x)fn() 5 想要解决上面出现的问题，有两种解决方法 在函数前声明这个变量如： 1234567x = 5def fn(): x = 0 y = x + 1 x += 1 # 等号左边的 x 是赋值即定义 ，等号右边的 x 却不是上层函数的x，右边的 x 和左边的 x 同一个 x 但是右边的 x 没有定义导致报错 print(x)fn() 1 使用 global 关键字的变量，将函数内的x声明为使用外部的全局变量 x 1234567x = 5def fn(): global x y = x + 1 x += 1 # 等号左边的 x 是赋值即定义 ，等号右边的 x 却不是上层函数的x，右边的 x 和左边的 x 同一个 x 但是右边的 x 没有定义导致报错 print(x)fn() 6 global总结： x += 1 这种特殊形式产生的错误原因，先引用，后赋值，而Python动态语言是赋值才算定义，才能被引用 解决方法：在这条语句前声明增加 x = 0 之类的赋值语句，或直接使用 global告诉内部作用域 去全局作用域找这个变量 内部作用域使用x = 5之类的赋值语句会重新定义局部作用域使用的变量x，但是，一旦这个作用域中使用global声明x为全局的，那么x=5相当于在为全局作用域的变量x赋值 global是使用原则： 外部作用域变量会内部作用域可见，但也不要在这个内部的局部作用域中直接使用，因为函数的目的就是为了封装，尽量与外界隔离 如果函数需要使用外部全局变量，请使用函数的形参传参解决 一句话： 不用global。学习它就是为了深入理解变量作用域 闭包自由变量： 未在本地作用域中定义的变量。例如嵌套函数中定义在内层函数外的外层函数中的变量 闭包： 只是一个概念，出现在嵌套函数中，指的是内层函数引用到外层函数的自由变量，就形成闭包举例： 1234567891011def counter(): c = [0] def inc(): c[0] +=1 return c[0] return incfn = counter()print(fn(),fn())c = 100print(fn()) 1 2 3 意是在嵌套函数中，内层函数的变量引用了外层函数的自由变量才叫闭包，所有说如果引用了全局变量，这不叫闭包。 闭包的作用，如经常用在棋子的走位，走下一步时，要记住上一步在什么位置，所以此时记录位置最好就不能定义在全局变量之中。 nonlocal 关键字 使用了nonlocal关键字，将变量标记为不在本地作用域定义，而在上级的某一级局部作用域中定义。 只能存在于嵌套函数的内层函数中，不能存在于普通函数，否则会报错 123456789def counter(): count = 0 def inc(): nonlocal count count += 1 return count return incfn = counter()fn(),fn() (1, 2) count 是外层函数的局部变量，被内层函数引用 内部函数使用nonlocal关键字声明count变量在上级作用域而非本地作用域中定义 默认值的作用域默认值及变量保存的位置举例： 12345678def foo(x=1,y=2,*args,z=3,**kwargs): print(x,y,z) print(foo.__defaults__) print(foo.__kwdefaults__) print(foo.__code__.co_consts) print(foo.__code__.co_varnames)foo() 1 2 3 (1, 2) {&apos;z&apos;: 3} (None,) (&apos;x&apos;, &apos;y&apos;, &apos;z&apos;, &apos;args&apos;, &apos;kwargs&apos;) 属性defaults中使用元组保存所有的位置参数默认值 属性kwdefaults中使用字典保存所有的位置参数默认值 属性code.co_varnames 中使用元组保存参数列表中的默认形参 默认值的作用域仅在本地有效，说明它是本地变量 使用可变类型作为默认值，因为是元组或者字典，就可能修改这个默认值 按需求定义默认值类型 影子拷贝默认值： 123456789101112def foo(xyz=[],u='abc',z=123): xyz = xyz[:] # 影子拷贝 xyz.append(1) print(xyz)foo()print(foo.__defaults__)foo()print(foo.__defaults__)foo([10])print(foo.__defaults__)foo([10,5])print(foo.__defaults__) [1] ([], &apos;abc&apos;, 123) [1] ([], &apos;abc&apos;, 123) [10, 1] ([], &apos;abc&apos;, 123) [10, 5, 1] ([], &apos;abc&apos;, 123) 采用影子拷贝创建一个新的对象，永远不能改变传入的参数 使用不可变类型创建list 12345678910111213def foo(xyz=None,u='abc',z=123): if xyz is None: xyz = [] xyz.append(1) print(xyz)foo()print(foo.__defaults__)foo()print(foo.__defaults__)foo([10])print(foo.__defaults__)foo([10,5])print(foo.__defaults__) [1] (None, &apos;abc&apos;, 123) [1] (None, &apos;abc&apos;, 123) [10, 1] (None, &apos;abc&apos;, 123) [10, 5, 1] (None, &apos;abc&apos;, 123) 通过值的判断就可以灵活的选择创建或修改传入的对象很多函数的定义，都可以看到None这个不可变的值作为默认参数 变量名解析原则LEGB Local，本地作用域、局部作用域的local命名空间。函数调用时创建，调用结束消亡 Enclosing， Python2.2时引入了嵌套函数，实现了闭包，这个就是嵌套函数的外部函数的命名空间 Global，全局作用域，即一个模块的命名空间。模块被import时创建，解释器退出时消亡 Build-in，内置模块的命名空间，生命周期从python解释器启动时创建到解释器退出时消亡。例如 print(open)， print和open都是内置的变量 所以一个变量名的查找顺序就是LEGB 销毁函数全局函数销毁12345678910def foo(xyz=[],u='abc',z=123): xyz.append(1) return xyzprint(foo(),id(foo),foo.__defaults__)def foo(xyz=[],u='abc',z=123): xyz.append(1) return xyzprint(foo(),id(foo),foo.__defaults__)del foo# print(foo(),id(foo),foo.__defaults__) # NameError: name 'foo' is not defined [1] 2637469441832 ([1], &apos;abc&apos;, 123) [1] 2637472253336 ([1], &apos;abc&apos;, 123) 全局函数的销毁函数 重新定义同名函数 del语句删除函数对象 程序结束 局部函数12345678910111213def foo(xyz=[],u='abc',z=123): xyz.append(1) def inner(a=10): pass print(inner) def inner(a=100): print(xyz) print(inner) return innerbar = foo()print(id(foo),id(bar),foo.__defaults__,bar.__defaults__)del bar# print(id(foo),id(bar),foo.__defaults__,bar.__defaults__) # NameError: name 'bar' is not defined &lt;function foo.&lt;locals&gt;.inner at 0x00000266159ED7B8&gt; &lt;function foo.&lt;locals&gt;.inner at 0x00000266159ED268&gt; 2637472650920 2637472649832 ([1], &apos;abc&apos;, 123) (100,) 局部函数的销毁函数 重新在上级作用域定义同名函数 del语句删除函数名称，函数对象的引用计数减1 上级作用域销毁时]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python之列表解析式、生成器、迭代器及可迭代对象]]></title>
    <url>%2F2019%2F01%2F10%2FPython%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F%E3%80%81%E7%94%9F%E6%88%90%E5%99%A8%E3%80%81%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%8F%8A%E5%8F%AF%E8%BF%AD%E4%BB%A3%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[Python之列表解析式、生成器、迭代器及可迭代对象语法糖语法糖(Syntactic sugar),是由Peter J. Landin(和图灵一样的天才人物，是他最先发现了Lambda演算，由此而创立了函数式编程)创造的一个词语，它意指那些没有给计算机语言添加新功能，而只是对人类来说更“甜蜜”的语法。语法糖往往给程序员提供了更实用的编码方式，有益于更好的编码风格，更易读。 在python语言中语法糖有三元表达式、列表生成式、列表生成器、迭代器等等 解析式通用语法为构造一个列表、集合或者字典，python提供了称谓”显式”的特殊语法，每种语法都有两种形式 1. 容器内容被明确列出（即普通常用的列表） 2. 它们通过一组循环和过滤指令来计算，称为生成式 语法格式如下： 1234comprehension ::= expression comp_forcomp_for ::= “for” target_list “in” or_test [comp_iter]comp_iter ::= comp_for | comp_ifcomp_if ::= “if” expression_nocond [comp_iter] File &quot;&lt;ipython-input-1-4d3e3e21b01e&gt;&quot;, line 1 comprehension ::= expression comp_for ^ SyntaxError: invalid syntax 生成式是由单个表达式后紧跟至少一个for语句和多个或0个if语句 列表解析式列表定义: 列表显示可能是方括号中包含的一系列空表达式 list_display ::= [ [starred_list | comprehension] ] 生成式基础语法格式: [expr for iter_var in iterable] 即 [返回值 for 元素 in 可迭代对象] 工作过程： - 迭代iterable中的每个元素； - 每次迭代都先把结构赋值给iter_var，然后通过exp得到一个新的返回值； - 最后将返回值形成一个新的列表。 代码示范： 12lst = [ x**2 for x in range(1,6)] # 保存5以内的阶乘print(lst) 条件语法格式[expr for item in iterable if cond1 if cond2] 工作过程： 迭代iterable中的每一个元素，然后对每个元素进行if条件判断，当有多个if时，if条件相当于if cond1 and if cond 2 将迭代的结果复制给item，然后通过expr表达式计算出返回值 将返回值形成新的列表 代码示范： 12lst = [x for x in range(1,20) if x &gt;=10 if x %2==0] # 求 10到20间的偶数print(lst) # [10, 12, 14, 16, 18] [10, 12, 14, 16, 18] 嵌套循环语法[expr for i in iterable1 for j in iterable2 ] 工作过程： 迭代iterable1中的第一个元素后，进入下一轮for循环迭代iterable2中的每一元素，interable2循环完成后，再次进入iterable1中的第二个元素，以此类推。 把迭代结果赋值给iter_var，荣光expr得到返回值 最后将返回值形成新的对象list 代码示范： 12lst = [ &#123;x,y&#125; for x in 'abc' for y in range(2) ] print(lst) # [&#123;0, 'a'&#125;, &#123;1, 'a'&#125;, &#123;0, 'b'&#125;, &#123;1, 'b'&#125;, &#123;0, 'c'&#125;, &#123;1, 'c'&#125;] [{0, &apos;a&apos;}, {&apos;a&apos;, 1}, {&apos;b&apos;, 0}, {&apos;b&apos;, 1}, {0, &apos;c&apos;}, {1, &apos;c&apos;}] 列表生成式经典习题 求10以内的阶乘 12lst = [ x**2 for x in range(1,11)]print(lst) [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 有一个列表lst = [1,4,9,16,2,5,10,15] 生成新列表，要求新列表元素是lst相邻2项的和 123lst = [1,4,9,16,2,5,10,15]nums = [ lst[i-1] + lst[i] for i in range(1,len(lst)) ]print(nums) [5, 13, 25, 18, 7, 15, 25] 打印九九乘法表 考点 严格按照工作过程和列表解析式的定义，套用至少一个for循环或多个for循环 for循环必须是连续在一起的，for循环不能分开 123lst = [ print('&#123;&#125;*&#123;&#125;=&#123;&#125;'.format(j,i,j*i),end = '\n' if j == i else '\t' ) for i in range(1,10) for j in range(1,i+1) ] 1*1=1 1*2=2 2*2=4 1*3=3 2*3=6 3*3=9 1*4=4 2*4=8 3*4=12 4*4=16 1*5=5 2*5=10 3*5=15 4*5=20 5*5=25 1*6=6 2*6=12 3*6=18 4*6=24 5*6=30 6*6=36 1*7=7 2*7=14 3*7=21 4*7=28 5*7=35 6*7=42 7*7=49 1*8=8 2*8=16 3*8=24 4*8=32 5*8=40 6*8=48 7*8=56 8*8=64 1*9=9 2*9=18 3*9=27 4*9=36 5*9=45 6*9=54 7*9=63 8*9=72 9*9=81 “0001.abadicddws”是ID格式要求ID格式是以点号分割，左边是4为从1开始的整数，右边是10位随机小写英文字母，请依次生成前100个ID的列表 1234import stringimport randomalphabet = string.ascii_lowercaselst = [ print( '&#123;:04&#125;.&#123;&#125;'.format(i ,''.join(random.choice(alphabet) for j in range(10) ) ) ) for i in range(1,5) ] 0001.pofdzgbvou 0002.qtncejuibm 0003.kabobmwrgf 0004.dxalxumcot 列表高阶函数经典1.将字典转换成元组组成的列表 123dic = &#123;'a':1,'b':2,'c':3&#125;lst = [(x,y) for x,y in dic.items()]print(lst) [(&apos;a&apos;, 1), (&apos;b&apos;, 2), (&apos;c&apos;, 3)] 把列表中所有字符转换小写，非字符串元素保留原样 123lst = ['abC34DRT','DE12Fav',10,'QQcom.com']lst0 = [ x.lower() if isinstance(x,str) else x for x in lst ]print(lst0) [&apos;abc34drt&apos;, &apos;de12fav&apos;, 10, &apos;qqcom.com&apos;] 把列表中所有的字符串转换小写，非字符串元素移除 123lst = ['abC34DRT','DE12Fav',10,'QQcom.com']lst0 = [ x.lower() for x in lst if isinstance(x,str) ]print(lst0) [&apos;abc34drt&apos;, &apos;de12fav&apos;, &apos;qqcom.com&apos;] 生成器生成器迭代器是通过生成器生成的一个对象，每次遇到yield时会暂停生产值并记住位置记住位置执行状态(包括本地变量和挂起的try语句)， 当生成器迭代器继续运行时，它会从中断的地方继续运行(与每次调用时都重新启动的函数相比) 其实生成器就是迭代器中的一种表现形式但是不同的对象，而且都是可迭代对象， 生成器的构成生成器的构成是通过两种方式： 使用类似列表解析式生成 具体信息如下： 1.语法格式(返回值 for 元素 in 可迭代对象 if条件) 2.列表解析式的中括号换成小括号即可 3.返回一个生成器 使用包含yield的函数来生成 通常情况下对应简单的列表等采用列表生成器，若遇到复杂的计算值采用yield函数构成。 生成器的执行过程与特性执行过程：在执行过程中，遇到yield关键字就会终端执行，下次继续从中断位置开始执行。 特性： 1.与列表解析式截然不同，列表解析式是立即返回一个完整的列表，生成器表达式是按需计算，惰性求值，需要是才进行求值； 2.遇到yield记录当前位置，下次从记录位置继续执行 3.从前到后走完一遍后，不能回头 生成器值的访问方式通过内置next()方法 使用循环方式进行迭代 调用生成器对象send()方法 生成器表访问方式1234567g = ("&#123;:04&#125;".format(i) for i in range(1,6)) print(next(g))for x in g: print(x) print('~~~~~~~~~~~~') for x in g: print(x) 0001 0002 0003 0004 0005 ~~~~~~~~~~~~ 生成器表达式返回值构成列表expr表达式返回值构成列表或生成器，若无返回值时反回NoneTpye 12345g = ( print('&#123;&#125;,format(i+1)') for i in range(2))first = next(g)second = next(g)val = first + second print(val) {},format(i+1) {},format(i+1) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-20-cac278df07ae&gt; in &lt;module&gt; 2 first = next(g) 3 second = next(g) ----&gt; 4 val = first + second 5 print(val) TypeError: unsupported operand type(s) for +: &apos;NoneType&apos; and &apos;NoneType&apos; 生成器的next不能回头123456g = ( i for i in range(10) if i % 2 )first = next(g)second = next(g)val = first + secondprint(val)print(next(g)) 4 5 写生成器的两种方式 生成器表达式 1g = (x for x in range(10)) yield语句 12def func():yield 列表解析式和生成器对比计算方式生成器表达式延迟计算，列表解析式立即计算 内存占用但从返回值本身来说，生成器表达式省内存，列表解析式返回新的列表 生成器没有数据，内存占用极少 ，它是使用时一个个返回数据。如果将这些返回的数据合起来占用的内存也和列表解析式差不多。但是，它不需要立即占用这么多内存 列表解析式构造新的列表需要占用内存 计算速度单看计算时间，生成器表达式耗时非常短，列表解析式耗时长 生成器本身并没有返回值，只返回一个生成器对象，虽然是返回值但是累加起来占用内存和列表生成式几乎相等 列表解析式构造并返回一个新的列表 集合解析式语法: { 返回值 for 元素 in 可迭代对象 if 条件 } 列表解析式的中括号换成大括号{}就行了 立即返回一个集合 用法: 123s1 = &#123;(x,x+1) for x in range(10)&#125;# s2 = &#123;[x] for x in range(10)&#125; # 集合内部不能添加不可哈希类型 即不可添加 列表或字典s1 {(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10)} 字典解析式语法: {返回值 for 元素 in 可迭代对象 if 条件} 列表解析式的中括号换成大括号{}就行了 使用key:value形式 立即返回一个字典 用法: 123456&#123;x:(x,x+1) for x in range(10)&#125;&#123;x:[x,x+1] for x in range(10)&#125;&#123;(x,):[x,x+1] for x in range(10)&#125;# &#123;[x]:[x,x+1] for x in range(10)&#125; # 字典的key必须是课哈希类型&#123;chr(0x41+x):x**2 for x in range(10)&#125;&#123;str(x):y for x in range(3) for y in range(4)&#125; # 输出3个元素 字典的key需唯一 {&apos;0&apos;: 3, &apos;1&apos;: 3, &apos;2&apos;: 3} 可迭代对象可直接用于for循环的对象统称为可迭代对象（Iterable） 判断是否是可迭代对象，用函数isinstance() 12345678910from collections import Iterableprint(isinstance('ac',Iterable)) # True 字符串print(isinstance('[]',Iterable)) # True 列表print(isinstance('&#123;&#125;',Iterable)) # True 字典print(isinstance('()',Iterable)) # True 元组print(isinstance((x for x in range(2)),Iterable)) # True 生成器print(isinstance([x for x in range(2)],Iterable)) # True 列表解析式print(isinstance(&#123;x for x in range(2)&#125;,Iterable)) # True 集合解析式 print(isinstance(&#123;x:x+1 for x in range(2)&#125;,Iterable)) # True 字典解析式 True True True True True True True True Iterable、Iterator和Generator的关系生成器对象即是可迭代对象，也是迭代器，因为生成器既可以用for循环求值，也可以通过next()求值，直到抛出StopIteration时无法继续生成新值 迭代器对象一定时可迭代对象，可迭代对象不一定为迭代器，因为迭代器、生成器、可迭代对象都可以用for循环迭代求值，只有生成器和迭代器可以被next()方法求值]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python之字典操作]]></title>
    <url>%2F2019%2F01%2F09%2FPython%E4%B9%8B%E5%AD%97%E5%85%B8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Python之字典操作字典类型的容器在编程中的重要性不再言谈，通过现有典型互联网企业及传统企业专门部署redis集群服务器可知字典的编程、业务应用方面的重要性。 字典定义及初始化字典是非线性结构容器 字典的key-value键值对的数据集合 字典是可变的，无须的，key不重复 字典的key值必须可hash 12345d1 = dict()d2 = dict(a=1,b=2)d3 = &#123;'a':1,'b':2&#125;d4 = dict(([1,'a'],[2,'b']))d5 = dict.fromkeys(range(5),0) {0: 0, 1: 0, 2: 0, 3: 0, 4: 0} 字典元素的访问d[key]返回key对应的值value key不存在抛出KeyError异常 123d = dict(a=1,b=2)d['a']# d['c'] # KeyError 1 get(key[, default])返回key对应的值value key不存在返回缺省值，如果没有设置缺省值就返回None 1234d = dict(a=1,b=2)d.get('a',0)d.get('c',0)print(d) {&apos;a&apos;: 1, &apos;b&apos;: 2} setdefault(key[, default])返回key对应的值value key不存在，添加kv对， value设置为default，并返回default，如果default没有设置，缺省为None 1234d = dict(a=1,b=2)d.setdefault('a',0) d.setdefault('c',10)print(d) {&apos;a&apos;: 1, &apos;b&apos;: 2, &apos;c&apos;: 10} 字典增加和修改d[key] = value将key对应的值修改为value key不存在添加新的kv对 12 update([other]) -&gt; None使用另一个字典的kv对更新本字典 key不存在，就添加 key存在，覆盖已经存在的key对应的值 就地修改 12345d = dict(a=0,b=2)d.update(a=1)d.update((('a',2),))d.update(&#123;'a':3&#125;)print(d) {&apos;a&apos;: 3, &apos;b&apos;: 2} 字典删除pop(key[,default])如果key在字典中，删除它并返回他对应的值， 否则返回默认值， 如果默认值没有给定和key不在字典中则抛出错误 1234d = dict(a=1,b=2)d.pop('a')d.pop('a',0)#d.pop('a') # KeyError 0 popitem()移除和删除任意一个键值对 如果字典为空则抛出一个KeyError 异常 1234d = dict(a=1,b=2)d.popitem()d.popitem()# d.popitem() # KeyError (&apos;a&apos;, 1) del语句从字典中删除一个值，若这个值不在字典中则抛出错误异常 123d = dict(a=1,b=2)del d['a']# del d['a'] # KeyError clear()清空字典 123d = dict(a=1,b=2)d.clear()print(d) {} 字典KEY遍历字典的初始化，和取值方式123456789101112d = dict(a=1,b=2,c=3)keys = d.keys()values = d.values()print(keys) print(values) for i in d: print(i,end=' ') print()for j in keys: print(j,end=' ') dict_keys([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;]) dict_values([1, 2, 3]) a b c a b c 字典key的遍历有三种方式遍历，第一种直接遍历字典 123d = dict(a = 1,b = 2,c = 3 )for i in d: print(i,end=' ') a b c 第二种通过类下的方法keys()进行遍历 123d = dict(a = 1,b = 2,c = 3)for i in d.keys(): print(i,end=' ') a b c 第三种通过将迭代出来的列表转换为迭代器 1234567d = dict(a = 1,b = 2,c = 3)keys = iter(d.keys())print(type(keys))next(keys)next(keys)next(keys) &lt;class &apos;dict_keyiterator&apos;&gt; &apos;c&apos; 字典value值的遍历字典value值的遍历可以通过遍历key获取到key值，然后通过d[key],get[key]访问对应的value值或者直接通过class类方法 通过key值，d[key]方法访问value123d = dict(a = 1,b = 2,c = 3)for k in d: print(d[k],end=' ') 1 2 3 通过key值，get方法访问value值123d = dict(a = 1,b = 2,c = 3)for k in d: print(d.get(k),end=' ') 1 2 3 通过items()方法获取value的值123d = dict(a = 1,b = 2,c = 3)for k,v in d.items(): print(v,end=' ') 1 2 3 字典变量，丢弃变量访问123d = dict(a = 1,b = 2,c = 3)for _,v in d.items(): print(v,end=' ') 1 2 3 字典遍历过程中移除元素1234567891011d = dict(a = 1,b = 2,c = 3)lst = []for k,_ in d.items(): if k == '1': # d.pop(k) # 在字典遍历的过程中不能改变字典的长度或大小， # 因此要真正的删除其key-value时，在遍历的过程中要收集好要删除的key，最后一次性删除 lst.append(k) for k in lst: d.pop(k)print(d) {&apos;a&apos;: 1, &apos;b&apos;: 2, &apos;c&apos;: 3} 字典遍历过程中构建构建字典思路：构建字典的思路就是首先创建一个空字典，然后再往空字典中加入key和对应的值，通常情况下key的值也可以为空，根据后续条件在添加key对应的值 12345678import randomdic = &#123;&#125;for k in 'abcdefg': if k not in dic.keys(): dic[k] = [] for i in range(random.randint(1,5)): dic[k].append(i)print(dic) {&apos;a&apos;: [0, 1], &apos;b&apos;: [0, 1, 2, 3], &apos;c&apos;: [0, 1, 2], &apos;d&apos;: [0, 1, 2, 3, 4], &apos;e&apos;: [0, 1], &apos;f&apos;: [0, 1, 2], &apos;g&apos;: [0, 1, 2, 3]} 1234567from collections import defaultdictimport randomd1 = defaultdict(list)for k in 'abcdef': for i in range(random.randint(1,5)): d1[k].append(i) print(d1) defaultdict(&lt;class &apos;list&apos;&gt;, {&apos;a&apos;: [0]}) defaultdict(&lt;class &apos;list&apos;&gt;, {&apos;a&apos;: [0], &apos;b&apos;: [0, 1, 2, 3]}) defaultdict(&lt;class &apos;list&apos;&gt;, {&apos;a&apos;: [0], &apos;b&apos;: [0, 1, 2, 3], &apos;c&apos;: [0, 1, 2]}) defaultdict(&lt;class &apos;list&apos;&gt;, {&apos;a&apos;: [0], &apos;b&apos;: [0, 1, 2, 3], &apos;c&apos;: [0, 1, 2], &apos;d&apos;: [0, 1, 2, 3]}) defaultdict(&lt;class &apos;list&apos;&gt;, {&apos;a&apos;: [0], &apos;b&apos;: [0, 1, 2, 3], &apos;c&apos;: [0, 1, 2], &apos;d&apos;: [0, 1, 2, 3], &apos;e&apos;: [0, 1, 2]}) defaultdict(&lt;class &apos;list&apos;&gt;, {&apos;a&apos;: [0], &apos;b&apos;: [0, 1, 2, 3], &apos;c&apos;: [0, 1, 2], &apos;d&apos;: [0, 1, 2, 3], &apos;e&apos;: [0, 1, 2], &apos;f&apos;: [0, 1, 2, 3, 4]}) 有序字典构建OrderedDict对象 有序字典和常规字典一样，但它们记住插入项目的顺序。 当迭代一个有序的字典时，这些项按照它们的键被第一次添加的顺序返回。 返回dict子类的实例，支持通常的dict方法。 ordereddict是一个记忆键首次插入顺序的dict。 如果新条目覆盖现有条目，则原始插入位置保持不变。删除一个条目并重新插入它将移动到末尾。 12345678910111213141516171819202122from collections import OrderedDictimport randomd = &#123;'a':1,'b':2,'c':3,'d':4&#125;print(d)keys = list(d.keys())random.shuffle(keys)print(keys)od =OrderedDict()for k in keys: od[k] = d[k]print(d.keys())print(od)print(od.keys())# 打印结果# &#123;'a': 1, 'b': 2, 'c': 3, 'd': 4&#125;# ['c', 'a', 'd', 'b']# dict_keys(['a', 'b', 'c', 'd'])# OrderedDict([('c', 3), ('a', 1), ('d', 4), ('b', 2)])# odict_keys(['c', 'a', 'd', 'b']) {&apos;a&apos;: 1, &apos;b&apos;: 2, &apos;c&apos;: 3, &apos;d&apos;: 4} [&apos;b&apos;, &apos;c&apos;, &apos;a&apos;, &apos;d&apos;] dict_keys([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;]) OrderedDict([(&apos;b&apos;, 2), (&apos;c&apos;, 3), (&apos;a&apos;, 1), (&apos;d&apos;, 4)]) odict_keys([&apos;b&apos;, &apos;c&apos;, &apos;a&apos;, &apos;d&apos;])]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[封装和解构]]></title>
    <url>%2F2019%2F01%2F07%2FPython%E4%B9%8B%E5%B0%81%E8%A3%85%E5%92%8C%E8%A7%A3%E6%9E%84%2F</url>
    <content type="text"><![CDATA[封装和结构封装(装箱)封装是将多个值使用逗号分割，组合在一起 本质上，封装是返回一个元组，只是省掉了小括号 1234t1 = (1,2)t2 = 1,2print(t1,type(t1))print(t2,type(t2)) (1, 2) &lt;class &apos;tuple&apos;&gt; (1, 2) &lt;class &apos;tuple&apos;&gt; 1封装、解构 可以理解为交换意思 123456789a = 4b = 5temp = aa = bb = tempprint(a,b)# 等价于a, b = b, aprint(a,b) 5 4 4 5 1上句中，等号右边使用了封装，而左边就使用了解构 解构（拆箱）解构就是把线性结构的元素解开，并按顺序赋给其他变量 解构左边接纳的变量数要和右边解开的元素个数一致 123lst = [3,5]a , b = lstprint(a,b) 3 5 注：非线性结构也可以解构 1234a,b = &#123;'a':10,'b':20&#125;print(a,b)a,b = (11,22)print(a,b) a b 11 22 *变量名Python的解构参数中可以使用 变量名 来接收参数被 变量名 收集的参数会组成一个列表*变量名 在结构参数中只能使用一次 1234lst = list(range(1,21,2))head,*body = lstprint(head,body)# head,*mid,*tail = lst error 1 [3, 5, 7, 9, 11, 13, 15, 17, 19] 丢弃变量如果不关心一个变量，就可以定义改变量的名字为‘_’ ‘_’是一个合法的标识符，也可以作为一个有效的变量使用，但是定义成下划线就是希望不要被使用，除非你明确的知道这个数据需要使用 12345lst = [7,8,9,2]head,*_,tail = lstprint(head,tail)# _是合法的标识符，看到下划线就知道这个变量就是不想被使用print(_) 7 2 [8, 9] 12]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python内置数据类型之Bytes和Bytearray]]></title>
    <url>%2F2019%2F01%2F06%2FPython%E5%86%85%E7%BD%AE%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B9%8BBytes%E5%92%8CBytearray%2F</url>
    <content type="text"><![CDATA[Python内置数据类型之Bytes和Bytearraybytes、bytearrayPython3引入两个新类型 bytes 不可变字节类型 byrearray 字节数组 可变 字符串与bytes 字符串是由字符组成的有序序列，字符可以使用编码来理解 bytes是字节组成的有序的不可变序列 bytearray是字节组成的有序的可变序列 编码与解码 字符串按照不同的字符集编码encode返回字节序列bytes 1encode(encoding=&quot;utf-8&quot;,errors=&quot;strict&quot;) -&gt; str 字节序列按照不同的字符集解码decode返回字符串 12bytes.decode(encoding=&quot;utf-8&quot;,errors=&quot;strict&quot;) -&gt; str bytearray.decode(encoding=&quot;utf-8&quot;.errors=&quot;strict&quot;) -&gt; str butes定义定义 bytes() 空bytes bytes(int) 指定字节的bytes，被0填充 bytes(iterable_of_ints) -&gt; bytes[0,255]的int组成的可迭代对象 bytes(string, encoding[, errors]) -&gt; bytes等价于string.encode() bytes(bytes_or_buffer) -&gt; immutable copy of bytes_or_buffer从一个字节序或者buffer复制出一个新的不可变的bytes对象 使用b前缀定义 只允许基本ASCII使用字符形式b’abc9’ 使用16进制表示b”\x41\x61” bytes操作 和str类型类似，都是不可变类型，所以方法很多都一样。只不过bytes的方法，输入是bytes，输出是bytes 12b&apos;abcdef&apos;.replace(b&apos;f&apos;,b&apos;k&apos;) b&apos;abc&apos;.find(b&apos;b&apos;) 类方法 bytes.fromhex(string) string必须是2个字符的16进制的形式，’6162 6a 6b’,空格将被忽略 12345 bytes.fromhex(&apos;6162 09 6a 6b00&apos;) hex() ``` * 返回16进制表示的字符串 ‘abc’.encode().hex() 12* 索引 b’abcde’[2] 返回该字节对应的数，int类型 ` bytearray定义 bytearray() 空bytearray bytearray(int) 指定字节的bytearray，被0 填充 bytearray(iterable_of_ints) -&gt; bytearray[0,255]的int组成的可迭代对象 bytearat(string,encoding[, errors]) -&gt; bytearray 近似string.encode(), 不可返回可变对象 bytearray(bytes_or_buffer) 从一个字节序列或者buffer复制出一个可变的bytearray对象 注意，b前缀定义的类型是bytes类型 bytearray操作 和bytes类型的方法相同 bytearray(b’abcdef’)replace(b’f’,b’k’) bytearray(b’abc’).find(b’b’) 类方法 bytearray.fromhex(string) string必须是2个字符的16进制的形式。’6162 6a 6b’, 空格将被忽略 bytearray.fromhex(‘6162 09 6a 6b00’) hex(): 返回16进制表示的字符串 bytearray(‘abc’.encode()).hex() 索引: bytearray(b’abcef’)[2] 返回该字节对应的数，int类型 append(int) 尾部追加一个元素 insert(index, int) 在指定索引位置插入元素 extend(iterable_of_ints) 将一个可迭代的整数集合追加到当前bytearray pop(index=-1) 从指定索引上移除元素，默认从尾部移除 remove(value) 找到第一个value移除，找不到抛ValueError异常 clear() 清空bytearray reverse() 翻转bytearray，就地修改 注意：上述方法若需要使用int类型，值在[0, 255]]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python之集合操作]]></title>
    <url>%2F2019%2F01%2F06%2FPython%E4%B9%8B%E9%9B%86%E5%90%88%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Python之集合操作set 集合set是 可变的、 无序的、不重复 的元素的集合 set的定义初始化set() -&gt; new empty set object set(iterable) -&gt; new set object 123456s1 = set()s2 = set(range(5))s3 = set(list(range(5)))s4 = &#123;1,2,3,4&#125;s5 = &#123;(1,2),3,'a'&#125;print(s1,s2,s3,s4,s4) set() {0, 1, 2, 3, 4} {0, 1, 2, 3, 4} {1, 2, 3, 4} {1, 2, 3, 4} 但是： set的元素要求必须可以hash 目前学过的不可hash的类型有list、 set,所以set不能添加list或set 元素不可以使用索引 set可以迭代 12s1 = &#123; [1,2],3,4 &#125;s2 = &#123; &#123;1,2&#125;,3,4 &#125; --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-2-562af6839204&gt; in &lt;module&gt; ----&gt; 1 s1 = { [1,2],3,4 } 2 s2 = { {1,2},3,4 } TypeError: unhashable type: &apos;list&apos; set增加add(elem)增加一个元素到set中 如果元素存在，什么都不做 1234s1 = &#123;1,2,3,4,5&#125;s1.add(6)s1.add(6)print(s1) {1, 2, 3, 4, 5, 6} update(*others)合并其他元素到set集合中来 参数others必须是可迭代对象 就地修改 1234s1 = &#123;1,2&#125;s1.update(range(5))s1.update(('a','b'))print(s1) {0, 1, 2, 3, 4, &apos;a&apos;, &apos;b&apos;} set 删除remove(elem)从set中移除一个元素 元素不存在，抛出keyerror异常 123s1 = &#123;1,2,3,4&#125;s1.remove(1)s1.remove(1) --------------------------------------------------------------------------- KeyError Traceback (most recent call last) &lt;ipython-input-5-06ea004ed743&gt; in &lt;module&gt; 1 s1 = {1,2,3,4} 2 s1.remove(1) ----&gt; 3 s1.remove(1) KeyError: 1 discard（elem）从set中移除一个元素 元素不存在，什么都不做 1234s1 = &#123;1,2,3,4&#125;s1.discard(1)s1.discard(1)print(s1) {2, 3, 4} pop() -&gt; item移除并返回任意的元素 空集返回KeyError异常 1234s1 = &#123;1,2&#125;s1.pop()s1.pop()s1.pop() --------------------------------------------------------------------------- KeyError Traceback (most recent call last) &lt;ipython-input-7-cb8a0766400b&gt; in &lt;module&gt; 2 s1.pop() 3 s1.pop() ----&gt; 4 s1.pop() KeyError: &apos;pop from an empty set&apos; clear()移除所有元素 123s1 = &#123;1,2,3&#125;s1.clear()print(s1) set() set的修改、查询修改set中没有修改的说法，修改删除元素，然后添加新元素 查询set是非线性结构，无法通过索引来查询元素 遍历set可以迭代通过for循环所有元素 123s1 = &#123;1,2,3,4&#125;for i in s1: print(i) 1 2 3 4 成员运算符set是通过in 或者 not in 判断元素是否在set中 线性结构和非线性结构的差别线性结构的查询时间复杂度是O(n)，即随着数据规模的增大而增加耗时 set、 dict等结构，内部使用hash值作为key，时间复杂度可以做到O(1)，查询时间和数据规模无关 可hash数据类型数值型int、 float、 complex 布尔型True、 False 字符串string、 bytes tuple None 以上都是不可变类型，是可哈希类型， hashableset的元素必须是可hash的]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python内置数据结构之tuple]]></title>
    <url>%2F2019%2F01%2F05%2FPython%E5%86%85%E7%BD%AE%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8Btuple%2F</url>
    <content type="text"><![CDATA[Python内置数据结构之tuple&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python的元组和列表类似，不同之处在于元组中的元素不能修改(因此元组又称为只读列表)，且元组使用小括号而列表使用中括号。 一、创建元组123tup1 = (&apos;physics&apos;, &apos;chemistry&apos;, 1997, 2000);tup2 = (1, 2, 3, 4, 5 );tup3 = &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创建空元组1tup1 = (); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;元组中只包含一个元素时，需要在元素后面添加逗号来消除歧义1tup1 = (50,); 元组与字符串类似，下标索引从0开始，可以进行截取，组合等。 二、访问元组&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;元组可以使用下标索引来访问元组中的值，如下实例:12345678tup1 = (&apos;physics&apos;, &apos;chemistry&apos;, 1997, 2000);tup2 = (1, 2, 3, 4, 5, 6, 7 );print &quot;tup1[0]: &quot;, tup1[0]print &quot;tup2[1:5]: &quot;, tup2[1:5]#以上实例输出结果：#tup1[0]: physics#tup2[1:5]: [2, 3, 4, 5] 三、修改元组&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;元组中的元素值是不允许修改的，但我们可以对元组进行连接组合，如下实例:1234567891011tup1 = (12, 34.56);tup2 = (&apos;abc&apos;, &apos;xyz&apos;);# 以下修改元组元素操作是非法的。# tup1[0] = 100;# 创建一个新的元组tup3 = tup1 + tup2;print tup3;#以上实例输出结果：#(12, 34.56, &apos;abc&apos;, &apos;xyz&apos;) 四、删除元组&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;元组中的元素值是不允许删除的，但我们可以使用del语句来删除整个元组，如下实例:123456789101112131415tup = (&apos;physics&apos;, &apos;chemistry&apos;, 1997, 2000);print tup;del tup;print &quot;After deleting tup : &quot;print tup;以上实例元组被删除后，输出变量会有异常信息，输出如下所示：#(&apos;physics&apos;, &apos;chemistry&apos;, 1997, 2000)#After deleting tup :#Traceback (most recent call last):# File &quot;test.py&quot;, line 9, in &lt;module&gt;# print tup;#NameError: name &apos;tup&apos; is not defined[/code] 五、元组运算符&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与字符串一样，元组之间可以使用 + 号和 * 号进行运算。这就意味着他们可以组合和复制，运算后会生成一个新的元组。 六、元组索引、截取&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为元组也是一个序列，所以我们可以访问元组中的指定位置的元素，也可以截取索引中的一段元素，如下所示：1元组：L = (&apos;spam&apos;, &apos;Spam&apos;, &apos;SPAM!&apos;) 七、无关闭分隔符&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;任意无符号的对象，以逗号隔开，默认为元组，如下实例：12345678print &apos;abc&apos;, -4.24e93, 18+6.6j, &apos;xyz&apos;;x, y = 1, 2;print &quot;Value of x , y : &quot;, x,y;以上实例允许结果：abc -4.24e+93 (18+6.6j) xyzValue of x , y : 1 2 八、元组内置函数Python元组包含了以下内置函数 cmp(tuple1, tuple2)：比较两个元组元素。 len(tuple)：计算元组元素个数。 max(tuple)：返回元组中元素最大值。 min(tuple)：返回元组中元素最小值。 tuple(seq)：将列表转换为元组。 九、另一种解读tuple和list非常类似，但是tuple一旦初始化就不能修改，比如同样是列出同学的名字： classmates = (‘Michael’, ‘Bob’, ‘Tracy’) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在，classmates这个tuple不能变了，它也没有append()，insert()这样的方法。其他获取元素的方法和list是一样的，你可以正常地使用classmates[0]，classmates[-1]，但不能赋值成另外的元素。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不可变的tuple有什么意义？因为tuple不可变，所以代码更安全。如果可能，能用tuple代替list就尽量用tuple。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tuple的陷阱：当你定义一个tuple时，在定义的时候，tuple的元素就必须被确定下来，比如：123t = (1, 2)t(1, 2) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果要定义一个空的tuple，可以写成()：123t = ()t() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，要定义一个只有1个元素的tuple，如果你这么定义：12t = (1)t &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;定义的不是tuple，是1这个数！这是因为括号()既可以表示tuple，又可以表示数学公式中的小括号，这就产生了歧义，因此，Python规定，这种情况下，按小括号进行计算，计算结果自然是1。所以，只有1个元素的tuple定义时必须加一个逗号,，来消除歧义：123t = (1,)t(1,) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python在显示只有1个元素的tuple时，也会加一个逗号,，以免你误解成数学计算意义上的括号。 在来看一个“可变的”tuple：12345t = (&apos;a&apos;, &apos;b&apos;, [&apos;A&apos;, &apos;B&apos;])t[2][0] = &apos;X&apos;t[2][1] = &apos;Y&apos;t(&apos;a&apos;, &apos;b&apos;, [&apos;X&apos;, &apos;Y&apos;]) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个tuple定义的时候有3个元素，分别是’a’，’b’和一个list。不是说tuple一旦定义后就不可变了吗？怎么后来又变了？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;表面上看，tuple的元素确实变了，但其实变的不是tuple的元素，而是list的元素。tuple一开始指向的list并没有改成别的list，所以，tuple所谓的“不变”是说，tuple的每个元素，指向永远不变。即指向’a’，就不能改成指向’b’，指向一个list，就不能改成指向其他对象，但指向的这个list本身是可变的！&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;理解了“指向不变”后，要创建一个内容也不变的tuple怎么做？那就必须保证tuple的每一个元素本身也不能变。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python内置数据类型之String]]></title>
    <url>%2F2019%2F01%2F05%2FPython%E5%86%85%E7%BD%AE%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B9%8BString%2F</url>
    <content type="text"><![CDATA[Python内置数据类型之String导论什么叫字符串？字符串就是一个个字符组成的有序的序列，是字符的集合，在python中通常使用单引号、双引号和三引号引住的字符序列 字符串属性字符串是不可变对象区别于列表类型的对象，列表对象时可变的，而字符串对象是不可变的，因此字符串对象不存在通过索引改变其中的字符 字符串支持使用索引访问字符串可以通过下标索引进行访问 字符串是有序的字符集合，字符序列字符串在内存中可以是连续的地址空间，有序的序列 字符串是可迭代的123sql = "select * from user where name='tom'"for i in sql: print(i,end = ' ') s e l e c t * f r o m u s e r w h e r e n a m e = &apos; t o m &apos; 字符串的操作str.join(iterable) –&gt;str1. 将可迭代对象连接起来，使用string作为分隔符 2. 可迭代对象本身元素都是字符串 3. 返回一个新的字符串 1print( ''.join(['a','b','c']) ) abc + 号连接将两个字符串连接在一起代码格式如下： 1print('abc' + 'def') abcdef 字符串分割分割字符串的两种方法分为2类 1. str.split(sep=None, maxsplit=-1) -&gt; list of strings将字符串安装分隔符分割成若干字符串，并返回列表 从左至右 sep 指定分割字符串，缺省的情况下空白字符串作为分隔符 maxsplit 指定分割的次数， -1 表示遍历整个字符串 123s1 = 'www.baidu.com'a,b,c = s1.split('.',maxsplit=2)a,b,c (&apos;www&apos;, &apos;baidu&apos;, &apos;com&apos;) 2. str.partition(sep) -&gt; (head, sep, tail):将字符串按照分隔符分割成两段，返回这两段和分隔符的元组 从左至右，遇到分隔符就把字符串分割成两部分，返回头、分隔符、尾三部分的三元组；如果 没有找到分隔符，就返回头、 2个空元素的三元组 sep 分割字符串， 必须指定 123s2 = 'www.qq.com'a,b,c = s2.partition('.')a,b,c (&apos;www&apos;, &apos;.&apos;, &apos;qq.com&apos;) 字符串大小写str.upper(): 全大写str.lower(): 全小写str.swapcase(): 交换大小写1234s3 = 'aBCDef'print(s3.upper())print(s3.lower())print(s3.swapcase()) ABCDEF abcdef AbcdEF 字符串排版str.title() -&gt; str 标题的每个单词都大写 1print('hello world'.title()) Hello World str.capitalize() -&gt; str 首个单词大写 1print('abc def '.capitalize()) Abc def str.center(width[, fillchar]) -&gt; str width 打印宽度 fillchar 填充的字符 1print(' abcd '.center(20,'*')) ******* abcd ******* str.zfill(width) -&gt; strwidth 打印宽度，居右，左边用0填充 12for i in range(1,14,3): print('&#123;&#125;'.format(i).zfill(4)) 0001 0004 0007 0010 0013 str.ljust(width[, fillchar]) -&gt; str 左对齐12print('abcd'.ljust(10))print('abcd'.ljust(10,'0')) abcd abcd000000 str.rjust(width[, fillchar]) -&gt; str 左对齐12print('abcd'.rjust(10))print('abcd'.rjust(10,'0')) abcd 000000abcd 字符串修改str.replace(old, new[, count]) -&gt; str字符串中找到匹配替换为新子串，返回新字符串 count表示替换几次，不指定就是全部替换 12print( 'www.baidu.com'.replace('w','p') )print( 'www.baidu.com'.replace('w','p',2) ) ppp.baidu.com ppw.baidu.com strip([chars]) -&gt; str从字符串两端去除指定的字符集chars中的所有字符 如果chars没有指定，去除两端的空白字符 12print(' abcd123 \r \n \t '.strip())print('****abcder***'.strip('*')) abcd123 abcder str.lstrip([chars]) -&gt; str 从左开始str.rstrip([chars]) -&gt; str 从右开始12print("***abcdef###".lstrip("*"))print("***abcdef###".rstrip("#")) abcdef### ***abcdef 字符串查找时间复杂度index和count方法都是O(n) 随着数据规模的增大，而效率下降 str.find(sub[, start[, end]]) -&gt; int在指定的区间[start, end)，从左至右，查找子串sub。找到返回索引，没找到返回-1 str.rfind(sub[, start[, end]]) -&gt; int在指定的区间[start, end)，从右至左，查找子串sub。找到返回索引，没找到返回-1 1234567s = "I am very very very sorry"print(s.find('very'))print(s.find('very',6))print(s.find('very',6,10))print(s.rfind('very',10))print(s.rfind('very',10,15))print(s.rfind('very',-10,-1)) 5 10 -1 15 10 15 str.index(sub[, start[, end]]) -&gt; int 在指定的区间[start, end)，从左至右，查找子串sub。找到返回索引，没找到抛出异常ValueError str.rindex(sub[, start[, end]]) -&gt; int 在指定的区间[start, end)，从左至右，查找子串sub。找到返回索引，没找到抛出异常ValueError 1234567s = "I am very very very sorry"print(s.index('very'))print(s.index('very', 5))# print(s.index('very', 6, 13))print(s.rindex('very', 10))print(s.rindex('very', 10, 15))print(s.rindex('very',-10,-1)) 5 5 15 10 15 str.count(sub[, start[, end]]) -&gt; int 在指定的区间[start, end)，从左至右，统计子串sub出现的次数 1234s = "I am very very very sorry"print(s.count('very'))print(s.count('very', 5))print(s.count('very', 10, 14)) 3 3 1 len(string) 返回字符串的长度，即字符的个数 12s = "I am very very very sorry"print(len(s)) 25 字符串判断*str.endswith(suffix[, start[, end]]) -&gt; bool在指定的区间[start, end)，字符串是否是suffix结尾 str.startswith(prefix[, start[, end]]) -&gt; bool在指定的区间[start, end)，字符串是否是prefix开头 12345678s = "I am very very very sorry"print(s.startswith('very'))print(s.startswith('very',5))print(s.startswith('very',5,9))print(s.endswith('sorry'))print(s.endswith('sorry',5))print(s.endswith('sorry',5,100))print(s.endswith('sorry',5,-1)) False True True True True True False 字符串判断 is系列isalnum() -&gt; bool 是否是字母和数字组成12print(' '.isalnum())print('abc123'.isalnum()) False True isalpha() 是否是字母12print("abcdAVAS".isalpha())print('abcd12'.isalpha()) True False isdecimal() 是否只包含十进制数字12print('1234'.isdecimal())print('abc123'.isdecimal()) True False isdigit() 是否全部数字(0~9)12print('12345'.isdigit())print('12345abcd'.isdigit()) True False isidentifier() 是不是字母和下划线开头，其他都是字母、数字、 下划线12print('_abcd124'.isidentifier())print('12abcd124'.isidentifier()) True False islower() 是否都是小写12print("abcd".islower())print('ABcd'.islower()) True False isupper() 是否全部大写12print('ABCD'.isupper())print('ABCde'.isupper()) True False isspace() 是否只包含空白字符12print(' \r \n \t '.isspace())print(' 11 '.isspace()) True False 字符串格式化字符串的格式化是一种拼接字符串输出样式的手段，更灵活方便 join拼接只能使用分隔符，且要求被拼接的是可迭代对象且其元素是字符串 拼接字符串还算方便，但是非字符串需要先转换为字符串才能拼接 format函数格式字符串语法 “{} {xxx}”.format(*args, kwargs) -&gt; str** 对齐 12345print('&#123;0&#125; * &#123;1&#125; = &#123;2:&lt;2&#125;'.format(3,2,2*3))print('&#123;0&#125; * &#123;1&#125; = &#123;2:&lt;02&#125;'.format(3,2,2*3))print('&#123;0&#125; * &#123;1&#125; = &#123;2:&gt;02&#125;'.format(3,2,2*3))print('&#123;:^30&#125;'.format('centered'))print('&#123;:*^30&#125;'.format('centered')) 3 * 2 = 6 3 * 2 = 60 3 * 2 = 06 centered ***********centered*********** 进制 12print('int:&#123;0:d&#125;; hexo:&#123;0:x&#125;; oct:&#123;0:o&#125;; bin:&#123;0:b&#125;'.format(42))print('int:&#123;0:#d&#125; hexo:&#123;0:x&#125; oct:&#123;0:o&#125; bin:&#123;0:b&#125;'.format(42)) int:42; hexo:2a; oct:52; bin:101010 int:42 hexo:2a oct:52 bin:101010 浮点数 123456789print("&#123;&#125;".format(3**0.5)) # 1.7320508075688772print("&#123;:f&#125;".format(3**0.5)) # 1.732051，精度默认6print("&#123;:10f&#125;".format(3**0.5)) # 右对齐，宽度10print("&#123;:2&#125;".format(102.231)) # 宽度为2print("&#123;:.2&#125;".format(3**0.5)) # 1.7 2个数字print("&#123;:.2f&#125;".format(3**0.5)) # 1.73 小数点后2位print("&#123;:3.2f&#125;".format(3**0.5)) # 1.73 宽度为3，小数点后2位print("&#123;:3.3f&#125;".format(0.2745)) # 0.275print("&#123;:3.3%&#125;".format(1/3)) # 33.333% 1.7320508075688772 1.732051 1.732051 102.231 1.7 1.73 1.73 0.275 33.333%]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python内置数据结构之list]]></title>
    <url>%2F2019%2F01%2F05%2FPython%E5%86%85%E7%BD%AE%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8Blist%2F</url>
    <content type="text"><![CDATA[Python内置数据结构之list列表是Python中最具灵活性的有序集合对象类型，与字符串不同的是，列表可以包含任何种类的对象：数字、字符串甚至其他列表。 同样，与字符串不同的，列表都是可变对象，它都支持在原处修改的操作，可以通过指定的偏移量和切片、列表方法调用、删除语句等等方法来实现 Python的列表可以完成大多数集合体数据结构的工作： 列表的主要属性有： 任意对象的有序集合&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从功能上看,列表就是收集其他对象的地方,你可以把它们看做组。同时列表所包含的每一项都保持了从左到右的位置顺序(也就是说,它们是序列)。 通过偏移读取数据&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;就像字符串一样,你可以通过列表对象的偏移对其进行索引,从而读取对象的某部分内容。由于列表的每一项都是有序的,那么你也可以执行诸如分片和合并之类的任务 可变长度、异构以及任意嵌套&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与字符串不同的是,列表可以实地的增长或者缩短(长度可变),并且可以包含任何类型的对象而不仅仅是包含有单个字符的字符串(异构)。因为列表能够包含其他复杂的对象,又能够支持任意的嵌套,所以可以创建列表的子列表的子列表等。 属于可变序列的分类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;就类型分类而言,列表支持在原处的修改(它们是可变的),也可以响应所有针对字符串序列的操作,例如,索引、分片以及合并。实际上,序列操作在列表与字符串中的工作方式相同。唯一的区别是:当应用于字符串上的合并和分片这样的操作应用于列表时,返回新的列表。然而列表是可变的,因此它们也支持字符串不支持的其他操作(例如,删除和索引赋值操作,它们都是在原处修改列表)。 对象引用数组&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从技术上来讲, Python列表包含了零个或多个其他对象的引用。列表也许会让你想起指针(地址)数组,从 Python的列表中读取一个项的速度与索引一个C语言数组差不多。实际上,在标准 Python解释器内部,列表就是C数组而不是链接结构。每当用到引用时, Python总是会将这个引用指向一个对象,所以程序只需处理对象的操作。当把一个对象赋给一个数据结构元素或变量名时, Python总是会存储对象的引用,而不是对象的一个拷贝(除非明确要求保存拷贝） 列表list的定义list()，里面可以什么都不放，也可以放可迭代对象。1234lst = list()lst = []lst = [2, 6, 9, &apos;ab&apos;]lst = list(range(5)) 列表的索引访问python中list的索引从0开始。绝大多数语言的下标是从0开始的负数的索引表示从后往前数，由-1开始，-1表示最后一个元素。12345678In [6]: lstOut[6]: [1, 2, 3] In [7]: lst[0]Out[7]: 1 In [8]: lst[-1]Out[8]: 3 如果索引超出范围，将引发IndexError。 123456789101112131415In [9]: lst[-4]---------------------------------------------------------------------------IndexError Traceback (most recent call last)&lt;ipython-input-9-7ea420056b9a&gt; in &lt;module&gt;()----&gt; 1 lst[-4] IndexError: list index out of range In [10]: lst[3]---------------------------------------------------------------------------IndexError Traceback (most recent call last)&lt;ipython-input-10-298ffefac8cf&gt; in &lt;module&gt;()----&gt; 1 lst[3] IndexError: list index out of range 修改元素的时候，如果超出索引范围，也会引发IndexError。 数字处理函数：round(): 四舍五取偶六入 math模块 floor():向下取整 ceil():向上取整 int():取整数部分 //:整除且向下取整 min():取最小值 max():取最大值 pow(x,y)等价于x**y math.sqrt():开平方 进制函数，返回值是字符串 bin():二进制转换 oct():八进制转换 hex():十六进制转换 random模块 randint(a,b) 返回a，b之间的整数 choice(seq)从非空序列的元素中随机挑选一个元素 randrange([start,] stop [,sttep])从指定范围内，按指定基数递增的集合中获取一个随机数 random.shuffle(list) -&gt;None 就地打乱列表元素 sample(population, k)从样本空间或总体中随机取出k个不同的元素，返回一个新的列表 len(list): 显示列表的元素个数 列表内建函数：list.append(obj): 在列表末尾添加新的对象 list.count(obj): 统计某个元素在列表中出现的次数 list.extend(seq):在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表） list.index(obj)： 从列表中找出某个值第一个匹配项的索引位置 list.insert(index, obj)： 将对象插入列表 list.pop([index=-1])： 移除列表中的一个元素（默认最后一个元素），并且返回该元素的值 list.remove(obj)： 移除列表中某个值的第一个匹配项 list.reverse()： 反向列表中元素 list.sort(cmp=None, key=None, reverse=False)：对原列表进行排序 list.clear()： 清空列表 list.copy()： 复制列表]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的内存管理机制]]></title>
    <url>%2F2019%2F01%2F04%2FPython%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[对象绝不会自行销毁；然而，无法得到对象时，可能会被当作垃圾回收 Python内存管理机制 Python的内存管理机制： 引入计数 垃圾回收 内存池机制 一、变量与对象关系图如下： 变量，通过变量指针引用对象 变量指针指向具体对象的内存空间，取对象的值。 对象，类型已知，每个对象都包含一个头部信息（头部信息：类型标识符和引用计数器） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注意： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;变量名没有类型，类型属于对象（因为变量引用对象，所以类型随对象），变量引用什么类型的对象，变量就是什么类型的。 12345678In [32]: var1=objectIn [33]: var2=var1In [34]: id(var1)Out[34]: 139697863383968In [35]: id(var2)Out[35]: 139697863383968 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PS：id()是python的内置函数，用于返回对象的身份，即对象的内存地址。 12345678910111213141516In [39]: a=123In [40]: b=aIn [41]: id(a)Out[41]: 23242832In [42]: id(b)Out[42]: 23242832In [43]: a=456In [44]: id(a)Out[44]: 33166408In [45]: id(b)Out[45]: 23242832 引用所指判断通过is进行引用所指判断，is是用来判断两个引用所指的对象是否相同。 整数 1234In [46]: a=1In [47]: b=1In [48]: print(a is b)True 短字符串 1234In [49]: c=&quot;good&quot;In [50]: d=&quot;good&quot;In [51]: print(c is d)True 长字符串 1234In [52]: e=&quot;very good&quot;In [53]: f=&quot;very good&quot;In [54]: print(e is f)False 列表 1234In [55]: g=[]In [56]: h=[]In [57]: print(g is h)False 由运行结果可知： 1. Python缓存了整数和短字符串，因此每个对象在内存中只存有一份，引用所指对象就是相同的，即使使用赋值语句，也只是创造新的引用，而不是对象本身； 2. Python没有缓存长字符串、列表及其他对象，可以由多个相同的对象，可以使用赋值语句创建出新的对象。 二、引用计数&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Python中，每个对象都有指向该对象的引用总数—引用计数 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;查看对象的引用计数：sys.getrefcount() 普通引用 1234567891011In [2]: import sysIn [3]: a=[1,2,3]In [4]: getrefcount(a)Out[4]: 2In [5]: b=aIn [6]: getrefcount(a)Out[6]: 3In [7]: getrefcount(b)Out[7]: 3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注意： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当使用某个引用作为参数，传递给getrefcount()时，参数实际上创建了一个临时的引用。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，getrefcount()所得到的结果，会比期望的多1。 容器对象 Python的一个容器对象(比如：表、词典等)，可以包含多个对象。 123456789101112131415In [12]: a=[1,2,3,4,5]In [13]: b=aIn [14]: a is bOut[14]: TrueIn [15]: a[0]=6 In [16]: aOut[16]: [6, 2, 3, 4, 5]In [17]: a is bOut[17]: TrueIn [18]: bOut[18]: [6, 2, 3, 4, 5] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由上可见，实际上，容器对象中包含的并不是元素对象本身，是指向各个元素对象的引用。 引用计数增加 3.1 对象被创建 1234567In [39]: getrefcount(123)Out[39]: 6In [40]: n=123In [41]: getrefcount(123)Out[41]: 7 3.2 另外的别人被创建 123In [42]: m=nIn [43]: getrefcount(123)Out[43]: 8 3.3 作为容器对象的一个元素 123In [44]: a=[1,12,123]In [45]: getrefcount(123)Out[45]: 9 3.4被作为参数传递给函数：foo(x) 引用计数减少4.1对象的别名被显式的销毁 123In [46]: del mIn [47]: getrefcount(123)Out[47]: 8 4.2 对象的一个别名被赋值给其他对象 123In [48]: n=456In [49]: getrefcount(123)Out[49]: 7 4.3对象从一个窗口对象中移除，或，窗口对象本身被销毁 123456In [50]: a.remove(123)In [51]: aOut[51]: [1, 12]In [52]: getrefcount(123)Out[52]: 6 4.4 一个本地引用离开了它的作用域，比如上面的foo(x)函数结束时，x指向的对象引用减1。 三、垃圾回收&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当Python中的对象越来越多，占据越来越大的内存，启动垃圾回收(garbage collection)，将没用的对象清除。 原理 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当Python的某个对象的引用计数降为0时，说明没有任何引用指向该对象，该对象就成为要被回收的垃圾。比如某个新建对象，被分配给某个引用，对象的引用计数变为1。如果引用被删除，对象的引用计数为0，那么该对象就可以被垃圾回收。123In [74]: a=[321,123]In [75]: del a 解析del &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;del a后，已经没有任何引用指向之前建立的[321,123]，该表引用计数变为0，用户不可能通过任何方式接触或者动用这个对象，当垃圾回收启动时，Python扫描到这个引用计数为0的对象，就将它所占据的内存清空。 注意 垃圾回收时，Python不能进行其它的任务，频繁的垃圾回收将大大降低Python的工作效率； Python只会在特定条件下，自动启动垃圾回收（垃圾对象少就没必要回收） 当Python运行时，会记录其中分配对象(object allocation)和取消分配对象(object deallocation)的次数。当两者的差值高于某个阈值时，垃圾回收才会启动。 1234In [93]: import gcIn [94]: gc.get_threshold() #gc模块中查看阈值的方法Out[94]: (700, 10, 10) 阈值分析： 700即是垃圾回收启动的阈值； 每10次0代垃圾回收，会配合1次1代的垃圾回收；而每10次1代的垃圾回收，才会有1次的2代垃圾回收； 当然也是可以手动启动垃圾回收： 12In [95]: gc.collect() #手动启动垃圾回收Out[95]: 2 何为分代回收 Python将所有的对象分为0，1，2三代； 所有的新建对象都是0代对象； 当某一代对象经历过垃圾回收，依然存活，就被归入下一代对象。 四、内存池机制 Python中有分为大内存和小内存：（256K为界限分大小内存） 大内存使用malloc进行分配 小内存使用内存池进行分配 Python的内存池(金字塔) 第3层：最上层，用户对Python对象的直接操作 第1层和第2层：内存池，有Python的接口函数PyMem_Malloc实现—–若请求分配的内存在1~256字节之间就使用内存池管理系统进行分配，调用malloc函数分配内存，但是每次只会分配一块大小为256K的大块内存，不会调用free函数释放内存，将该内存块留在内存池中以便下次使用。 第0层：大内存—–若请求分配的内存大于256K，malloc函数分配内存，free函数释放内存。 第-1，-2层：操作系统进行操作]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的流程控制]]></title>
    <url>%2F2019%2F01%2F03%2FPython%E7%9A%84%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Python的流程控制 顺序 按照先后顺序一条条执行 例如，先洗手，再吃饭，再洗碗 分支 根据不同的情况判断，条件满足执行某条件下的语句 例如，先洗手，如果饭没有做好，玩游戏，如果饭做好了，就吃饭，如果饭都没有，叫外卖 循环 条件满足就反复执行，不满足就不执行或不再执行 例如，先洗手，看饭好了没有，没有好，一会来看一次是否好了，一会儿来看一次，直到饭好了，才可是吃饭。这里循环的条件是饭没有好，饭没有好，就循环的来看饭好了没有。 分支结构Python条件语句是通过一条或多条语句的执行结果（True或者False）来决定执行的代码块。 可以通过下图来简单了解分支结构语句的执行过程: 单分支结构：if语句 12345if condition: 代码块 condition必须是一个bool类型，这个地方有一个隐式转换boolcondition)if 1&lt;2: print(&apos;1 less than 2&apos;) 代码块 类似于if语句的冒号后面的就是一个语句块 在if、for、def、class等关键字后使用代码块 多分支结构：if…elif…else语句 123456789if condition1:代码块1elif condition2:代码块2elif condition3:代码块3......else:代码块 分支嵌套：单分支结构嵌套多分支结构例如：给定一个不超过5位的正整数，判断其有几位 1234567891011121314val = input(&apos;&gt;&gt;&gt;&apos;)val = int(val)if val &gt;= 1000: #foldif val&gt;=10000:print(5)else:print(4)else:if val&gt;=100:print(3)elif val &gt;= 10:print(2)else:print(1 循环语句 while语句 语法: 12while condition: block 当条件满足即condition为True，进入循环体，执行block 例如： 1234flag=10while flag:print(flag)flag -= 1 for语句 语法: 12for element in iteratable: block 当可迭代对象中有元素可以迭代，进入循环体，执行block range函数: 创建一个整数列表 举例：打印1~10 12for i in range(10):print(i+1) 循环 else子句 语法： 123456789while condition: blockelse: blockfor element in iteratable: blockelse: block 如果循环正常的执行结束，就执行else子句；如果使用break终止，else子句不会执行 continue中断当前循环的当次执行，继续下一次循环举例：打印10以内的偶数 1234for i in range(10): if i%2 == 1: continue print(i) break终止当前循环举例：计算1000以内的被7整除的前20个数 123456count = 0for i in range(0,1000,7): print(i) count += 1 if count &gt;= 20: break continue、break语句总结 continue和break是循环的控制语句，只影响当前循环，包括while、for循环 如果循环嵌套， continue和break也只影响语句所在的那一层循环 continue和break 不是跳出语句块，所以 if cond: break 不是跳出if，而是终止if外的break所在的循环]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的运算符]]></title>
    <url>%2F2019%2F01%2F02%2FPython%E7%9A%84%E8%BF%90%E7%AE%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[什么是运算符？举个简单的例子：4 + 5 = 9 ，其中4和5被称为操作数，’+’就是运算符 Python运算符算数运算符以下假设变量a为10，变量b为20：以下为算数运算符的实例：1234567891011121314151617181920212223242526272829a = 21b = 10c = 0c = a + bprint (&quot;1: c 的值为：&quot;, c)c = a - bprint (&quot;2: c 的值为：&quot;, c) c = a * bprint (&quot;3: c 的值为：&quot;, c )c = a / bprint (&quot;4: c 的值为：&quot;, c )c = a % bprint (&quot;5: c 的值为：&quot;, c)# 修改变量 a 、b 、ca = 2b = 3c = a**b print (&quot;6: c 的值为：&quot;, c)a = 10b = 5c = a//b print (&quot;7: c 的值为：&quot;, c) 关系运算符以下为关系运算符的实例：123456789101112131415161718192021222324252627282930313233343536a = 21b = 10c = 0 if ( a == b ): print (&quot;1 - a 等于 b&quot;)else: print (&quot;1 - a 不等于 b&quot;) if ( a != b ): print (&quot;2 - a 不等于 b&quot;)else: print (&quot;2 - a 等于 b&quot;) if ( a &lt; b ): print (&quot;3 - a 小于 b&quot;)else: print (&quot;3 - a 大于等于 b&quot;) if ( a &gt; b ): print (&quot;4 - a 大于 b&quot;)else: print (&quot;4 - a 小于等于 b&quot;) # 修改变量 a 和 b 的值a = 5;b = 20;if ( a &lt;= b ): print (&quot;5 - a 小于等于 b&quot;)else: print (&quot;5 - a 大于 b&quot;) if ( b &gt;= a ): print (&quot;6 - b 大于等于 a&quot;)else: print (&quot;6 - b 小于 a&quot;) 赋值运算符以下为赋值运算符的实例：12345678910111213141516171819202122232425a = 21b = 10c = 0 c = a + bprint (&quot;1 - c 的值为：&quot;, c) c += aprint (&quot;2 - c 的值为：&quot;, c) c *= aprint (&quot;3 - c 的值为：&quot;, c) c /= a print (&quot;4 - c 的值为：&quot;, c) c = 2c %= aprint (&quot;5 - c 的值为：&quot;, c) c **= aprint (&quot;6 - c 的值为：&quot;, c) c //= aprint (&quot;7 - c 的值为：&quot;, c) 逻辑运算符以下为逻辑运算符的实例： 位运算符以下为位运算符的实例： 成员运算符以下为成员运算符的实例： 身份运算符以下为身份运算符的实例： 运算符优先级 算数运算符 &gt; 位运算符 &gt; 身份运算符 &gt; 成员运算符 &gt; 逻辑运算符 记不住，用括号 长表达式，多用括号， 易懂、易读]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的基础语法]]></title>
    <url>%2F2019%2F01%2F01%2FPython%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Python的基础语法编码&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;默认情况下，Python 3 源码文件是以UTF-8编码，所有的字符串都是unicode字符串 标识符 标识符的第一个字符必须以字母表中的字母或者下划线 _ 表示，但是建议不要使用 _ 下划线表示，_下划线在Python中有特殊的含义 标识符的其它组成部分必须有字母、数字、下划线组成 标识符对大小写敏感 Python 3中，非ASCII表标识符也被允许使用 标识符不能和Python保留关键字同名 注释: Python中的单行注释是以 # 开头注释 Python中的多行注释可以使用多个 # 号注释，也可以使用单双三引号注释如： 12345678910# 第一个注释print (&quot;Hello, Python!&quot;) # 第二个注释 &apos;&apos;&apos;第三注释第四注释&apos;&apos;&apos;&quot;&quot;&quot;第五注释第六注释&quot;&quot;&quot; 缩进&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python最具特色的就是使用缩进来代表代码块，不需要像其他语言一样使用大括号{ }来代表代码块 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python缩进的空格数是可变的，但是同一个代码块的语言必须包含相同的缩进空格，一般约定使用4个空格设置为缩进&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如：1234if True: print (&quot;True&quot;)else: print (&quot;False&quot;) 续行&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python 通常是一行写完一条语句，但如果语句很长，我们可以在行尾使用反斜杠()来实现多行语句&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如：123print(&quot;hello &quot;+&quot;py\thon &quot;+&apos;world\!&apos;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是在 [ ], { }, 或 ( ) 中的多行语句，不需要使用反斜杠( \ )，可以用’,’结尾直接续行 常量&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一旦赋值就不能改变值的标识符，但是Python中无法定义常量 字面常量&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个单独的量，如12、’abc’、’2341453.03e-9’ 变量&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;赋值后，可以改变值的标识符 数字类型：python中数字有四种类型：整数、布尔型、浮点数和复数。 int (整数), 如 1, 从 Python3开始不区分long和int，long被重命名为int，所以只有int了 bool (布尔), 如 True、False。 float (浮点数), 如 1.23、3E-2，本质上就是使用C语言的double类型 complex (复数), 如 1 + 2j、 1.1 + 2.2j 字符串&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python的字符串可以使用单引号、双引号、单双三引号声明字符串 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python字符串的单双三引号可以跨行使用、也以在其中自由的使用单引号和双引号 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python在字符串前面加上r或者R前缀，表示该字符串不做特殊的处理 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如：123456789s1 = &apos;hello&apos;s2 = &quot;python&quot;s3 = &apos;&apos;&apos;world&apos;&apos;&apos;s4 = &quot;&quot;&quot;!&quot;&quot;&quot;s5 = &apos;abc \n def&apos; # 使用反斜杠(\)+n转义特殊字符s6 = r&apos;abc \n def&apos; # 在字符串前面添加一个 r，表示原始字符串，不会发生转义print(s1,s2,s3,s4)print(s5) print(s6) Python的语言类型 静态语言：静态语言是在编译时期就检查数据类型的，所以必须在声明变量的时候指定数据类型，否则编译会不通过。例如C/C++，Java等 动态语言：动态语言是在运行时期才检查数据类型的，所以在声明变量的时候可以先不指定数据类型，因为在运行期间变量的数据类型是可变的。它会在运行的时候根据赋予变量的值，来判断这个变量的数据类型，然后记录下来。例如Javascript，PHP，Python等。 强类型语言：强类型语言是指，变量的数据类型一旦确定下来，就不能改变了，除非经过强制类型转换。例如Java，C#，Python等。 弱类型语言：弱类型语言是指一个变量可以赋予不同数据类型的值，因为它可以进行隐式的自动类型转换。例如Javascript，C/C++等。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python就是动态语言、强类型语言]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的环境搭建]]></title>
    <url>%2F2019%2F01%2F01%2FPython%E7%9A%84%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[工欲善其事必先利其器,我们想学好Python，就需要先学会搭建运行Python的环境 Windows下搭建Python环境1、在Python官网下载Python的Windows版本Python官网地址：https://www.python.org/ 2、安装Python 勾选将Python3.7 加入到PATH路径选择 Install Now，它里面包括pip包管理直接下一步，这样就将Python的环境安装好了 3、使用Python3.7打开命令行，测试Python和pip的版本 打开Python的两种方法： 在命令行下直接输入Python 在开始菜单找到刚刚安装的Python程序，直接打开即可 4、安装IPython在命令行下输入：1pip install ipython 安装完成后直接输入ipython即可 5、安装Python的IDE工具这里介绍两种IDE工具 安装jupyter 在命令放下输入安装指令： pip install jupyter 安装结束后，直接运行下面代码: jupyter notebook 浏览器直接打开jupyter 工具，如下 这样就可以直接输入Python代码了 安装Pycharm 打开Pycharm官网：https://www.jetbrains.com/pycharm/ 下载社区版的Pycharm 然后直接下一步，下一步安装程序即可 Linux下安装pyenv兼容python3并与python2共存编译安装Python3 安装源码编译安装需求的软件包 1yum -y install gcc make patch gdbm-devel openssl-devel sqlite-devel readline-devel zlib-devel bzip2-devel 下载源代码 1wget https://www.python.org/ftp/python/3.6.6/Python-3.6.6.tgz 解压压缩包 1tar xf Python-3.6.6.tgz 编译源代码 12cd Python-3.6.6/./configure --prefix=/usr/local/python3.6.6 安装程序 1make &amp;&amp; make install 添加环境变量 1echo &quot;export PATH=/usr/local/python3.6.6/bin:$PATH&quot; &gt; /etc/profile.d/pyenv.sh pyenv 安装及常用命令git 安装 安装git 1yum install git -y 克隆pyenv仓库 1git clone https://github.com/pyenv/pyenv.git ~/.pyenv 配置环境变量 123echo &apos;export PYENV_ROOT=&quot;$HOME/.pyenv&quot;&apos; &gt;&gt; ~/.bash_profileecho &apos;export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;&apos; &gt;&gt; ~/.bash_profileecho -e &apos;if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1; then\n eval &quot;$(pyenv init -)&quot;\nfi&apos; &gt;&gt; ~/.bash_profile 激活环境变量 1source ~/.bash_profile pyenv常用命令 12345678pyenv install --list # 列出可安装版本 pyenv install &lt;version&gt; # 安装对应版本 pyenv install -v &lt;version&gt; # 安装对应版本，若发生错误，可以显示详细的错误信息 pyenv versions # 显示当前使用的python版本 pyenv which python # 显示当前python安装路径 pyenv global &lt;version&gt; # 设置默认Python版本 pyenv local &lt;version&gt; # 当前路径创建一个.python-version, 以后进入这个目录自动切换为该版本 pyenv shell &lt;version&gt; # 当前shell的session中启用某版本，优先级高于global 及 local python的虚拟环境 安装插件 创建虚拟的python环境需要pyenv-virtualenv的插件 123git clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenv echo ‘eval “$(pyenv virtualenv-init -)”’ &gt;&gt; ~/.bash_profile source ~/.bash_profile 创建虚拟环境 1pyenv virtualenv 2.7.13 env2713 这是创建了一个名为env2713的python虚拟环境，这个环境的目录位于：~/.pyenv/versions/ 查看python版本 12345678pyenv versions * system (set by /root/.pyenv/version) 2.7.13 2.7.13/envs/env2713 3.6.4 3.6.4/envs/env364 env2713 env364 使用虚拟环境 1234567[xxx]#pyenv activate env364 pyenv-virtualenv: prompt changing will be removed from future release. configure `export PYENV_VIRTUALENV_DISABLE_PROMPT=1’ to simulate the behavior.v364)[xxx]# python Python 3.6.4 (default, Apr 19 2018, 10:35:10) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linux Type “help”, “copyright”, “credits” or “license” for more information. 退出虚拟环境 1pyenv deactivate 环境迁移 123456789pyenv virtualenv 2.7.13 env2713&lt;1&gt;~./pyenv/versions/下名为2.7.14的文件夹拷贝到要迁移的服务器上 &lt;2&gt;修改env364/pyvenv.cfg文件中的home路径(迁移的服务器无需安装任何东西)[xxx env364]# cat pyvenv.cfg home =/root/.pyenv/versions/2.7.13/bin include-system-site-packages = false version = 2.7.13]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[冒泡排序]]></title>
    <url>%2F2018%2F12%2F31%2F%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[最近在学习Python，下面是我的一些笔记 冒泡排序实现思路 ：使用双重for循环，内层变量为i， 外层为j，在内层循环中不断的比较相邻的两个值（i, i+1）的大小，如果i+1的值大于i的值，交换两者位置，每循环一次，外层的j增加1，等到j等于n-1的时候，结束循环 第一次看不懂很正常，不要灰心，下面是使用代码的实现12345678arr = [7, 4, 3, 67, 34, 1, 8]n = len(arr)for j in range(0, n - 1): for i in range(0, n - 1 - j): if arr[i] &gt; arr[i + 1]: arr[i], arr[i + 1] = arr[i + 1], arr[i]print(arr) # [1, 3, 4, 7, 8, 34, 67] 关键点其实在双重for循环变量的配置，我们来分析一下 第一次循环： j = 0, i~n-2 range(0, n-1)第二次循环： j = 1, i~n-3 range(0, n-1-1)第三次循环： j = 2, i~n-4 range(0, n-1-1-1) —&gt; range(0, n-1-j) 理解这一点后，我们就可以换一种写法来实现了123456789arr = [7, 4, 3, 67, 34, 1, 8]for j in range(len(arr) - 1, 0, -1): # [n-1, n-2, ....2, 1] for i in range(0, j): if arr[i] &gt; arr[i + 1]: arr[i], arr[i + 1] = arr[i + 1], arr[i]print(arr) # [1, 3, 4, 7, 8, 34, 67] 优化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;写到这里我们发现，无论是第一种写法还是第二种写法，他的时间复杂度都是O(n ^ 2), 第二种写法也仅仅停留在优化样式的层面，并没有带来性能的提升，想象一下，如果我们输入的本来就是一个有序序列，其实只需要一次循环就够了，所以我们需要针对特殊情况进行优化123456789101112arr = [7, 4, 3, 67, 34, 1, 8]for j in range(len(arr)-1, 0, -1): count = 0 for i in range(0, j): if arr[i] &gt; arr[i + 1]: arr[i], arr[i + 1] = arr[i + 1], arr[i] count += 1 if count == 0: returnprint(arr) # [1, 3, 4, 7, 8, 34, 67] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们在循环中定义了一个变量count，如果第一次循环后count没有变化，就说明输入的是有序序列，这时我们直接return退出循环，这时候的时间复杂度为O(n) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;扩展知识：冒泡排序还是一种稳定性的算法，如果序列中出现两个相同的值的时候，无论选取最大值，还是最小值进行排序，最后两个相同值的前后位置都是不变的。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python历史]]></title>
    <url>%2F2018%2F12%2F31%2FPython%E7%9A%84%E5%8E%86%E5%8F%B2%2F</url>
    <content type="text"><![CDATA[起源&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python的作者，Guido von Rossum，荷兰人。1982年，Guido从阿姆斯特丹大学获得了数学和计算机硕士学位。然而，尽管他算得上是一位数学家，但他更加享受计算机带来的乐趣。用他的话说，尽管拥有数学和计算机双料资质，他总趋向于做计算机相关的工作，并热衷于做任何和编程相关的活儿。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在那个时候，Guido接触并使用过诸如Pascal、C、Fortran等语言。这些语言的基本设计原则是让机器能更快运行。在80年代，虽然IBM和苹果已经掀起了个人电脑浪潮，但这些个人电脑的配置很低。比如早期的Macintosh，只有8MHz的CPU主频和128KB的RAM，一个大的数组就能占满内存。所有的编译器的核心是做优化，以便让程序能够运行。为了增进效率，语言也迫使程序员像计算机一样思考，以便能写出更符合机器口味的程序。在那个时代，程序员恨不得用手榨取计算机每一寸的能力。有人甚至认为C语言的指针是在浪费内存。至于动态类型，内存自动管理，面向对象…… 别想了，那会让你的电脑陷入瘫痪。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种编程方式让Guido感到苦恼。Guido知道如何用C语言写出一个功能，但整个编写过程需要耗费大量的时间，即使他已经准确的知道了如何实现。他的另一个选择是shell。Bourne Shell作为UNIX系统的解释器已经长期存在。UNIX的管理员们常常用shell去写一些简单的脚本，以进行一些系统维护的工作，比如定期备份、文件系统管理等等。shell可以像胶水一样，将UNIX下的许多功能连接在一起。许多C语言下上百行的程序，在shell下只用几行就可以完成。然而，shell的本质是调用命令。它并不是一个真正的语言。比如说，shell没有数值型的数据类型，加法运算都很复杂。总之，shell不能全面的调动计算机的功能。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Guido希望有一种语言，这种语言能够像C语言那样，能够全面调用计算机的功能接口，又可以像shell那样，可以轻松的编程。ABC语言让Guido看到希望。ABC是由荷兰的数学和计算机研究所开发的。Guido在该研究所工作，并参与到ABC语言的开发。ABC语言以教学为目的。与当时的大部分语言不同，ABC语言的目标是“让用户感觉更好”。ABC语言希望让语言变得容易阅读，容易使用，容易记忆，容易学习，并以此来激发人们学习编程的兴趣。比如下面是一段来自Wikipedia的ABC程序，这个程序用于统计文本中出现的词的总数：12345HOW TO RETURN words document: PUT &#123;&#125; IN collection FOR line IN document: FOR word IN split line: IF word not.in collection: INSERT word IN collection RETURN collection &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HOW TO用于定义一个函数。一个Python程序员应该很容易理解这段程序。ABC语言使用冒号和缩进来表示程序块。行 尾没有分号。for和if结构中也没有括号() 。赋值采用的是PUT，而不是更常见的等号。这些改动让ABC程序读起来像一段文字。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 尽管已经具备了良好的可读性和易用性，ABC语言最终没有流行起来。在当时，ABC语言编译器需要比较高配置的电脑才能运行。而这些电脑的使用者通常精通计算机，他们更多考虑程序的效率，而非它的学习难度。除了硬件上的困难外，ABC语言的设计也存在一些致命的问题： 可拓展性差。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ABC语言不是模块化语言。如果想在ABC语言中增加功能，比如对图形化的支持，就必须改动很多地方。比如说不能直接进行IO。ABC语言不能直接操作文件系统。尽管你可以通过诸如文本流的方式导入数据，但ABC无法直接读写文件。输入输出的困难对于计算机语言来说是致命的。你能想像一个打不开车门的跑车么？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 过度革新。ABC用自然语言的方式来表达程序的意义，比如上面程序中的HOW TO 。然而对于程序员来说，他们更习惯 用function或者define来定义一个函数。同样，程序员更习惯用等号来分配量。尽管ABC语言很特别，但学习难度 也很大。 传播困难。ABC编译器很大，必须被保存在磁带上。当时Guido在访问的时候，就必须有一个大磁带来给别人安装ABC编译器。 这样，ABC语言就很难快速传播。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1989年，为了打发圣诞节假期，Guido开始写Python语言的编译器。Python这个名字，来自Guido所挚爱的电视剧Monty Python’s Flying Circus。他希望这个新的叫做Python的语言，能符合他的理想：创造一种C和shell之间，功能全面，易学易用，可拓展的语言。Guido作为一个语言设计爱好者，已经有过设计语言的尝试。这一次，也不过是一次纯粹的hacking行为。 一门语言的诞生&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1991年，第一个Python编译器诞生。它是用C语言实现的，并能够调用C语言的库文。 从一出生，Python已经具有了：类，函数，异常处理，包含表和词典在内的核心数据类型，以及模块为基础的拓展系统。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python语法很多来自C，但又受到ABC语言的强烈影响。来自ABC语言的一些规定直到今天还富有争议，比如强制缩进。 但这些语法规定让Python容易读。另一方面，Python聪明的选择服从一些惯例，特别是C语言的惯例，比如回归等号赋值。Guido认为，如果“常识”上确立的东西，没有必要过度纠结。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Python从一开始就特别在意可拓展性。Python可以在多个层次上拓展。从高层上，你可以直接引入. py文件。在底层，你可以引用C语言的库。Python程序员可以快速的使用Python写. py文件作为拓展模块。但当性能是考虑的重要因素时，Python程序员可以深入底层，写C程序，编译为.so文件引入到Python中使用。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python就好像是使用钢构建房一样，先规定好大的框架。而程序员可以在此框架下相当自由的拓展或更 改。 最初的Python完全由Guido本人开发。Python得到Guido同事的欢迎。他们迅速的反馈使用意见，并参与到Python的改进。Guido和一些同事构成Python的核心团队。他们将自己大部分的业余时间用于hack Python。随后，Python拓 展到研究所之外。Python将许多机器层面上的细节隐藏，交给编译器处理，并凸显出逻辑层面的编程思考。Python程 序员可以花更多的时间用于思考程序的逻辑，而不是具体的实现细节。这一特征吸引了广大的程序员。Python开始流行。 时势造英雄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们不得不暂停我们的Python时间，转而看一看瞬息万变的计算机行业。1990年代初，个人计算机开始进入普通家庭。Intel发布了486处理器，windows发布window 3.0开始的一系列视窗系统。计算机的性能大大提高。程序员开始关注计算机的易用性，比如图形化界面。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Windows 3.0由于计算机性能的提高，软件的世界也开始随之改变。硬件足以满足许多个人电脑的需要。硬件厂商甚至渴望高需求软件的出现，以带动硬件的更新换代。C++和Java相继流行。C++和Java提供了面向对象的编程范式，以及丰富的对象库。在牺牲了一定的性能的代价下，C++和Java大大提高了程序的产量。语言的易用性被提到一个新的高度。我们还记得 ，ABC失败的一个重要原因是硬件的性能限制。从这方面说，Python要比ABC幸运许多。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 另一个悄然发生的改变是Internet。1990年代还是个人电脑的时代，windows和Intel挟PC以令天下，盛极一时。尽管Internet为主体的信息革命尚未到来，但许多程序员以及资深计算机用户已经在频繁使用Internet进行交流，比如 使用email和newsgroup。Internet让信息交流成本大大下降。一种新的软件开发模式开始流行：开源。程序员利用 业余时间进行软件开发，并开放源代码。1991年，Linus在comp.os.minix新闻组上发布了Linux内核源代码，吸引大批hacker的加入。Linux和GNU相互合作，最终构成了一个充满活力的开源平台。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;硬件性能不是瓶颈，Python又容易使用，所以许多人开始转向Python。Guido维护了一个maillist，Python用户就通过邮件进行交流。Python用户来自许多领域，有不同的背景，对Python也有不同的需求。Python相当的开放，又容易拓展，所以当用户不满足于现有功能，很容易对Python进行拓展或改造。随后，这些用户将改动发给Guido，并由Guido决定是否将新的特征加入到Python或者标准库中。如果代码能被纳入Python自身或者标准库，这将极大的荣誉。由于Guido至高无上的决定权，他因此被称为“终身的仁慈独裁者”。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python被称为“Battery Included”，是说它以及其标准库的功能强大。这些是整个社区的贡献。Python的开发者来自不同领域，他们将不同领域的优点带给Python。比如Python标准库中的正则表达是参考Perl，而lambda, map, filter, reduce等函数参考了Lisp。Python本身的一些功能以及大部分的标准库来自于社区。Python的社区不断扩大，进而拥有了自己的newsgroup，网站，以及基金。从Python 2.0开始，Python也从maillist的开发方式，转为完全开源的开发方式。社区气氛已经形成，工作被整个社区分担，Python也获得了更加高速的发展。 到今天，Python的框架已经确立。Python语言以对象为核心组织代码，支持多种编程范式，采用动态类型，自动进行内存回收。Python支持解释运行，并能调用C库进行拓展。Python有强大的标准库。由于标准库的体系已经稳定，所以Python的生态系统开始拓展到第三方包。这些包，如Django、web.py、wxpython、numpy、matplotlib、PIL，将Python升级成了物种丰富的热带雨林。 启示录&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Python崇尚优美、清晰、简单，是一个优秀并广泛使用的语言。Python在TIOBE排行榜中排行第八，它是Google的第三大开发语言，Dropbox的基础语言，豆瓣的服务器语言。Python的发展史可以作为一个代表，带给我许多启示。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在Python的开发过程中，社区起到了重要的作用。Guido自认为自己不是全能型的程序员，所以他只负责制订框架。如果问题太复杂，他会选择绕过去，也就是cut the corner。这些问题最终由社区中的其他人解决。社区中的人才是异常丰富的，就连创建网站，筹集基金这样与开发稍远的事情，也有人乐意于处理。如今的项目开发越来越复杂，越来越庞大，合作以及开放的心态成为项目最终成功的关键。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Python从其他语言中学到了很多，无论是已经进入历史的ABC，还是依然在使用的C和Perl，以及许多没有列出的其他 语言。可以说，Python的成功代表了它所有借鉴的语言的成功。同样，Ruby借鉴了Python，它的成功也代表了Python某些方面的成功。每个语言都是混合体，都有它优秀的地方，但也有各种各样的缺陷。同时，一个语言“好与不好”的评 判，往往受制于平台、硬件、时代等等外部原因。程序员经历过许多语言之争。其实，以开放的心态来接受各个语言，说不定哪一天，程序员也可以如Guido那样，混合出自己的语言。 关键点常识Python的发音与拼写Python的意思是蟒蛇，源于作者喜欢的一部电视剧 (C呢？)Python的作者是Guido van Rossum（龟叔）Python是龟叔在1989年圣诞节期间，为了打发无聊的圣诞节而用C编写的一个编程语言Python正式诞生于1991年Python的解释器如今有多个语言实现，我们常用的是CPython（官方版本的C语言实现），其他还有Jython（可以运行在Java平台）、IronPython（可以运行在.NET和Mono平台）、PyPy（Python实现的，支持JIT即时编译）Python目前有两个版本，Python2和Python3，最新版分别为2.7.12和3.5.2，现阶段大部分公司用的是Python3，Python2即将推出历史舞台 Python优缺点优点简单： Python是一种代表简单主义思想的语言。阅读一个良好的Python程序就感觉像是在读英语一样，尽管这个英语的要求非常严格！Python的这种伪代码本质是它最大的优点之一。它使你能够专注于解决问题而不是去搞明白语言本身。 易学： 就如同你即将看到的一样，Python极其容易上手。前面已经提到了，Python有极其简单的语法。 免费、开源： Python是FLOSS（自由/开放源码软件）之一。简单地说，你可以自由地发布这个软件的拷贝、阅读它的源代码、对它做改动、把它的一部分用于新的自由软件中。FLOSS是基于一个团体分享知识的概念。这是为什么Python如此优秀的原因之一——它是由一群希望看到一个更加优秀的Python的人创造并经常改进着的。 高层语言： 当你用Python语言编写程序的时候，你无需考虑诸如如何管理你的程序使用的内存一类的底层细节。 可移植性： 由于它的开源本质，Python已经被移植在许多平台上（经过改动使它能够工作在不同平台上）。如果你小心地避免使用依赖于系统的特性，那么你的所有Python程序无需修改就可以在下述任何平台上面运行。这些平台包括Linux、Windows、FreeBSD、Macintosh、Solaris、OS/2、Amiga、AROS、AS/400、BeOS、OS/390、z/OS、Palm OS、QNX、VMS、Psion、Acom RISC OS、VxWorks、PlayStation、Sharp Zaurus、Windows CE甚至还有PocketPC、Symbian以及Google基于linux开发的Android平台！ 解释性： 这一点需要一些解释。一个用编译性语言比如C或C++写的程序可以从源文件（即C或C++语言）转换到一个你的计算机使用的语言（二进制代码，即0和1）。这个过程通过编译器和不同的标记、选项完成。当你运行你的程序的时候，连接/转载器软件把你的程序从硬盘复制到内存中并且运行。而Python语言写的程序不需要编译成二进制代码。你可以直接从源代码运行程序。在计算机内部，Python解释器把源代码转换成称为字节码的中间形式，然后再把它翻译成计算机使用的机器语言并运行。事实上，由于你不再需要担心如何编译程序，如何确保连接转载正确的库等等，所有这一切使得使用Python更加简单。由于你只需要把你的Python程序拷贝到另外一台计算机上，它就可以工作了，这也使得你的Python程序更加易于移植。 面向对象： Python既支持面向过程的编程也支持面向对象的编程。在“面向过程”的语言中，程序是由过程或仅仅是可重用代码的函数构建起来的。在“面向对象”的语言中，程序是由数据和功能组合而成的对象构建起来的。与其他主要的语言如C++和Java相比，Python以一种非常强大又简单的方式实现面向对象编程。 可扩展性: 如果你需要你的一段关键代码运行得更快或者希望某些算法不公开，你可以把你的部分程序用C或C++编写，然后在你的Python程序中使用它们。 丰富的库： Python标准库确实很庞大。它可以帮助你处理各种工作，包括正则表达式、文档生成、单元测试、线程、数据库、网页浏览器、CGI、FTP、电子邮件、XML、XML-RPC、HTML、WAV文件、密码系统、GUI（图形用户界面）、Tk和其他与系统有关的操作。记住，只要安装了Python，所有这些功能都是可用的。这被称作Python的“功能齐全”理念。除了标准库以外，还有许多其他高质量的库，如wxPython、Twisted和Python图像库等等。 规范的代码： Python采用强制缩进的方式使得代码具有极佳的可读性。 缺点运行速度，有速度要求的话，用C++改写关键部分吧。国内市场较小（国内以python来做主要开发的，目前只有一些web2.0公司）。但时间推移，目前很多国内软件公司，尤其是游戏公司，也开始规模使用他。中文资料匮乏（好的python中文资料屈指可数）。托社区的福，有几本优秀的教材已经被翻译了，但入门级教材多，高级内容还是只能看英语版。构架选择太多（没有像C#这样的官方.net构架，也没有像ruby由于历史较短，构架开发的相对集中。Ruby on Rails 构架开发中小型web程序天下无敌）。不过这也从另一个侧面说明，python比较优秀，吸引的人才多，项目也多。 Python之禅Beautiful is better than ugly. 优美胜于丑陋（Python以编写优美的代码为目标） Explicit is better than implicit. 明了胜于晦涩（优美的代码应当是明了的，命名规范，风格相似） Simple is better than complex. 简洁胜于复杂（优美的代码应当是简洁的，不要有复杂的内部实现） Complex is better than complicated. 复杂胜于凌乱（如果复杂不可避免，那代码间也不能有难懂的关系，要保持接口简洁） Flat is better than nested. 扁平胜于嵌套（优美的代码应当是扁平的，不能有太多的嵌套） Sparse is better than dense. 间隔胜于紧凑（优美的代码有适当的间隔，不要奢望一行代码解决问题） Readability counts. 可读性很重要（优美的代码是可读的） Special cases aren&apos;t special enough to break the rules. Although practicality beats purity. 即便假借特例的实用性之名，也不可违背这些规则（这些规则至高无上） Errors should never pass silently. Unless explicitly silenced. 不要包容所有错误，除非你确定需要这样做（精准地捕获异常，不写except:pass风格的代码） In the face of ambiguity, refuse the temptation to guess. 当存在多种可能，不要尝试去猜测 There should be one-- and preferably only one --obvious way to do it. 而是尽量找一种，最好是唯一一种明显的解决方案（如果不确定，就用穷举法） Although that way may not be obvious at first unless you&apos;re Dutch. 虽然这并不容易，因为你不是 Python 之父（这里的Dutch是指Guido） Now is better than never. Although never is often better than *right* now. 做也许好过不做，但不假思索就动手还不如不做（动手之前要细思量） If the implementation is hard to explain, it&apos;s a bad idea. If the implementation is easy to explain, it may be a good idea. 如果你无法向人描述你的方案，那肯定不是一个好方案；反之亦然（方案测评标准） Namespaces are one honking great idea -- let&apos;s do more of those! 命名空间是一种绝妙的理念，我们应当多加利用（倡导与号召） Python的应用方向常规软件开发&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Python支持函数式编程和OOP面向对象编程，能够承担任何种类软件的开发工作，因此常规的软件开发、脚本编写、网络编程等都属于标配能力。 科学计算&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;随着NumPy，SciPy，Matplotlib，Enthoughtlibrarys等众多程序库的开发，Python越来越适合于做科学计算、绘制高质量的2D和3D图像。和科学计算领域最流行的商业软件Matlab相比，Python是一门通用的程序设计语言，比Matlab所采用的脚本语言的应用范围更广泛，有更多的程序库的支持。虽然Matlab中的许多高级功能和toolbox目前还是无法替代的，不过在日常的科研开发之中仍然有很多的工作是可以用Python代劳的。 自动化运维&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这几乎是Python应用的自留地，作为运维工程师首选的编程语言，Python在自动化运维方面已经深入人心，比如Saltstack和Ansible都是大名鼎鼎的自动化平台。 云计算&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;开源云计算解决方案OpenStack就是基于Python开发的，搞云计算的同学都懂的。 WEB开发&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于Python的Web开发框架不要太多，比如耳熟能详的Django，还有Tornado，Flask。其中的Python+Django架构，应用范围非常广，开发速度非常快，学习门槛也很低，能够帮助你快速的搭建起可用的WEB服务。 网络爬虫&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;也称网络蜘蛛，是大数据行业获取数据的核心工具。没有网络爬虫自动地、不分昼夜地、高智能地在互联网上爬取免费的数据，那些大数据相关的公司恐怕要少四分之三。能够编写网络爬虫的编程语言有不少，但Python绝对是其中的主流之一，其Scripy爬虫框架应用非常广泛。 数据分析&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在大量数据的基础上，结合科学计算、机器学习等技术，对数据进行清洗、去重、规格化和针对性的分析是大数据行业的基石。Python是数据分析的主流语言之一。 人工智能&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python在人工智能大范畴领域内的机器学习、神经网络、深度学习等方面都是主流的编程语言，得到广泛的支持和应用。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控系统]]></title>
    <url>%2F2018%2F08%2F01%2FZabbix%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[zabbix监控系统zabbix（音同 zæbix）是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。zabbix能监视各种网络参数，保证服务器系统的安全运营；并提供灵活的通知机制以让系统管理员快速定位/解决存在的各种问题。zabbix由2部分构成，zabbix server与可选组件zabbix agent。 zabbix server：zabbix的监控服务器，负责接收agent端发送过来的数据，并做处理。端口：10051 zabbix agent：安装在各个需要监控主机上，负责收集本地数据并发往server端。端口：10050 zabbix server可以通过SNMP，zabbix agent，ping，端口监视等方法提供对远程服务器/网络状态的监视，数据收集等功能，它可以运行在Linux，Solaris，HP-UX，AIX，Free BSD，Open BSD，OS X等平台上。 监控系统具备的四种功能：采集：根据用户的要求，周期性的采集数据存储：对采集到的各种数据进行预约存储。可视化：对采集到的数据，进行可视化。报警：报警系统，在特定的条件下被触发（超出合理的区间） 监控数据采集通道SNMP：Simple Network Management Protocolssh/telnet:IPMI：agent: （master/agent） zabbix程序的组件：zabbix_server：服务端守护进程；zabbix_agentd：agent守护进程；zabbix_proxy：代理服务器，可选组件；zabbix_get：命令行工具，手动测试向agent发起数据采集请求；zabbix_sender：命令行工具，运行于agent端，手动向server端发送数据；zabbix_java_gateway: java网关；zabbix_database：MySQL或PostgreSQL；zabbix_web：Web GUI 端口号：10051 https://www.zabbix.com/download （官方下载安装地址） 服务端快速安装脚本1234567891011121314151617181920212223242526272829#!/bin/bash#下载安装zabbix包wget https://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpmyum install zabbix-release-3.4-2.el7.noarch.rpm #安装zabbix yum install -y zabbix-server-mysql zabbix-web-mysql zabbix-agen#安装启动 mariadb数据库yum install -y mariadb-server httpdsystemctl start mariadb.service#创建数据库mysql -e &apos;create database zabbix character set utf8 collate utf8_bin;&apos;mysql -e &apos;grant all privileges on zabbix.* to zabbix@192.168.2.7 identified by &quot;zabbix&quot;;&apos;#导入数据zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz|mysql -uzabbix -pzabbix zabbix#配置zabbixserver连接mysqlsed -i.ori &apos;115a DBPassword=zabbix&apos; /etc/zabbix/zabbix_server.conf#添加时区sed -i.ori &apos;18a php_value date.timezone Asia/Shanghai&apos; /etc/httpd/conf.d/zabbix.conf#启动服务systemctl start zabbix-serversystemctl start httpd http://192.168.2.7/zabbix/（在浏览器上访问此路径并安装zabbix;此IP地址为zabbix主服务的IP地址） 配置zabbix功能： 如果需要更改不需要重新安装，只要去修改上面的配置文件就可以了 切换中文版： updata 应用即可。 监控一个独立的主机(zabbix-agent监控的主机)：（简单的手动添加的监控选项和参数：） 12345678910111213141516171819#安装zabbix源、aliyu nYUM源curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repocurl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.reporpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm# 安装zabbix客户端yum install -y zabbix-agent zabbix-sendervim /etc/zabbix/zabbix_agentd.conf （修改配置文件）Server=192.168.2.7（更改为 zabbix-server服务器的地址）97行ServerActive=192.168.2.7 （更改为 zabbix-server服务器的地址）138行Hostname=nod01 （设定本机的主机名）149行systemctl start zabbix-agent （启动服务）ss -nult (查看端口号；10050) 然后再浏览器上的zabbix的主界面里添加刚才的主机： 添加新的组： 添加新的主机： 创建一个新的应用级： 创建一个监控项： 最后点击添加就可以了。 再添加一个触发器：（一个监控项可定义多个触发器来响应不同级别的警告） 查看监控的状态： 一旦检测中有触发器报警，就需要定义actio(动作)，来对触发器的警告做相应的处理。 实验：实现nginx的简单的监控和报警后的触发操作在从被监测的主机上安装nginx服务，并添加新的监控项，定义新的触发器，并且定义action在触发器报警后做相应的处理。 在被检测的服务器上：yum install nginx -y；（装包）nginx (启动服务) 创建一个新的监控项在nod01上： 在创建一个新的触发器针对nginx做警告处理的 添加之后查看已创建好的nginx的触发器： 在监测—&gt;最新数据—-&gt;nod01可以看到nginx监控现在处于正常状态。 如果此时将nginx服务手动暂停的化，zabbix监控就会显示已经down了。 在此将服务手动开启后此时监控又正常了。此时在监测—&gt;触发器;会触发一个事件。需要点击确认一下。 创建一个action(动作)来解决nginx触发器出现警告的故障：（首先让他远程自动重启，如果还是失败，就发送信息） 配置—-&gt;动作，去创建一个action： 为了测试，需要在nod01上添加zabbix的管理员权限：（只为临时测试使用，生产中是危险的） visudo 还需要在被监测的服务器上： 12345vim /etc/zabbix/zabbix_agentd.confEnableRemoteCommands=1 （允许agent在本机执行命令）74行systemctl restart zabbix-agent （重启服务让修改的agent配置文件生效） 最后手动将被监测的nginx服务停掉，查看是否能够自己修复。（如果有问题查自定义脚本是否写错） 定义媒介来实现出现警告的通过邮箱的发送：（仅在本机测试使用）在本机zabbix-server服务器上安装邮件包;yum install mailx 管理——&gt;报警媒介类型 ;创建一个报警媒介 点击添加即可。由于是本机的邮件服务，所以只能在本机的用户之间发送。 在次：管理—-&gt;用户—-&gt;admin 然后添加nginx触发警报的第二步的操作： 恢复操作也给用户发送邮件信息： 现在就可以实现了；当nginx执行动作里的脚本没有将nginx服务重新启动起来，就会执行第二步的操作，发送邮件给定义的用户通知消息。 使用脚本来创建脚本报警的方式： 脚本放置路径：zabbix_server.conf配置文件中AlertScriptsPath参数定义的路径下；/usr/lib/zabbix/alertscripts/ （只要将脚本放在此目录下，直接调用脚本名称就可以了） zabbix 3.0之后的版本，此三个变量定义为内部宏：{ALERT.SENDTO}{ALERT.SUBJECT}{ALERT.MESSAGE} Python报警脚本可以在互联网上查找。（安装好python的执行环境） 脚本示例：给与执行权限，测试执行成功就可以。 123456789101112131415161718192021222324252627282930313233343536#!/usr/bin/python#coding:utf-8import smtplibfrom email.mime.text import MIMETextfrom email.header import Headerfrom email.utils import parseaddr, formataddrimport sysdef formatAddr(s):name, addr = parseaddr(s)return formataddr((Header(name, ‘utf-8’).encode(), addr))def send_mail(to_list,subject,content):mail_host = ‘smtp.exmail.qq.com’ mail_user = ‘973366980@qq.com’mail_pass = ‘密码’\#以上内容根据你的实际情况进行修改msg = MIMEText(content,”,’utf-8′)msg[‘Subject’] = Header(subject, ‘utf-8’).encode()msg[‘From’] = formatAddr(‘zabbix监控 &lt;%s&gt;’ % mail_user).encode()msg[‘to’] = to_listtry:s = smtplib.SMTP()s.connect(mail_host)s.login(mail_user,mail_pass)s.sendmail(mail_user,to_list,msg.as_string())s.close()return Trueexcept Exception,e:print str(e)return Falseif __name__ == “__main__”:send_mail(sys.argv[1], sys.argv[2], sys.argv[3]) 创建图形来显示数据的信息： 定义好图形后再桌面上添加多个图形： 首先创建一个聚合图： zabbix的宏的定义： 宏：macro，预设的文本替换模式；变量级别：全局：Administration –&gt; General –&gt; Macros模板：编辑模板 –&gt; Macros主机：编辑主机 –&gt; Macros （仅对当前主机一个有效的） 假如在三个级别都定义了宏，则主机级别的生效 类型：内建宏：{MACRO_NAME}文档参考：https://www.zabbix.com/documentation/3.4/manual/appendix/macros/supported_by_location 自定义：{$MACRO_NAME}命名方式：大写字母、数字和下划线；不能以数字开头 1 . 设置全局宏的界面： 在设置参数的时候，有关80端口的，就可以不用写80，而是用宏替换。（好处：当需要更改多处的80端口改为8080；时不需要一个个的去修改了，只需要在此处将宏的变量更改一下就可以了） 2 .配置主机的宏的界面： 使用模板来构建监控选项： 示例：在已有主机上添加关于linux监控的选项；（使用模板来添加） 也可以自己创建一个新的模板然后自定义（跟配置主机一样） 使用网络上的脚本来构建监控 选项： https://share.zabbix.com/ （在此网站上可以查找所需要的模板） 要选择相对应的版本即可。 模板文件下载完成后，导入到zabbix模板库里面。就可以调用导入的模板文件了。 在下面搜索就可以查看了。 在被监控的服务器上： vim /etc/zabbix/zabbix_agentd.d/test.conf （新建配置文件） 定义一个key,然后在监控端就可以看到此key的值。 UserParameter=memory.used,/usr/bin/free |/usr/bin/awk’/^Mem/{print $3}’ （内容） systemctl restart zabbix-agent （重启服务，然后让key值生效） yum install zabbix-get -y （在服务器端下载手动测试的工具） zabbix_get -s 192.168.60.21 -p 10050 -k “memory.used” （手动测试在服务器端）]]></content>
      <categories>
        <category>自动化运维</category>
      </categories>
      <tags>
        <tag>zabbix监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Virtualization虚拟化技术介绍]]></title>
    <url>%2F2018%2F07%2F27%2FVirtualization%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[一、虚拟化基本概念什么是虚拟化？虚拟化是把物理的事物转换成为逻辑的方式表现出来 常见的虚拟化 内存虚拟化：内存页面Page File 磁盘虚拟化：RAID，Volume 网络虚拟化：vlan，vxlan FusionSphere-x86/x64服务器的虚拟化 计算能力：CPU/Memory的虚拟化 存储：VIMS文件系统 网络：分布式虚拟交换机 虚拟化的优势传统物流服务器 操作系统与物理服务器绑定 1.难以迁移 2.难以扩展 3.空间占用高 4.可靠性难以控制 5.资源利用率低 6.难以管理 虚拟化服务器 操作系统与物理服务器分离 1.易于迁移、扩展、资源整合 2.标准化的虚拟硬件 3.由一系列文件组成，易于保护 虚拟化常见概念Guset OS：运行在虚拟机上的OS Guset Machine：虚拟出来的虚拟机 Hypervisor：也叫VMM (Virtual Machine Monitor)虚拟机监控器， Host OS：运行在物理机上的OS Host Machine：物理机 模拟：emulation x86 -&gt; arm sata -&gt; scsi 完全虚拟化：Full Virtualization 开发人员直接针对物理平台开发即可，性能能达到硬件IDE的40% CPU: BT HVM 半虚拟化：Para Virtualization 也叫不完全虚拟化，开发人员需针对虚拟化平台开发,性能能达到硬件IDE的80% 建议：生产环境一般使用半虚拟化技术：简单、性能好、易迁移上云 IAAS**：**CloudOS上部署xen或kvm这样的虚拟机，基础架构即服务 PAAS**：**CloudOS上直接提供一个容器作为平台，不需要用户安装操作系统，平台即服务 SAAS**：**本机只需运行个浏览器，其他全交给云来解决，软件即服务 以此延伸，近些年还出现了： DBaas：数据库即服务 LBaas：负载均衡即服务 …… 二、虚拟化常见架构类型根据在整个系统中的位置不同，虚拟化架构分为以下几种： 1.寄居虚拟化架构 2.裸金属虚拟化架构 3.操作系统虚拟化架构 4.混合虚拟化架构 (一)寄居虚拟化架构寄居虚拟化架构指在宿主操作系统之上安装和运行虚拟化程序，依赖于宿主操作系统对设备的支持和物理 资源的管理。（类似 Vmware Workstation 的程序） 优点：简单、易于实现 缺点：1.安装和运行应用程序依赖主机操作系统对设备的支持； 2.管理开销较大，性能损耗大 代表产品：**VMware Workstation** 2**）裸金属虚拟化架构**裸金属虚拟化架构指直接在硬件上面安装虚拟化软件，再在其上安装操作系统和应用，依赖虚拟层内核和 服务器控制台进行管理。 优点：1.虚拟机不依赖操作系统 2.支持多种操作系统，多种应用 缺点：虚拟层内核开发难度大 代表产品：**WNware ESXServer、Citrix XenServer** (三)操作系统虚拟化架构操作系统虚拟化架构在操作系统层面增加虚拟服务器功能。操作系统虚拟化架构把单个的操作系统划分为 多个容器，使用容器管理器来进行管理。 宿主操作系统负责在多个虚拟服务器（即容器）之间分配硬件资源，并且让这些服务器彼此独立。 优点：1.简单、易于实现 2.管理开销非常低 缺点：隔离性查，多容器共享同一操作系统 代表产品：**Docker** (四)混合虚拟化架构混合虚拟化架构将一个内核级驱动器插入到宿主操作系统内核。这个驱动器作为虚拟硬件管理器来协调虚 拟机和宿主操作系统之间的硬件访问。 优点：1.相对于寄居虚拟化架构，没有冗余，性能高； 2.可支持多种操作系统 缺点：需底层硬件支持虚拟化拓展功能 代表产品：**Redhat KVM** 三、Xen架构简介 Domain U**：**运行在Xen Hypervisor上的普通虚拟机 Domain 0**：**运行在Xen Hypervisor上的特权虚拟机。它拥有访问物理I/O资源的权限，同时和系统上运 行的其他虚拟机进行交互。Domain 0必须要在其他Domain启动之前启动。 虚拟机复用有限的外设资源：1)Hypervisor截获虚拟机对物理硬件的访问请求，然后通过软件的方式来模拟真实设备的效果； 2)前端设备驱动将数据通过VMM提供的接口转发到后端驱动 3)后端驱动VM的数据进行分时分通道的处理 四、CPU虚拟化原理介绍(一)基于软件的CPU的虚拟化基于软件的 CPU 虚拟化，故名思议，就是通过软件的形式来模拟每一条指令。通过前面的文章我们知道常 用的软件虚拟化技术有两种：优先级压缩和二进制代码翻译。这两种是通用技术，可以用在所有虚拟化类 型中。我们就结合 intercept 和 virtualize 来看看 CPU 软件虚拟化是怎么做的。 首先，一些必须的硬件知识要知道，X86 体系架构为了让上层的软件（操作系统、应用程序）能够访问硬 件，提供了四个 CPU 特权级别，Ring 0 是最高级别，Ring 1 次之，Ring 2 更次之，Ring 3 是最低级别。 一般，操作系统由于要直接访问硬件和内存，因此它的代码需要运行在最高级别 Ring 0 上，而应用程序的 代码运行在最低级别 Ring 3 上，如果要访问硬件和内存，比如设备访问，写文件等，就要执行相关的系统 调用，CPU 的运行级别发生从 Ring 3 到 Ring 0 的切换，当完成之后，再切换回去，我们熟悉的用户态和 内核态切换的本质就来自这里。 虚拟化的实现也是基于这个思想，VMM 本质上是个 Host OS，运行在 Ring 0 上，Guest OS 运行在 Ring 1 上，再往上是相应层次的应用程序运行在 Ring 2 和 Ring 3 上。 (二)基于硬件的CPU虚拟化上面的这种截获再模拟的纯软件的虚拟化方式，势必是性能非常低的。那怎么样提高性能呢，有一种改进 的方式是修改 Guest OS 中关于特权指令的相关操作，将其改为一种函数调用的方式，让 VMM 直接执 行，而不是截获和模拟，这样就能在一定程度上提高性能。 但这种方式并不通用，要去改 Guest OS 的代码，只能看作是一种定制。为了能够通用，又能够提高性 能，就只能从硬件上去做文章了。所以，后来，以 Intel 的 VT-x 和 AMD 的 AMD-V 为主的硬件辅助的 CPU 虚拟化就被提出来（Intel VT 包括 VT-x （支持 CPU 虚拟化）、EPT（支持内存虚拟化）和 VT- d（支持 I/O 虚拟化）。 CPU 硬件辅助虚拟化在 Ring 模式的基础上引入了一种新的模式，叫 VMX 模式。它包括根操作模式 （VMX Root Operation）和非根操作模式（VMX Non-Root Operation）。 这两种模式都有 Ring 0 – Ring 3 的特权级。所以，在描述某个应用程序时，除了描述其属于哪个特权级， 还要指明其处于根模式还是非根模式。 引入这种模式的好处就在于，Guest OS 运行在 Ring 0 上，就意味着它的核心指令可以直接下达到硬件层 去执行，而特权指令等敏感指令的执行则是由硬件辅助，直接切换到 VMM 执行，这是自动执行的，应用 程序是感知不到的，性能自然就提高了。 KVM 是一种硬件辅助的虚拟化技术，支持 Intel VT-x 和 AMD-v 技术。 五、内存虚拟化原理介绍通过各种内存复用技术（零页共享、内存气泡和内存交换）与合理的调度，使主机上的虚拟机对内存的 访问及时响应，减少内存复用开启情况下的虚拟机性能损耗 (一)零页共享 将主机上的多个虚拟机的零页内存在物理内存中进行合并，释放出更多的物理内存供虚拟机使用。 (二)内存气泡 Hypervisor通过内存气泡将较空闲虚拟机内存释放给内存使用率较高的虚拟机，用来提升内存利用率。 内存气泡技术对虚拟机性能影响较小，但是在内存减少时，用户能感知到 (三)内存交换 当虚拟机的内存压力较大时，将虚拟机内存页交换到磁盘中从而释放内存； 当虚拟机内存页交换到磁盘后，虚拟机的性能将下降比较明显]]></content>
  </entry>
  <entry>
    <title><![CDATA[Tomcat介绍及相关实验]]></title>
    <url>%2F2018%2F07%2F24%2FTomcat%E4%BB%8B%E7%BB%8D%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一、tomcat介绍Tomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，由 Apache、Sun 和其他一些公司及个人共同开发而成。因为Tomcat 技术先进、性能稳定，而且免费，因而 深受Java 爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的Web 应用服务器。 Tomcat 服务器是一个免费的开放源代码的Web 应用服务器，属于轻量级应用服务器，在中小型系统和并 发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选。对于一个初学者来说，可以这 样认为，当在一台机器上配置好Apache 服务器，可利用它响应HTML（标准通用标记语言下的一个应用） 页面的访问请求。实际上Tomcat是Apache 服务器的扩展，但运行时它是独立运行的，所以当你运行 tomcat 时，它实际上作为一个与Apache 独立的进程单独运行的。Apache 为HTML页面服务，而 Tomcat 实际上运行JSP 页面和Servlet。 官方网站：http://tomcat.apache.org/ 如何安装tomcat？方法一：本地yum安装(base源) systemctl start tomcat 默认监听：8080，8005(管理端口)，8009 方法二：ASF官网站点下载安装 官方网站下载地址：https://tomcat.apache.org/download-90.cgi wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.24/bin/apache-tomcat-8.5.24.tar.gz tar -zxf apache-tomcat-8.5.24.tar.gz 启动tomcat ./apache-tomcat-8.5.24/bin/startup.sh 添加环境变量CATELINA_HOME vim /etc/profile.d/ export CATALINA_BASE=/usr/local/tomcat export PATH=$CATALINA:$PATH 服务控制由catalina脚本执行 catalina.sh start 此时，浏览器访问localhostIp:8080就可以看到tomcat默认界面了 二、tomcat服务配置Tomcat的主要目录结构： bin：脚本，及启动时用到的类； conf：配置文件目录； lib：库文件，Java类库，jar； logs：日志文件目录； temp：临时文件目录； webapps：webapp的默认目录； work：工作目录，存放编译后的字节码文件； Tomcat的配置文件构成：server.xml：主配置文件； web.xml：每个webapp只有“部署”后才能被访问，它的部署方式通常由web.xml进行定义，其存放位置为 WEB-INF/目录中；此文件为所有的webapps提供默认部署相关的配置； context.xml：每个webapp都可以使用的配置文件，它通常由专用的配置文件context.xml来定义，其存 放位置为WEB-INF/目录中；此文件为所有的webapps提供默认配置； tomcat-users.xml：用户认证的账号和密码文件；角色（role），用户（User）；此文件在tomcat启动 时被装入内存； catalina.policy：当使用-security选项启动tomcat时，用于为tomcat设置安全策略； catalina.properties：Java属性的定义文件，用于设定类加载器路径，以及一些与JVM调优相关参数； logging.properties：日志系统相关的配置； Tomcat的核心组件：server.xml ………… 每一个组件都由一个Java“类”实现，这些组件大体可分为以下几个类型： 顶级组件：Server 服务类组件：Service 连接器组件：http, https, ajp（apache jserv protocol） 容器类：Engine, Host, Context 被嵌套类：valve, logger, realm, loader, manager, … 集群类组件：listener, cluster, … 一般 web 项目路径结构 webapp归档格式： .war：webapp; .jar：EJB的类打包文件(类库)； .rar：资源适配器类打包文件； .ear：企业级webapp； … 部署(deploy)webapp的相关操作：deploy：将webapp的源文件放置于目标目录(网页程序文件存放目录)，配置tomcat服务器能够基于 web.xml和context.xml文件中定义的路径来访问此webapp；将其特有的类和依赖的类通过class loader装载 至JVM； 部署有两种方式： 自动部署：auto deploy 手动部署: 冷部署：把webapp复制到指定的位置，而后才启动tomcat； 热部署：在不停止tomcat的前提下进行部署； 部署工具：manager、ant脚本、tcd(tomcat client deployer)等； undeploy：拆除（反部署），停止webapp，并从tomcat实例上卸载webapp； start：启动处于停止状态的webapp； stop：停止webapp，不再向用户提供服务；其类依然在jvm上； redeploy：重新部署； Tomcat基础架构 连接器(connector)负责接收请求并传给引擎，由引擎运行jsp代码并返回给连接器 Server：代表整个服务器，一个server可以包含多个service 一个Service可包含一个Engine，多个Connecter Connector：连接器类元素，代表通信接 Engine：为特定的Service组件处理客户请求，要包含多个Host Host：为特定的虚拟主机组件处理客户请求，可包含多个Context Context：为特定的Web应用处理所有的客户请求 Tomcat的常用组件配置：Server 功能：代表tomcat instance，即表现出的一个java进程；监听在8005端口，只接收“SHUTDOWN”。各 server监听的端口不能相同，因此，在同一物理主机启动多个实例时，需要修改其监听端口为不同的端 口； port=”-1″, shutdown=”RANDOM_CHARCTER” Service 功能：用于实现将一个或多个connector组件关联至一个engine组件； 一个Server中可以有多个Service Connector 功能：负责接收请求，常见的有三类http/https/ajp； 进入tomcat的请求可分为两类： (1) standalone : 请求来自于客户端浏览器； (2) 由其它的web server反代：来自前端的反代服务器； nginx –&gt; http connector –&gt; tomcat httpd(proxy_http_module) –&gt; http connector –&gt; tomcat httpd(proxy_ajp_module) –&gt; ajp connector –&gt; tomcat httpd(mod_jk) –&gt; ajp connector –&gt; tomcat 属性： port=”8080″ protocol=”HTTP/1.1″ connectionTimeout=”20000″ address：监听的IP地址；默认为本机所有可用地址； maxThreads：最大并发连接数，默认为200； enableLookups：是否启用DNS查询功能； acceptCount：等待队列的最大长度； secure： sslProtocol： Engine 功能：Servlet实例，即servlet引擎，其内部可以一个或多个host组件来定义站点； 通常需要通过 defaultHost来定义默认的虚拟主机； 属性： name= #此引擎的逻辑名称，用于日志和错误消息。 defaultHost=”localhost” #默认主机名，用于标识将处理指向此服务器上主机名称但未在此配置文件中配 置的请求的主机。 jvmRoute= Host 功能：位于engine内部用于接收请求并进行相应处理的主机或虚拟主机 Host元素表示一个虚拟主机 常用属性说明： name：名称；用于日志输出 appBase：虚拟主机对应的应用基础路径，可以是个绝对路径, 或${CATALINA_BASE}相对路径 xmlBase：虚拟主机XML基础路径,里面应该有Context xml配置文件；可以是个绝对路径, 或${CATALINA_BASE}相对路径 createDirs：当appBase和xmlBase不存在时,是否创建目录；默认为true autoDeploy：是否周期性的检查appBase和xmlBase并deploy web应用和context描述符；默认为true deployIgnore：忽略deploy的正则 deployOnStartup：Tomcat启动时是否自动deploy；默认为true Context 功能：Context元素表示一个Web应用程序，它在特定的虚拟主机中运行。每个Web应用程序都基于Web 应用程序存档（WAR）文件，或者包含相应的解包内容的相应目录 常用属性说明： altDDName：web.xml部署描述符路径；默认 /WEB-INF/web.xml docBase：Context的Root路径，和Host的appBase相结合, 可确定web应用的实际目录 path ：web应用的context path；如果为根路径,则配置为空字符串(“”), 不能不配置 privileged：是否使用Tomcat提供的manager servlet reloadable：/WEB-INF/classes/ 和/WEB-INF/lib/ 目录中class文件发生变化是否自动重新加载；默认为false swallowOutput：true情况下, System.out和System.err输出将被定向到web应用日志中；默认为false Valve Valve存在多种类型： 定义访问日志：org.apache.catalina.valves.AccessLogValve 定义访问控制：org.apache.catalina.valves.RemoteAddrValve 三、实验：实现tomcat应用部署及版本控制前期准备：本节实验全部以yum安装为准,tomcat版本：tomcat-7.0.76-6.el7.noarch 创建一个测试类应用 mkdir -pv /usr/share/tomcat/webapps/test/{classes,lib,WEB-INF} tomcat端测试： 浏览器打开：tomcat.wxlinux.com/test/ 当应用被部署上线后，就会在/usr/share/tomcat/work/Catalina/localhost/test目录生成源码和类 库文件 版本部署软连接实现部署部署 软连接方式不支持热部署，需重启tomcat服务后才能连接成功 systemctl restart tomcat 生产环境中一般使用git来实现版本控制，可以使用一个目录名包含多个版本程序 四、实验：tomcat创建虚拟主机Host及Context定义虚拟主机修改server配置文件添加一个host配置： vim /etc/tomcat/server.xml 写入一个测试类应用，内容如下： mkdir /data/webapps/ROOT/{classes,lib,META-INF,WEB-INF} -pv 为了方便访问，这里添加主机名解析到hosts文件中 vim /etc/hosts 192.168.30.18 node1.wxlinux.com 浏览器访问node1.wxlinux.com:8080 自定义host日志：vim /etc/tomcat/server.xml 当host被访问时，后生成日志： 创建一个context： vim /etc/tomcat/server.xml 在context定义的目录中创建另外一个应用，为了方便对比，仅仅改变字体颜色： 测试访问： 五、实验：开启tomcat管理页面前期准备：虚拟机一台 系统版本：CentOS 7.4 IP：192.168.30.27 manager管理页面：vim /etc/tomcat/tomcat-users.xml 浏览器打开192.168.30.27:8080点击红色区域 管理界面可进行对web的管理，如停止，开始，卸载部署等操作 图形界面热部署WAR文件： HostManager管理页面：vim /etc/tomcat/tomcat-users.xml 测试访问：]]></content>
  </entry>
  <entry>
    <title><![CDATA[Varnish缓存服务介绍及相关实验]]></title>
    <url>%2F2018%2F07%2F19%2FVarnish%E7%BC%93%E5%AD%98%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一、缓存基本概念缓存是指把对某些请求的结果缓存下来，下次请求直接使用数据响应，这样极大的节省了系统获取源数据 资源的时间，若我们把大量的请求结果都使用缓存服务器来响应，那么我们可以大大减少计算机数量减少 成本。 数据缓存：从后端关系系数据库加载到应用服务器进行缓存，存在于数据库与服务器之间，一般是缓存 SELECT语句。常用有：redis，memcached 页面缓存：对静态内容进行缓存，存在于调度器与WEB服务器之间，通常只是缓存GET,HEAD方法的请 求。常用有：squid-cache,varinish-cache 缓存命中：hit，多次查询能够在缓存中找到对应项 衡量缓存命中率有两种标准： 字节命中率 请求命中率 一般来说，当缓存命中率30%以上能够带来正向作用 代理式缓存：页面缓存一般都是代理式缓存，要成为代理式缓存，首先它是台代理服务器 旁挂式缓存：数据缓存一般都是旁挂式缓存 页面缓存squid-cache：历史悠久页面缓存系统，类似于Apache与Nginx的关系 varinish-cache：轻量级页面缓存系统，但稳定性不如squid-cache 基于页面过期时间的缓存机制(**早期)**： 当客户端发起请求时，先到缓存服务器中查找有无对应的缓存，如果没有则将请求发送到后端服务器，后‘’ 端服务器发送响应报文并附带过期时间(expires) 存在问题： (1)当后端数据发送变化时，缓存变为旧内容 (2)当缓存服务器中数据过期时，有可能还会收到相同的客户端请求 根据条件式验证的缓存机制： 存在问题： 粒度大，1秒，可能会出现缓存查询一致，其实内容已发生变化，得到过期内容 解决方法： 添加一个标签Etag，将标签与查询结果一起返回 http 1.1时代：过期时间+条件式验证组合使用 缓存预热：通过自己下载一些网络请求来访问缓存服务器以达到最佳状态 private cache：私有缓存，如浏览器缓存 public cache：公共缓存，可能不止一级，如CDN,页面缓存系统 一般公有缓存+私有缓存应该能到达90%的缓存命中率 CDN：Ccontent Delivery Network内容分发系统 距离判定 链路状态；判定 二、Varnish缓存服务介绍epel源提供，支持三类缓存： 内存缓存：malloc，重启后所有缓存项失效； 磁盘缓存：file，黑盒，重启后所有缓存项失效； 持久缓存：persistent(实验阶段)，黑盒，重启后所有缓存项有效 默认监听端口：6081,6082(管理端口) Varinish**官方架构图** varnish主要包含三个部分： management：提供管理接口，并控制缓存进程的特性 child/cache：提供缓存功能，记录日志，访问控制，后端服务器管理 vcl：给child/cache提供配置文件的编译 Varinishd服务配置：/etc/varnish/varnish.params： 配置varnish服务进程的工作特性，例如监听的地址和端口，缓存机制； /etc/varnish/default.vcl：配置各Child/Cache线程的工作属性； 主程序： /usr/sbin/varnishd CLI interface： /usr/bin/varnishadm Shared Memory Log交互工具： /usr/bin/varnishhist /usr/bin/varnishlog /usr/bin/varnishncsa /usr/bin/varnishstat /usr/bin/varnishtop 测试工具程序： /usr/bin/varnishtest VCL配置文件重载程序： /usr/sbin/varnish_reload_vcl Systemd Unit File： /usr/lib/systemd/system/varnish.service #varnish服务 /usr/lib/systemd/system/varnishlog.service #logger daemon /usr/lib/systemd/system/varnishncsa.service #lgger daemon in apache format 实验：实现varnishd**缓存基本功能**前期准备： 虚拟机2台 varinishd服务器：192.168.30.10 系统版本：CentOS 7.4 node1：192.168.30.27 系统版本：CentOS 7.4 varinish： yum install varnish systemctl start varnishd 此时访问varnish的6081端口，显示连接后端失败 配置varnish： vim /etc/varnish/default.vcl varnish_reload acl node1： 开启WEB服务 echo backend Server node1 &gt; /var/www/html/index.html 此时再次访问192.168.30.10:6081，基本的varnish缓存功能就实现了 三、VCL语言与状态引擎相关概念： ”域“专有类型的配置语言； state engine：状态引擎； VCL有多个状态引擎，状态之间存在相关性，但状态引擎彼此间互相隔离；每个状态引擎可使用return(x) 指明关联至哪个下一级引擎；每个状态引擎对应于vcl文件中的一个配置段，即为subroutine vcl_hash –&gt; return(hit) –&gt; vcl_hit varnish状态引擎类型：varnish 4.0： ​ vcl_init ​ vcl_recv ​ vcl_hash ​ vcl_hit ​ vcl_pass ​ vcl_miss ​ vcl_pipe ​ vcl_waiting ​ vcl_purge ​ vcl_deliver ​ vcl_synth ​ vcl_fini ​ ​ vcl_backend_fetch ​ vcl_backend_response ​ vcl_backend_error vcl_recv的默认配置： sub vcl_recv { if (req.method == “PRI”) { / We do not support SPDY or HTTP/2.0 / return (synth(405)); } if (req.method != “GET” &amp;&amp; req.method != “HEAD” &amp;&amp; req.method != “PUT” &amp;&amp; req.method != “POST” &amp;&amp; req.method != “TRACE” &amp;&amp; req.method != “OPTIONS” &amp;&amp; req.method != “DELETE”) { / Non-RFC2616 or CONNECT which is weird. / return (pipe); } if (req.method != “GET” &amp;&amp; req.method != “HEAD”) { / We only deal with GET and HEAD by default / return (pass); } if (req.http.Authorization || req.http.Cookie) { / Not cacheable by default / return (pass); } return (hash); } } Client Side： vcl_recv, vcl_pass, vcl_hit, vcl_miss, vcl_pipe, vcl_purge, vcl_synth, vcl_deliver vcl_recv： hash：vcl_hash pass: vcl_pass pipe: vcl_pipe synth: vcl_synth purge: vcl_hash –&gt; vcl_purge vcl_hash： lookup： hit: vcl_hit miss: vcl_miss pass, hit_for_pass: vcl_pass purge: vcl_purge Backend Side： vcl_backend_fetch, vcl_backend_response, vcl_backend_error 两个特殊的引擎： vcl_init：在处理任何请求之前要执行的vcl代码：主要用于初始化VMODs； vcl_fini：所有的请求都已经结束，在vcl配置被丢弃时调用；主要用于清理VMODs； 格式： (1) VCL files start with vcl 4.0; (2) //, # and / foo / for comments; (3) Subroutines are declared with the sub keyword; 例如sub vcl_recv { …}； (4) No loops, state-limited variables（受限于引擎的内建变量）； (5) Terminating statements with a keyword for next action as argument of the return() function, i.e.: return(action)；用于实现状态引擎转换； (6) Domain-specific; Finite State Machine (1) Each request is processed separately; (2) Each request is independent from others at any given time; (3) States are related, but isolated; (4) return(action); exits one state and instructs Varnish to proceed to the next state; (5) Built-in VCL code is always present and appended below your own VCL; 语法： sub subroutine { ​ … } if CONDITION { ​ … } else { ​ … } return(), hash_data() t-in Functions and Keywords 函数： regsub(str, regex, sub) regsuball(str, regex, sub) ban(boolean expression) hash_data(input) synthetic(str) Keywords: call subroutine， return(action)，new，set，unset 操作符： ==, !=, ~, &gt;, &gt;=, &lt;, &lt;= 逻辑操作符：&amp;&amp;, ||, ! 变量赋值：= 示例1：obj.hits是内建变量，用于保存某缓存项的从缓存中命中的次数； if (obj.hits&gt;0) { ​ set resp.http.X-Cache = “HIT via” + ” ” + server.ip; ​ } else { ​ set resp.http.X-Cache = “MISS from ” + server.ip; ​ } vim /etc/varnish/default.vcl 使用curl -I -s http:url 可以判断是否缓存命中 示例2**：判定curl**类型的请求拒绝访问修改配置文件 vim /etc/varnish/default.vcl 调用配置文件 varnishadm -S /etc/varnish/secret -T 127.0.0.1:6082 切换到另外一台主机进行curl测试： 返回403错误状态码 示例3：判定admin相关的请求拒绝访问node1： 创建一个名称为admin访问目录： echo hello,world &gt; /var/www/html/admin/index.html systemctl reload httpd 正常访问返回如下： 修改配置文件： vim /etc/varnish/default.vcl 调用配置文件 再次访问http://192.168.30.10:6081/admin/ 示例4：强制对某类资源请求不检查缓存 示例5：对于特定类型的资源，例如公开的图片等，取消其私有标识，并强行设定其可以由varnish缓存的**时长； 定义在vcl_backend_response中；**语法格式： if (beresp.http.cache-control !~ “s-maxage”) { if (bereq.url ~ “(?i).(jpg|jpeg|png|gif|css|js)$”) { ​ unset beresp.http.Set-Cookie; ​ set beresp.ttl = 3600s; } } 四、Varnish缓存修剪缓存对象的修剪有两种： purge：指定删除某条url的缓存 ban：指定删除某类url的缓存 配置purge操作：(1) 能执行purge操作 ​ sub vcl_purge { ​ return (synth(200,”Purged”)); ​ } (2) 何时执行purge操作 ​ sub vcl_recv { ​ if (req.method == “PURGE”) { ​ return(purge); ​ } ​ … ​ } ​ 添加此类请求的访问控制法则： acl purgers { ​ “127.0.0.0”/8; ​ “10.1.0.0”/16; } sub vcl_recv { ​ if (req.method == “PURGE”) { ​ if (!client.ip ~ purgers) { ​ return(synth(405,”Purging not allowed for ” + client.ip)); ​ } ​ return(purge); ​ } ​ … } 示例： 修改配置： 缓存修剪测试： 如果担心缓存修剪被其他人操作，也可添加ACL的访问控制 当使用不再ACL范围内的主机进行访问时，返回结果如下： 而在ACL定义范围内的主机则可正常使用PURGE修剪缓存 配置Banning操作：(1) varnishadm： ban 示例： ban req.url ~ (?i)^/javascripts (2) 在配置文件中定义，使用ban()函数； 示例： if (req.method == “BAN”) { ​ ban(“req.http.host == ” + req.http.host + ” &amp;&amp; req.url == ” + req.url); ​ # Throw a synthetic page so the request won’t go to the backend. ​ return(synth(200, “Ban added”)); } curl -X BAN http://www.ilinux.io/test1.html ban req.http.host==www.ilinux.io &amp;&amp; req.url==/test1.html 五、Varnish负载均衡如何设定使用多个后端主机：backend default { ​ .host = “172.16.100.6”; ​ .port = “80”; } backend appsrv { ​ .host = “172.16.100.7”; ​ .port = “80”; } sub vcl_recv { ​ if (req.url ~ “(?i).php$”) { ​ set req.backend_hint = appsrv; ​ } else { ​ set req.backend_hint = default; ​ } ​ ​ … } nginx: proxy_pass haproxy: use_backend 实验：实现varnish的负载均衡前期准备： Varnish服务器：192.168.30.10 系统版本：CentOS 7.4 node1：192.168.30.27 系统版本：CentOS 7.4 node2：192.168.30.16 系统版本：CentOS 7.4 客户端：192.168.30.18 系统版本：CentOS 7.4 具体步骤： 修改配置文件： vim /etc/varnish/default.vcl node1： 创建javascripts的web目录，并创建文件test1-test6，内容分别也为test1-test6 node2： 创建javascripts的web目录，并创建文件test1-test6，内容分别为node1-node6 客户端进行测试访问： 可看到轮询算法调度已生效，当第二次进行访问时，均缓存命中 也可实现基于cookie的会话粘性，及随机性算法调度方式 配置格式如下： 六、后端服务器健康性状态检查.probe：定义健康状态检测方法； .url：检测时要请求的URL，默认为”/”; .request：发出的具体请求； .request = “GET /.healthtest.html HTTP/1.1” “Host: www.magedu.com” “Connection: close” .window：基于最近的多少次检查来判断其健康状态； .threshold：最近.window中定义的这么次检查中至有.threshhold定义的次数是成功的； .interval：检测频度； .timeout：超时时长； .expected_response：期望的响应码，默认为200； 健康状态检测的配置方式：(1) probe PB_NAME { } ​ backend NAME = { ​ .probe = PB_NAME; ​ … ​ } ​ ​ (2) backend NAME { ​ .probe = { ​ … ​ } ​ } 设置后端的主机属性： ​ backend BE_NAME { ​ … ​ .connect_timeout = 0.5s; ​ .first_byte_timeout = 20s; ​ .between_bytes_timeout = 5s; ​ .max_connections = 50; ​ } 示例： 查看后端服务器健康性状态： varnishadm -S /etc/varnish/secret -T 127.0.0.1:6082 手动设定BE主机的状态： sick：管理down; healthy：管理up； auto：probe auto；]]></content>
  </entry>
  <entry>
    <title><![CDATA[HAProxy介绍及相关实验]]></title>
    <url>%2F2018%2F07%2F13%2FHAProxy%E4%BB%8B%E7%BB%8D%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一、HAPrxoy介绍HAProxy是一个使用C语言编写的自由及开放源代码软件，其提供高可用性、负载均衡，以及基于tcp和 http的应用程序代理。 mode http：七层反向代理，受端口数量限制 mode tcp：四层反向代理，不受套接字文件数量限制 官方网站： http://www.haproxy.org http://www.haproxy.com 官方文档： http://cbonte.github.io/haproxy-dconv/ HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行 在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进 您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。 HAProxy实现了一种事件驱动, 单一进程模型，此模型支持非常大的并发连接数。多进程或多线程模型受 内存限制 、系统调度器限制以及无处不在的锁限制，很少能处理数千并发连接。事件驱动模型因为在有更 好的资源和时间管理的用户空间(User-Space) 实现所有这些任务，所以没有这些问题。此模型的弊端是， 在多核系统上，这些程序通常扩展性较差。这就是为什么他们必须进行优化以 使每个CPU时间片(Cycle)做 更多的工作。 建议：生产环境运行在单进程模型下，便于分析，排查问题 二、HAProxy服务配置程序环境：主程序：/usr/sbin/haproxy 主配置文件：/etc/haproxy/haproxy.cfg Unit file：/usr/lib/systemd/system/haproxy.service 配置段：​ global：全局配置段 进程及安全配置相关的参数 性能调整相关参数 Debug参数 用户列表 peers proxies：代理配置段 defaults：为frontend, listen, backend提供默认配置； fronted：前端，相当于nginx, server {} backend：后端，相当于nginx, upstream {} listen：同时拥前端和后端 简单的配置示例： frontend web ​ bind *:80 ​ default_backend websrvs backend websrvs ​ balance roundrobin ​ server srv1 172.16.100.6:80 check ​ server srv2 172.16.100.7:80 check global配置参数： 进程及安全管理：chroot, daemon，user, group, uid, gid log：定义全局的syslog服务器；最多可以定义两个； log [len ] [max level [min level]] nbproc ：要启动的haproxy的进程数量； ulimit-n ：每个haproxy进程可打开的最大文件数； 性能调整： maxconn ：设定每个haproxy进程所能接受的最大并发连接数； Sets the maximum per-process number of concurrent connections to . 总体的并发连接数：nbproc * maxconn maxconnrate ：每个进程每秒种所能创建的最大连接数量； Sets the maximum per-process number of connections per second to . maxsessrate ：每个进程每秒所能创建最大会话数 maxsslconn :设定每个haproxy进程所能接受的ssl的最大并发连接数； Sets the maximum per-process number of concurrent SSL connections to . spread-checks &lt;0..50, in percent&gt; 三、实验：实现HAProxy反向代理前期准备：虚拟机4台 HAproxy：192.168.30.10 node1：192.168.30.17 node2：192.168.30.27 Client：192.168.30.16 具体步骤：HAProxy服务器操作： yum install haproxy 修改配置文件 vim /etc/haproxy/haproxy.cfg frontend main *:80 ​ default_backend websrvs backend websrvs ​ balance roundrobin ​ server websrv1 192.168.30.17:80 check #check 健康性检查 ​ server websrv2 192.168.30.27:80 check 重启haproxy systemctl restart haproxy node1，node2开启http服务 [root@node1 ~]# systemctl start httpd [root@node1 ~]# echo Backend Server 1 &gt; /var/www/html/index.html [root@node2 ~]# systemctl start httpd [root@node2 ~]# echo Backend Server 2 &gt; /var/www/html/index.html 客户端访问测试： 添加权重：vim /etc/haproxy/haproxy.cfg backend websrvs ​ balance roundrobin ​ server websrvs1 192.168.30.17:80 check weight 2 ​ server websrvs2 192.168.30.27:80 check 重启HAProxy服务网 systemctl restart haproxy.service 访问测试： 四、实验：实现根据url(uri算法)和客户端来源(hdr算法)进行调度实现uri算法对同一url的访问请求都调度至同一个后端服务器 注意：如果HAProxy调度后端为缓存服务器，就要使用uri算法，且使用动态算法，一致性哈希 实验前期准备承接实现HAProxy反向代理中的环境 具体步骤：修改配置文件 vim /etc/haproxy/haproxy.cfg 重启haproxy服务 systemctl restart haproxy.service 在node1，node2上分别创建http页面test1–test10 访问测试： 实现hdr算法来自同一客户端的请求都调度至同一个后端服务器 修改配置文件 vim /etc/haproxy/haproxy.cfg 重启haproxy服务 systemctl restart haproxy.service 访问测试： 五、实验：实现基于cookie的会话绑定前期准备：虚拟机4台 HAproxy：192.168.30.10 node1：192.168.30.17 node2：192.168.30.27 Client：192.168.30.16 具体步骤：修改配置文件 vim /etc/haproxy/haproxy.cfg 重启haproxy服务 systemctl restart haproxy.service 访问测试： 重启服务前在server1与server2之间轮询调度，重启后将绑定在其中一台server中 注意：curl命令之间访问不能绑定cookie 六、实验：启用HAproxy统计接口统计接口启用相关的参数： stats enable 启用统计页；基于默认的参数启用stats page； ​ – stats uri : /haproxy?stats ​ – stats realm : “HAProxy Statistics” ​ – stats auth : no authentication ​ – stats scope : no restriction ​ ​ stats auth : 认证时的账号和密码，可使用多次； ​ stats realm 认证时的realm； ​ stats uri 自定义stats page uri ​ stats refresh 设定自动刷新时间间隔； ​ stats admin { if | unless } 启用stats page中的管理功能 具体步骤：只需在frontend或者backend中添加一行 stats enable 重启haproxy服务 systemctl restart haproxy.service 浏览器访问：http://192.168.30.10/haproxy?stats ### 避免状态页被其他客户端访问：(1)修改状态页监听端口 (2)修改状态页url (3)添加安全认证 启用state page中的管理功能：可利用此功能实现脚本执行发布，网上搜索基于haproxy的发布脚本 再次访问： 七、实验：Errorfile实现自定义错误页，状态码修改前端响应报文及后端请求报文头部信息 前端响应报文删除一个头部信息 修改前的报文头部信息： 访问测试 前端响应报文添加一个头部信息 访问测试]]></content>
      <categories>
        <category>Web服务器</category>
      </categories>
      <tags>
        <tag>HAProxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx介绍及Web服务相关配置]]></title>
    <url>%2F2018%2F07%2F10%2FNginx%E4%BB%8B%E7%BB%8D%E5%8F%8AWeb%E6%9C%8D%E5%8A%A1%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Nginx 是一个高性能的Web和反向代理服务器, 它具有有很多非常优越的特性:作为 Web 服务器：相比Apache，Nginx 使用更少的资源，支持更多的并发连接，体现更高的效率，这点使 Nginx尤其受到虚拟主机提供商的欢迎。 一、Nginx介绍Nginx：engine X ，2002年，开源，商业版 Nginx是免费，开源，高性能的HTTP和反向代理服务器，邮件代理服务器，通 用TCP/UDP代理服务器 解决C10K问题（10K Connections） 官网：http://nginx.org 二次开发版： Tengine, OpenResty（章亦春） 特性：模块化设计，较好的扩展性 高可靠性 支持热部署：不停机更新配置文件，升级版本，更换日志文件 低内存消耗：10000个keep-alive连接模式下的非活动连接，仅需2.5M内存 event-driven,aio,mmap，sendfile 基本功能：静态资源的web服务器 http协议反向代理服务器 pop3/imap4协议反向代理服务器 FastCGI(LNMP),uWSGI(python)等协议 模块化（非DSO），如zip，SSL模块 web服务相关的功能：虚拟主机（server） 支持 keep-alive 和管道连接 访问日志（支持基于日志缓冲提高其性能） url rewirte 路径别名 基于IP及用户的访问控制 支持速率限制及并发数限制 重新配置和在线升级而无须中断客户的工作进程 Memcached的GET 接口 为什么选择Nginx？Nginx 是一个高性能的Web和反向代理服务器, 它具有有很多非常优越的特性:作为 Web 服务器：相比 Apache，Nginx 使用更少的资源，支持更多的并发连接，体现更高的效率，这点使 Nginx尤其受到虚拟主 机提供商的欢迎。能够支持50000个并发连接数的响应，Nginx选择了epoll作为开发模型. 作为负载均衡服务器：Nginx 既可以在内部直接支持Rails 和 PHP，也可以支持作为 HTTP代理服务器 对 外进行服务。Nginx 用 C 编写, 不论是系统资源开销还是 CPU 使用效率都比Perlbal 要好的多。 作为邮件代理服务器: Nginx 同时也是一个非常优秀的邮件代理服务器（最早开发这个产品的目的之一也是 作为邮件代理服务器），Last.fm 描述了成功并且美妙的使用经验。 Nginx 安装非常的简单，配置文件 非常简洁（还能够支持perl语法），Bugs非常少的服务器:Nginx 启动特 别容易，并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。你还能够在 不间断服务 的情况下进行软件版本的升级。 Nginx程序架构 Nginx程序架构： master/worker结构 一个master进程： 负载加载和分析配置文件、管理worker进程、平滑升级 一个或多个worker进程 处理并响应用户请求 缓存相关的进程： cache loader：载入缓存对象 cache manager：管理缓存对象 高度模块化nginx高度模块化，但其模块早期不支持DSO机制；1.9.11版本支持动态装载和 卸载 模块分类： 核心模块：core module 标准模块： HTTP 模块： ngx_http_* HTTP Core modules 默认功能 HTTP Optional modules 需编译时指定 Mail 模块 ngx_mail_* Stream 模块 ngx_stream_* 第三方模块 二、Nginx服务配置配置文件的组成部分： 主配置文件：nginx.conf 子配置文件：include conf.d/*.conf fastcgi， uwsgi，scgi等协议相关的配置文件 mime.types：支持的mime类型 主配置文件的配置指令： directive value [value2 …]; 注意： (1) 指令必须以分号结尾 (2) 支持使用配置变量 内建变量：由Nginx模块引入，可直接引用 自定义变量：由用户使用set命令定义 set variable_name value; 引用变量：$variable_name 主配置文件结构：主配置文件结构：四部分组成 main block：主配置段，即全局配置段，对http,mail都有效 event { … } #事件驱动相关的配置 http { … } #http/https协议相关配置段 mail { … } #mail协议相关配置段 stream { … } # stream服务器相关配置段 http协议相关的配置结构 三、Web服务常见功能及配置(一)性能优化相关的配置：1、worker_processes number | auto worker进程的数量；通常应该为当前主机的cpu的物理核心数 2、worker_cpu_affinity cpumask … worker_cpu_affinity auto [cpumask] 提高缓存命中率 CPU MASK： 00000001：0号CPU 00000010：1号CPU 10000000：8号CPU worker_cpu_affinity 0001 0010 0100 1000; worker_cpu_affinity 0101 1010; 3、worker_priority number 指定worker进程的nice值，设定worker进程优先级：[-20,20] 4、worker_rlimit_nofile number worker进程所能够打开的文件数量上限,如65535 示例：修改worker**进程数量** 示例：设置NICE**优先级** 变为前台执行 daemon on|off 是否以守护进程方式运行nignx，默认是守护进程方式，用于测试环境 以守护方式（前台执行）运行 EVENT**语句块** 每个worker**支持的最大连接1024**，生成环境应适当调大 work_connections *Cpu个数= worker_rlimit_nofile number (二)虚拟主机配置 定义一个专门存放虚拟主机的目录： 配置一个虚拟主机 server { listen address[:PORT]|PORT; server_name SERVER_NAME; root /PATH/TO/DOCUMENT_ROOT; } vim a.com.conf vim b.com.conf server { ​ listen 8080 ​ server_name www.b.com } (三)改变默认指向：default_server vim c.com.conf 要注意将主配置文件中的defaults_server删掉，否则nginx服务将无法正常启动 (四)支持通配符写法 匹配优先级机制从高到低： (1) 首先是字符串精确匹配 如：www.magedu.com (2) 左侧***通配符 如：*.magedu.com** (3) 右侧***通配符 如：www.magedu.\*** (4) 正则表达式 如： ~^.*.magedu.com$ (5) default_server (五)隐藏Nginx版本 server_tokens on | off | build | string 是否在响应报文的Server首部显示nginx版本 vim /etc/nginx/conf/nginx.conf 再次访问 (五)软连接指向 (六)针对特定文件指定存放位置 location [ = | ~ | ~* | ^~ ] uri { … } location @name { … } 在一个server**中location配置段可存在多个，用于实现从uri到文件系统的路** 径映射；ngnix**会根据用户请求的URI来检查定义的所有location，并找出一个最** 佳匹配，而后应用其配置 示例： server {… server_name www.magedu.com; location /images/ { root /data/imgs/; } } http://www.magedu.com/images/logo.jpg –&gt; /data/imgs/images/logo.jpg 示例： (七)定制错误页面 echo ‘NO FOUND PAGE’ &gt; /data/sitea/error/404.html 客户端访问测试： (八)避免流氓浏览器404**劫持** error_page code … [=[response]] uri; 模块：ngx_http_core_module 定义错误页，以指定的响应状态码进行响应 可用位置：http, server, location, if in location error_page 404 /404.html error_page 404 =200 /404.html 修改配置文件 再次访问： 修改404**页面到指定默认页面** keepalive_timeout timeout [header_timeout]; 设定保持连接超时时长，0**表示禁止长连接，默认为75s** keepalive_requests number; 在一次长连接上所允许请求的资源的最大数量 默认为100 (九)除了管理员域其他主机无法使用GET**以外的其他方法** (十)实现基于ip**的访问控制功能** ngx_http_access_module**模块** 1、allow address | CIDR | unix: | all; 2、deny address | CIDR | unix: | all; http, server, location, limit_except 自上而下检查，一旦匹配，将生效，条件严格的置前 示例： location / { deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/16; allow 2001:0db8::/32; deny all; } (十一)实现基于用户的访问控制： ngx_http_auth_basic_module**模块** 实现基于用户的访问控制，使用basic**机制进行用户认证** 1**、auth_basic string | off;** 2**、auth_basic_user_file file;** location /admin/ { auth_basic “Admin Area”; auth_basic_user_file /etc/nginx/.ngxpasswd; } 用户口令文件： 1**、明文文本：格式name:password:comment** 2**、加密文本：由htpasswd**命令实现 httpd-tools**所提供** 示例： cd /etc/nginx/conf.d/vhost htpasswd -cm nginxuser httpuser1 htpasswd -m nginxuser httpuser2 修改配置 针对整个网站生效 针对特定目录生效 http://www.a.com/admin/ (十二)Nginx**状态页** ngx_http_stub_status_module**模块** 功能：用于输出nginx的基本状态信息 输出信息示例： Active connections: 291 server accepts handled requests 16630948 16630948 31070465 上面三个数字分别对应accepts,handled,requests三个值 Reading: 6 Writing: 179 Waiting: 106 示例： 浏览器访问http://192.168.30.10/status 相关参数说明： Active connections:当前状态，活动状态的连接数 accepts：统计总值，已经接受的客户端请求的总数 handled：统计总值，已经处理完成的客户端请求的总数 requests：统计总值，客户端发来的总的请求数 Reading：当前状态，正在读取客户端请求报文首部的连接的连接数 Writing：当前状态，正在向客户端发送响应报文过程中的连接数 Waiting：当前状态，正在等待客户端发出请求的空闲连接数 (十三)日志相关设置 ngx_http_log_module**模块** 指定日志格式记录请求 1、log_format name string …; string可以使用nginx核心模块及其它模块内嵌的变量 2、access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 访问日志文件路径，格式及相关的缓冲的配置 buffer=size flush=time 3、open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; 缓存各日志文件相关的元数据信息 max：缓存的最大文件描述符数量 min_uses：在inactive指定的时长内访问大于等于此值方可被当作活动项 inactive：非活动时长 valid：验证缓存中各缓存项是否为活动项的时间间隔 示例：自定义日志 系统默认： 自定义一个日志： 添加到access_log(可添加到任何语句块中) 测试日志 (十四)实现**Nginx的SSL加密https** ngx_http_ssl_module**模块：** 1、ssl on | off; 为指定虚拟机启用HTTPS protocol， 建议用listen指令代替 2、ssl_certificate file; 当前虚拟主机使用PEM格式的证书文件 3、ssl_certificate_key file; 当前虚拟主机上与其证书匹配的私钥文件 4、ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2];支持ssl协议版本，默 认为后三个 5、ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; none: 通知客户端支持ssl session cache，但实际不支持 builtin[:size]：使用OpenSSL内建缓存，为每worker进程私有 [shared:name:size]：在各worker之间使用一个共享的缓存 6、ssl_session_timeout time; 客户端连接可以复用ssl session cache中缓存的ssl参数的有效时长，默认5m 示例： server { listen 443 ssl; server_name www.magedu.com; root /vhosts/ssl/htdocs; ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; } 检查语法： nginx -t 验证https (十五)实现**NGINX搭建多个HTTPS**网站 修改配置文件 验证https： (十六)rewite**重写** ngx_http_rewrite_module**模块：** The ngx_http_rewrite_module module is used to change request URI using PCRE regular expressions, return redirects, and conditionally select configurations. 将用户请求的URI基于PCRE regex所描述的模式进行检查，而后完成重定向替换 1**、**rewrite regex replacement [flag] 将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为 replacement指定的新的URI 注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个 检查；被某条件规则替换完成后，会重新一轮的替换检查 隐含有循环机制,但不超过10次；如果超过，提示500响应码，[flag]所表示 的标志位用于控制此循环机制 如果replacement是以http://或https://开头，则替换结果会直接以重向返 回给客户端, 即永久重定向301 [flag]**：** last：重写完成后停止对当前URI在当前location中后续的其它重写操作， 而后对新的URI启动新一轮重写检查；提前重启新一轮循环，不建议在location中 使用 break：重写完成后停止对当前URI在当前location中后续的其它重写操作， 而后直接跳转至重写规则配置块之后的其它配置；结束循环，建议在location中使 用 redirect：临时重定向，重写完成后以临时重定向方式直接返回重写后生成 的新URI给客户端，由客户端重新发起请求；使用相对路径,或者http://或https:// 开头，状态码：302 permanent: 重写完成后以永久重定向方式直接返回重写后生成的新URI给 客户端，由客户端重新发起请求，状态码：301 2**、**return return code [text]; return code URL; return URL; 停止处理，并返回给客户端指定的响应码 3**、**rewrite_log on | off; 是否开启重写日志, 发送至error_log（notice level） 4**、**set $variable value; 用户自定义变量 注意：变量定义和调用都要以$开头 5**、**if (condition) { … } 条件满足时，执行配置块中的配置指令；server, location condition： 比较操作符： = 相同 != 不同 ~：模式匹配，区分字符大小写 ~*：模式匹配，不区分字符大小写 !~：模式不匹配，区分字符大小写 !~*：模式不匹配，不区分字符大小写 文件及目录存在性判断： -e, !-e 存在（包括文件，目录，软链接） -f, !-f 文件 -d, !-d 目录 -x, !-x 执行 示例： www.a.com/images/a.jpg –&gt; www.a.com/media/images/a.jpg 相关配置： rewrite ^(images/.*)$ /media/$1 示例： www.a.com/bbs –&gt; www.a.com/forum redirect**模式：**302 permanent**模式** (十七)实现**http自动跳转https** (十八)实现将**http与https**写入同一个虚拟机 break**模式：可避免死循环** (十九)实现自定义响应码 (二十)Nginx**防盗链** ngx_http_referer_module**模块：** 功能：用来阻止Referer首部无有效值的请求访问，可防止盗链 格式：valid_referers none|blocked|server_names|string …; 定义referer首部的合法可用值，不能匹配的将是非法值 none：请求报文首部没有referer首部 blocked：请求报文有referer首部，但无有效值 server_names：参数，其可以有值作为主机名或主机名模式 arbitrary_string：任意字符串，但可使用*作通配符 regular expression：被指定的正则表达式模式匹配到的字符串,要使用~开头 开启防盗链功能后，盗链图片将无法正常显示]]></content>
      <categories>
        <category>Web服务器</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS虚拟服务器相关实验]]></title>
    <url>%2F2018%2F07%2F07%2FLVS%E8%99%9A%E6%8B%9F%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[本节内容主要是是lvs相关性实验，及lvs健康性检查工具Ldirectord 一、实验：实现LVS-NAT逻辑拓扑： 前期准备：CLIENT: 172.20.0.123； 网关：172.20.0.200 LVS: VIP：192.168.30.200, DIP：172.20.0.200，启用ip_forward RS1: 192.168.30.17 RS2: 192.168.30.27 LVS：开启路由转发 echo net.ipv4.ip_forward=1 &gt;&gt; /etc/sysctl.conf sysctl –p sysctl –a |grep ip_f RS1、2:搭建WEB环境 网关指向192.168.30.200 yum install httpd RS1: echo RS1&gt; /var/www/html/index.html systemctl start httpd RS2: echo RS2&gt; /var/www/html/index.html systemctl start httpd LVS:添加LVS规则 yum install ipvsadm Ipvsadm –A –t 172.20.0.200:80 –s rr Ipvsadm –a –t 172.20.0.200:80 –r 192.168.30.17 –m Ipvsadm –a –t 172.20.0.200:80 –r 192.168.30.27 –m Ipvsadm –Ln 测试：curl 172.20.0.200 二、实验：实现LVS与RS之间添加路由器的LVS-NAT逻辑拓扑： 前期准备：新增加一台虚拟机作为路由器，按下图进行网络环境搭建 CLIENT: 172.20.0.123；网关：172.20.0.200 LVS: 192.168.30.0,172.20.0.200，不启用ip_forward ROUTER： VIP：172.20.0.100/16；DIP：192.168.30.200 /24，启用ip_forward RS1: 192.168.30.17 RS2: 192.168.30.27 路由器必须配置到LVS的网关，并且开启路由转发功能 curl 172.20.0.200测试 实现端口映射：以httpd服务为例，修改其中一台RS服务器的80端口为8080 RS1： vim /etc/httpd/conf/httpd.conf Listen 80 ==&gt;Listen 8080 LVS： 清除原有LVS规则 ipvsadm -C ipvsadm -A -t 172.20.0.200:80 -s rr ipvsadm -a -t 172.20.0.200:80 -r 192.168.30.17:8080 -m ipvsadm -a -t 172.20.0.200:80 -r 192.168.30.27:80 -m CLIENT： 添加权重：LVS： 修改调度算法为wrr模式 ipvsadm -a -t 172.20.0.200:80 -r 192.168.30.17:8080 -m -w 3 CLIENT： 我们看到LVS已按RS1:RS1 = 3:1的权重进行调度 三、实验：实现单网络LVS-DR逻辑拓扑： 前期准备:5台虚拟机，网络环境配置如下： CLIENT: 桥接模式；172.20.0.222/16 ROUTER: 桥接模式；172.20.0.200/16；192.168.30.200/24 LVS: 仅主机模式;VIP:192.168.30.7/24；DIP：192.168.30.100/24 RS1: 仅主机模式;192.168.30.17/24；VIP:192.168.30.7/24 RS2: 仅主机模式;192.168.30.27/24；VIP:192.168.30.7/24 RS1,RS2:echo 1&gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 1&gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 2&gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo 2&gt; /proc/sys/net/ipv4/conf/all/arp_announce 一般习惯是将VIP绑定到RS服务器的回环网卡lo上 ip a a 192.168.30.7/32 dev lo ### 在RS1,RS2上搭建web服务 yum install httpd RS1: echo RS1&gt; /var/www/html/index.html systemctl start httpd RS2: echo RS2&gt; /var/www/html/index.html systemctl start httpd LVS：网络配置要求 VIP: ip addr a192.168.30.7/32 dev lo DIP: 192.168.30.100/24 eth0 GATEWAY: 192.168.30.X #网关必须配，但可随意配置，同一网段即可 配置调度策略： yum install ipvsadm ipvsadm -A -t 192.168.30.7:80 -s rr ipvsadm -a -t 192.168.30.7:80 -r 192.168.30.17 #默认dr模型 ipvsadm -a -t 192.168.30.7:80 -r 192.168.30.27 CLIENT:测试 四、Ldirectord:实现LVS的RS健康性检查ldirectord：监控和控制LVS守护进程，可管理LVS规则 包名：**ldirectord-3.9.6-0rc1.1.1.x86_64.rpm** 文件： /etc/ha.d/ldirectord.cf 主配置文件 /usr/share/doc/ldirectord-3.9.6/ldirectord.cf 配置模版 /usr/lib/systemd/system/ldirectord.service 服务 /usr/sbin/ldirectord 主程序 /var/log/ldirectord.log 日志 /var/run/ldirectord.ldirectord.pid pid 文件 Ldirectord**配置文件示例** checktimeout=3 checkinterval=1 autoreload=yes logfile=”/var/log/ldirectord.log” #日志文件 quiescent=no #down时yes权重为0，no为删除 virtual=5 #指定VS的FWM或IP：port real=172.16.0.7:80 gate 2 real=172.16.0.8:80 gate 1 fallback=127.0.0.1:80 gate #sorry server service=http scheduler=wrr checktype=negotiate checkport=80 request=”index.html” receive=”test Ldirectord” 重启ldirectord服务，将自动生成LVS规则 systemctl start ldirectord 默认情况下，当有一台RS服务器宕机时，LVS还将继续调度，启动ldirectord服务后，当某台RS服 务器**宕机后，LVS将不再继续调度至该台服务器**]]></content>
      <categories>
        <category>集群</category>
      </categories>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS介绍及工作原理]]></title>
    <url>%2F2018%2F07%2F03%2FLVS%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[一、Cluster集群概念集群(cluster)技术是一种较新的技术，通过集群技术，可以在付出较低成本的情况 下获得在性能、可靠性、灵活性方面的相对较高的收益，其任务调度则是集群系统中 的核心技术。 系统扩展方式：Scale UP：向上扩展,增强 Scale Out：向外扩展,增加设备，调度分配问题，Cluster Cluster：集群,为解决某个特定问题将多台计算机组合起来形成的单个系统 Linux Cluster类型： LB：Load Balancing，负载均衡 HA：High Availiablity，高可用，SPOF（single Point Of failure） MTBF：Mean Time Between Failure 平均无故障时间 MTTR：Mean Time To Restoration（ repair）平均恢复前时间 A=MTBF/（MTBF+MTTR） (0,1)：99%, 99.5%, 99.9%, 99.99%, 99.999% HPC：High-performance computing，高性能 www.top500.org 分布式系统：分布式存储：云盘 分布式计算：hadoop，Spark 分布式文件系统：fastfs 集群与分布式：简单来说集群是解决高可用的，而分布式是解决高性能、高并发的 集群：同一个业务，部署在多个服务器上 分布式：一个业务分拆多个子业务，部署在不同的服务器上 Cluster分类LB Cluster的实现 硬件 F5 Big-IP Citrix Netscaler A10 A10 软件 lvs：Linux Virtual Server nginx：支持七层调度 haproxy：支持七层调度 ats：apache traffic server，yahoo捐助 perlbal：Perl 编写 pound 基于工作的协议层次划分： 传输层（通用）：DPORT LVS： nginx：stream haproxy：mode tcp 应用层（专用）：针对特定协议，自定义的请求模型分类 proxy server： http：nginx, httpd, haproxy(mode http), … fastcgi：nginx, httpd, … mysql：mysql-proxy, … 会话保持：负载均衡 (1)session sticky：同一用户调度固定服务器 Source IP：LVS sh算法（对某一特定服务而言） Cookie (2)session replication：每台服务器拥有全部session session multicast cluster (3)session server：专门的session服务器 Memcached，Redis HA集群实现方案 keepalived:vrrp协议 ais:应用接口规范 heartbeat cman+rgmanager(RHCS) coresync_pacemaker 二、LVS介绍LVS：Linux Virtual Server，负载调度器，集成内核 章文嵩 阿里 官网：http://www.linuxvirtualserver.org/ VS：Virtual Server，负责调度 RS：Real Server，负责真正提供服务 L4：四层路由器或交换机 工作原理：VS根据请求报文的目标IP和目标协议及端口将其调度转发至某RS，根据调度 算法来挑选RS iptables/netfilter： iptables：用户空间的管理工具 netfilter：内核空间上的框架 流入：PREROUTING –&gt; INPUT 流出：OUTPUT –&gt; POSTROUTING 转发：PREROUTING –&gt; FORWARD –&gt; POSTROUTING DNAT：目标地址转换； PREROUTING LVS集群的通用结构： LVS工作原理LVS集群类型中的术语： VS：Virtual Server，Director Server(DS)，Dispatcher(调度器)，Load Balancer RS：Real Server(lvs), upstream server(nginx)，backend server(haproxy) CIP：Client IP VIP: Virtual serve IP VS外网的IP DIP: Director IP VS内网的IP RIP: Real server IP 访问流程：CIP &lt;–&gt; VIP == DIP &lt;–&gt; RIP lvs：ipvsadm/ipvs ipvsadm：用户空间的命令行工具，规则管理器 用于管理集群服务及RealServer ipvs：工作于内核空间netfilter的INPUT钩子上的框架 lvs集群的类型：lvs-nat：修改请求报文的目标IP,多目标IP的DNAT(重点) lvs-dr：操纵封装新的MAC地址(重点) lvs-tun：在原请求IP报文之外新加一个IP首部 lvs-fullnat：修改请求报文的源和目标IP 三、LVS模式与调度算法lvs-nat模式本质是多目标IP的DNAT，通过将请求报文中的目标地址和目标端口修改为某挑 出的RS的RIP和PORT实现转发 LVS-NAT的体系结构如下图所示： （1）RIP和DIP应在同一个IP网络，且应使用私网地址；RS的网关要指向DIP （2）请求报文和响应报文都必须经由Director转发，Director易于成为系统瓶颈 （3）支持端口映射，可修改请求报文的目标PORT （4）VS必须是Linux系统，RS可以是任意OS系统 LVS-NAT数据流程时序图： LVS-DR模式LVS-DR：Direct Routing，直接路由，LVS默认模式,应用最广泛,通过为请求报文重新 封装一个MAC首部进行转发，源MAC是DIP所在的接口的MAC，目标MAC是某挑选出 的RS的RIP所在接口的MAC地址；源IP/PORT，以及目标IP/PORT均保持不变 LVS-DR的体系结构如下图所示： （1） Director和各RS都配置有VIP （2） 确保前端路由器将目标IP为VIP的请求报文发往Director 在前端网关做静态绑定VIP和Director的MAC地址 在RS上使用arptables工具 arptables -A IN -d $VIP -j DROP arptables -A OUT -s $VIP -j mangle –mangle-ip-s $RIP 在RS上修改内核参数以限制arp通告及应答级别 /proc/sys/net/ipv4/conf/all/arp_ignore /proc/sys/net/ipv4/conf/all/arp_announce （3）RS的RIP可以使用私网地址，也可以是公网地址；RIP与DIP在同一IP网络； RIP的网关不能指向DIP，以确保响应报文不会经由Director （4）RS和Director要在同一个物理网络 （5）请求报文要经由Director，但响应报文不经由Director，而由RS直接发往 Client （6）不支持端口映射（端口不能修败） （7）RS可使用大多数OS系统 LVS-DR数据流程时序图： lvs-tun模式转发方式：不修改请求报文的IP首部（源IP为CIP，目标IP为VIP），而在原IP报文 之外再封装一个IP首部（源IP是DIP，目标IP是RIP），将报文发往挑选出的目标 RS；RS直接响应给客户端（源IP是VIP，目标IP是CIP） LVS-TUN的体系结构如图所示： (1) DIP, VIP, RIP都应该是公网地址 (2) RS的网关一般不能指向DIP (3) 请求报文要经由Director，但响应不能经由Director (4) 不支持端口映射 (5) RS的OS须支持隧道功能 LVS-TUN数据流程时序图： LVS-FULLNAT模式lvs-fullnat：通过同时修改请求报文的源IP地址和目标IP地址进行转发 CIP –&gt; DIP VIP –&gt; RIP (1) VIP是公网地址，RIP和DIP是私网地址，且通常不在同一IP网络；因此， RIP的网关一般不会指向DIP (2) RS收到的请求报文源地址是DIP，因此，只需响应给DIP；但Director还 要将其发往Client (3) 请求和响应报文都经由Director (4) 支持端口映射 注意：此类型kernel默认不支持 三种 主要IP 负载均衡技术比较： lvs-nat与lvs-fullnat：请求和响应报文都经由Director lvs-nat：RIP的网关要指向DIP lvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信 lvs-dr与lvs-tun：请求报文要经由Director，但响应报文由RS直接发往Client lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发 lvs-tun：通过在原IP报文外封装新IP头实现转发，支持远距离通信 lvs-nat 的优点是服务器可以运行任何支持 TCP/IP 的操作系统，它只需要 一个 IP 地址配置在调度器上，服务器组可以用私有的 IP 地址。缺点是它的伸缩 能力有限，当服务器结点数目升到 20 时，调度器本身有可能成为系统的新瓶颈， 因为在 lvs-nat 中请求和响应报文都需要通过负载调度器。 lvs-dr优点是负载调度器可以处理大量的请求，因为调度器只处理客户到服 务器端的连接，响应数据可以直接从独立的网络路由返回给客户，这可以极大地 提高 LVS 集群系统的伸缩性。缺点是要求负载调度器与实际服务器都有一块网 卡连在同一物理网段上，服务器网络设备（或者设备别名）不作 ARP 响应，或 者能将报文重定向（Redirect）到本地的 Socket 端口上。 lvs-tun 的优点是负载调度器可以处理大量的请求，它甚至可以调度百台以 上的服务器（同等规模的服务器），而它不会成为系统的瓶颈，因为负载调度器 只将请求调度到不同的后端服务器，后端服务器将应答的数据直接返回给用户。 LVS的调度算法轮训算法 加权轮训算法 最小连接算法 加权最下连接算法 ….. LVS Scheduling Method LVS的调度方法： 1.Fixed Scheduling Method 静态调度方法 (1).RR 轮询 (2).WRR 加权轮询 (3).SH 源地址hash；实现session sticky，源IP地址hash；将来自于同一 个IP地址的请求始终发往第一次挑中的RS，从而实现会话绑定 (4).DH 目标地址hash；目标地址哈希，将发往同一个目标地址的请求始终转 发至第一次挑中的RS，典型使用场景是正向代理缓存场景中的负载均 衡，如：宽带运营商 2.Dynamic Scheduling Method 动态调度方法 (1).LC 最少连接；适用于长连接应用 ​ Overhead=activeconns*256+inactiveconns (2).WLC 加权最少连接(默认调度方法) Overhead=(activeconns*256+inactiveconns)/weight (3).SED 最少期望延迟 Overhead=(activeconns+1)*256/weight (4).NQ 第一轮均匀分配，后续SED (5).LBLC 基于本地的最少连接；动态的DH算法，使用场景：根据负载状态实现正向代理 (6).LBLCR 带复制的基于本地的最少连接；带复制功能的LBLC解决LBLC负载不均衡 问题，从负载重的复制到负载轻的RS 四、ipvsadm命令核心功能： 集群服务管理：增、删、改 集群服务的RS管理：增、删、改 查看 ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] [-M netmask] [–pe persistence_engine] [-b sched-flags] ipvsadm -D -t|u|f service-address 删除 ipvsadm –C 清空 ipvsadm –R 重载 ipvsadm -S [-n] 保存 ipvsadm -a|e -t|u|f service-address -r server-address [options] ipvsadm -d -t|u|f service-address -r server-address ipvsadm -L|l [options] ipvsadm -Z [-t|u|f service-address] 管理集群服务：增、改、删 增、改： ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] 删除： ipvsadm -D -t|u|f service-address service-address： -t|u|f： -t: TCP协议的端口，VIP:TCP_PORT -u: UDP协议的端口，VIP:UDP_PORT -f：firewall MARK，标记，一个数字 [-s scheduler]：指定集群的调度算法，默认为wlc 管理集群上的RS：增、改、删 增、改：ipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m] [-w weight] 删：ipvsadm -d -t|u|f service-address -r server-address server-address： rip[:port] 如省略port，不作端口映射 选项： lvs类型： -g: gateway, dr类型，默认 -i: ipip, tun类型 -m: masquerade, nat类型 -w weight：权重 清空定义的所有内容：ipvsadm –C 清空计数器：ipvsadm -Z [-t|u|f service-address] 查看：ipvsadm -L|l [options] –numeric, -n：以数字形式输出地址和端口号 –exact：扩展信息，精确值 –connection，-c：当前IPVS连接输出 –stats：统计信息 –rate ：输出速率信息 ipvs规则： /proc/net/ip_vs ipvs连接：/proc/net/ip_vs_conn]]></content>
      <categories>
        <category>集群</category>
      </categories>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防火墙技术(一)]]></title>
    <url>%2F2018%2F06%2F30%2F%E9%98%B2%E7%81%AB%E5%A2%99%E6%8A%80%E6%9C%AF(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[防火墙（Firewall），也称防护墙，是由Check Point创立者Gil Shwed于1993年发明并引入国际互联网。 它是一种工作在网络或主机边缘，对进出网络或主机的数据包基于一定的规则检查，并在匹配某规则时 由规则定义的行为进行处理的一组功能的组件，基本上的实现都是默认情况下关闭所有的通过型访问， 只开放允许访问的策略 一、防火墙介绍防火墙的分类按防火墙服务范围可分为： 主机防火墙：服务范围为当前主机 网络防火墙：服务范围为防火墙一侧的局域网 按软硬件可分为： 硬件防火墙：在专用硬件级别实现部分功能的防火墙；另一个部分功能基于软件 实现，Checkpoint, NetScreen 软件防火墙：运行于通用硬件平台之上的防火墙的应用软件 按OSI模型可分为： 网络层防火墙：OSI下面第三层 应用层防火墙/代理服务器：代理网关，OSI七层 Netfilter组件Netfilter是Linux 2.4内核防火墙框架，该框架既简洁又灵活，可实现安全策略应用中的许多功能， 如数据包过滤、数据包处理、地址伪装、透明代理、动态网络地址转换（NAT）， 以及基于用户及媒体访问控制（MAC）地址的过滤和基于状态的过滤、包速率限制等。 特性： 内核空间，集成在Linux内核中 扩展各种网络服务的结构化底层框架 内核中选取五个位置放了五个hook(勾子) function(INPUT、OUTPUT、FORWARD、 PREROUTING、POSTROUTING)，而这五个hook function向用户开放，用户可以通过一 个命令工具（iptables）向其写入规则 由信息过滤表（table）组成，包含控制IP包处理的规则集（rules），规则被分组放在链（chain）上 三种报文流向： 流入本机：PREROUTING –&gt; INPUT–&gt;用户空间进程 流出本机：用户空间进程 –&gt;OUTPUT–&gt; POSTROUTING 转发：PREROUTING –&gt; FORWARD –&gt; POSTROUTING iptables由四个表和五个链以及一些规则组成 四个表table：filter、nat、mangle、raw filter表：过滤规则表，根据预定义的规则过滤符合条件的数据包 nat表：network address translation 地址转换规则表 mangle：修改数据标记位规则表 raw：关闭NAT表上启用的连接跟踪机制，加快封包穿越防火墙速度 优先级由高到低的顺序为:raw–&gt;mangle–&gt;nat–&gt;filter 五个内置链chain INPUT OUTPUT FORWARD PREROUTING POSTROUTING 二、iptables工具格式：iptables [-t table] SUBCOMMAND chain [-m matchname [per-matchoptions]] -j targetname [per-target-options] (1)table： ​ raw, mangle, nat, [filter]默认 (2)SUBCOMMAND： 链管理： 1234567-N new, 自定义一条新的规则链-X delete，删除自定义的空的规则链-P Policy，设置默认策略；对filter表中的链而言，其默认策略有: ACCEPT：接受 DROP：丢弃 REJECT：拒绝-E 重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除 查看： 123456-L list, 列出指定鏈上的所有规则，本选项须置后-n numberic，以数字格式显示地址和端口号-v verbose，详细信息-vv 更详细-x exactly，显示计数器结果的精确值,而非单位转换后的易读值–line-numbers 显示规则的序号 常用组合： 123-vnL–vvnxL –line-numbers-S selected,以iptables-save 命令格式显示链上规则 规则管理： 1234567891011-A：append，追加-I：insert, 插入，要指明插入至的规则编号，默认为第一条-D：delete，删除 (1) 指明规则序号 (2) 指明规则本身-R：replace，替换指定链上的指定规则编号-F：flush，清空指定的规则链-Z：zero，置零iptables的每条规则都有两个计数器 (1) 匹配到的报文的个数 (2) 匹配到的所有报文的大小之和 (3)扩展匹配条件 ​ 扩展匹配条件：需要加载扩展模块（/usr/lib64/xtables/*.so），方可生效 ​ 查看帮助 man iptables-extensions ​ 扩展匹配分为隐性扩展和显性扩展两种 隐性扩展：不需要写模块名称 12 显性扩展：必须指定模块名称 1如：iptables -A INPUT -p tcp -m multiport –dports 21,80,445 -j REJECT (4)处理动作： 1-j targetname [per-target-options] 简单： ACCEPT，DROP 扩展： REJECT：–reject-with:icmp-port-unreachable默认 RETURN：返回调用链 REDIRECT：端口重定向 LOG：记录日志，dmesg MARK：做防火墙标记 DNAT：目标地址转换 SNAT：源地址转换 MASQUERADE：地址伪装 … 自定义链： 三、iptables基本命令使用举例(一)链及NAT的基本操作 清除所有的规则。 1）清除预设表filter中所有规则链中的规则。 1iptables -F 2）清除预设表filter中使用者自定链中的规则。 12iptables -Xiptables -Z 3)清楚NAT表规则 1iptables -F -t nat 4)NAT表的显示 1iptables -t nat -nL 设置链的默认策略。一般有两种方法。 1）首先允许所有的包，然后再禁止有危险的包通过放火墙。 123iptables -P INPUT ACCEPTiptables -P OUTPUT ACCEPTiptables -P FORWARD ACCEPT 2）首先禁止所有的包，然后根据需要的服务允许特定的包通过防火墙。 123iptables -P INPUT DROPiptables -P OUTPUT DROPiptables -P FORWARD DROP 列出表/链中的所有规则。默认只列出filter表。 1iptables -L 向链中添加规则。下面的语句用于开放网络接口： 123456iptables -A INPUT -i lo -j ACCEPTiptables -A OUTPUT -o lo -j ACCEPTiptables -A INPUT -i eth0 -j ACEPTiptables -A OUTPUT -o eth1 -j ACCEPTiptables -A FORWARD -i eth1 -j ACCEPTiptables -A FORWARD -0 eth1 -j ACCEPT 注意:由于本地进程不会经过FORWARD链，因此回环接口lo只在INPUT和OUTPUT两个链上作用。 使用者自定义链。 123iptables -N customiptables -A custom -s 0/0 -d 0/0 -p icmp -j DROPiptables -A INPUT -s 0/0 -d 0/0 -j DROP (二)设置基本的规则匹配 指定协议匹配。 1）匹配指定协议。 1iptables -A INPUT -p tcp 2）匹配指定协议之外的所有协议。 1iptables -A INPUT -p !tcp 指定地址匹配。 1）指定匹配的主机。 1iptables -A INPUT -s 192.168.0.18 2）指定匹配的网络。 1iptables -A INPUT -s 192.168.2.0/24 3）匹配指定主机之外的地址。 1iptables -A FORWARD -s !192.168.0.19 4）匹配指定网络之外的网络。 1iptables -A FORWARD -s ! 192.168.3.0/24 指定网络接口匹配。 1）指定单一的网络接口匹配。 12iptables -A INPUT -i eth0iptables -A FORWARD -o eth0 2）指定同类型的网络接口匹配。 1iptables -A FORWARD -o ppp+ 指定端口匹配。 1）指定单一端口匹配。 12iptables -A INPUT -p tcp –sport wwwiptables -A INPUT -p udp –dport 53 2）匹配指定端口之外的端口。 1iptables -A INPUT -p tcp –dport !22 3）匹配端口范围。 1iptables -A INPUT -p tcp –sport 22:80 ​ 4）匹配ICMP端口和ICMP类型。 1iptables -A INOUT -p icmp –icimp-type 8 ​ 5）指定ip碎片。 ​ 每个网络接口都有一个MTU（最大传输单元），这个参数定义了可以通过的数据包的最大尺寸。 ​ 如果一个 数据包大于这个参数值时，系统会将其划分成更小的数据包称为ip碎片）来传输， ​ 而接受方则对这些ip碎片再进行重组以还原整个包。 ​ 这样会导致一个问题：当系统将大数据包划分成ip碎片传输时，第一个碎片含有完整的包头信息 （IP+TCP、UDP和ICMP），但是后续的碎片只有包头的部分信息（如源地址、目的地址）。 ​ 因此，检查后面的ip碎片的头部（象有TCP、UDP和ICMP一样）是不可能的。假如有这样的一条 规则： 1iptables -A FORWARD -p tcp -s 192.168.1.0/24 -d 192.168.2.100 –dport 80 -j ACCEPT 并且这时的FORWARD的policy为DROP时，系统只会让第一个ip碎片通过，而余下的碎片因为包头信息不 完整而无法通过。可以通过—fragment/-f 选项来指定第二个及以后的ip碎片解决上述问题。 #iptables -A FORWARD -f -s 192.168.1.0/24 -d 192.168.2.100 -j ACCEPT 注意现在有许多进行ip碎片的实例，如DoS，因此允许ip碎片通过是有安全隐患的，对于这一点可以 采用iptables的匹配扩展来进行限制。 (三)设置扩展的规则匹配（举例已忽略目标动作）1、多端口匹配。 1）匹配多个源端口。 #iptables -A INPUT -p tcp -m multiport –sport 22,53,80,110 2）匹配多个目的端口。 #iptables -A INPUT -p tcp -m multiport –dpoort 22,53,80 3）匹配多端口(无论是源端口还是目的端口） #iptables -A INPUT -p tcp -m multiport –port 22,53,80,110 2、指定TCP匹配扩展 使用 –tcp-flags 选项可以根据tcp包的标志位进行过滤。 #iptables -A INPUT -p tcp –tcp-flags SYN,FIN,ACK SYN #iptables -A FROWARD -p tcp –tcp-flags ALL SYN,ACK 上实例中第一个表示SYN、ACK、FIN的标志都检查，但是只有SYN匹配。第二个表示ALL（SYN， ACK，FIN，RST，URG，PSH）的标志都检查，但是只有设置了SYN和ACK的匹配。 #iptables -A FORWARD -p tcp –syn 选项—syn相当于”–tcp-flags SYN,RST,ACK SYN”的简写。 3、limit速率匹配扩展。 1）指定单位时间内允许通过的数据包个数，单位时间可以是/second、/minute、/hour、/day或使用第一个子母。 #iptables -A INPUT -m limit –limit 300/hour 2 )指定触发事件的阀值。 #iptables -A INPUT -m limit –limit-burst 10 用来比对一次同时涌入的封包是否超过10个，超过此上限的包将直接丢弃。 3）同时指定速率限制和触发阀值。 #iptables -A INPUT -p icmp -m limit –-limit 3/m –limit-burst 3 表示每分钟允许的最大包数量为限制速率（本例为3）加上当前的触发阀值burst数。任何情况下，都可保 证3个数据包通过，触发阀值burst相当于允许额外的包数量。 4、基于状态的匹配扩展（连接跟踪） 每个网络连接包括以下信息：源地址、目标地址、源端口、目的端口，称为套接字对（socket pairs）；协 议类型、连接状态（TCP协议） 和超时时间等。防火墙把这些信息称为状态（stateful）。状态包过滤防火墙能在内存中维护一个跟踪状态 的表，比简单包过滤防火墙具有更大的安全性，命令格式如下： iptables -m state –-state [!]state [,state,state,state] 其中，state表是一个逗号分割的列表，用来指定连接状态，4种： &gt;NEW：该包想要开始一个新的连接（重新连接或连接重定向） &gt;RELATED：该包是属于某个已经建立的连接所建立的新连接。举例： FTP的数据传输连接和控制连接之间就是RELATED关系。 &gt;ESTABLISHED：该包属于某个已经建立的连接。 &gt;INVALID：该包不匹配于任何连接，通常这些包被DROP。 &gt;UNTRACKED：未进行追踪的连接，如raw表中关闭追踪 示例： iptables -A INPUT -d 172.16.1.10 -p tcp -m multiport –dports 22,80 -m state — state NEW,ESTABLISHED -j ACCEPT iptables -A OUTPUT -s 172.16.1.10 -p tcp -m multiport –sports 22,80 -m state — state ESTABLISHED -j ACCEPT 已经追踪到的并记录下来的连接信息库 /proc/net/nf_conntrack 调整连接追踪功能所能够容纳的最大连接数量 /proc/sys/net/nf_conntrack_max 不同的协议的连接追踪时长 /proc/sys/net/netfilter/ 注意：CentOS7 需要加载模块： modprobe nf_conntrack 开放被动模式的ftp服务 装载ftp连接追踪的专用模块： 跟踪模块路径：/lib/modules/kernelversion/kernel/net/netfilter 123vim /etc/sysconfig/iptables-config IPTABLES_MODULES=“nf_conntrack_ftp” modproble nf_conntrack_ftp 放行请求报文： 命令连接：NEW, ESTABLISHED 数据连接：RELATED, ESTABLISHED 123iptables –I INPUT -d LocalIP -p tcp -m state –state ESTABLISHED,RELATED -j ACCEPTiptables -A INPUT -d LocalIP -p tcp –dport 21 -m state –state NEW -j ACCEPT 放行响应报文： 1iptables -I OUTPUT -s LocalIP -p tcp -m state –state ESTABLISHED -j ACCEPT 开放被动模式的ftp服务示例： 12345678910yum install vsftpdsystemctl start vsftpdmodprobe nf_conntrack_ftpiptables -Fiptables -A INPUT -m state –state ESTABLISHED,RELATED -j ACCEPTiptables -A INPUT -p tcp –dport 21 -m state –state NEW -j ACCEPTiptables -A OUTPUT -m state –state ESTABLISHED -j ACCEPTiptables -P INPUT DROPiptables -P OUTPUT DROPiptables –vnL iptable防火墙优化原则任何不允许的访问，应该在请求到达时给予拒绝 规则在链接上的次序即为其检查时的生效次序 基于上述，规则优化 1 安全放行所有入站和出站的状态为ESTABLISHED状态连接 2 谨慎放行入站的新请求 3 有特殊目的限制访问功能，要在放行规则之前加以拒绝 4 同类规则（访问同一应用），匹配范围小的放在前面，用于特殊处理 5 不同类的规则（访问不同应用），匹配范围大的放在前面 6 应该将那些可由一条规则能够描述的多个规则合并为一条 7 设置默认策略，建议白名单（只放行特定连接） 1） iptables -P，不建议 2） 建议在规则的最后定义规则做为默认策略 ## 四、NAT地址转换NAT：network address translation PREROUTING，INPUT，OUTPUT，POSTROUTING 请求报文：修改源/目标IP，由定义如何修改 响应报文：修改源/目标IP，根据跟踪机制自动实现 SNAT：source NAT POSTROUTING, INPUT 让本地网络中的主机通过某一特定地址访问外部网络，实现地址伪装 请求报文：修改源IP 典型应用场景：多个PC机使用ADSL路由器共享上网，每个PC机都配置了内网IP，PC机访问 外部网络的时候，路由器将数据包的报头中的源地址替换成路由器的ip，当外部网络的服 务器比如网站web服务器接到访问请求的时候，他的日志记录下来的是路由器的ip地址，而 不是pc机的内网ip；这是因为，这个服务器收到的数据包的报头里边的“源地址”，已经 被替换了所以叫做SNAT，基于源地址的地址转换。 DNAT：destination NAT PREROUTING , OUTPUT 把本地网络中的主机上的某服务开放给外部网络访问(发布服务和端口映射)， 但隐藏真实IP 请求报文：修改目标IP 典型应用场景：比如有web服务器放在内网配置内网ip，前端有个防火墙配置公网ip，互联 网上的访问者使用公网ip来访问这个网站当访问的时候，客户端发出一个数据包，这个数据 包的报头里边，目标地址写的是防火墙的公网ip，防火墙会把这个数据包的报头改写一次， 将目标地址改写成web服务器的内网ip，然后再把这个数据包发送到内网的web服务器上，这 样，数据包就穿透了防火墙，并从公网ip变成了一个对内网地址的访问了，即DNAT，基于目 标的网络地址转换。 PNAT：port nat，端口和IP都进行修改 SNAT：固定IP –to-source [ipaddr[-ipaddr]][:port[-port]] –random iptables -t nat -A POSTROUTING -s LocalNET ! -d LocalNet -j SNAT –tosource ExtIP 示例： iptables -t nat -A POSTROUTING -s 10.0.1.0/24 ! –d 10.0.1.0/24 -j SNAT — to-source 172.18.1.6-172.18.1.9 SNAT：动态IP MASQUERADE：地址伪装 如此配置的话，不用指定SNAT的目标ip了，不管现在网卡的出口获得了怎样的动态ip， MASQUERADE会自动读取网卡现在的ip地址然后做SNAT出去，这样就实现了很好的动态 SNAT地址转换。 –to-ports port[-port] –random iptables -t nat -A POSTROUTING -s LocalNET ! -d LocalNet -j MASQUERADE 示例： iptables -t nat -A POSTROUTING -s 10.0.1.0/24 ! –d 10.0.1.0/24 -j MASQUERADE 如何区分SNAT和DNAT从定义来讲它们一个是源地址转换，一个是目标地址转换。都是地址转换的功能，将私有地 址转换为公网地址。 要区分这两个功能可以简单的由连接发起者是谁来区分： 内部地址要访问公网上的服务时（如web访问），内部地址会主动发起连接，由路由器或者 防火墙上的网关对内部地址做个地址转换，将内部地址的私有IP转换为公网的公有IP，网 关的这个地址转换称为SNAT，主要用于内部共享IP访问外部。 当内部需要提供对外服务时（如对外发布web网站），外部地址发起主动连接，由路由器或 者防火墙上的网关接收这个连接，然后将连接转换到内部，此过程是由带有公网IP的网关替 代内部服务来接收外部的连接，然后在内部做地址转换，此转换称为DNAT，主要用于内部服 务对外发布。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SAMBA服务介绍及相关实验]]></title>
    <url>%2F2018%2F06%2F29%2FSAMBA%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一、SAMBA介绍Samba是在Linux和UNIX系统上实现SMB协议的一个免费软件，由服务器及客户端程序构成。 SMB：Server Messages Block，信息服务块，是一种在局域网上共享文件和打印机的一种通信协议， 它为局域网内的不同计算机之间提供文件及打印机等资源的共享服务。 CIFS：common internet file system，微软基于SMB发布，CIFS是公共的或开放的SMB协议版本， 并由Microsoft使用。像SMB协议一样，CIFS在高层运行，而不像TCP/IP协议那样运行在底层。 CIFS可以看做是应用程序协议如文件传输协议和超文本传输协议的一个实现。 SAMBA的功能：共享文件和打印，实现在线编辑 实现登录SAMBA用户的身份认证 可以进行NetBIOS名称解析 外围设备共享 计算机网络管理模式：工作组 WORKGROUP：计算机对等关系，帐号信息各自管理 域 DOMAIN： C/S结构，帐号信息集中管理，DC,AD 相关包：​ Samba 提供smb服务 ​ Samba-client 客户端软件 ​ samba-common 通用软件 ​ cifs-utils smb 客户端工具 ​ samba-winbind 和AD相关 相关服务进程：​ smbd 提供smb（cifs）服务 TCP:139,445 ​ nmbd NetBIOS名称解析 UDP:137,138 主配置文件：/etc/samba/smb.conf 帮助参看：man smb.conf 语法检查： 1testparm [-v][/etc/samba/smb.conf] 客户端工具：smbclient,mount.cifs 二、SAMBA服务配置smb.conf继承了.ini文件的格式，用[ ]分成不同的部分 全局设置： ​ [global] 服务器通用或全局设置的部分 特定共享设置： ​ [homes] 用户的家目录共享 ​ [printers] 定义打印机资源和服务 ​ [sharename] 自定义的共享目录配置 其中：#和;开头的语句为注释，大小写不敏感 宏定义： 12345678910111213141516171819%m 客户端主机的NetBIOS名%M 客户端主机的FQDN%H 当前用户家目录路径%U 当前用户用户名%g 当前用户所属组%h samba服务器的主机名%L samba服务器的NetBIOS名%I 客户端主机的IP%T 当前日期和时间%S 可登录的用户名 workgroup 指定工作组名称 server string 主机注释信息 netbios name 指定NetBIOS名 interfaces 指定服务侦听接口和IP hosts allow 可用“,” ，空格，或tab分隔，默认允许所有主机访问，也可在每个共享独立配置， 如在[global]设置，将应用并覆盖所有共享设置 ​ IPv4 network/prefix：172.25.0.0/24 IPv4前缀: 172.25.0. ​ IPv4 network/netmask：172.25.0.0/255.255.255.0 ​ 主机名：desktop.example.com ​ 以example.com后缀的主机名：.example.com 示例： ​ hosts allow = 172.25. ​ hosts allow = 172.25. .example.com hosts deny 拒绝指定主机访问 config file=/etc/samba/conf.d/%U 用户独立的配置文件 Log file=/var/log/samba/log.%m 不同客户机采用不同日志 max log size=50 日志文件达到50K，将轮循rotate,单位KB Security三种认证方式： ​ share：匿名(CentOS7不再支持) ​ user：samba用户（采有linux用户，samba的独立口令） ​ domain：使用DC（DOMAIN CONTROLLER)认证 passdb backend = tdbsam 密码数据库格式 实现samba用户： 包：samba-common-tools 工具：smbpasswd pdbedit samba用户须是Linux用户，建议使用/sbin/nologin 配置samba日志默认不记录 以IP方式记录日志 12log file = /var/log/samba/log.%Ilog level = 2 日志文件达到50K，将轮循rotate,单位KB 1max log size=50 配置目录共享[共享名称] 远程网络看到的共享名称 comment 注释信息 path 所共享的目录路径 public 能否被guest访问的共享，默认no，和guest ok 类似 browsable 是否允许所有用户浏览此共享,默认为yes,no为隐藏 writable=yes 可以被所有用户读写，默认为no read only=no 和writable=yes等价，如与以上设置冲突，放在后面的设置生效，默认只读 write list 三种形式：用户，@组名，+组名,用，分隔如writable=no，列表中用户或组可读写，不在列表中用户只读 valid users 特定用户才能访问该共享，如为空，将允许所有用户，用户名之间用空格分隔 备注：每个共享目录应该有独立的[ ]部分 三、SMABA用户管理与挂载管理samba用户实现samba用户 包：samba-common-tools 工具：smbpasswd pdbedit samba用户须是Linux用户，建议使用/sbin/nologin ### 添加samba用户 12smbpasswd -a &lt;user&gt;pdbedit -a -u &lt;user&gt; 修改用户密码 1smbpasswd &lt;user&gt; 删除用户和密码： 12smbpasswd –x &lt;user&gt;pdbedit –x –u &lt;user&gt; 查看samba用户列表： 12/var/lib/samba/private/passdb.tdbpdbedit –L –v 查看samba服务器状态 1smbstatus 挂载CIFS文件系统手动挂载 12mount -t cifs -o user=wang,password=wxlinux //server//shared/mnt/smb 开机自动挂载 123456cat /etc/fstab 可以用文件代替用户名和密码的输入//server/homes /mnt cifs credentials=/etc/smb.txt 0 0cat /etc/smb.txtusername=wangpassword=passwordchmod 600 /etc/smb.txt 四、实验：将Linux作为SAMBA客户端访问Windows共享文件前期准备：Window系统版本为 win10 Linux系统版本为 CentOS 7.4 Windows系统中共享目录如下： 在Windows系统中创建一个test用户(必须以管理员身份创建) Linux系统：安装samba-client包 1yum install samba-client 查看Windows系统上的共资源 1smbclient -L 192.168.30.1 -U test%123 连接Windows系统上的共享资源 1smbclient //192.168.30.1/lamp -U test%123 挂载windows共享目录到/mnt/win目录下 123mkdir /mnt/winmount -o username=test,password=123,vers=3.0 //192.168.30.1/lamp /mnt/win 也可写入/etc/fstab文件中永久挂载，为了防止明文用户名密码，可用下面写法，将用户和账号保存在一个文件中 123vim /etc/user.txt username=test password=123 五、实验：Linux系统作为SAMBA服务器端在LINUX系统中创建SAMBA账号需要先创建LINUX账号在使用smbpasswd命令转换为samba账号 创建linux账号 123useradd -s /sbin/nologin smb1useradd -s /sbin/nologin smb2useradd -s /sbin/nologin smb3 将linux账号变为samba账号 123smbpasswd -a smb1smbpasswd -a smb2smbpasswd -a smb3 删除samba账号可使用 1smbpasswd –x 修改samba账号密码： 1smbpasswd user 查看已有的samba账号： 1pdbedit -L 开启smb服务 1systemctl start smb 切换客户端进行测试： 12 默认以samba用户的家目录作为共享目录 也可在Window作为访问端连接SAMBA服务器 六、实验：SAMBA共享指定目录添加配置 123456789vim etc/samba/sam.conf [share] comment=smba share dir path=/data/tools read only=no # 等价于writeabe=yes public=no # 是否允许匿名访问，默认为NO valid users=smb1 smb2 # 指定有效用户，其他用户不可访问 \#valid users=+staff # 也可指定有效组，用户多时建议用组管理 \#wirte list # 指定列表中用户可写，需配合read only=yes smbclient //192.168.30.10/share -U smb1%centos smb3用户由于没有授权，所有拒绝登录 七、实验：针对不同的用户设置不同的共享目录和权限SAMBA服务器端:目前已存在的SAMBA用户 配置文件中加上此行，指定配置目录 123vim etc/samba/sam.conf [global] config file = /etc/samba/conf.d/%U 创建SAMBA共享目录和测试文件 1234mkdir /data/smb2mkdir /data/smb3touch /data/smb2/test2touch /data/smb3/test3 创建SAMBA配置目录 123456789mkdir /etc/samba/conf.d/cd /etc/samba/conf.d/vim smb2 [share] path=/data/smb2 writeable=yesvim smb3 [share] path=/data/smb3 给data目录添加777权限 1chmod -R 777 /data/ 重启smb服务 1systemct restart smb 测试： 使用samb2用户登录，共享目录为/data/smb2 1smbclient //192.168.30.7/share -U smb2%centos 使用samb2用户登录，共享目录为/data/smb3 1smbclient //192.168.30.7/share -U smb3%centos 八、实验：实现多用户SAMBA挂载(仅CentOS 7支持，RHCE)SAMBA服务器端：目前已有四个samba账号，smb1，smb2，smb3，smb4 1234567vim /etc/samba/[share] comment = samba share dir path = /data/tools read only = yes valid users = smb1 smb2 smb3 smbshare write list = smb1 smb3 添加/data/tools目录读写权限 1chmod 777 /data/tools 重启smb服务 1systemctl restart smb 客户端：必须建立同名用户，UID可以不一致 123useradd smb1useradd smb2useradd smb3 用smbshare用户挂载share目录 1mount -o username=smbshare,password=centos,multiuser //192.168.30.10/share /mnt 若要永久挂载，可修改/etc/fstab目录 备注：SELinux环境下还需： 1chcon -R -t samba_share_t /data/to 测试1su – smb1 验证SAMBA服务器是否有同名用户 12 创建f1文件所有者为f1 1su – smb2 由于smb2不在wirte_list表中，不具有读权限，登录失败 12su – smb3cifscreds add 192.168.30.7 创建f3文件所有者为smb3]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>SAMBA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS文件系统介绍及相关实验]]></title>
    <url>%2F2018%2F06%2F28%2FNFS%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一、NFS网络文件系统介绍NFS：Network File System 网络文件系统，基于内核的文件系统。Sun公司开发，通过使用NFS， 用户和程序可以像访问本地文件一样访问远端系统上的文件，基于RPC（远程过程调用）实现 RPC采用C/S模式。客户机请求程序调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。 在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数， 计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果， 然后调用执行继续进行。 NFS优势： 节省本地存储空间，将常用的数据如：home目录,存放在一台NFS服务器上且可以通过网络访问，那么本 地终端将可以减少自身存储空间的使用，适合在局域网使用 用户不需要在网络中的每个机器上都建有Home目录，Home目录可以放在NFS服务器上且可以在网络上 被访问使用。 一些存储设备如软驱、CDROM和Zip（一种高储存密度的磁盘驱动器与磁盘）等都可以在网络上被别的 机器使用。这可以减少整个网络上可移动介质设备的数量。 NFS常见应用场景： 多个机器共享一台CDROM或者其他设备。这对于在多台机器中安装软件来说更加便宜跟方便。 在大型网络中，配置一台中心NFS服务器用来放置所有用户的home目录可能会带来便利。这些目录能被输出到网络以便用户不管在哪台工作站上登录，总能得到相同的home目录。 不同客户端可在NFS上观看影视文件，节省本地空间。 在客户端完成的工作数据，可以备份保存到NFS服务器上用户自己的路径下。 二、NFS服务介绍软件包：nfs-utils(系统自带) Kernel支持:nfs.ko 端口：2049(nfsd), 其它端口由rpcbind(111)分配 配置文件：/etc/exports,/etc/exports.d/*.exports CentOS 7不支持同一目录同时用nfs和samba共享，因为使用锁机制不同 相关软件包：rpcbind（必须），tcp_wrappers CentOS 6开始portmap进程由rpcbind代替 NFS服务主要进程： ​ rpc.nfsd 最主要的NFS进程，管理客户端是否可登录 ​ rpc.mountd 挂载和卸载NFS文件系统，包括权限管理 ​ rpc.lockd 非必要，管理文件锁，避免同时写出错 ​ rpc.statd 非必要，检查文件一致性，可修复文件 日志：/var/lib/nfs/ 配置防火墙，开放NFS服务 配置NFS使用固定端口 1234567vim /etc/sysconfig/nfs RQUOTAD_PORT=875 LOCKD_TCPPORT=32803 LOCKD_UDPPORT=32769 MOUNTD_PORT=892 STATD_PORT=662 STATD_OUTGOING_PORT=2020 防火墙除开放上述端口，还需开放TCP和UDP的111和2049共4个端口 导出的文件系统的格式：/dir 主机1(opt1,opt2) 主机2(opt1,opt2)… #开始为注释 主机格式： 单个主机：ipv4，ipv6，FQDN IP networks：两种掩码格式均支持 172.18.0.0/255.255.0.0 172.18.0.0/16 wildcards：主机名通配，例如*.magedu.com，IP不可以 netgroups：NIS域的主机组，@group_name anonymous：表示使用*通配所有客户端 每个条目指定目录导出到的哪些主机，及相关的权限和选项 默认选项：**(ro,sync,root_squash,no_all_squash)** 示例：在/etc/exports文件中定义导出目录 123456789101112/myshare server.example.com/myshare *.example.com/myshare server?.example.com/myshare server[0-20].example.com/myshare 172.25.11.10/myshare 172.25.0.0/16/myshare 2000:472:18:b51:c32:a21/myshare 2000:472:18:b51::/64/myshare *.example.com 172.25.0.0/16/myshare desktop.example.com(ro)/myshare desktop.example.com(ro) server[0-20].example.com(rw)/myshare diskless.example.com(rw,no_root_squash) NFS工具：rpcinfo rpcinfo -p hostname rpcinfo -s hostname 查看RPC注册程序 exportfs ​ -v 查看本机所有NFS共享 ​ -r 重读配置文件，并共享目录 ​ -a 输出本机所有共享 ​ -au 停止本机所有共享 查看指定NFS服务器提供的共享目录文件 showmount -e NfsServerIP mount.nfs 挂载工具 NFSv4支持通过挂载NFS服务器的共享“根”，从而浏览NFS服务器上的共享目录列表 mount nfsserver:/ /mnt/nfs 三、NFS挂载及autofs自动挂载客户端NFS挂载：基于安全考虑，建议使用nosuid,nodev,noexec挂载选项 NFS相关的挂载选项： ​ fg（默认）前台挂载，bg后台挂载 ​ hard（默认）持续请求，soft 非持续请求 ​ intr 和hard配合，请求可中断 ​ rsize和wsize 一次读和写数据最大字节数，rsize=32768 ​ _netdev 无网络不挂载 示例： 默认NFS v4版本挂载 ​ mount -o rw,nosuid,fg,hard,intr 192.168.0.1:/testdir /mnt/nfs/ 也可指定以其他NFS版本挂载 ​ mount -o vers=3 192.168.2.7:/data/nfsdir2 /mnt/nfs2 开机挂载:/etc/fstab ​ 192.168.0.1:/public /mnt/nfs nfs defaults 0 0 autofs自动挂载：可使用autofs按需要挂载NFS共享，在空闲时自动卸载 由autofs包提供 系统管理器指定由/etc/auto.master自动挂载器守护进程控制的挂载点 自动挂载监视器访问这些目录并按要求挂载文件系统 文件系统在失活的指定间隔5分钟后会自动卸载 为所有导出到网络中的NFS启用特殊匹配 -host 至“browse” 参看帮助：man 5 autofs 支持含通配符的目录名 server:/export/&amp; 四、实验：实现NFS服务前期准备：虚拟机两台 NFS服务器：CentOS 7.4 IP：192.168.2.7 客户端：CentOS 7.4 IP：192.168.2.11 NFS服务器端：123456systemctl start nfs-servermkdir /data/nfsdir&#123;1,2,3&#125;vim /etc/exports /data/nfsdir1 * /data/nfsdir2 *(rw) /data/nfsdir3 *(rw,no_root_squash) 也可基于IP控制NFS访问(安全性不高，可被冒充) 12 重启NFS服务 1exportfs –r 查看本机已生效的NFS共享文件 1exportfs -v 客户端：查看NFS服务器提供的文件 1showmount -e 192.168.2.7 创建挂载NFS的目录 12 挂载nfsdir1，默认NFS v4版本挂载 1mount 192.168.2.7:/data/nfsdir1 /mnt/nfs1 也可指定以其他NFS版本挂载 1mount -o vers=3 192.168.2.7:/data/nfsdir2 /mnt/nfs2 NFS也是一种文件系统，可用mount命令查看已挂载的NFS文件系统 写入/etc/fstab文件中实现永久挂载 nfs1目录只读挂载，无法创建文件 nfs2目录可创建文件，文件所有者，所属组映射为nfsnobody nfs3目录因为加了no_root_squash，root创建文件不影响到nfsnobody 五、实验：实现NFS伪根(RHCE)前期准备：虚拟机两台 NFS服务器：CentOS 7.4 IP：192.168.2.7 客户端：CentOS 7.4 IP：192.168.2.11 NFS服务器端：123456789mkdir /app/nfsdir1mkdir /data/nfsdir2mkdir /nfsroot/dir&#123;1,2&#125; -pv# 挂载目录vim /etc/fstab /app/nfsdir1 /nfsroot/dir1 none bind 0 0 /data/nfsdir2 /nfsroot/dir2 none bind 0 0mount -a NFS配置文件 1234vim /etc/exports.d/nfsroot.exports /nfsroot *(fsid=0,rw,crossmnt) /nfsroot/dir1 *(rw) /nfsroot/dir2 *(ro) 重启NFS服务 1exportfs –r 查看本机生效的NFS文件 1exportfs –v 客户端：查看NFS服务器提供的文件 1showmount -e 192.168.2.7 挂载伪根目录 1mount 192.168.2.7:/nfsroot /mnt 六、实验：实现家目录NFS自动绝对路径、相对路径挂载前期准备：虚拟机三台 NFS服务器：CentOS 6.9 IP：192.168.30.13 客户端1：CentOS 7.4 IP：192.168.2.7 客户端2：CentOS 7.4 IP：192.168.2.11 实验预期：客户端1实现相对路径挂载，客户端2实现绝对路基挂载 NFS服务器：开启nfs服务 12service rpcbind startservice nfs start 建立用户nfs1，nfs2 12useradd -d /data/nfs/nfs1 -u 2001 nfs1useradd -d /data/nfs/nfs2 -u 2002 nfs2 编写测试文件 12touch /data/nfs/nfs1/test1touch /data/nfs/nfs2/test2 编写nfs共享配置 12vim /etc/exports/data/ *(rw) 相对路径挂载：切换到客户端1： 12 建立两个用户nfsuser1，nfsuser2 12useradd -u 2001 nfsuser1useradd -u 2002 nfsuser2 配置相对路径自动挂载 12vim /etc/auto.master/home /etc/home.autofs 123vim /etc/home.autofs nfsuser1 -fstype=nfs,vers=3 192.168.30.11:/data/nfs/nfs1 nfsuser2 -fstype=nfs,vers=3 192.168.30.11:/data/nfs/nfs2 重启autofs服务 1systemctl restart autofs 测试 1su -nfsuser1 绝对路径挂载：切换到客户端2： 12useradd -u 2001 nfsuser1useradd -u 2002 nfsuser2 配置绝对路径自动挂载 12vim /etc/auto.master /- /etc/home.autofs 123vim /etc/home.autofs /home/nfsuser1 -fstype=nfs,vers=3 192.168.30.11:/data/nfs/nfs1 /home/nfsuser2 -fstype=nfs,vers=3 192.168.30.11:/data/nfs/nfs2 测试：]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>NFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FTP服务介绍及相关实验]]></title>
    <url>%2F2018%2F06%2F26%2FFTP%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一、FTP服务FTP是File Transfer Protocol（文件传输协议）的英文简称，而中文简称为“文传协议”。 用于Internet上的控制文件的双向传输。FTP协议是早期的三个应用级协议之一。 基于C/S结构 双通道协议：数据和命令连接 数据传输格式：二进制（默认）和文本 两种模式：服务器角度 主动(PORT style)：服务器主动连接 ​ 命令（控制）：客户端：随机port — 服务器：tcp21 ​ 数据： 客户端：随机port — 服务器：tcp20 被动(PASV style)：客户端主动连接 ​ 命令（控制）：客户端：随机port — 服务器：tcp21 ​ 数据： 客户端：随机port — 服务器：随机port 服务器被动模式数据端口示例： ​ 227 Entering Passive Mode (192,168,175,138,224,59) ​ 服务器数据端口为：224*256+59 注：Linux客户端默认使用被动模式 ​ Windows客户端默认使用主动模式 ​ Linux系统客户端若要切换主动模式，可使用：ftp -A ServerIP Port 主动连接与被动连接的优缺点： 主动连接对FTP服务器的管理有利，但对客户端的管理不利。因为FTP服务器企图与客户端的高位随机端口建立连接，而这个端口很有可能被客户端的防火墙阻塞掉。 被动连接对FTP客户端的管理有利，但对服务器端的管理不利。因为客户端要与服务器端建立两个连接，其中一个连到一个高位随机端口，而这个端口很有可能被服务器端的防火墙阻塞掉。 注：可通过为FTP服务器指定一个有限的端口范围来减小服务器端口暴露的风险。 FTP服务器：Wu-ftpd，Proftpd，Pureftpd，ServU，IIS vsftpd：Very Secure FTP Daemon，CentOS默认FTP服务器 高速，稳定，下载速度是WU-FTP的两倍 ftp.redhat.com数据：单机最多可支持15000个并发 客户端软件：ftp，lftp，lftpget，wget，curl ​ ftp -A ftpserver port -A 主动模式 -p 被动模式 ​ lftp -u username ftpserver ​ lftp username@ftpserver ​ lftpget ftp://ftpserver/pub/file gftp: GUI centos5 最新版2.0.19 (11/30/2008) filezilla，CuteFtp，FlashFXP，LeapFtp IE ftp://username:password@ftpserver 状态码：1XX：信息类 125：数据连接打开 2XX：成功类状态 200：命令OK 230：登录成功 3XX：补充类 331：用户名OK 4XX：客户端错误 425：不能打开数据连接 5XX：服务器错误 530：不能登录 用户认证：匿名用户：ftp,anonymous,对应Linux用户ftp 系统用户：Linux用户,用户/etc/passwd,密码/etc/shadow 虚拟用户：特定服务的专用用户，独立的用户/密码文件 nsswitch：network service switch 名称解析框架 pam：pluggable authentication module 可插拔认证模块 ​ pam的相关文件： /lib64/security /etc/pam.d/ /etc/pam.conf 二、vsftpd服务vsftpd全称为”Very Secure FTP Daemon“,意为非常安全的FTP守护进程， vsftpd最初发展理念就是建构一个以安全为重心的FTP服务器。 由vsftpd包提供，CentOS 7之后不再由xinetd管理 用户认证配置文件： /etc/pam.d/vsftpd 服务脚本： /usr/lib/systemd/system/vsftpd.service /etc/rc.d/init.d/vsftpd 配置文件： /etc/vsftpd/vsftpd.conf 格式：option=value 注意：= 前后不要有空格 匿名用户（映射为系统用户ftp ）登录的根目录位置：/var/ftp 系统用户共享文件位置：用户家目录 虚拟用户共享文件位置：为其映射的系统用户的家目录 vsftpd虚拟用户虚拟用户： 所有虚拟用户会统一映射为一个指定的系统帐号：访问共享位置，即为此系统帐号的家目录 各虚拟用户可被赋予不同的访问权限，通过匿名用户的权限控制参数进行指定 虚拟用户帐号的存储方式： 文件：编辑文本文件，此文件需要被编码为hash格式 奇数行为用户名，偶数行为密码 db_load -T -t hash -f vusers.txt vusers.db 关系型数据库中的表中： 实时查询数据库完成用户认证 mysql库：pam要依赖于pam-mysql /lib64/security/pam_mysql.so /usr/share/doc/pam_mysql-0.7/README vsftpd.conf常用配置帮助查询：man 5 vsftpd.conf 重设命令端口：listen_port=21 主动模式端口 ​ connect_from_port_20=YES 主动模式端口为20 ​ ftp_data_port=20 指定主动模式的端口 被动模式端口范围 ​ Linux客户端默认使用被动模式 ​ Windows客户端默认使用主动模式 ​ pasv_min_port=6000 0为随机分配 ​ pasv_max_port=6010 注：可以通过为FTP服务器指定一个有限的端口范围来减小服务器端口暴露的风险 使用当地时间 use_localtime=YES 使用当地时间（默认为NO，使用GMT） 匿名用户 ​ anonymous_enable=YES 支持匿名用户 ​ no_anon_password=YES(默认NO) 匿名用户略过口令检查 ​ anon_world_readable_only (默认YES)只能下载全部读的文件 ​ anon_upload_enable=YES 匿名上传，注意:文件系统权限 ​ anon_mkdir_write_enable=YES 匿名创建，写权限 ​ anon_umask=077 指定匿名上传文件的umask ​ anon_other_write_enable=YES 可删除和修改上传的文件 可指定上传文件的默认的所有者和权限 ​ chown_uploads=YES(默认NO) ​ chown_username=wang ​ chown_upload_mode=0644 Linux系统用户 ​ guest_enable=YES 所有系统用户都映射成guest用户 ​ guest_username=ftp 配合上面选项才生效，指定guest用户 ​ local_enable=YES 是否允许Linux用户登录 ​ write_enable-YES 是否允许Linux用户上传文件 ​ local_umask=022 指定系统用户上传文件的默认权限 ​ local_root=/ftproot 非匿名用户登录所在目录 禁锢所有系统用户在家目录中 ​ chroot_local_user=YES（默认NO，不禁锢）禁锢系统用户 禁锢或不禁锢特定的系统用户在家目录中，与上面设置功能相反 ​ chroot_list_enable=YES chroot_list_file=/etc/vsftpd/chroot_list ​ 当chroot_local_user=YES时，则chroot_list中用户不禁锢，白名单 ​ 当chroot_local_user=NO时，则chroot_list中用户禁锢，黑名单 ftp日志wu-ftp日志：默认启用 ​ xferlog_enable=YES （默认） 启用记录上传下载日志 ​ xferlog_std_format=YES （默认）使用wu-ftp日志格式 ​ xferlog_file=/var/log/xferlog （默认）可自动生成 vsftpd日志：默认不启用 ​ dual_log_enable=YES 使用vsftpd日志格式，默认不启用 ​ vsftpd_log_file=/var/log/vsftpd.log（默认）可自动生成 登录提示信息 ​ ftpd_banner=”welcome to mage ftp server” ​ banner_file=/etc/vsftpd/ftpbanner.txt 优先上面项生效 目录访问提示信息 ​ dirmessage_enable=YES (默认) ​ message_file=.message(默认) 信息存放在指定目录下.message 使用PAM完成用户认证 ​ pam_service_name=vsftpd ​ pam配置文件:/etc/pam.d/vsftpd /etc/vsftpd/ftpusers 默认文件中用户拒绝登录 /etc/vsftpd/users_list 默认文件中用户拒绝登录，不提示口令输入 是否启用控制用户登录的列表文件 ​ userlist_enable=YES 默认有此设置 ​ userlist_deny=YES(默认值) 黑名单,不提示口令，NO为白名单 ​ userlist_file=/etc/vsftpd/users_list 此为默认值 连接限制 ​ max_clients=0 最大并发连接数 ​ max_per_ip=0 每个IP同时发起的最大连接数 注：生成环境一般会将最大并发连接数按需设置；单个IP最大连接数尽量调小 vsftpd服务指定用户身份运行 ​ nopriv_user=nobody 传输速率：字节/秒 ​ anon_max_rate=0 匿名用户的最大传输速率 ​ local_max_rate=0 本地用户的最大传输速率 连接时间：秒为单位 ​ connect_timeout=60 主动模式数据连接超时时长 ​ accept_timeout=60 被动模式数据连接超时时长 ​ data_connection_timeout=300 数据连接无数据输超时时长 ​ idle_session_timeout=60 无命令操作超时时长 优先以文本方式传输 ​ ascii_upload_enable=YES ​ ascii_download_enable=YES 配置FTP服务以非独立服务方运行:listen=NO，默认为独立方式 1234567891011vim /etc/xinetd.d/rsyncservice ftp&#123; flags = REUSE socket_type = stream wait = no user = root server = /usr/sbin/vsftpd log_on_failure += USERID disable = no&#125; 三、实验：实现基于SSL的FTPS前期准备：FTP服务器：CentOS7.4 IP地址：192.168.2.11 具体步骤：查看是否支持SSL 1ldd `which vsftpd`|grep libssl # 查看到libssl.so 创建自签名证书 123cd /etc/pki/tls/certs/make vsftpd.pemopenssl x509 -in vsftpd.pem -noout -text 配置vsftpd服务支持SSL： 123456vim /etc/vsftpd/vsftpd.conf ssl_enable=YES # 启用SSL allow_anon_ssl=NO # 匿名不支持SSL force_local_logins_ssl=YES # 本地用户登录加密 force_local_data_ssl=YES # 本地用户数据传输加密 rsa_cert_file=/etc/pki/tls/certs/vsftpd.pem # 指定证书位置 用filezilla工具测试: 点击文件–&gt;站点管理器–&gt;新站点，协议选择SFTP，登录类型选择一般 是否信任主机并继续，点确定 连接成功 四、实验：基于文件验证的vsftpd虚拟用户前期准备:Ftp服务器: CentOS 7.4 192.168.2.7 访问端：CentOS7.5 192.168.2.11 具体步骤： 创建用户数据库文件 12345678vim /etc/vsftpd/vusers.txt vuse1 centos vuse2 lpxcd /etc/vsftpd/ db_load -T -t hash -f vusers.txt vusers.db # 转换为db型文件chmod 600 vusers.db 创建用户和访问FTP目录 1234567mkdir -pv /data/ftpuseradd -d /data/ftp -s /sbin/nologin vuserchmod +rx /data/ftp/# centos7 还需要执行以下操作：chmod -w /data/ftp/mkdir /data/ftp/uploadsetfacl -m u:vuser:rwx /data/ftp/upload 创建pam配置文件 123vim /etc/pam.d/vsftpd.db auth required pam_userdb.so db=/etc/vsftpd/vusers account required pam_userdb.so db=/etc/vsftpd/vusers 指定pam 1234vim /etc/vsftpd/vsftpd.conf guest_enable=YES guest_username=vuser user_config_dir=/etc/vsftpd/vusers.d/ 找到此行，将vsftpd模块替换为vsftpd.db 1pam_service_name=vsftpd==&gt;pam_service_name=vsftpd.db 虚拟用户建立独立的配置文件 12345678910111213mkdir /etc/vsftpd/vusers.d/cd /etc/vsftpd/vusers.d/# 创建个用户自己的配置文件# 允许vuser1用户可读写，其他用户只读vim vuser1 anon_upload_enable=YES anon_mkdir_write_enable=YES anon_other_write_enable=YES指定vuse2用户登录的根目录vim vuser2 local_root=/data/ftp 测试 切换到另外一台主机ftp连接，虚拟用户vuser1，vuser2登录成功 五、实验：实现基于MySQL验证的vsftpd虚拟用户前期准备：虚拟机2台 FTP服务器： CentOS 7.4 IP：192.168.2.11 MySQL服务器：CentOS 7.4 IP：192.168.2.12 具体步骤：一、安装所需要包和包组： 在数据库服务器上安装包： Centos7：在数据库服务器上安装 123yum –y install mariadb-serversystemctl start mariadb.servicesystemctl enable mariadb Centos6：在数据库服务器上安装 1yum –y install mysql-server 在FTP服务器上安装vsftpd和pam_mysql包 CentOS6：pam_mysql由epel6的源中提供 1yum install vsftpd pam_mysql CentOS7：无对应rpm包，需手动编译安装 12yum -y groupinstall &quot;Development Tools&quot;yum -y install mariadb-devel pam-devel vsftpd 编译安装pam_mysql 123456下载pam_mysql-0.7RC1.tar.gz报tar xvf pam_mysql-0.7RC1.tar.gzcd pam_mysql-0.7RC1/./configure --with-mysql=/usr --with-pam=/usr --with-pam-mods-dir=/lib64/securitymakemake install 二、在数据库服务器上创建虚拟用户账号 建立存储虚拟用户数据库和连接的数据库用户 1234mysql&gt; CREATE DATABASE vsftpd;mysql&gt; SHOW DATABASES;# ftp服务和mysql不在同一主机：mysql&gt; GRANT SELECT ON vsftpd.* TO vsftpd@&apos;192.168.%.%&apos; IDENTIFIED BY &apos;magedu&apos;; ftp服务和mysql在同一主机： 123mysql&gt; GRANT SELECT ON vsftpd.* TO vsftpd@localhost IDENTIFIED BY &apos;magedu&apos;;mysql&gt; GRANT SELECT ON vsftpd.* TO vsftpd@&apos;127.0.0.1′ IDENTIFIED BY &apos;magedu&apos;;mysql&gt; FLUSH PRIVILEGES; 准备相关表 12345678mysql&gt; USE vsftpd;mysql&gt; SHOW TABLES;mysql&gt; CREATE TABLE users ( id INT AUTO_INCREMENT NOT NULL PRIMARY KEY, name CHAR(50) BINARY NOT NULL, password CHAR(48) BINARY NOT NULL);mysql&gt;DESC users; 测试连接 12mysql -uvsftpd –h192.168.2.11 -pmagedumysql&gt; SHOW DATABASES; 添加虚拟用户 根据需要添加所需要的用户，为了安全应该使用PASSWORD函数加密其密码后存储 1234mysql&gt; DESC users;mysql&gt; INSERT INTO users(name,password) values(&apos;wang&apos;,password(&apos;magedu&apos;));mysql&gt; INSERT INTO users(name,password) values(&apos;mage&apos;,password(&apos;magedu&apos;));mysql&gt; SELECT * FROM users; 三、在FTP服务器上配置vsftpd服务 在FTP服务器上建立pam认证所需文件 1234567vim /etc/pam.d/vsftpd.mysql 添加如下两行 auth required pam_mysql.so user=vsftpd passwd=magedu host=192.168.2.11 db=vsftpd table=users usercolumn=name passwdcolumn=password crypt=2 account required pam_mysql.so user=vsftpd passwd=magedu host=192.168.2.11 db=vsftpd table=users usercolumn=name passwdcolumn=password crypt=2 注意：参考README文档，选择正确的加密方式 crypt是加密方式，0表示不加密，1表示crypt(3)加密，2表示使用mysql password()函数加密，3表示md5加密，4表示sha1加密 配置字段说明： ​ auth 表示认证 ​ account 验证账号密码正常使用 ​ required 表示认证要通过 ​ pam_mysql.so 模块是默认的相对路径，是相对/lib64/security/路径而言，也可以写绝对路径； ​ 后面为给此模块传递的参数 ​ user=vsftpd 登录mysql的用户 ​ passwd=magedu 登录mysql的的密码 ​ host=mysqlserver mysql 服务器的主机名或ip地址 ​ db=vsftpd 指定连接msyql的数据库名称 ​ table=users 指定连接数据库中的表名 ​ usercolumn=name 当做用户名的字段 ​ passwdcolumn=password 当做用户名字段的密码 ​ crypt=2 密码的加密方式为mysql password()函数加密 建立相应用户和修改vsftpd配置文件，使其适应mysql认证 建立虚拟用户映射的系统用户及对应的目录 12345678910useradd -s /sbin/nologin -d /var/ftproot vuserchmod 555 /var/ftproot centos7 需除去ftp根目录的写权限mkdir /var/ftproot/&#123;upload,pub&#125;setfacl –m u:vuser:rwx /var/ftproot/upload# 确保**/etc/vsftpd.conf**中已经启用了以下选项vim /etc/vsftpd.conf anonymous_enable=YES# 添加下面两项 guest_enable=YES guest_username=vuser 修改下面一项，原系统用户无法登录 1pam_service_name=vsftpd.mysql 四、启动vsftpd服务 12345service vsftpd start;systemctl start vsftpdchkconfig vsftpd on;systemctl enable vsftpd#查看端口开启情况netstat -tnlp |grep :21 五、测试：利用FTP客户端工具,以虚拟用户登录验证结果]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP架构实现]]></title>
    <url>%2F2018%2F06%2F23%2FLAMP%E6%9E%B6%E6%9E%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[一、LAMP介绍LAM(M)P是一组Web应用软件的组合，Linux+Apache+Mysql/MariaDB+Perl/PHP/Python一组 常用来搭建动态网站或者服务器的开源软件，所有组成产品均是开源软件，本身都是各自 独立的程序，但是因为常被放在一起使用，拥有了越来越高的兼容度，共同组成了一个强 大的Web应用程序平台。 L：Linux A：Apache (httpd) M：Mysql, Mariadb M：Memcached P：PHP, Perl, Python WEB资源类型：​ 静态资源：原始形式与响应内容一致，在客户端浏览器执行 动态资源：原始形式通常为程序文件，需要在服务器端执行之后，将执行结果返回给客户端 Web相关语言 客户端技术： html，javascript 服务器端技术：php, jsp，python，asp LAMP工作原理： 二、实例：LAMP搭建PhpMyAdmin实验环境：Linux： CentOS 7.4 Apache： httpd-2.4.6 MariaDB：mariadb-server-5.5.56 Php，php-mysql：php-5.4.16 具体步骤：1 下载phpMyAdmin 4.0.10.20 注：此版本支持PHP 5.2 和 MySQL 5之前，不支持 PHP 5.5 更新的版本 1wget https://files.phpmyadmin.net/phpMyAdmin/4.0.10.20/phpMyAdmin-4.0.10.20-all-languages.tar.xz 2 解压到httpd目录下 1tar xvf phpMyAdmin-4.0.10.20-all-languages.tar.xz -C /var/www/html/ 统一该目录名称，方便操作 12cd /var/www/html/mv phpMyAdmin-4.0.10.20-all-languages/ phpMyAdmin 3 复制配置文件，不需要更改内容 12cd phpMyAdmin/cp config.sample.inc.php config.inc.php 安装php-mbstring 1yum install php-mbstring –y 4 重启httpd服务 1systemctl restart httpd 5 打开浏览器访问http://192.168.30.10/phpMyAdmin/，出现下图即表示PhpMyAdmin搭建成功 6使用mysql账号进行登录，就可进行数据库的图形化操作了 三、实例：CentOS7编译Php-xcache实验环境：亚马逊云主机一台，以WordPress搭建了www.wxlinux.com 操作系统版本：CentOS7.5 PHP版本为：5.4.16 Httpd版本为：Apache2.4.6 数据库版本：mariadb-server-5.5.56 安全前我们测试下www.wxlinux.com的每秒请求数，为1.90次/秒 ab -c 10 -n 100 http://www.wxlinux.com/ 下载最新版本Php-xcache wget https://xcache.lighttpd.net/pub/Releases/3.2.0/xcache-3.2.0.tar.gz 解压包到/data目录下 tar xvf xcache-3.2.0.tar.gz -C /data cd xcache-3.2.0 此时xcache目录下是没有configure文件的，我们需要使用phpize命令生成它 安装php-devlop包 yum install php-devlop yum install gcc 生成编译环境 phpize 查看下php-config文件位置 [root@wxlinux ~]#which php-config /bin/php-config 编译安装 ./configure –enable-xcache –with-php-config=/bin/php-config make &amp;&amp; make install cp xcache-3.2.0/xcache.ini /etc/php.d/ 重启http服务使其生效 systemctl restart httpd.service 再次进行测试，每秒请求数提升到3.95 四、实例：LAMP搭建wordpress前期准备： 操作系统版本：CentOS7.5 PHP版本为：5.4.16 Httpd版本为：Apache2.4.6 数据库版本：mariadb-server-5.5.56 配置环境： 1yum -y install httpd php mariadb-server php-mysql 启动相应服务 1systemctl start httpd mariadb 为数据库设置root账号密码 1mysqladmin -u root password “XXXXXXXX” 创建一个名为wordpress的数据库 1mysql&gt; create database wordpress; 下载wordpress wget http://wordpress.org/latest.tar.gz 解压安装包 tar –zxf latest.tar.gz -C /var/www/html 注意wordpress目录权限 setfacl -R -m u:apache:rwx /var/www/html/wordpress 重启httpd服务 systemctl restart httpd 浏览器打开：http://192.168.30.10/wordpress 简单的进行一些配置，即可完成wordpress的搭建 ![DLH}ZHW]GR6Q_QTE3DQSU2 五、实验：centos7上源码编译安装LAMP的多虚拟主机wordpress，discuz前期准备：虚拟机两台 LAMP server： CentOS 7.5，完全干净的系统环境 IP：192.168.30.17 Client： CentOS7.4 IP：192.168.30.10 准备以下安装包 apr-1.6.3.tar.gz apr-util-1.6.1.tar.gz httpd-2.4.33.tar.bz2 mariadb-10.2.15-linux-x86_64.tar.gz php-7.1.18.tar.bz2 wordpress-4.9.4-zh_CN.tar.gz Discuz_X3.3_SC_UTF8.zip 1.编译安装httpdtar xvf httpd-2.4.33.tar.bz2 tar xvf apr-1.6.3.tar.gz tar xvf apr-util-1.6.1.tar.gz cp -av apr-util-1.6.1 httpd-2.4.33/srclib/apr-util cp -av apr-1.6.3 httpd-2.4.33/srclib/apr ./configure –prefix=/app/httpd24 \ –enable-so \ –enable-ssl \ –enable-cgi \ –enable-rewrite \ –with-zlib \ –with-pcre \ –with-included-apr \ –enable-modules=most \ –enable-mpms-shared=all \ –with-mpm=prefork make &amp;&amp; make install echo PATH=/app/httpd24/bin:$PATH &gt; /etc/profile.d/lamp.sh . /etc/profile.d/lamp.sh 开启httpd服务 apachectl 2.二进制安装mariadbtar xvf mariadb-10.2.15-linux-x86_64.tar.gz -C /usr/local/ cd /usr/local/ ln -s mariadb-10.2.15-linux-x86_64/ mysql useradd -r -s /sbin/nologin mysql chown -R mysql.mysql mysql/ mkdir /data/mysql -pv chown mysql.mysql /data/mysql/ vim /etc/profile.d/lamp.sh PATH=/appl/httpd24/bin:/usr/local/mysql/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin . /etc/profile.d/lamp.sh cd mysql/ ./scripts/mysql_install_db –datadir=/data/mysql –user=mysql vim /etc/my.cnf datadir=/data/mysql chkconfig –add mysqld chkconfig –list service mysqld start ss -ntl 创建wordpress数据库，和管理用户 MariaDB [(none)]&gt; create database wordpress; MariaDB [(none)]&gt; grant all on wordpress.* to wpuser@’192.168.30.%’ identified by ‘centos’; 3.编译安装fastcgi模式的phptar xvf php-7.1.18.tar.bz2 cd php-7.1.18/ ./configure –prefix=/app/php \ –enable-mysqlnd \ –with-mysqli=mysqlnd \ –with-openssl \ –with-pdo-mysql=mysqlnd \ –enable-mbstring \ –with-freetype-dir \ –with-jpeg-dir \ –with-png-dir \ –with-zlib \ –with-libxml-dir=/usr \ –enable-xml \ –enable-sockets \ –enable-fpm \ –with-config-file-path=/etc \ –with-config-file-scan-dir=/etc/php.d \ –enable-maintainer-zts \ –disable-fileinfo make &amp;&amp; make install cd /root/srcs/php-7.1.18/ cp php.ini-production /etc/php.ini cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm chmod +x /etc/init.d/php-fpm chkconfig –add php-fpm chkconfig php-fpm on cd /app/php/etc cp php-fpm.conf.default php-fpm.conf cp php-fpm.d/www.conf.default php-fpm.d/www.conf service php-fpm start ss -ntl vim /etc/profile.d/lamp.sh PATH=/app/php/bin:/app/php/sbin:/app/httpd24/bin:/usr/local/mysql/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin . /etc/profile.d/lamp.sh vim /app/httpd24/conf/httpd.conf 取消下面两行的注释，启用代理功能 LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so 修改下面行 DirectoryIndex index.php index.html addType application/x-httpd-php .php AddType application/x-httpd-php-source .phps ProxyRequests Off ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 重启httpd服务 apache restart 4.安装wordpress解压安装包 tar –zxf – wordpress-4.9.4-zh_CN.tar.gz -C /app/httpd24/htdocs/blog 注意wordpress目录权限 setfacl -R -m u:apache:rwx /var/www/html/wordpress 重启httpd服务 systemctl restart httpd 5.安装Discuzmv Discuz_X3.3_SC_UTF8.zip /app/httpd24/htdocs/bbs/ cd /app/httpd24/htdocs/bbs/ unzip mv Discuz_X3.3_SC_UTF8.zip 配置虚拟主机 修改配置文件，开启虚拟主机配置目录 vim httpd-vhosts.conf # Virtual hosts Include conf/extra/httpd-vhosts.conf 找到此行，去掉注释 6.配置虚拟主机 vim /app/httpd24/conf/extra/httpd-vhosts.conf ​ servername www.blog.com​ documentroot /app/httpd24/htdocs/blog/wordpress​ DirectoryIndex index.php​ ProxyRequests Off​ ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/blog/wordpress/$1 ​ servername www.bbs.com​ documentroot /app/httpd24/htdocs/bbs​ DirectoryIndex index.php​ ProxyRequests Off​ ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/bbs/$1 7.测试：此时切换到另外一台主机访问www.blog.com及www.bbs.com 为了方便实现，这里修改hosts文件模拟DNS 加入此行： vim /etc/hosts 192.168.30.17 www.blog.com www.bbs.com 切换到图形界面，打开firefox浏览器直接输入www.blog.com，直接转向了wordpress的安装页面 输入www.bbs.com，则直接转向了wordpress的安装页面 至此，我们完成了编译LAPM，基于主机头的wordpress和Discuz的安装！]]></content>
      <categories>
        <category>Web服务器</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP简介]]></title>
    <url>%2F2018%2F06%2F23%2FPHP%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[PHP简介PHP是通用服务器端脚本编程语言，主要用于web开发实现动态web页面，也是最早实现将脚本嵌入 HTML源码文档中的服务器端脚本语言之一。同时，PHP还提供了一个命令行接口，因此，其也可以 在大多数系统上作为一个独立的shell来使用 官方网站：http://www.php.net/ PHP 文件是什么?PHP 文件可包含文本、HTML、JavaScript代码和 PHP 代码 PHP 代码在服务器上执行，结果以纯 HTML 形式返回给浏览器 PHP 文件的默认文件扩展名是 “.php” PHP 能做什么?PHP 可以生成动态页面内容 PHP 可以创建、打开、读取、写入、关闭服务器上的文件 PHP 可以收集表单数据 PHP 可以发送和接收 cookies PHP 可以添加、删除、修改您的数据库中的数据 PHP 可以限制用户访问您的网站上的一些页面 PHP 可以加密数据 通过 PHP，您不再限于输出 HTML。您可以输出图像、PDF 文件，甚至 Flash 电影。您还可以输出任意的文本， 比如 XHTML 和 XML。 为什么使用 PHP?PHP 可在不同的平台上运行（Windows、Linux、Unix、Mac OS X 等） PHP 与目前几乎所有的正在被使用的服务器相兼容（Apache、IIS 等） PHP 提供了广泛的数据库支持 PHP 是免费开源的 PHP 易于学习，并可高效地运行在服务器端 php语言格式12345&lt;?php…php code…?&gt; 基于LINUX系统的PHP布署php：脚本语言解释器 配置文件：/etc/php.ini, /etc/php.d/*.ini 配置文件在php解释器启动时被读取 对配置文件的修改生效方法 Modules：重启httpd服务 FastCGI：重启php-fpm服务 ### Modules配置格式：/etc/php.ini配置文件格式： 12345678910111213141516171819202122232425[foo]：Section Headerdirective = value注释符：较新的版本中，已经完全使用;进行注释\#： 纯粹的注释信息;： 用于注释可启用的directivemax_execution_time= 30 最长执行时间30smemory_limit 128M 生产不够，可调大display_errors off 调试使用，不要打开，否则可能暴露重要信息display_startup_errors off 建议关闭post_max_size 8M 最大上传数据大小，生产可能临时要调大，比下面项要大upload_max_filesize 2M 最大上传文件，生产可能要调大max_file_uploads = 20 同时上传最多文件数date.timezone =Asia/Shanghai 指定时区short_open_tag=on 开启短标签,如&lt;? phpinfo();?&gt; php.ini的核心配置选项文档： http://php.net/manual/zh/ini.core.php php.ini配置选项列表： http://php.net/manual/zh/ini.list.php FastCGI配置格式：配置文件：/etc/php.ini，/etc/php.d/*.ini Module下，重启Httpd服务 FastCGI模式下，重启php-fpm服务 配置文件格式 配置文件格式：[foo]:Section Header Directive=value 注释符：# 纯粹的注释信息 ; 用于注释可启动的指令 说明：在较新的版本中，已经完全使用”;”进行注释 fcgi服务配置文件：/etc/php-fpm.conf, /etc/php-fpm.d/*.conf 连接池： ​ pm = static|dynamic static：固定数量的子进程；pm.max_children dynamic：子进程数量以动态模式管理 12345pm.max_childrenpm.start_serverspm.min_spare_serverspm.max_spare_serverspm.max_requests = 500 确保运行php-fpm进程的用户对session目录有读写权限 12mkdir /var/lib/php/sessionchown apache.apache /var/lib/php/session 配置fastcgi (1)配置httpd，添加/etc/httpd/conf.d/fcgi.conf配置文件，内容类似 12 注意：在HTTPD服务器上必须启用proxy_fcgi_module模块，充当PHP客户端 httpd –M |grep fcgi cat /etc/httpd/conf.modules.d/00-proxy.conf (2)虚拟主机配置 1234567891011121314vim /etc/httpd/conf.d/vhosts.conf DirectoryIndex index.php &lt;VirtualHost *:80&gt; ServerName www.b.net DocumentRoot /apps/vhosts/b.net ProxyRequests Off ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/apps/vhosts/b.net/$1 &lt;Directory “/apps/vhosts/b.net”&gt; Options None AllowOverride None Require all granted &lt;/Directory&gt; &lt;/VirtualHost&gt; php-mysqlPhp连接数据库三种方式： 1)使用mysql扩展连接数据库(渐已淘汰) 2)使用mysqli扩展连接数据库 3)使用pdo扩展连接数据库(主流)；支持mysql外的其他一些数据库 测试代码： PHP使用mysql扩展连接数据库的测试代码： 12345678910vim /var/www/html/test.php &lt;?php $conn = mysql_connect(‘mysql_host’,’mysql_username’,’mysql_password’); if ($conn) echo “OK”; else echo “Failure”; \#echo mysql_error(); mysql_close(); ?&gt; ​ 连接成功返回OK，失败则返回Failure PHP用mysqli扩展连接数据库的测试代码： 1234567891011vim /var/www/html/test.php &lt;?php $mysqli=new mysqli(‘mysql_host’,’mysql_username’,’mysql_password’); if(mysqli_connect_errno())&#123; echo “Failure”; $mysqli=null; exit; &#125; echo “OK”; $mysqli-&gt;close(); ?&gt; ​ 连接成功返回OK，失败则返回Failure PHP使用pdo扩展连接数据库的测试代码1： 12345678vim /var/www/html/test.php &lt;?php $dsn=’mysql:host=localhost;dbname=mysql’; $username=’root’; $passwd=’centos’; $dbh=new PDO($dsn,$username,$passwd); var_dump($dbh); ?&gt; ​ 连接成功返回object(PDO)#1 (0) { } ，失败则返回500状态码 PHP使用pdo扩展连接数据库的测试代码2： 123456789101112131415vim /var/www/html/test.php &lt;?php try &#123; $user=’root’; $pass=’centos’; $dbh = new PDO(‘mysql:host=localhost;dbname=mysql’, $user, $pass); foreach($dbh-&gt;query(‘SELECT user,host from user’) as $row) &#123; print_r($row); &#125; $dbh = null; &#125; catch (PDOException $e) &#123; print “Error!: ” . $e-&gt;getMessage() . “&lt;br/&gt;”; die(); &#125; ?&gt; 成功返回：Array([user]=&gt;root[0]=&gt;root[host]=&gt;127.0.0.1[1]=&gt;127.0.0.1)… 失败返回：Error!]]></content>
      <categories>
        <category>Web服务器</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[https网络安全协议]]></title>
    <url>%2F2018%2F06%2F22%2Fhttps%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[一、https协议介绍HTTPS（全称：Hyper Text Transfer Protocol over Secure Socket Layer）， 是以安全为目标的HTTP通道，简单讲是HTTP的安全版。即HTTP下加入SSL层，HTTPS的安全基础是SSL， 因此加密的详细内容就需要SSL。 https:URL表明它使用了HTTP，但HTTPS存在不同于HTTP的默认端口及一个加 密身份验证层（在HTTP与TCP之间）。 发展历史：这个系统的最初研发由网景公司(Netscape)进行，并内置于其浏览器Netscape Navigator中，提供了身份 验证与加密通讯方法。现在它被广泛用于网络安全敏感的通讯，例如交易支付方面。 主要作用： 建立一个信息安全通道，来保证数据传输的安全； 确认网站的真实性，凡是使用了 https 的网站，都可以通过点击浏览器地址栏的锁头标志来查看网站 认证之后的真实信息，也可以通过 CA 机构颁发的安全签章来查询 。 HTTPS与HTTP的区别：1、https协议需要到ca申请证书，一般免费证书很少，需要交费。 2、http是超文本传输协议，信息是明文传输，https 则是具有安全性的ssl加密传输协议。 3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证 的网络协议，比http协议安全。 SSL会话的简化过程： 客户端发送可供选择的加密方式，并向服务器请求证书 服务器端发送证书以及选定的加密方式给客户端 客户端取得证书并进行证书验证 如果信任给其发证书的CA a. 验证证书来源的合法性；用CA的公钥解密证书上数字签名 b. 验证证书的内容的合法性：完整性验证 c. 检查证书的有效期限 d. 检查证书是否被吊销 e. 证书中拥有者的名字，与访问的目标主机要一致 客户端生成临时会话密钥（对称密钥），并使用服务器端的公钥加密此数据发送给服务器，完成密钥交换 服务用此密钥加密用户请求的资源，响应给客户端 注意：SSL是基于IP地址实现,单IP的主机仅可以使用一个https虚拟主机 二、实验：实现https前期准备：两台虚拟机 CA： CentOS 7.4 IP：192.168.30.10 客端户：CentOS 6.9 IP：192.168.30.11 实验预期：CA服务器为客户端颁发证书，使其能够实现https访问 具体步骤：CA端： 生成私钥 (umask 077;openssl genrsa -out /etc/pki/CA/private/cakey.pem 2048) 自签名证书 openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3650 交互式填写 国家：CN 省份：beijing 城市：beijing 公司名称：lvpx 部门：opt Common name：lvpx.com Client端： 生成客户端私钥 (umask 066;openssl genrsa -out httpd.key 1024) 生成证书申请 openssl req -new -key httpd.key -out httpd.csr 交互式填写 国家：CN 省份：beijing 城市：beijing 公司名称：lvpx 部门：opt Common name：http.lvpx.com 注：国家，省份，公司必须一致才能申请成功 将证书申请发送到CA scp httpd.csr 192.168.30.10:/root/ CA端： 建立已颁发证书信息列表文件；V：生效；R：吊销； touch /etc/pki/CA/index.txt 建立证书序列号 echo 0F &gt; /etc/pki/CA/serial 颁发证书 openssl ca -in httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 730 将证书及CA自授权证书发送到客户端： scp /etc/pki/CA/certs/httpd.crt 192.168.30.11:/root/ scp /etc/pki/CA/cacert.pem 192.168.30.11:/root/ Client端： 安装加密模块 yum install mod_ssl –y rpm -ql mod_ssl 修改配置文件其中此三行 vim /etc/httpd/conf.d/ssl.conf SSLCertificateFile /etc/httpd/conf.d/ssl/httpd.crt SSLCertificateKeyFile /etc/httpd/conf.d/ssl/httpd.key SSLCACertificateFile /etc/httpd/conf.d/ssl/cacert.pem 重启httpd服务 service httpd restart 此时打开浏览器已能够正常访问https://192.168.30.11/ 显示不安全的页面，这是由于证书未添加到浏览器信任造成的 将CA自签名证书导入到浏览器即可安全访问 三、http重定向https当我们区域https协议后，就出现了一个问题，此时http与https是可以同时被访问的，那么当用户用http访 问网站时，还是有安全隐患的，如何解决呢？我们只需要将http重定向到https即可 实现http请求转发至https的URL方法如下： 方法一：重定向备注：有安全隐患，每次请求还会先走http协议 Redirect [status] URL-path URL status状态： permanent: 永久301 Temp： 临时302 示例： Redirect temp / https://www.magedu.com/ 方法二：HSTS备注：仅第一次访问会走http协议，建议使用此种方法 HSTS:HTTP Strict Transport Security 服务器端配置支持HSTS后，会在给浏览器返回的HTTP首部中携带HSTS字段。浏览 器获取到该信息后，会将所有HTTP访问请求在内部做307跳转到HTTPS。而无需任何 网络过程 HSTS preload list 作用：使第一次访问也走https协议 是Chrome浏览器中的HSTS预载入列表，在该列表中的网站，使用Chrome浏览器访 问时，会自动转换成HTTPS。Firefox、Safari、Edge浏览器也会采用这个列表 实现HSTS示例：vim /etc/httpd/conf/httpd.conf Header always set Strict-Transport-Security “max-age=31536000” RewriteEngine on RewriteRule ^(/.*)$ https://%{HTTP_HOST}$1 [redirect=302] curl -I www.taobao.com Strict-Transport-Security: max-age=31536000 四、云主机实现免费的https现在许多云服务厂商都提供了免费的域名型加密SSL证书，仅对域名所有权进行验证，快速颁发，较好保 护网站数据安全，适合个人，小微企业应用。 本次就以在腾讯云申请免费SSL证书为例： 腾讯云官方网站：https://cloud.tencent.com 1登录进入页面后点击上方+号，添加SSL证书管理 2点击申请证书，显示证书颁发机构为亚洲诚信(TRUSTASIA)，证书有效期为一年 3.点击确定后，会要求输入域名，申请邮箱等信息，按需填写即可 4.接下来会进行域名身份验证，这里我们选择选择手动DNS验证 5.点击确认申请，生成解析记录 接下来我们需要等待10分钟左右证书审核通过 6.回到我们的域名DNS管理页，添加一条TXT/SPF的解析 HOSTNAME填写腾讯云解析记录中的主机记录 TEXT填写记录值 7.证书申请完成后，就可以点击下载了 8.根据自己web服务类型，进行后续配置 腾讯云官方证书安装方法指引文档：https://cloud.tencent.com/document/product/400/4143]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache介绍及常用配置]]></title>
    <url>%2F2018%2F06%2F21%2FApache%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[一、Apache介绍Apache是世界使用排名第一的Web服务器软件。它可以运行在几乎所有广泛使用的计算机平台上， 由于其跨平台和安全性被广泛使用，是最流行的Web服务器端软件之一。 它快速、可靠并且可通过简单的API扩充，将Perl/Python等解释器编译到服务器中。 官方网站：http://httpd.apache.org/ 发展历史：20世纪90年代初，国家超级计算机应用中心NCSA开发 1995年开源社区发布apache（a patchy server） ASF: apache software foundation FSF：Free Software Foundation 特性： 高度模块化：core+modules 动态加/卸载：DSO(Dynamic Shared Object) 多路处理模块：MPM(multi-processing module) 功能特性： 虚拟主机: 基于IP、Port、FQDN的建立的 CGI(通用网关接口): ​ CGI是WWW技术中最重要的技术之一，有着不可替代的重要地位。CGI是外部应用程序与WEB服务器之间的接口标准，是在CGI程序和Web服务器之间传递信息的过程。CGI规范允许Web服务器执行外部程序，并将它们的输出发送给Web浏览器，CGI将Web的一组简单的静态超媒体文档变成一个完整的新的交互式媒体。 反向代理 ​ 是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器 负载均衡 ​ 负载均衡建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性 路径别名 丰富的用户认证机制 ​ basic：明文传输密码信息认证机制 ​ digestL：加密传输密码认证机制 支持第三方模块 Httpd安装及主要文件版本： ​ CentOS 6：2.2 ​ CentOS 7：2.4 安装方式： rpm，yum：centos发行版，稳定，建议使用 编译安装：定制或特殊需求 CentOS 6程序环境：httpd-2.2配置文件： ​ /etc/httpd/conf/httpd.conf ​ /etc/httpd/conf.d/*.conf 检查配置语法： ​ httpd –t ​ service httpd configtest 服务脚本：/etc/rc.d/init.d/httpd 脚本配置文件：/etc/sysconfig/httpd 服务控制和启动： ​ chkconfig httpd on|off ​ service {start|stop|restart|status|configtest|reload} httpd 站点网页文档根目录： ​ /var/www/html 模块文件路径： ​ /etc/httpd/modules ​ /usr/lib64/httpd/modules 主程序文件： ​ /usr/sbin/httpd ​ /usr/sbin/httpd.worker ​ /usr/sbin/httpd.event 主进程文件： ​ /etc/httpd/run/httpd.pid 日志文件目录： ​ /var/log/httpd ​ access_log: 访问日志 ​ error_log：错误日志 帮助文档包： ​ httpd-manual Apache是一个模块化的程序，管理员可以选择一些模块来增加服务器的某些功能。 这些模块，可以在创建服务器程序时静态地编译到httpd服务器的二进制代码中， 也可以编译成一些独立于服务器程序的DynamicShared Objects (DSOs)文件 模块索引官方文档：http://httpd.apache.org/docs/2.4/mod/ 查看静态编译的模块: httpd -l 查看静态编译及动态装载的模块: httpd –M 动态模块加载:不需重启即生效 动态模块路径:/usr/lib64/httpd/modules/ httpd-2.4 新特性 MPM支持运行为DSO机制；以模块形式按需加载 event MPM生产环境可用 异步读写机制 支持每模块及每目录的单独日志级别定义 每请求相关的专用配置 增强版的表达式分析式 毫秒级持久连接时长定义 基于FQDN的虚拟主机不需要NameVirutalHost指令 新指令，AllowOverrideList 支持用户自定义变量 更低的内存消耗 修改了一些配置机制 不再支持使用Order, Deny, Allow来做基于IP的访问控制 新模块 mod_proxy_fcgi: 用于MODY代理的FASCGI协议后端 mod_remoteip: 替换表观客户端远程IP地址用IP地址列表请求的主机名由代理或负载平衡器通过请求报头。 mod_ratelimit: 为客户端提供带宽速率限制 CentOS 7程序环境：安装方法：rpm，编译安装 配置文件： ​ /etc/httpd/conf/httpd.conf /etc/httpd/conf.d/*.conf 模块相关的配置文件： ​ /etc/httpd/conf.modules.d/*.conf ​ systemd unit file： ​ /usr/lib/systemd/system/httpd.service 主程序文件： ​ /usr/sbin/httpd httpd-2.4支持MPM的动态切换 日志文件： ​ /var/log/httpd access_log：访问日志 error_log：错误日志 站点文档： ​ /var/www/html 模块文件路径： ​ /usr/lib64/httpd/modules 服务控制： ​ systemctl enable|disable httpd.service systemctl {start|stop|restart|status} httpd.service 二、httpd-2.2常用设置httpd配置文件的组成： grep “Section” /etc/httpd/conf/httpd.conf ： 123### Section 1: Global Environment： 全局设置### Section 2: &apos;Main&apos; server configuration： 主服务器### Section 3: Virtual Hosts：虚拟主机 配置格式： directive value directive: 不区分字符大小写 value: 为路径时，是否区分大小写，取决于文件系统 1. 服务器版本信息显示格式1234567ServerTokens Major|Minor|Min[imal]|Prod[uctOnly]|OS|FullServerTokens Prod[uctOnly] ：Server: ApacheServerTokens Major: Server: Apache/2ServerTokens Minor: Server: Apache/2.0ServerTokens Min[imal]: Server: Apache/2.0.41ServerTokens OS: Server: Apache/2.0.41 (Unix)ServerTokens Full (or not specified): Server: Apache/2.0.41 (Unix) PHP/4.2.2MyMod/1.2 建议使用：ServerTokens Prod 示例： ​ 当使用curl –I命令访问一台主机时，系统默认： ServerTokens OS ​ 修改为：ServerToken Prod 2. 修改监听的IP和PortListen [IP:]PORT (1) 省略IP表示为本机所有IP (2) Listen指令至少一个，可重复出现多次 ​ Listen 80 ​ Listen 8080 示例：vim /etc/httpd/conf/httpd.conf 12Listen 192.168.1.7:8080Lsten 80 注：当主配置文件/etc/httpd/conf/httpd.conf以及 /etc/httpd/conf.d目录下同时有Listen指令时，将同时生效 3.持久连接Persistent Connection：连接建立，每个资源获取完成后不会断开连接，而是继续等待其它的请求完成， 默认关闭持久连接 断开条件：数量限制：100 时间限制：以秒为单位， httpd-2.4 支持毫秒级 副作用：对并发访问量较大的服务器，持久连接功能会使用有些请求得不到响应 折衷：使用较短的持久连接时间 设置： 123KeepAlive On|Off # 开启或关闭持久连接KeepAliveTimeout 15 # 设置持久连接的时间限制MaxKeepAliveRequests 100 # 设置断开持久连接的数量限制 测试： 123telnet WEB_SERVER_IP PORTGET /URL HTTP/1.1Host: WEB_SERVER_IP 4. MPM 多路处理模块​ 经过适当的配置，可以提高服务器的负载能力。 ​ 原理是通过增加服务进程数量使服务器可以同时处理更多用户请求。 ​ 三种模式：prefork, worker, event（2.2为试验阶段） ​ httpd-2.2不支持同时编译多个模块，所以只能编译时选定一个；rpm安装 ​ 的包提供三个二进制程序文件，分别用于实现对不同MPM机制的支持 ​ 确认方法： ​ httpd –V ​ ps aux | grep httpd ​ 默认为/usr/sbin/httpd, 即prefork模式 ​ 更换使用的httpd程序： 12vim /etc/sysconfig/httpd HTTPD=/usr/sbin/httpd.worker #切换worker模式,也可切换成其他模式 ​ 重启服务生效 12service httpd restart pstree -p|grep httpd # 查看进程和线程发现httpd Httpd 2.4 与之不同 ​ 以动态模块方式提供 配置文件： 123vim /etc/httpd/conf.modules.d/00-mpm.confhttpd –M |grep mpm 重启服务生效 ​ pstree -p|grep httpd 查看进程和线程 prefork：多进程I/O模型，每个进程响应一个请求，默认模型 一个主进程：生成和回收n个子进程，创建套接字，不响应请求 多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过1024个 优点：成熟稳定，兼容所有新老模块。同时，不需要担心线程安全的问题。（我们常用的mod_php，PHP的拓展不需要支持线程安全） 缺点：一个进程相对占用更多的系统资源，消耗更多的内存。而且，它并不擅长处理高并发请求，在这种场景下，它会将请求放进队列中，一直等到有可用进程，请求才会被处理。 prefork的默认配置： 123456789101112131415&lt;IfModule prefork.c&gt;StartServers 8 服务启动时，预先同时开启几个进程MinSpareServers 5MaxSpareServers 20ServerLimit 256 最多进程数,最大20000MaxClients 256 最大并发MaxRequestsPerChild 4000 子进程最多能处理的请求数量。在处理MaxRequestsPerChild 个请求之后,子进程将会被父进程终止，这时候子进程占用的内存就会释放(为0时永远不释放）&lt;/IfModule&gt; worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型 一个主进程：生成m个子进程，每个子进程负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n 优点：占据更少的内存，高并发下表现更优秀。 缺点：必须考虑线程安全的问题，因为多个子线程是共享父进程的内存地址的。 如果使用keep-alive的长连接方式，某个线程会一直被占据，也许中间几乎没有请求，需要一直等待到超时才会被 释放。如果过多的线程，被这样占据，也会导致在高并发场景下的无服务线程可用。（该问题在prefork模式下， 同样会发生） worker的默认配置： 123456789101112131415&lt;IfModule worker.c&gt;StartServers 4MaxClients 300MinSpareThreads 25MaxSpareThreads 75ThreadsPerChild 25MaxRequestsPerChild 0 无限制&lt;/IfModule&gt; event：事件驱动模型（worker模型的变种） 一个主进程：生成m个子进程，每个进程直接响应n个请求，并发响应请求：m*n， 有专门的线程来管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程， 执行完毕后，又允许释放。这样增强了高并发场景下的请求处理能力 ​ httpd-2.2: event 测试版，centos6默认 ​ httpd-2.4：event 稳定版，centos7默认 5. DSO 动态共享对象加载动态模块配置文件 ​ /etc/httpd/conf/httpd.conf 配置指定实现模块加载格式： ​ LoadModule &lt;mod_name&gt; &lt;mod_path&gt; 模块文件路径可使用相对路径： 相对于ServerRoot（默认/etc/httpd） 示例： 123LoadModule auth_basic_modulemodules/mod_auth_basic.so 6. 更改httpd服务默认目录DocumentRoot “/path” 文档路径映射：DocumentRoot指向的路径为URL路径的起始位置 示例： ​ DocumentRoot “/app/data” CentOS7必须给目录授权才能使用： 123456&lt;Directory “/app/data”&gt; Require all granted&lt;/Directory&gt;http://HOST:PORT/test/index.html**–&gt;** /app/data/test/index.html 注意：SELinux和iptables的状态 7. 定义站点未指定时的默认页面默认为testing页面： DirectoryIndex index.html index.html.var 8. 基于IP的访问控制:CentOS 6： order和allow、deny 放在directory, .htaccess中 order：定义生效次序；写在后面的表示默认法则 ​ Order allow,deny ​ Order deny,allow Allow from和Deny from：定义客户端地址 客户端地址： IP 网络: 172.16 172.16.0.0 172.16.0.0/16 172.16.0.0/255.255.0.0 CentOS 7： 无明确授权的目录，默认拒绝 允许所有主机访问：Require all granted 拒绝所有主机访问：Require all denied 控制特定的IP访问： ​ Require ip IPADDR：授权指定来源的IP访问 ​ Require not ip IPADDR：拒绝特定的IP访问 控制特定的主机访问： ​ Require host HOSTNAME：授权特定主机访问 ​ Require not host HOSTNAME：拒绝 HOSTNAME： ​ FQDN：特定主机 ​ domin.tld：指定域名下的所有主机 9. 针对资源进行访问控制可基于两种机制指明对哪些资源进行何种访问控制 访问控制机制有两种：客户端来源地址，用户账号 文件系统路径：针对目录： 123&lt;Directory “/path”&gt;…&lt;/Directory&gt; 针对文件，支持通配符： 123&lt;File “/path/file”&gt;…&lt;/File&gt; 支持正则表达式： 123&lt;FileMatch “PATTERN”&gt;…&lt;/FileMatch&gt; URL路径：1234567&lt;Location “”&gt;…&lt;/Location&gt;&lt;LocationMatch “”&gt;…&lt;/LocationMatch&gt; 示例： 1234567&lt;FilesMatch “\.(gif|jpe?g|png)$”&gt;&lt;Files “?at.*”&gt; 通配符&lt;Location /status&gt;&lt;LocationMatch “/(extra|special)/data”&gt; 10 . 中“基于源地址”实现访问控制(1) Options：后跟1个或多个以空白字符分隔的选项列表 在选项前的+，- 表示增加或删除指定选项 常见选项： Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源 文件时，返回索引列表给用户 FollowSymLinks：允许访问符号链接文件所指向的源文件 None：全部禁用 All： 全部允许 示例： 123456789101112131415&lt;Directory /web/docs&gt; Options Indexes FollowSymLinks&lt;/Directory&gt;&lt;Directory /web/docs/spec&gt; Options FollowSymLinks&lt;/Directory&gt;&lt;Directory /web/docs&gt; Options Indexes FollowSymLinks&lt;/Directory&gt;&lt;Directory /web/docs/spec&gt; Options +Includes -Indexes&lt;/Directory&gt; (2) AllowOverride 与访问控制相关的哪些指令可以放在指定目录下的.htaccess（由AccessFileName指定）文件中， 覆盖之前的配置指令 只对语句有效 ​ AllowOverride All: 所有指令都有效 ​ AllowOverride None：.htaccess 文件无效 ​ AllowOverride AuthConfig Indexes 除了AuthConfig 和Indexes的其它指令都无法覆盖 11.日志设定日志类型： /var/log/httpd ​ 访问日志 ​ 错误日志 错误日志： ​ ErrorLog logs/error_log ​ LogLevel warn ​ LogLevel 可选值: debug, info, notice, warn,error,crit, alert, emerg 越靠后等级越高 访问日志： 定义日志格式：LogFormat format strings LogFormat “%h %l %u %t \”%r\” %&gt;s %b \”%{Referer}i\” \”%{User-Agent}i\”” combined 使用日志格式： CustomLog logs/access_log combined 参考帮助：http://httpd.apache.org/docs/2.2/mod/mod_log_config.html#formats 12345678910%h 客户端IP地址%l 远程用户,启用mod_ident才有效，通常为减号“-”%u 验证（basic，digest）远程用户,非登录访问时，为一个减号“-”%t 服务器收到请求时的时间%r First line of request，即表示请求报文的首行；记录了此次请求的“方法”，“URL”以及协议版本%&gt;s 响应状态码%b 响应报文的大小，单位是字节；不包括响应报文http首部%&#123;Referer&#125;i 请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的，超链接来源%&#123;User-Agent&#125;i 显示浏览器类型；请求报文中首部“User-Agent”的值；即发出请求的应用程序更多的格式选项请参考官方**mod_log_config** 文档 示例： 默认日志中日期显示为：[21/Jun/2018:17:00:54 +0800] vim /etc/httpd/conf/httpd.conf 123LogFormat “%h %l %u %t \”%r\” %&gt;s %b \”%&#123;Referer&#125;i\” \”%&#123;User-Agent&#125;i\”” combined找到此行修改 %t **==&gt;** %&#123;%F %T&#125;t再次打开access_log日志日期格式：**2018-06-21 19:02:27** 12. 设定默认字符集/etc/httpd/conf/httpd.conf： AddDefaultCharset UTF-8 中文字符集：GBK, GB2312, GB18030 13定义路径别名格式： Alias /URL/ “/PATH/” 1234567891011121314151617181920212223DocumentRoot “/www/htdocs”http://www.magedu.com/download/bash.rpm==&gt;/www/htdocs/download/bash.rpmAlias /download/ “/rpms/pub/”http://www.magedu.com/download/bash.rpm==&gt;/rpms/pub/bash.rpmhttp://www.magedu.com/images/logo.png==&gt;/www/htdocs/images/logo.png注意：CentOS 7要给重新指定的路径进行grant授权才可访问&lt;directory “/rpm/pub”&gt;require all granted&lt;/directory&gt; 14. 基于用户的访问控制认证质询：WWW-Authenticate：响应码为401，拒绝客户端请求，并说明要求客户端提供账号和密码 认证：Authorization：客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源 认证方式两种： ​ basic：明文 ​ digest：消息摘要认证,兼容性差 安全域：需要用户认证后方能访问的路径；应该通过名称对其进行标识，以便于告知用户认证的原因 用户的账号和密码 ​ 虚拟账号：仅用于访问某服务时用到的认证标识 ​ 存储：文本文件，SQL数据库，ldap目录存储，nis等 basic认证配置示例： 定义安全域 12345678&lt;Directory “/path”&gt;Options NoneAllowOverride NoneAuthType BasicAuthName “String“AuthUserFile “/PATH/HTTPD_USER_PASSWD_FILE”Require user username1 username2 …&lt;/Directory&gt; ​ 允许账号文件中的所有用户登录访问： ​ Require valid-user 提供账号和密码存储（文本文件） 使用专用命令完成此类文件的创建及用户管理 htpasswd [options] /PATH/HTTPD_PASSWD_FILE username ​ -c：自动创建文件，仅应该在文件不存在时使用 ​ -p：明文密码 ​ -d：CRYPT格式加密，默认 ​ -m：md5格式加密 ​ -s: sha格式加密 ​ -D：删除指定用户 基于组账号进行认证 定义安全域 1234567&lt;Directory “/path”&gt;AuthType BasicAuthName “String“AuthUserFile “/PATH/HTTPD_USER_PASSWD_FILE”AuthGroupFile “/PATH/HTTPD_GROUP_FILE”Require group grpname1 grpname2 …&lt;/Directory&gt; 创建用户账号和组账号文件 组文件：每一行定义一个组 GRP_NAME: username1 username2 … 示例： 12345678910111213&lt;Directory “/www/htdocs/admin”&gt; Options None AllowOverride None AuthType Basic AuthName “Administator private” AuthUserFile “/etc/httpd/conf.d/.htpasswd” AuthGroupFile “/etc/httpd/conf.d/.htgroup” Require group webadmins&lt;/Directory&gt;vim /etc/httpd/conf.d/.htgroupwebadmins:wang mage 远程客户端和用户验证的控制 Satisfy ALL|Any ALL 客户机IP和用户验证都需要通过才可以 Any客户机IP和用户验证,有一个满足即可 示例： ​ Require valid-user ​ Order allow,deny ​ Allow from 192.168.1 ​ Satisfy Any 15. 实现用户家目录的http共享基于模块mod_userdir.so实现 ​ httpd -M |grep userdir ​ SELinux: http_enable_homedirs 相关设置： 12345vim /etc/httpd/conf/httpd.conf &lt;IfModule mod_userdir.c&gt; #UserDir disabled UserDir public_html #指定共享目录的名称 &lt;/IfModule&gt; 准备目录 ​ su – lpx;mkdir ~/public_html ​ setfacl –m u:apache:x ~lpx 访问 http://localhost/~lpx/index.html 16. status页面功能：显示系统中的状态信息，了解服务器状态，监控用 123456LoadModule status_module modules/mod_status.so&lt;Location /server-status&gt;SetHandler server-statusRequire all granted&lt;/Location&gt;ExtendedStatus On 显示扩展信息 访问： http://IP:PORT/server-status 就可以监控apache服务了下面就是该网页所显示的监控情况： 参数说明： 字段 说明 Server Version Apache 服务器的版本。 Server MPM MPM工作模式 Server Built Apache 服务器编译安装的时间。 Current Time 目前的系统时间。 Restart Time Apache 重新启动的时间。 Parent Server Generation Apache 父程序 (parent process) 的世代编号，就是 httpd 接收到 SIGHUP 而重新启动的次数。 Server uptime Apache 启动后到现在经过的时间。 Total accesses 到目前为此 Apache 接收的联机数量及传输的数据量。 CPU Usage 目前 CPU 的使用情形。 _SWSS…. 所有 Apache process 目前的状态。每一个字符表示一个程序，最多可以显示 256 个程序 的状态。 Scoreboard Key 上述状态的说明。以下为每一个字符符号所表示的意义： * _：等待连结中。 * S：启动中。 * R：正在读取要求。 * W：正在送出回应。 * K：处于保持联机的状态。 * D：正在查找DNS。 * C：正在关闭连结。 * L：正在写入记录文件。 * G：进入正常结束程序中。 * I：处理闲置。 * .：尚无此程序。 Srv 本程序与其父程序的世代编号。 PID 本程序的process id。 Acc 分别表示本次联机、本程序所处理的存取次数。 M 该程序目前的状态。 CPU 该程序所耗用的CPU资源。 SS 距离上次处理要求的时间。 Req 最后一次处理要求所耗费的时间，以千分之一秒为单位。 Conn 本次联机所传送的数据量。 Child 由该子程序所传送的数据量。 Slot 由该 Slot 所传送的数据量。 Client 客户端的地址。 VHost 属于哪一个虚拟主机或本主机的IP。 Request 联机所提出的要求信息。 三、httpd-2.4常用配置1.切换使用的MPM Centos 7: /etc/httpd/conf.modules.d/00-mpm.conf 启用要启用的MPM相关的LoadModule指令即可 centos6编译安装: 1234vim /etc/httpd24/httpd.conf Include /etc/httpd24/extra/httpd-mpm.conf LoadModule mpm_event_module modules/mod_mpm_event.so 2.主目录：​ DocumentRoot /path 3.基于IP的访问控制:无明确授权的目录，默认拒绝允许所有主机访问：Require all granted拒绝所有主机访问：Require all denied控制特定的IP访问： 12Require ip IPADDR：授权指定来源的IP访问Require not ip IPADDR：拒绝特定的IP访问 控制特定的主机访问： 12345Require host HOSTNAME：授权特定主机访问Require not host HOSTNAME：拒绝HOSTNAME： FQDN：特定主机 domin.tld：指定域名下的所有主机 不能有失败，至少有一个成功匹配才成功，即失败优先 1234&lt;RequireAll&gt; Require all granted Require not ip 172.16.1.1 拒绝特定IP&lt;/RequireAll&gt; 多个语句有一个成功，则成功，即成功优先 1234&lt;RequireAny&gt; Require all denied require ip 172.16.1.1 允许特定IP&lt;/RequireAny&gt; 4. 虚拟主机基于FQDN的虚拟主机不再需要NameVirutalHost指令 123456789&lt;VirtualHost *:80&gt; ServerName www.b.net DocumentRoot &quot;/apps/b.net/htdocs&quot; &lt;Directory &quot;/apps/b.net/htdocs&quot;&gt; Options None AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt; 注意：任意目录下的页面只有显式授权才能被访问 5. ssl:安装mod_ssl，和httpd-2.2相同配置6. KeepAlive on12KeepAliveTimeout #msMaxKeepAliveRequests 100 毫秒级持久连接时长定义 四、mod_deflate模块——压缩页面优化传输mod_deflate 功能：压缩页面优化传输速度 官方文档：http://httpd.apache.org/docs/2.4/mod/mod_deflate.html 适用场景： (1) 节约带宽，额外消耗CPU；同时，可能有些较老浏览器不支持 (2) 压缩适于压缩的资源，例如文本文件 LoadModule deflate_module modules/mod_deflate.so SetOutputFilter DEFLATE # Restrict compression to these MIME types AddOutputFilterByType DEFLATE text/plain AddOutputFilterByType DEFLATE text/html AddOutputFilterByType DEFLATE application/xhtml+xml AddOutputFilterByType DEFLATE text/xml AddOutputFilterByType DEFLATE application/xml AddOutputFilterByType DEFLATE application/x-javascript AddOutputFilterByType DEFLATE text/javascript AddOutputFilterByType DEFLATE text/css Level of compression (Highest 9 – Lowest 1) 压缩比(1-9) DeflateCompressionLevel 9 排除特定旧版本的浏览器，不支持压缩 Netscape 4.x 只压缩text/html BrowserMatch ^Mozilla/4 gzip-only-text/html Netscape 4.06-08三个版本 不压缩 BrowserMatch ^Mozilla/4.0[678] no-gzip Internet Explorer标识本身为“Mozilla / 4”，但实际上是能够处理请求的压缩。 如果用户代理首部匹配字符串“MSIE”（“B”为单词边界”），就关闭之前定 义的限制 BrowserMatch \bMSI[E] !no-gzip !gzip-only-text/html 查看网站是否压缩 方法一：利用curl命令 Curl -I -v –compressed http://www.178linux.com 方法二：站长工具查询 http://tool.chinaz.com/Gzips/ 示例： 查看mod_deflate.so模块是否已加载 修改配置文件 重启httpd服务即可 systemctl restart httpd 五、centos6.9编译安装httpd2.4.29 解压包 123456yum groupinstall &quot;development tools&quot;yum install openssl-devel pcre-devel expat-devel tar xvf apr-1.6.3.tar.bz2 tar xvf apr-util-1.6.1.tar.bz2 tar xvf httpd-2.4.29.tar.bz2 安装apr和apr-util 安装apr-1.4+ 123cd apr-1.6.2./configure --prefix=/app/aprmake &amp;&amp; make install 安装apr-util-1.4+ 123cd ../apr-util-1.6.0./configure --prefix=/app/apr-util --with-apr=/app/apr/make -j 2 &amp;&amp; make install 编译安装httpd2.4 123456789101112./configure --prefix=/app/httpd24 \--enable-so \--enable-ssl \--enable-cgi \--enable-rewrite \--with-zlib \--with-pcre \--with-apr=/app/apr/ \--with-apr-util=/app/apr-util/ \--enable-modules=most \--enable-mpms-shared=all \--with-mpm=prefork 环境变量 12echo &apos;PATH=/app/httpd24/bin/:$PATH&apos; &gt; /etc/profile.d/httpd24.sh. /etc/profile.d/httpd24.sh 用户和组 1useradd -r -s /sbin/nologin apache 配置文件 123vim /app/httpd24/conf/httpd.conf user apache group apache 开机脚本 12345678910cp /etc/init.d/httpd /etc/init.d/httpd24vim /etc/init.d/httpd24 apachectl=/app/httpd24/bin/apachectl httpd=$&#123;HTTPD-/app/httpd24/bin/httpd&#125; pidfile=$&#123;PIDFILE-/app/httpd24/logs/httpd.pid&#125; lockfile=$&#123;LOCKFILE-/var/lock/subsys/httpd24&#125;chkconfig --add httpd24chkconfig httpd24 onservice httpd24 start 六、实现虚拟主机——单台主机搭建多个网站前期准备：虚拟机一台，操作系统版本为CentOS 7.4，IP地址：192.168.30.10 1实验：基于端口号的虚拟主机实验预期： 搭建三个网站，网站与监听端口对应关系如下： www.a.com Listen 81 www.b.com Listen 82 www.c.com Listen 83 具体步骤： 创建网站目录 mkdir /data/website{1,2,3} -pv echo www.a.com &gt; /data/website1/index.html echo www.b.com &gt; /data/website2/index.html echo www.c.com &gt; /data/website3/index.html 编写配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849vim /etc/httpd/conf.d/test2.confListen 81listen 82listen 83&lt;directory “/data/”&gt;require all granted&lt;/directory&gt;&lt;VirtualHost *:81&gt;DocumentRoot “/data/website1”ServerName www.a.comErrorlog “logs/a.com.error_log”Transferlog “logs/a.con-access_log”&lt;/VirtualHost&gt;&lt;VirtualHost *:82&gt;DocumentRoot “/data/website2”ServerName www.b.comErrorlog “logs/b.com.error_log”Transferlog “logs/b.con-access_log”&lt;/VirtualHost&gt;&lt;VirtualHost *:83&gt;DocumentRoot “/data/website3”ServerName www.c.comErrorlog “logs/c.com.error_log”Transferlog “logs/c.con-access_log”&lt;/VirtualHost&gt; 重启httpd服务 ​ systemctl restart httpd 检查端口是否监听状态 ​ ss -ntl 浏览器分别打开IP:port测试网页能否正常显示 2. 实验：基于IP地址的虚拟主机实验预期： 搭建三个网站，网站与IP地址对应关系如下： www.a.com 192.168.30.11 www.b.com 192.168.30.22 www.c.com 192.168.30.33 添加IP地址 ip addr add 192.168.30.11/24 dev ens33 ip addr add 192.168.30.22/24 dev ens33 ip addr add 192.168.30.33/24 dev ens33 修改配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243vim /etc/httpd/conf.d/test.conf&lt;directory “/data/”&gt;require all granted&lt;/directory&gt;&lt;VirtualHost 192.168.30.11:80&gt;DocumentRoot “/data/website1”ServerName www.a.comErrorlog “logs/a.com.error_log”Transferlog “logs/a.con-access_log”&lt;/VirtualHost&gt;&lt;VirtualHost 192.168.30.22:80&gt;DocumentRoot “/data/website2”ServerName www.b.comErrorlog “logs/b.com.error_log”Transferlog “logs/b.con-access_log”&lt;/VirtualHost&gt;&lt;VirtualHost 192.168.30.33:80&gt;DocumentRoot “/data/website3”ServerName www.c.comErrorlog “logs/c.com.error_log”Transferlog “logs/c.con-access_log”&lt;/VirtualHost&gt; 重启httpd服务 systemctl restart httpd 打开浏览器分别测试 3实验：基于主机头的虚拟主机实验预期： 通过主机头可直接访问到网站页面，也是实际应用中最常见的虚拟主机搭建方式 具体步骤： 修改配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243vim /etc/httpd/conf.d/test.conf&lt;directory “/data/”&gt;require all granted&lt;/directory&gt;&lt;VirtualHost *:80&gt;DocumentRoot “/data/website1”ServerName www.a.comErrorlog “logs/a.com.error_log”Transferlog “logs/a.con-access_log”&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt;DocumentRoot “/data/website2”ServerName www.b.comErrorlog “logs/b.com.error_log”Transferlog “logs/b.con-access_log”&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt;DocumentRoot “/data/website3”ServerName www.c.comErrorlog “logs/c.com.error_log”Transferlog “logs/c.con-access_log”&lt;/VirtualHost&gt; 配置DNS解析，为了方便模拟，我们就在/etc/hosts文件中配置解析 重启httpd服务 systemctl restart httpd 打开浏览器分别访问www.a.com,www.b.com,www.c.com，访问成功]]></content>
      <categories>
        <category>Web服务器</category>
      </categories>
      <tags>
        <tag>Apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP协议介绍]]></title>
    <url>%2F2018%2F06%2F19%2FHTTP%E5%8D%8F%E8%AE%AE%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[HTTP协议(HyperText Transfer Protocol，超文本传输协议)是互联网上应用最为广泛的一种网络协议。 所有的WWW文件都必须遵守这个标准。 HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。 一、套接字概念跨Internet的主机间通讯时，在建立通信连接的每一端，进程间的传输要有两个标志： IP地址和端口号，合称为套接字地址(socket address) 客户机套接字地址定义了一个唯一的客户进程 服务器套接字地址定义了一个唯一的服务器进程 Socket: 套接字，进程间通信IPC的一种实现，允许位于不同主机（或同一主机）上不同进程之间进行通信和数据交换，SocketAPI出现于1983年，4.2 BSD实现 Socket API：封装了内核中所提供的socket通信相关的系统调用 Socket Domain：根据其所使用的地址 ​ AF_INET：Address Family，IPv4 ​ AF_INET6：IPv6 ​ AF_UNIX：同一主机上不同进程之间通信时使用 Socket Type：根据使用的传输层协议 ​ SOCK_STREAM：流，tcp套接字，可靠地传递、面向连接 ​ SOCK_DGRAM：数据报，udp套接字，不可靠地传递、无连接 ​ SOCK_RAW: 裸套接字,无须tcp或tdp,APP直接通过IP包通信 套接字相关的系统调用：socket(): 创建一个套接字 bind()：绑定IP和端口 listen()：监听 accept()：接收请求 connect()：请求连接建立 write()：发送 read()：接收 close(): 关闭连接 相关通信过程如下图： ​ 二、HTTP相关术语http: Hyper Text Transfer Protocol, 80/tcp html: Hyper Text Markup Language 超文本标记语言，编程语言 示例： 12345678910&lt;html&gt;&lt;head&gt; &lt;title&gt;html语言&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;标题1&lt;/h1&gt; &lt;p&gt;&lt;a href=http://www.lvpeixin.tech&gt;你好&lt;/a&gt;欢迎访问&lt;/p&gt; &lt;h2&gt;标题2&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt; CSS: Cascading Style Sheet 层叠样式表 js: javascript MIME: Multipurpose Internet Mail Extensions:多用途互联网邮件扩展 ​ 是设定某种扩展名的文件用一种应用程序来打开的方式类型，当该扩展名文件被访问的时候，浏览器会自动使用指定应用程序来打开。多用于指定一些客户端自定义的文件名，以及一些媒体文件打开方式。 配置文件：/etc/mime.types 格式：major/minor ​ text/plain ​ text/html ​ text/css ​ image/jpeg ​ image/png ​ video/mp4 ​ application/javascript ​ 参考：http://www.w3school.com.cn/media/media_mimeref.asp URI(Uniform Resource Identifier)统一资源标识，分为URL和URN URN: Uniform Resource Naming，统一资源命名 ​ 示例： P2P下载使用的磁力链接是URN的一种实现 ​ magnet:?xt=urn:btih:660557A6890EF888666 URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置 URN与URL区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份， 而URL提供查找该事物的方法。URN仅用于命名，而不指定地址 URL的组成格式： 1&lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; schame:方案，访问服务器以获取资源时要使用哪种协议 user:用户，某些方案访问资源时需要的用户名 password:密码，用户对应的密码，中间用：分隔 Host:主机，资源宿主服务器的主机名或IP地址 port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号 path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔 params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔 query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&amp;分隔 frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔 示例： 123456http://www.lvpeixin.tech:8080/images/logo.jpgftp://wang:password@172.16.0.1/pub/linux.pptrtsp://videoserver/video_demo/Real Time Streaming Protocolhttp://www.lvpeixin.tech/bbs/hello;gender=f/send;type=titlehttps://list.jd.com/list.html?cat=670,671,672&amp;ev=149_2992&amp;sort=sort_totalsales15_desc&amp;trans=1 HTTP的历史目前主流使用的http版本有1.1版本及2.0版本 http/1.1：1997年1月 引入了持久连接（persistent connection），即TCP连接默认不关闭，可以被多个请求复用， 不用声明Connection: keep-alive。对于同一个域名，大多数浏览器允许同时建立6个持久连接 引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求， 进一步改进了HTTP协议的效率 新增方法：PUT、PATCH、OPTIONS、DELETE 同一个TCP连接里面，所有的数据通信是按次序进行的。服务器只能顺序处理回应， 前面的回应慢，会有许多请求排队，造成”队头堵塞”（Head-of-line blocking） 为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧， 比如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等 HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度 Spdy：2009年,谷歌研发,解决 HTTP/1.1 效率不高问题 http/2.0：2015年 头信息和数据体都是二进制，称为头信息帧和数据帧 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应， 且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing） 引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送； 客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段， 只发送索引号，提高速度 HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push） 三、HTTP工作机制工作机制：http请求：http request http响应：http response 一次http事务：请求&lt;–&gt;响应 http协议：stateless 无状态 ​ 服务器无法持续追踪访问者来源 解决http协议无状态方法: ​ cookie 客户端存放 ​ session 服务端存放 Cookie HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别， 协议对于发送过的请求或响应都不做持久化处理。这是为了更快地处理大量事务，确保协议的可伸缩性， 而特意把 HTTP 协议设计成如此简单的。可是随着 Web 的不断发展，很多业务都需要对通信状态进行保存。 于是引入了 Cookie 技术。使用 Cookie 的状态管理Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制 客户端的状态。Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端 保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。 服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上 的记录，最后得到之前的状态信息 Web资源：web resource一个网页由多个资源构成，打开一个页面，会有多个资源展示出来，但是每个资源都 要单独请求。因此，一个“Web 页面”通常并不是单个资源，而是一组资源的集合 静态文件：无需服务端做出额外处理 ​ 文件后缀：.jpg, .html, .txt, .js, .css, .mp3, .avi 动态文件：服务端执行程序，返回执行的结果 ​ 文件后缀：.asp, .php, .jsp 提高HTTP连接性能并行连接：通过多条TCP连接发起并发的HTTP请求 持久连接：keep-alive,长连接，重用TCP连接，以消除连接和关闭的时延,以事务个数和时间来决定是否关闭连接 管道化连接：通过共享TCP连接发起并发的HTTP请求 复用的连接：交替传送请求和响应报文（实验阶段） 串行连接： 并行连接： 串行、持久连接和管道化连接 四、HTTP请求过程及相应报文格式一次完整的http请求处理过程 建立连接：接收或拒绝连接请求 接收请求：接收客户端请求报文中对某资源的一次请求的过程 Web访问响应模型（Web I/O） 单进程I/O模型：启动一个进程处理用户请求，而且一次只处理一个，多个请求被串行响应 多进程I/O模型：并行启动多个进程,每个进程响应一个连接请求 复用I/O结构：启动一个进程，同时响应N个连接请求实现方法：多线程模型和事件驱动 多线程模型：一个进程生成N个线程，每线程响应一个连接请求 事件驱动：一个进程处理N个请求 复用的多进程I/O模型：启动M个进程，每个进程响应N个连接请求，同时接收M*N个请求 处理请求：服务器对请求报文进行解析，并获取请求的资源及请求方法等相关信息，根据方法，资源， 首部和可选的主体部分对请求进行处理 元数据：请求报文首部 HEADERS 格式 name:value 示例： 12Host: www.magedu.com 请求的主机名称Server: Apache/2.4.7 Method: HTTP常用请求方式 GET、POST、HEAD、PUT、DELETE、TRACE、OPTIONS 访问资源：服务器获取请求报文中请求的资源web服务器，即存放了web资源的服务器， 负责向请求者提供对方请求的静态资源，或动态运行后生成的资源资源放置于本地文件 系统特定的路径：DocRoot 123DocRoot /var/www/html/var/www/html/images/logo.jpghttp://www.lvpeixin.tech/images/logo.jpg web服务器资源路径映射方式： a. docroot b. alias c. 虚拟主机docroot d. 用户家目录docroot 构建响应报文：一旦Web服务器识别除了资源，就执行请求方法中描述的动作，并返回响应报文。 响应报文中 包含有响应状态码、响应首部，如果生成了响应主体的话，还包括响应主体 响应实体：如果事务处理产生了响应主体，就将内容放在响应报文中回送过去。 响应报文中通常包括： 描述了响应主体MIME类型的Content-Type首部 描述了响应主体长度的Content-Length 实际报文的主体内容 URL重定向：web服务构建的响应并非客户端请求的资源，而是资源另外一个访问路径 永久重定向：http://www.360buy.com临时重定向：http://www.taobao.com MIME类型：Web服务器要负责确定响应主体的MIME类型。多种配置服务器的方法可将MIME类型与资源管理起来 魔法分类：Apache web服务器可以扫描每个资源的内容，并将其与一个已知模式表(被称为魔法文件)进行匹配， 以决定每个文件的MIME类型。这样做可能比较慢，但很方便，尤其是文件没有标准扩展名时显式分类：可以对Web服务器进行配置，使其不考虑文件的扩展名或内容， 强制特定文件或目录内容拥有某个MIME类型类型协商： 有些Web服务器经过配置，可以以多种文档格式来存储资源。在这种情况下，可以配置Web服务器，使其可以通过与用户的协商来决定使用哪种格式(及相关的MIME类型)”最好” 发送响应报文: Web服务器通过连接发送数据时也会面临与接收数据一样的问题。 服务器可能有很多条到各个客户端的连接，有些是空闲的，有些在向服务器发送数据， 还有一些在向客户端回送响应数据。服务器要记录连接的状态，还要特别注意对持久连接的处理。 对非持久连接而言，服务器应该在发送了整条报文之后，关闭自己这一端的连接。 对持久连接来说，连接可能仍保持打开状态，在这种情况下，服务器要正确地计算Content-Length首部， 不然客户端就无法知道响应什么时候结束了 记录日志: 最后，当事务结束时，Web服务器会在日志文件中添加一个条目，来描述已执行的事务 request报文123&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; response报文123&lt;version&gt; &lt;status&gt; &lt;reason-phrase&gt;&lt;headers&gt;&lt;entity-body&gt; Mehod属性： 请求方法：标明客户端希望服务器对资源执行的动作 GET：从服务器获取一个资源 HEAD：只从服务器获取文档的响应首部 POST：向服务器输入数据，通常会再由网关程序继续处理 PUT：将请求的主体部分存储在服务器中，如上传文件 DELETE：请求删除服务器上指定的文档 TRACE：追踪请求到达服务器中间经过的代理服务器 OPTIONS：请求服务器返回对指定资源支持使用的请求方法 version: ​ HTTP/. status: ​ 三位数字，如200，301, 302, 404, 502; 标记请求处理过程中发生的情况 reason-phrase： ​ 状态码所标记的状态的简要描述 headers： 每个请求或响应报文可包含任意个首部；每个首部都有首部名称，后面跟一个冒号，而后跟一个可选空格，接着是一个值 entity-body： 请求时附加的数据或响应时附加的数据 五、网站访问量统计IP(独立IP)：即Internet Protocol,指独立IP数。一天内来自相同客户机IP地址只计算一次，记录远程客户机IP地址的计算机访问网站的次数，是衡量网站流量的重要指标 PV(访问量)： 即Page View, 页面浏览量或点击量，用户每次刷新即被计算一次，PV反映的是浏览某网站的页面数，PV与来访者的数量成正比，PV并不是页面的来访者数量，而是网站被访问的页面数量 UV(独立访客)：即Unique Visitor,访问网站的一台电脑为一个访客。一天内相同的客户端只被计算一次。可以理解成访问某网站的电脑的数量。网站判断来访电脑的身份是通过来访电脑的cookies实现的。如果更换了IP后但不清除cookies，再访问相同网站，该网站的统计中UV数是不变的 网站统计：http://www.alexa.cn/rank/ 网站访问统计示例：甲乙丙三人在同一台通过ADSL上网的电脑上（中间没有断网），分别访问www.lvpeixin.tech 网站， 并且每人各浏览了2个页面，那么网站的流量统计是： IP: 1 PV:6 UV:1 若三人都是ADSL重新拨号后,各浏览了2个页面，则 IP: 3 PV:6 UV:1 QPS：request per second，每秒请求数 QPS= PV* 页⾯衍生连接次数/ 统计时间（86400） 并发连接数 =QPS * http平均响应时间 峰值时间：每天80%的访问集中在20%的时间里，这20%时间为峰值时间 峰值时间每秒请求数(QPS)=( 总PV数 *页⾯衍⽣连接次数）80% ) / ( 每天秒数 20% ) 六、HTTP状态码HTTP状态码由三个十进制数字组成，第一个十进制数字定义了状态码的类型，后两个数字没有分类的作用。 HTTP状态码共分为5种类型： HTTP状态码列表：​ 1：信息 ​ 2：成功 ​ 3：重定向 ​ 4：客户端错误 ​ 5：服务器错误]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之主从复制相关实验]]></title>
    <url>%2F2018%2F06%2F18%2FMySQL%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[实验一：搭建主从复制前期准备：两台虚拟机 主服务器： CentOS7.4 192.168.30.10 提示符：蓝色 从服务器： CentOS7.5 192.168.30.18 提示符：黄色 主服务器：vim /etc/my.cnf [mariadb] log-bin server_id=1 log-basename=master 可选项 重启mysql服务使生效 systemctl restart mariadb 创建有复制权限的用户账号 masql&gt; grant replication slave on . to repluser@’192.168.30.%’ identified by ‘centos’; 导入一个数据库hellodb #mysql &lt; hellodb_innodb.sql 此时查看当前使用的二进制日志： masql&gt; show master logs; 从服务器：vim /etc/my.cnf [mariadb] server_id=2 read_only 重启mysql服务使之生效 systemctl restart mariadb 使用有复制权限的用户账号连接至主服务器，并启动复制线程 mysql&gt; CHANGE MASTER TO MASTER_HOST=’192.168.30.10′, MASTER_USER=’repluser’, MASTER_PASSWORD=’centos’, MASTER_PORT=3306, MASTER_LOG_FILE=’mariadb-bin.000001′, MASTER_LOG_POS=245, MASTER_CONNECT_RETRY=10; 开始从服务器复制 mysql&gt;start slaves; 此时我们可以查看从服务器的工作状态 mysql&gt; show slaves status\G; 此时我们看到从服务器已开始工作，并且已将主服务器的hellodb数据库复制过来 mysql&gt; show databases; 切换到主服务器，继续测试，创建数据库db1 mysql&gt; create database db1; 切换回从服务器，我们看到，从服务同步成功 实验二：为已存放大量数据的在用服务器搭建从服务器前期准备：主服务器数据库仍沿用实验一的主服务器，作为已运行且有数据的服务器 数据库初始信息如下： 从服务器为新环境下的服务器 主服务器：vim /etc/my.cnf [mariadb] log-bin server_id=1 innod_file_per_table 单表存储 log-basename=master 可选项，指定二进制文件前缀 重启mysql服务使之生效 systemctl restart mariadb 创建有复制权限的用户账号 masql&gt; grant replication slave on . to repluser@’192.168.30.%’ identified by ‘centos’; 查看当前主服务器二进制日志状态 使用mysqldump全备份主服务器二进制日志 mysqldump -A -F –single-transaction –master-data=1 &gt; all.sql 复制到新的从服务器 scp all.sql 192.168.30.18:/ 从服务器：[mariadb] server_id=2 read_only 只读，防止普通用户修改 重启mysql服务 systemctl restart mysql 修改全备份添加入主服务器信息： vim all.sql 找到此行 替换为： CHANGE MASTER TO MASTER_HOST=’192.168.30.10′, MASTER_USER=’repluser’, MASTER_PASSWORD=’centos’, MASTER_PORT=3306, MASTER_LOG_FILE=’mariadb-bin.000002′, MASTER_LOG_POS=245, MASTER_CONNECT_RETRY=10; 在从服务器上导入全备份 mysql &lt; all.sql 此时我们看到全备份中数据库已导入成功 开启从服务器复制 mysql&gt; start slave; 查看从服务器工作状态，已开始正常工作 mysql&gt; show slave status; 切换到主服务器，继续测试，创建数据库db2 mysql&gt; create database db2; 切换回从服务器，我们看到，从服务同步成功 实验三：级联复制 前期准备：三台虚拟机 主服务器： CentOS7.4 192.168.30.10 提示符：蓝色 中间从服务器： CentOS7.5 192.168.30.18 提示符：黄色 从服务器： CentOS7.5 192.168.30.19 提示符：红色 主服务器：vim /etc/my.cnf [mariadb] log-bin server_id=1 重启mysql systemctl restart mariadb 创建有复制权限的用户账号 masql&gt; grant replication slave on . to repluser@’192.168.30.%’ identified by ‘centos’; 中间从服务器：vim /etc/my.cnf [mariadb] log-bin server_id=2 log_slave_updates read_only 重启mysql服务 systemctl restart mariadb 填写master服务信息，即主服务器信息 mysql&gt; CHANGE MASTER TO MASTER_HOST=’192.168.30.10′, MASTER_USER=’repluser’, MASTER_PASSWORD=’centos’, MASTER_PORT=3306, MASTER_LOG_FILE=’mariadb-bin.000001′, MASTER_LOG_POS=245, MASTER_CONNECT_RETRY=10; 开启从服务器 start slave; 从服务器：vim /etc/my.cnf [mariadb] server_id=3 read_only 重启mysql服务 systemctl start mariadb 指定主服务器，即中间从服务器 mysql&gt; CHANGE MASTER TO MASTER_HOST=’192.168.30.18′, MASTER_USER=’repluser’, MASTER_PASSWORD=’centos’, MASTER_PORT=3306, MASTER_LOG_FILE=’mariadb-bin.000001′, MASTER_LOG_POS=245, MASTER_CONNECT_RETRY=10; 开启从服务 mysql&gt; start slave; 查看从服务器工作状态 mysql&gt; show slave status; 测试： 主服务器导入hellodb数据库，测试是否同步成功 #mysql &lt; hellodb_innodb.sql 中间服务器，我们看到hellodb数据库已同步成功 再切换至从服务器，hellodb数据库也同步成功，至此我们实现了数据库服务器的级联复制 实验四：提升一个从服务器为主服务器模拟场景：当主服务器出现损坏时，我们需要提升一台从服务器作为主服务器使用，由于每台从服务器同步的数据完 整情况可能不同，所有第一步应该选出数据同步最完整的从服务器。 那么，如何查看同步数据的完整性呢？ 当slave开启成功后，会在mysql目录下生产一个master.info的文件，里面统计的是master服务器的相关信 息，其中介于二进制文件名与主机名之间的数字即为已同步数据量，我们只需要打开每一台从服务器，观 察这个值，取最大的一台从服务器即可 cat /var/lib/mysql/master.info 将此从服务器配置修改为主服务器配置 [mariadb] log-bin server_id=1 再将其他从服务器的master重新执行此台从服务器即可 清除其他从服务器原有master配置信息 mysql&gt; reset slave all; mysql&gt; CHANGE MASTER TO MASTER_HOST=’192.168.30.XX’, MASTER_USER=’repluser’, MASTER_PASSWORD=’centos’, MASTER_PORT=3306, MASTER_LOG_FILE=’mariadb-bin.00000X’, MASTER_LOG_POS=XXX, MASTER_CONNECT_RETRY=10; 实验五：主主复制 主主复制：互为主从 容易产生的问题：数据不一致；因此慎用 前期准备：虚拟机2台 主服务器1： CentOS7.4 192.168.30.10 提示符：蓝色 主服务器2： CentOS7.5 192.168.30.18 提示符：黄色 主服务器1：vim /etc/my.cnf log-bin server_id=1 auto_increment_offset=1 auto_increment_increment=2 #自动递增，避免数据冲突，当三台互为主从，改为3 重启mysql服务 systemctl restart mariadb 创建账号 masql&gt; grant replication slave on . to repluser@’192.168.30.%’ identified by ‘centos’; 互相添加master配置为对方： mysql&gt; CHANGE MASTER TO MASTER_HOST=’192.168.30.18′, MASTER_USER=’repluser’, MASTER_PASSWORD=’centos’, MASTER_PORT=3306, MASTER_LOG_FILE=’mariadb-bin.000001′, MASTER_LOG_POS=245, MASTER_CONNECT_RETRY=10; mysql&gt; start slave; 主服务器2：vim /etc/my.cnf log-bin server_id=2 auto_increment_offset=2 auto_increment_increment=2 重启mysql服务 systemctl restart mariadb 创建账号 masql&gt; grant replication slave on . to repluser@’192.168.30.%’ identified by ‘centos’; 添加master配置： mysql&gt; CHANGE MASTER TO MASTER_HOST=’192.168.30.10′, MASTER_USER=’repluser’, MASTER_PASSWORD=’centos’, MASTER_PORT=3306, MASTER_LOG_FILE=’mariadb-bin.000001′, MASTER_LOG_POS=245, MASTER_CONNECT_RETRY=10; mysql&gt; start slave; 测试： 主服务器1创建db1数据库： mysql&gt; create database db1; 主服务器2创建db2数据库： mysql&gt; create database db1; 分别查看两台主服务器均同步成功 当在主服务器1数据库中不指定ID添加数据时，默认以奇数递增；同理主服务2默认以偶数递增；主主复制 就是通过此种方法来避免数据可能出现的冲突。 实验六：半同步复制应用场景：默认情况下，MySQL的复制功能是异步的，这就会造成主服务器和从服务器的数据不一致，甚 至在恢复时造成数据的丢失。半同步复制能够使从服务器始终有一台数据与主服务器保持一致，避免出现 数据丢失。在生产环境中，一般都要搭建半同步复制。 主服务器需要安装的mysql插件：semisync_master.so 从服务器需要安装的musql插件：semisync_slave.so 主服务器：安装semisync_master.so插件 mysql&gt; INSTALL PLUGIN rpl_semi_sync_master SONAME ‘semisync_master.so’; 查看master半同步相关变量： mysql&gt; show global variables like ‘%semi%’; 启用master半同步功能 mysql&gt; set global rpl_semi_sync_master_enabled=on; 从服务器：同理在从服务器安装semisync_slave.so mysql&gt; INSTALL PLUGIN rpl_semi_sync_master SONAME ‘semisync_slave.so’; mysql&gt; show global variables like ‘%semi%’; 启用slave半同步功能 mysql&gt; set global rpl_semi_sync_slave_enabled=on; 至此，主从服务器的半同步复制就搭建完成了 实验七：实现主从SSL加密复制前期准备：三台虚拟机 CA： CentOS7.4 192.168.30.10 提示符：蓝色 主服务器： CentOS7.5 192.168.30.20 提示符：黄色 从服务器： CentOS7.5 192.168.30.17 提示符：红色 生成CA的私钥 cd /etc/my.cnf.d/ssl openssl genrsa 2048 &gt; cakey.pem 生成自签名 openssl req -new -x509 -key cakey.pem -out cacert.pem -days 3650 ls /etc/my.cnf.d/ssl cacert.pem cakey.pem 在本机生成master和slave的私钥 同时生成主服务器的私钥和签名请求 openssl req -newkey rsa:2048 –days 365 -nodes -keyout master.key &gt; master.csr CN beijing beijing magedu.com opt master.magedu.com 颁发证书 openssl x509 -req -in master.csr -CA cacert.pem -CAkey cakey.pem -set_serial 01 &gt; master.crt 此时ssl目录下的文件有 继续生成从服务器的私钥和签名请求 openssl req -newkey rsa:2048 -days365 -nodes -keyout slave.key &gt; slave.csr CN beijing beijing magedu.com opt slave.magedu.com 颁发证书 openssl x509 -req -in slave.csr -CA cacert.pem -CAkey cakey.pem -set_serial 01 &gt; slave.crt 此时ssl目录下文件有 scp -r /etc/my.cnf.d/ssl 192.16.30.17:/etc/my.cnf.d scp -r /etc/my.cnf.d/ssl 192.16.30.27:/etc/my.cnf.d master 服务器保留下列文件 cacert.pem master.crt master.key slave 服务器保留下列文件 cacert.pem slave.crt slave.key Master服务器配置[mysqld] log-bin server_id=1 ssl ssl-ca=/etc/my.cnf.d/ssl/cacert.pem ssl-cert=/etc/my.cnf.d/ssl/master.crt ssl-key=/etc/my.cnf.d/ssl/master.key 重启mysql服务 systemctl retart mariadb 查看是否生效 mysql&gt; show variables like ‘%ssl’ 创建用户且要求必须以加密方式连接 masql&gt; grant replication slave on . to repluser@’192.168.30.%’ identified by ‘centos’ require ssl; 可以在slave端测试replusr用户用ssl连接 mysql -urepluser -pcentos -h192.168.30.17 –ssl-ca=cacert.pem –ssl-cert=slave.crt –ssl-key=slave.key slave服务器配置第一种方法：CHANGE MASTER TO [mysqld] serverid=2 ssl 重启mysql服务 systemctl restart mariadb 查看是否生效 mysql&gt; show variables like ‘%ssl’ 配置master服务器信息 mysql&gt; CHANGE MASTER TO MASTER_HOST=’192.68.30.20′, MASTER_USER=’repluser’, MASTER_PASSWORD=’centos’, MASTER_PORT=3306, MASTER_LOG_FILE=’ mariadb-bin.000001′, MASTER_LOG_POS=245, MASTER_CONNECT_RETRY=10, MASTER_SSL=1, MASTER_SSL_CA = ‘/etc/my.cnf.d/ssl/cacert.pem’, MASTER_SSL_CERT = ‘/etc/my.cnf.d/ssl/slave.crt’, MASTER_SSL_KEY = ‘/etc/my.cnf.d/ssl/slave.key’; 开启从服务器 mysql&gt; start slave 测试： master创建一个数据库 查看slave是否同步 第二种方法：写入配置 stop slave; reset slave all; [mysqld] log-bin server_id=2 ssl ssl-ca=/etc/my.cnf.d/ssl/cacert.pem ssl-cert=/etc/my.cnf.d/ssl/slave.crt ssl-key=/etc/my.cnf.d/ssl/slave.key master服务器： mysql&gt; show master logs; 000002 493 slave服务器： mysql&gt; CHANGE MASTER TO MASTER_HOST=’192.68.30.17’， MASTER_USER=’repluser’, MASTER_PASSWORD=’centos’, MASTER_PORT=3306, MASTER_LOG_FILE=’master-bin.000002′, MASTER_LOG_POS=493, MASTER_CONNECT_RETRY=10; MASTER_SSL=1]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql之备份及还原相关实验]]></title>
    <url>%2F2018%2F06%2F14%2FMysql%E4%B9%8B%E5%A4%87%E4%BB%BD%E5%8F%8A%E8%BF%98%E5%8E%9F%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[实验准备：CentOS虚拟机两台，一台作为数据库服务器，一台作为中间存放备份的服务器 数据库服务器：操作系统：CentOS7.4 IP：192.168.30.10 提示符颜色：蓝色 中间服务器：操作系统：CentOS7.5 IP：192.168.30.17 提示符颜色：黄色 两台主机安装MariaDB 5.5.56，并且开启二进制日志功能 实验一：冷备份数据库并还原备份：数据库初始状态为： 1停止mysql服务 systemctl stop mariadb.service 2打包并压缩备份文件 （注：生产环境应将备份文件与数据库服务器分开存放） tar Jcvf /data/all.tar.xz /var/lib/mysql/ 3模拟破坏数据库 rm -rf /var/lib/mysql/* 还原：tar xvf /data/all.tar.xz mv var/lib/mysql/* /var/lib/mysql/ 确认文件已生成 ls /var/lib/mysql/ 重新启动服务： systemctl start mariadb.service 确认数据库已恢复 实验二：结合LVM逻辑卷实现几乎热备备份：1.创建逻辑卷 新建一个磁盘分区/dev/sda6 pvcreate /dev/sda6 vgcreate vg0 /dev/sda6 lvcreate -L 4G -n lv_mysql vg0 lvcreate -L 4G -n lv_binlog vg0 mkfs.xfs lv_mysql lv_binlog mkdir /data/{mysql,binlog} mount /dev/vg0/lv_mysql /data/mysql/ mount /dev/vg0/lv_binlog /data/binlog/ 2修改目录权限 chown -R mysql.mysql /data/mysql/ chown -R mysql.mysql /data/binlog/ 3修改配置文件 vim /etc/my.cnf [mysqld] datadir=/data/mysql log_bin=/data/binlog/mysql-bin 4重启mysql服务 systemctl restart mariadb 5添加读锁，防止有用户继续写入数据 mysql&gt; flush tables with read lock; 刷新日志 mysql&gt; flush logs; 查看当前二进制日志 mysql&gt; show master logs; 记录最新的二进制日志为：mariadb-bin.000004 6创建快照 lvcreate -L 1G -n lv_mysql_snap -s -p r /dev/vg0/lv_mysql 7解锁数据库 Mysql&gt; unlock tables； 8挂载逻辑卷快照 mount -o nouuid,norecovery /dev/vg0/lv_mysql_snap /mnt 9将逻辑卷文件备份至backup目录 mkdir /backup cp -a /mnt/* /backup/ 10删除快照,否则影响用户访问数据库速度 umount /mnt lvremove /dev/vg0/lv_mysql_snap 备份过程结束 Mysql &gt; create databases db2 Mysql &gt; create databases db3 模拟数据库损坏:rm –rf /data/mysql/* 还原：停止mysql服务 systemctl stop mariadb 拷贝备份文件至数据库目录 cp -av /backup/* /data/mysql/ 开启mysql服务 systemctl start mariadb 此时数据库已还原至快照时的状态 二进制继续修复db1，db2 mysql&gt; flush tables with read lock; mysqlbinlog –start-position=245 mysql-bin.000004 &gt; /backup/bin.sql mysqlbinlog mysql-bin.000005 &gt;&gt; /backup/bin.sql 确保恢复过程中，没有用户可以读取或写入 vim /etc/my.cnf [mysqld] skip_networking 或iptables –A 重启mysql服务使生效 systemctl restart mariadb 导入二进制文件 mysql &lt; /backup/bin.sql 此时数据库已还原至最新状态 最后，恢复用户访问 vim /etc/my.cnf [mysqld] skip_networking 去掉 或清除防火墙 systemctl restart mariadb 实验三：数据库数据文件损坏后，利用mysqldump还原至最新状态初始数据库为： 利用mysqldump生成备份文件 mysqldump -A -F –single-transaction –master-data=2&gt;/backup/fullbak_date +%F.sql ls /backup -l ![(}{FM3NQF{)%UHU75G2IAE mysql&gt; create database db2 mysql&gt; create database db3 此时数据库为： 最新二进制日志为：mariadb-bin.000006 模拟日常将备份传至中间主机：192.168.30.17 接下来为了方便演示，我们之间在中间主机进行数据库恢复： rm -rf /var/lib/mysql 还原：利用mysqlbinlog命令可查看二进制日志，看到创建db2，db3发生在position245之后 mysqlbinlog mariadb-bin.000006 首先还是停止mysql服务 systemctl stop mariadb.service 禁止其他用户访问或修改数据库 vim /etc/my.cnf [msyqld] skip_networking 生成二进制备份文件 mysqlbinlog –start-position=245 mysql-bin.000012 &gt; bin.sql 重新开启mysql服务 systemctl start mariadb.service 修复至mysqldump全备份阶段 mysql &lt; fullbak_2018-06-14.sql 继续二进制修复db2，db3 mysql &lt; bin.sql 此时，数据库修复完成，最后别忘了修改配置文件 vim /etc/my.cnf [msyqld] skip_networking 去掉此行 重启mysql服务 systemctl restart mysql 实验四：误删除表后，利用mysqldump还原至最新状态前期准备:开启二进制日志功能 实验场景：模拟周日进行了全备份，周一上午10表被误删除，10点之前与之后均发生了其他操作，尝试还 原数据库中误删除的表并且操作不发生丢失 数据库初始状态 模拟周日进行完全备份： 模拟周一上午10点数据发生了修改(students表原总行数为25) Mysql &gt; insert students values(26,’mysql’,’30’,’M’,2,3); 模拟周一上午10点某张表被删除 Mysql &gt; drop table students; 模拟周一上午10点至10点10分间又进行了其他操作 insert teachers values(5,’mht’,’46’,’m’)； 周一上午10点10分，发现students表丢失 还原：Mysql &gt; flush tables with read lock; 查看当前二进制日志为：mariadb-bin.000003 Mysql &gt; show master logs; 刷新二进制日志 Mysql &gt; flush logs 查看全备份的position，确定全备份到目前之间的所有日志文件及position less /backup/fullbak mysqlbinlog –start-position=245 /var/lib/mysql/mariadb-bin.000003 &gt; /backup/bin.sql mysqlbinlog /var/lib/mysql/mariadb-bin.000004 &gt;&gt; /backup/bin.sql 找到想要撤销的操作，删除 vim /backup/bin.sql 停止mysql服务 systemctl stop mariadb.service 禁止其他用户访问或修改数据库 vim /etc/my.cnf [msyqld] skip_networking 删除库下数据(不用紧张^^) rm -rf /var/lib/mysql/* 重新启动mysql服务 systemctl start mariadb.service 导入周日的全备份 mysql &lt; /backup/fullbak_2018-06-14.sql 继续导入修改过的二进制备份 mysql &lt; /backup/bin.sql 我们看到students表还原成功，而且不论是表删除之前还是之后发生的操作也都恢复回来了 此时，数据库修复完成，最后别忘了修改配置文件 vim /etc/my.cnf [msyqld] skip_networking 去掉此行 重启mysql服务 systemctl restart mysql 实验五：Xtrabackup完全备份及还原安装xtrabackup包(epel) yum install percona* 数据库初始为： 利用innobackupex命令完全备份 Innobackupex [ –user=root –password=!@#$% ] /backup/ 模拟日常将备份传至中间主机：192.168.30.17 scp -r /backup/ 192.168.30.17:/ 还原：接下来为了方便演示，我们之间在中间主机进行数据库恢复： 停止mysql服务 systemctl stop mariadb.service 清空数据库 rm –rf /var/lib/mysql/* 整合完全备份 innobackupex –apply-log /backup/2018-06-14_17-08-53/ 自动复制到数据库目录，但所属主为root，需要变更 innobackupex –copy-back /backup/2018-06-14_17-08-53/ chown -R mysql.mysql /var/lib/mysql/ 重新开启mysql服务 systemctl start mariadb.server 数据库恢复成功 实验六：Xtrabackup完全，增量备份及还原初始数据库为： mkdir /backup/ mkdir /backup/{inc1,inc2} Innobackupex [ –user=root –password=!@#$% ] /backup/ 模拟第一次修改数据库 mysql&gt; insert students values(26,’test1′,18,’M’,1,2)； 第一次增量备份 innobackupex –incremental /backup/inc1 –incremental-basedir= /backup/2018-06-14_17-50-43 模拟第二次修改数据库 mysql&gt; insert students values(27,’test1′,28,’M’,1,2)； 第二次增量备份 Innobackupex –incremental/backup/inc2 –incremental-basedir= /backup/inc1/2018-06-14_17-55-52 此时backup目录结构 复制到远程主机做备份： scp -r /backup/ 192.68.30.17:/ 还原：接下来为了方便演示，我们之间在中间主机进行数据库恢复： 停止mysql服务 systemctl stop mariadb.service 清空数据库 rm –rf /var/lib/mysql/* 整合完全备份： innobackupex –apply-log –redo-only /backup/2018-06-14_17-50-43/ 整合第一次增量备份： innobackupex –apply-log –redo-only /backup/2018-06-14_17-50-43/ –incremental-dir /backup/inc1/2018-06-14_17-55-52 整合第二次增量备份： innobackupex –apply-log –redo-only /backup/2018-06-14_17-50-43/ –incremental-dir /backup/inc2/2018-06-14_17-59-00 自动复制到数据库目录，但所属主为root，需要变更 innobackupex –copy-back /backup/2018-06-14_17-50-43/ 更改属主为mysql chown -R mysql.mysql /var/lib/mysql/* 重新开启mysql服务 systemctl start mariadb.service 此时，我们看到第一次修改，第二次修改的数据也已还原 实验七：Xtrabackup单表导出和导入前期准备：必须设置独立表空间 vim /etc/my.cnf [mysqld] innodb_file_per_table 初始表信息为: 1单表备份 innobackupex –include=”hellodb.students” /backup/ 2备份表结构 mysql -e ‘show create table hellodb.students’ &gt; students.sql 删除其中的多余部分，留下下图所示内容 vim students.sql 3模拟破坏表 mysql -e ‘drop table hellodb.students’ ### 还原：整合备份 innobackupex –apply-log –export /backup/2018-06-14_19-03-21 导入表结构 mysql hellodb &lt; students.sql 此时表结构已生成，但数据为空 删除表空间 mysql -e ‘alter table hellodb.students discard tablespace’ 复制相关文件到hellodb目录 cd /backup/2018-06-14_19-37-02/hellodb/ cp students.cfg students.exp students.ibd /data/mysql/hellodb/ 修改hellodb目录下文件权限 chown mysql.mysql /data/mysql/hellodb/* mysql&gt;alter table students import tablespace; 此时数据已恢复完成]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之日志管理]]></title>
    <url>%2F2018%2F06%2F12%2FMySQL%E4%B9%8B%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[MySQL数据库中支持多种日志类型，通过分析日志，我们可以优化数据库性能，排除故障，甚至能够还原 数据，本节内容将带你了解MySQL数据库中的日志管理 一、事务日志作用：用来记录数据库更新情况的文件，它可以记录针对数据库的任何操作，并将记录的结果保存到独立的文件 中。对于每一次数据库更新的过程，事务日志文件都有非常全面的记录。根据这些记录可以恢复数据库更 新前的状态。 日志文件：事务型存储引擎自行管理和使用，建议和数据文件分开存放 事务日志包括 Redo log 重做日志 Undo log 回滚日志 Redo记录的是已经全部完成的事务，就是执行了commit的事务，记录文件是： ib_logfile0，ib_logfile1…… 默认路径：/var/lib/mysql/ 相关变量： 日志管理：调整事务日志文件大小及数量 服务器选项中指定 vim /etc/my.cnf [mysqld] innodb_log_file_size=10240000 innodb_log_files_in_group=5 注：调整事务日志数量后，必须将原有事务日志文件删除，否则服务无法重启成功 生产环境建议：(1) 生产环境中一般根据具体情况将文件大小调大并增加日志文件数量 (2) 由于事务日志会重复交替覆盖，所以利用事务日志仅仅可以避免数据库突然崩溃，如掉电的情况，而不 可用做恢复数据用 二、错误日志功能：在MySQL数据库中，错误日志时默认开启的。用于记录MySQL 运行过程中较为严重的警告和错误信息， 以及MySQL每次启动和关闭的详细信息。 日志文件：logerror=/PATH/TO/LOGERRORFILE 默认存放路径：/var/log/mariadb/mariadb.log 日志管理：是否记录警告信息至错误日志文件 logwarnings=1|0 1表示开启，0表示关闭，默认值为1 生产环境建议：数据库管理员可以删除很长时间之前的错误日志，以保证mysql服务器上的硬盘空间。 可使用重命名原来的错误日志文件，手动冲洗日志创建一个新的错误日志，方法如下： [root@CentOS7 mysql]#mv mariadb.log mariadb.log.data [root@CentOS7 mysql]#mysqladmin -pcentos flush-logs 三、通用日志功能：记录对数据库的通用操作，包括错误的SQL语句，MySQL数据库默认不启用通用日志 文件：file，默认值 表：table 日志相关设置： 日志管理：general_log=ON|OFF general_log_file=HOSTNAME.log log_output=TABLE|FILE|NONE optimize table testlog； 整理数据库，释放磁盘数据库碎片 生产环境建议：由于通用日志在并发操作大的环境下会产生大量的信息从而导致不必要的磁盘IO，会影响mysql的性能。 如若不是为了调试数据库的目的建议不要开启查询日志。 四、慢查询日志功能：记录执行查询时长超出指定时长的操作，可以帮助我们定位性能问题。 日志文件：/var/lib/mysql/Hostname-slow.log 日志管理：log_slow_filter = admin,filesort,filesort_on_disk,full_join, full_scan,query_cache,query_cache_miss,tmp_table,tmp_table_on_disk 上述查询类型且查询时长超过long_query_time，则记录日志 log_queries_not_using_indexes=ON 不使用索引或使用全索引扫描，不论是否达到慢查询阀值的语句是否 记录日志，默认OFF，即不记录,生产环境中可监控此项优化数据库环境 log_slow_rate_limit = 1 多少次查询才记录，mariadb特有 log_slow_verbosity= Query_plan,explain 记录内容 log_slow_queries = OFF 同slow_query_log 新版已废弃 生产环境建议：通过慢查询日志，可以查找出哪些查询语句的执行效率很低，以便进行优化。一般建议开启，它对服务器 性能的影响微乎其微，但是可以记录mysql服务器上执行了很长时间的查询语句。 示例：模拟慢查询 打开慢查询日志： 五、二进制日志作用：主要用于记录修改数据或有可能引起数据改变的mysql语句，并且记录了语句发生时间、执行时长、操作 的数据等等。所以说通过二进制日志可以查询mysql数据库中进行了哪些变化，通过“重放”日志文件中的事 件来恢复数据副本。 日志文件的构成：有两类文件 (1) 日志文件：mysql|mariadb-bin.文件名后缀，二进制格式 如： mysql-bin.000001 (2) 索引文件：mysql|mariadb-bin.index，文本格式 二进制日志记录有三种格式：(1) 基于“语句”记录：statement，记录语句，默认模式 (2) 基于“行”记录：row，记录数据，日志量较大 (3) 混合模式：mixed, 让系统自行判定该基于哪种方式进行 相关变量： sql_log_bin=ON|OFF：是否记录二进制日志，默认ON，需配合log_bin，支持动态修改 log_bin=/PATH/BIN_LOG_FILE：指定文件位置；默认OFF，表示不启用二进制日志功能，上述两 项都开启才可，不写路径默认在/var/lib/mysql目录下，生产中建议分开存放 两项都是ON**状态才开启二进制日志功能，缺一不可！** binlog_format=STATEMENT|ROW|MIXED：二进制日志记录的格式，默认STATEMENT max_binlog_size=1073741824：单个二进制日志文件的最大体积，到达最大值会自动滚动，默认为 1G 说明：文件达到上限时的大小未必为指定的精确值 sync_binlog=1|0：设定是否启动二进制日志即时同步磁盘功能，默认0，由操作系统负责同步日志到 磁盘 expire_logs_days=N：二进制日志可以自动删除的天数。 默认为0，即不自动删除 日志管理：二进制日志相关配置 查看mariadb自行管理使用中的二进制日志文件列表，及大小 SHOW {BINARY | MASTER} LOGS 查看使用中的二进制日志文件 SHOW MASTER STATUS 查看二进制文件中的指定内容 SHOW BINLOG EVENTS [IN ‘log_name’] [FROM pos] [LIMIT [offset,] row_count] show binlog events in ‘mysql-bin.000001′ from 6516 limit 2,3 清除指定二进制日志： ​ PURGE { BINARY | MASTER } LOGS ​ { TO ‘log_name’ | BEFORE datetime_expr } 示例： PURGE BINARY LOGS TO ‘mariadb-bin.000003’;删除3前日志 PURGE BINARY LOGS BEFORE ‘2017-01-23’; PURGE BINARY LOGS BEFORE ‘2017-03-22 09:25:30’; 删除所有二进制日志，index文件重新记数 ​ RESET MASTER [TO #]; 日志文件从#开始记数，默认从1开始，一般是 master第一次启动时执行，MariaDB10.1.6开始支持TO # 切换日志文件： ​ FLUSH LOGS; 二进制日志事件格式：# at 328 #151105 16:31:40 server id 1 end_log_pos 431 Query thread_id=1 exec_time=0 error_code=0 use mydb/!/; SET TIMESTAMP=1446712300/!/; CREATE TABLE tb1 (id int, name char(30)) /!/; 事件发生的日期和时间：151105 16:31:40 事件发生的服务器标识：server id 1 事件的结束位置：end_log_pos 431 事件的类型：Query 事件发生时所在服务器执行此事件的线程的ID：thread_id=1 语句的时间戳与将其写入二进制文件中的时间差：exec_time=0 错误代码：error_code=0 事件内容： GTID：Global Transaction ID，mysql5.6以mariadb10以上版本专属属性：GTID 生产环境建议：(1) 强烈建议开启二进制日志功能！ (2) 强烈建议以基于“行”的格式记录二进制日志，条件不允许可采用混合模式 mysqlbinlog命令功能：二进制日志的客户端命令工具 格式：mysqlbinlog [OPTIONS] log_file… –start-position=# 指定开始位置 –stop-position=# –start-datetime= –stop-datetime= 时间格式：YYYY-MM-DD hh:mm:ss –base64-output[=name] 示例： mysqlbinlog –start-position=6787 –stop-position=7527 /var/lib/mysql/mariadb-bin.000003 mysqlbinlog –start-datetime=”2018-01-30 20:30:10″ –stopdatetime=”2018-01-30 20:35:22″ mariadb-bin.000003 mysqlbinlog –start-position=647 –stop-position=797 -v /data/mysqllogs/mysql-bin.000003 六、性能分析工具profile功能：用于跟踪执行过的sql语句的资源消耗信息，可以帮助查看sql语句的执行情况，可以在做性能分析或者问题 诊断的时候作为参考。 相关变量： Profiling功能默认关闭，开启profiling： MariaDB [hellodb]&gt; set profiling=ON; 显示每条SQL语句所消耗的时间： MariaDB [hellodb]&gt; show profiles; 显示指定Query_id的SQL语句执行过程各阶段消耗的时间： MariaDB [hellodb]&gt; show profile for query 3;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之事务及并发控制]]></title>
    <url>%2F2018%2F06%2F12%2FMySQL%E4%B9%8B%E4%BA%8B%E5%8A%A1%E5%8F%8A%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[一、事务什么是事务？事务Transactions：一组原子性的SQL语句，或一个独立工作单元。 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个 人员，你既需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等， 这样，这些数据库操作语句就构成一个事务 事务日志：记录事务信息，实现undo,redo等故障恢复功能 ACID特性：A：atomicity原子性； 整个事务中的所有操作要么全部成功执行，要么全部失败后回滚，不可能停滞在中间某个环节。 C：consistency一致性； 数据库总是从一个一致性状态转换为另一个一致性状态 也就是说：如果事务是并发多个，系统也必须如同串行事务一样操作。其主要特征是保护性和不 变性(Preserving an Invariant)，以转账案例为例，假设有五个账户，每个账户余额是100元，那 么五个账户总额是500元，如果在这个5个账户之间同时发生多个转账，无论并发多少个，比如在 A与B账户之间转账5元，在C与D账户之间转账10元，在B与E之间转账15元，五个账户总额也应该 还是500元，这就是保护性和不变性 I：Isolation隔离性； 一个事务所做出的操作在提交之前，是不能为其它事务所见；隔离有多种隔离级别，实现并发。 如果有两个事务，运行在相同的时间内，执行相同的功能，事务的隔离性将确保每一事务在系统中 认为只有该事务在使用系统。这种属性有时称为串行化，为了防止事务操作间的混淆，必须串行化 或序列化请求，使得在同一时间仅有一个请求用于同一数据。 D：durability持久性； 一旦事务提交，其所做的修改会永久保存于数据库中 如图所示一个事务的生命周期： (1) 开启一个事务 (2) 进行事务操作，注：只有对数据库的增、删、改操作才记入事务，SELECT查 询语句不计入事务。 (3) ROLLBACK将会使未提交的数据回滚，数据还原至更改前的数据 (4) 一旦进行了COMMIT提交，新的数据将会持久的保存在数据库之中，并不会被回 滚，即事务的持久性。 事务控制语句：BEGIN或START TRANSACTION：显式地开启一个事务； ROLLBACK：回滚会结束用户的事务，并撤销正在进行的所有未提交的修改； COMMIT：提交事务，并使已对数据库进行的所有修改称为永久性的； SAVEPOINT identifier：SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT； ROLLBACK TO identifier：把事务回滚到标记点； RELEASE SAVEPOINT identifier：删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常； 实现MySQL事务处理：方法一：用 BEGIN, ROLLBACK, COMMIT来实现 BEGIN 开始一个事务 ROLLBACK 事务回滚 COMMIT 事务确认 方法二：直接用 SET 来改变 MySQL 的自动提交模式: SET AUTOCOMMIT=OFF 禁止自动提交 SET AUTOCOMMIT=ON 开启自动提交（系统默认项） 示例：事务测试 ![M40SD}~}HE((AK_QBQ0}%W 二、事务隔离级别在数据库操作中，为了有效保证并发读取数据的正确性，提出的事务隔离级别。 数据库是要被广大客户所共享访问的，那么在数据库操作过程中很可能出现以下几种不确定情况。 更新丢失两个事务都同时更新一行数据，一个事务对数据的更新把另一个事务对数据的更新覆盖了。这是因为系统 没有执行任何的锁操作，因此并发事务并没有被隔离开来。 脏读一个事务读取到了另一个事务未提交的数据操作结果。这是相当危险的，因为很可能所有的操作都被回 滚。 虚读事务T1读取某一数据后，事务T2对其做了修改，当事务T1再次读该数据时得到与前一次不同的值。 幻读事务在操作过程中进行两次查询，第二次查询的结果包含了第一次查询中未出现的数据或者缺少了第一次 查询中出现的数据（这里并不要求两次查询的SQL语句相同）。这是因为在两次查询过程中有另外一个事 务插入数据造成的。 事务隔离级别为了避免上面出现的几种情况，在标准SQL规范中，定义了4个事务隔离级别，不同的隔离级别对事务的 处理不同。 从上至下更加严格： READ UNCOMMITTED：可读取到未提交数据，产生脏读 READ COMMITTED：可读取到提交数据，但未提交数据不可读，产 生不可重复读，即可读取到多个提交数据，导致每次读取数据不一致 REPEATABLE READ 可重复读，多次读取数据都一致，产生幻读，即 读取过程中，即使有其它提交的事务修改数据，仍只能读取到未修改 前的旧数据。此为MySQL默认设置 SERIALIZABILE 可串行化，未提交的读事务阻塞修改事务，或者未 提交的修改事务阻塞读事务。导致并发性能差 管理事务隔离级别：服务器变量**tx_isolation**指定， 默认为REPEATABLE-READ，可在GLOBAL和SESSION级进行设置 SET tx_isolation=” ​ READ-UNCOMMITTED ​ READ-COMMITTED ​ REPEATABLE-READ ​ SERIALIZABLE 服务器选项中指定 vim /etc/my.cnf [mysqld] transaction-isolation=SERIALIZABLE 三、并发控制锁粒度： 表级锁 行级锁 锁： 读锁：共享锁，只读不可写，多个读互不阻塞， 写锁：独占锁,排它锁，一个写锁会阻塞其它读和它锁 实现： 存储引擎：自行实现其锁策略和锁粒度 服务器级：实现了锁，表级锁；用户可显式请求 分类： 隐式锁：由存储引擎自动施加锁 显式锁：用户手动请求 锁策略：在锁粒度及数据安全性寻求的平衡机制 显示使用锁 LOCK TABLES tbl_name [[AS] alias] lock_type ​ [, tbl_name [[AS] alias] lock_type] … ​ lock_type: READ ， WRITE 解锁 UNLOCK TABLES FLUSH TABLES tb_name[,…] [WITH READ LOCK] 关闭正在打开的表（清除查询缓存），通常在备份前加全局读锁 SELECT clause [FOR UPDATE | LOCK IN SHARE MODE] 查询时加写或读锁 读锁：读锁也称为共享锁，读锁允许多个连接可以同一时刻并发的读取同一资源,互不干扰； 添加读锁： MariaDB [hellodb]&gt; lock tables teachers read; 写锁：写锁也称为排他锁，一个写锁会阻塞其他的写锁或读锁，保证同一时刻只有一个连接可以写入数据，同时 防止其他用户对这个数据的读写。 添加写锁： MariaDB [hellodb]&gt; lock tables students write; 死锁：两个或多个事务在同一资源相互占用并请求锁定对方占用的资源的状态 如下所示： 事务1 事务2 update table1 update table2 update table2 update table1 产生死锁 四、MVCC-多版本的并发控制协议MySQL InnoDB存储引擎，实现的是基于多版本的并发控制协议——MVCC (Multi-Version Concurrency Control) (注：与MVCC相对的，是基于锁的并发控制，Lock-Based Concurrency Control)。MVCC最大的好处，相信也是耳熟能详：读不加锁，读写不冲突。 在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能。 InnoDB在每行数据都增加两个隐藏字段，一个记录创建的版本号，一个记录删除的版本号。 * SELECT**：** 当隔离级别是REPEATABLE READ时select操作，InnoDB必须每行数据来保证它符合两个条件： 1、InnoDB必须找到一个行的版本，它至少要和事务的版本一样老(也即它的版本号不大于 事务的版本号)。这保证了不管是事务开始之前，或者事务创建时，或者修改了这行数据的 时候，这行数据是存在的。 2、这行数据的删除版本必须是未定义的或者比事务版本要大。这可以保证在事务开始之前 这行数据没有被删除。 符合这两个条件的行可能会被当作查询结果而返回。 * INSERT**：**InnoDB为这个新行记录当前的系统版本号。 * DELETE**：**InnoDB将当前的系统版本号设置为这一行的删除ID。 * UPDATE**：**InnoDB会写一个这行数据的新拷贝，这个拷贝的版本为当前的系统版本号。 它同时也会将这个版本号写到旧行的删除版本里。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之存储引擎及索引]]></title>
    <url>%2F2018%2F06%2F11%2FMySQL%E4%B9%8B%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E5%8F%8A%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[一、MySQL存储引擎介绍存储引擎**是什么？** 例如，如果你在研究大量的临时数据，你也许需要使用内存存储引擎。内存存储引擎 能够在内存中存储所有的表格数据。又或者，你也许需要一个支持事务处理的数据库 (以确保事务处理不成功时数据的回退能力)。 这些不同的技术以及配套的相关功能在MySQL中被称作存储引擎。 下图是MySQL体系结构： MySQL的存储引擎是MySQL体系架构中的重要组成部分，也是MySQL体系结构的核 心，它处于MySQL体系架构中Server端底层，是底层物理结构的实现，用于将数据以 各种不同的技术方式存储到文件或者内存中，不同的存储引擎具备不同的存储机制、索 引技巧和锁定水平。常见的MySQL存储引擎有InnoDB、MyISAM、Memory、Archive 等等，它们具备各自的特征，我们可以根据不同的具体应用来建立对应的存储引擎表。 MySQL常见的存储引擎有：InnodDB：5.5版本之后的默认存储引擎，事务型数据库的首选引擎，支持ACID事务，支持 行级锁定 MyISAM：拥有较高的插入，查询速度，但不支持事务5.5版本之前的默认存储引擎 Performance_Schema：Performance_Schema数据库 Memory ：将所有数据存储在RAM中，以便在需要快速查找参考和其他类似数据的环境中进 行快速访问。适用存放临时数据。引擎以前被称为HEAP引擎MRG_MyISAM：使MySQL DBA 或开发人员能够对一系列相同的MyISAM表进行逻辑分组，并将它们作为一个对象引用。适用 于VLDB(Very Large DataBase)环境，如数据仓库 Archive ：为存储和检索大量很少参考的存档或安全审核信息，只支持SELECT和INSERT操 作；支持行级锁和专用缓存区 Federated联合：用于访问其它远程MySQL服务器一个代理，它通过创建一个到远程MySQL 服务器的客户端连接，并将查询传输到远程服务器执行，而后完成数据存取，提供链接单独 MySQL服务器的能力，以便从多个物理服务器创建一个逻辑数据库。非常适合分布式或数据集 市环境 BlackHole ：黑洞引擎，写入的任何数据都会消失，一般用于记录binlog做复制的中继 MariaDB支持的其它存储引擎：OQGraph SphinxSE TokuDB Cassandra CONNECT SQUENCE 下图是MySQL常见存储引擎比较： InnoDB support for FULLTEXT indexes(全文索引) is available in MySQL 5.6.4 and later. 存储引擎比较：https://docs.oracle.com/cd/E17952_01/mysql-5.5-en/storage-engines.html 作为MySQL数据库发展过程中的默认引擎，接下来我们重点介绍下InnodDB及MyISAM存储引擎 二、InnoDB与MyISAM对比MyISAM存储引擎MyISAM特性：不支持事务 表级锁定 读写相互阻塞，写入不能读，读时不能写 只缓存索引 不支持外键约束 不支持聚簇索引 读取数据较快，占用资源较少 不支持MVCC（多版本并发控制机制）高并发 崩溃恢复性较差 MySQL5.5.5前默认的数据库引擎 适用场景：只读（或者写较少）、表较小（可以接受长时间进行修复操作） ### MyISAM引擎文件：tbl_name.frm: 表格式定义 tbl_name.MYD: 数据文件 tbl_name.MYI: 索引文件 InnoDB存储引擎InnoDB特性：行级锁 支持事务，适合处理大量短期事务 读写阻塞与事务隔离级别相关 可缓存数据和索引 支持聚簇索引 崩溃恢复性更好 支持MVCC高并发 从MySQL5.5后支持全文索引 从MySQL5.5.5开始为默认的数据库引擎 InnoDB数据库文件：所有InnoDB表的数据和索引放置于同一个表空间中 表空间文件：datadir定义的目录下 数据文件：ibddata1, ibddata2, … 每个表单独使用一个表空间存储表的数据和索引 启用：innodb_file_per_table=ON 两类文件放在数据库独立目录中 数据文件(存储数据和索引)：tb_name.ibd 表格式定义：tb_name.frm 管理存储引擎查看mysql支持的存储引擎: show engines; 查看当前默认的存储引擎: show variables like ‘%storage_engine%’; 查看库中所有表使用的存储引擎 show table status from db_name; 查看库中指定表的存储引擎 show table status like ‘ tb_name ‘; show create table tb_name; 设置表的存储引擎： CREATE TABLE tb_name(… ) ENGINE=InnoDB; ALTER TABLE tb_name ENGINE=InnoDB; 操作：修改MySQL默认的存储引擎 vim /etc/my.conf [mysqld] default_storage_engine= InnoDB; 重启mysql服务生效 操作：修改MySQL中Innodb引擎每个表有独立的数据文件 vim /etc/my.cnf [mysqld] innodb_file_per_table 重启mysql服务生效 三、MVCC-多版本的并发控制协议MySQL InnoDB存储引擎，实现的是基于多版本的并发控制协议——MVCC (Multi-Version Concurrency Control) (注：与MVCC相对的，是基于锁的并发控制，Lock-Based Concurrency Control)。MVCC最大的好处，相信也是耳熟能详：读不加锁，读写不冲突。 在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能。 InnoDB在每行数据都增加两个隐藏字段，一个记录创建的版本号，一个记录删除的版本号。 * SELECT： 当隔离级别是REPEATABLE READ时select操作，InnoDB必须每行数据来保证它符合两个条件： 1、InnoDB必须找到一个行的版本，它至少要和事务的版本一样老(也即它的版本号不大于 事务的版本号)。这保证了不管是事务开始之前，或者事务创建时，或者修改了这行数据的 时候，这行数据是存在的。 2、这行数据的删除版本必须是未定义的或者比事务版本要大。这可以保证在事务开始之前 这行数据没有被删除。 符合这两个条件的行可能会被当作查询结果而返回。 * INSERT：InnoDB为这个新行记录当前的系统版本号。 * DELETE：InnoDB将当前的系统版本号设置为这一行的删除ID。 * UPDATE：InnoDB会写一个这行数据的新拷贝，这个拷贝的版本为当前的系统版本号。 它同时也会将这个版本号写到旧行的删除版本里。 在进行InnoDB与MyISAM引擎的对比时，我们还提到了索引的概念，什么是MySQL 数据库的索引呢？ 四、索引INDEX如同图书的目录，可以根据目录中的页码快速找到所需的内容。在关系数据库中，索引是一种单 独的、物理的对数据库表中一列或多列的值进行排序的一种存储结构，它是某个表中一列或若干 列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单。 索引提供指向存储在表的指定列中的数据值的指针，然后根据您指定的排序顺序对这些指针排序。 数据库使用索引以找到特定值，然后顺指针找到包含该值的行。这样可以使对应于表的SQL语句 执行得更快，可快速访问数据库表中的特定信息。 作用：1.快速取数据； 2.保证数据记录的唯一性； 3.实现表与表之间的参照完整性； 4.在使用ORDER by、group by子句进行数据检索时，利用索引可以减少排序和 分组的时间。 优点：1.大大加快数据的检索速度; 2.创建唯一性索引，保证数据库表中每一行数据的唯一性; 3.加速表和表之间的连接; 4.在使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间。 缺点：1.索引需要占物理空间。 2.当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，降低了数 据的维护速度。 索引类型：聚簇（集）索引、非聚簇索引：数据和索引存储顺序是否一致 注：MyISAM不支持聚簇索引 主键索引、辅助索引（二级索引） 稠密索引、稀疏索引：是否索引了每一个数据项 B+ TREE、HASH、R TREE 简单索引、组合索引 左前缀索引：取前面的字符做索引 覆盖索引：从索引中即可取出要查询的数据，性能高 B+ Tree索引 顺序存储，每一个叶子节点到根结点的距离是相同的；左前缀索引，适合查询范围类的数据 可以使用B-Tree索引的查询类型： 全值匹配：精确所有索引列，如：姓wang，名xiaochun，年龄30 匹配最左前缀：即只使用索引的第一列，如：姓wang 匹配列前缀：只匹配一列值开头部分，如：姓以w开头的 匹配范围值：如：姓ma和姓wang之间 精确匹配某一列并范围匹配另一列：如：姓wang,名以x开头的 只访问索引的查询 B-Tree索引的限制：如果不从最左列开始，则无法使用索引：如：查找名为xiaochun，或姓为g结尾 不能跳过索引中的列：如：查找姓wang,年龄30的，只能使用索引第一列 如果查询中某个列是为范围查询，那么其右侧的列都无法再使用索引：如： 姓wang,名x%,年龄30，只能利用姓和名上面的索引 特别提示：索引列的顺序和查询语句的写法应相匹配，才能更好的利用索引 为优化性能，可能需要针对相同的列但顺序不同创建不同的索引来满足不同 类型的查询需求 Hash索引基于哈希表实现，只有精确匹配索引中的所有列的查询才有效，索引自身只存储索引列对应 的哈希值和数据指针，索引结构紧凑，查询性能好只有Memory存储引擎支持显式hash索引 适用场景：只支持等值比较查询，包括=, &lt;=&gt;, IN(), 不适合使用hash索引的场景： 不适用于顺序查询：索引存储顺序的不是值的顺序 不支持模糊匹配 不支持范围查询 不支持部分索引列匹配查找：如A，B列索引，只查询A列索引无效 空间索引（R-Tree）：MyISAM支持空间索引，可以使用任意维度组合查询，使用特有的函数访问， 常用于做地理数据存储，使用不多 全文索引(FULLTEXT)：在文本中查找关键词，而不是直接比较索引中的值，类似搜索引擎 InnoDB support for FULLTEXT indexes(全文索引) is available in MySQL 5.6.4 and later. 聚簇索引与非聚簇索引聚簇索引是顺序结构与数据存储物理结构一致的一种索引，并且一个表的聚簇 索引只能有唯一的一条。MyISAM不支持聚簇索引。 非聚簇索引记录的物理顺序与逻辑顺序没有必然的联系，与数据的存储物理结构 没有关系；一个表对应的非聚簇索引可以有多条，根据不同列的约束可以建立不 同要求的非聚簇索引； 索引优化建议：独立地使用列：尽量避免其参与运算，独立的列指索引列不能是表达式的一 部分，也不能是函数的参数，在where条件中，始终将索引列单独放在比较 符号的一侧 左前缀索引：构建指定索引字段的左侧的字符数，要通过索引选择性来评估 索引选择性：不重复的索引值和数据表的记录总数的比值 多列索引：AND操作时更适合使用多列索引，而非为每个列创建单独的索引 选择合适的索引列顺序：无排序和分组时，将选择性最高放左侧 只要列中含有NULL值，就最好不要在此例设置索引，复合索引如果有NULL值， 此列在使用时也不会使用索引 尽量使用短索引，如果可以，应该制定一个前缀长度 对于经常在where子句使用的列，最好设置索引 对于有多个列where或者order by子句，应该建立复合索引 对于like语句，以%或者‘-’开头的不会使用索引，以%结尾会使用索引 尽量不要在列上进行运算（函数操作和表达式操作） 尽量不要使用not in和&lt;&gt;操作]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之用户与权限管理]]></title>
    <url>%2F2018%2F06%2F09%2FMySQL%E4%B9%8B%E7%94%A8%E6%88%B7%E4%B8%8E%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[一、MySQL用户管理用户账号：MySQL的用户账号由两部分组成：用户名+主机名 ‘USERNAME’@’HOST’ 其中： 主机名HOST可以是IP地址或Network； 如：wxlinux@192.168.30.10 主机名HOST也支持通配符的写法： 如：wxlinux@172.20.%.% MySQL中自带有一张名称为mysql的数据库，称为元数据数据库。 它是mysql的核心数据库，类似于sql server中的master库，主要负责存储数据库的 用户、权限设置、关键字等mysql自己需要使用的控制和管理信息。 系统授权表： user表：该表决定是否允许用户连接到服务器。如果允许连接，权限字段则 为该用户的全局权限。 db表：用于决定哪些用户可以从哪些主机访问哪些数据库。包含在db表中的 权限适用于这个表标识的数据库。 host表：当您想在db表的范围之内扩展一个条目时，就会用到这个表。举例 来说，如果某个db允许通过多个主机访问的话，那么超级用户就可 以让db表内将host列为空，然后用必要的主机名填充host表。 tables_priv表：该表与db表相似，不同之处是它用于表而不是数据库。这个 表还包含一个其他字段类型，包括timestamp和grantor两个字段，用 于存储时间戳和授权方。在本文后面我们会对这个表做进一步的讲解。 columns_priv：该表作用几乎与db和tables_priv表一样，不同之处是它提供 的是针对某些表的特定列的权限。这个表也多 出了一个字段类型，即 其他字段，包括了一个timestamp列，用于存放时间戳。 用户管理创建用户：方法一： CREATE USER ‘USERNAME’@’HOST’ [IDENTIFIED BY ‘password’]； 默认权限：USAGE，只能连接数据库，无法查看、更改、删除 示例： Mysql&gt; create user wxlinux@’192.168.30.%’ identified by ‘wxlinux’; Mysql&gt; select user,host,password from mysql.user where user=’wxlinux’; 方法二： 也可使用GRANT 授权同时创建用户 示例： 授权wang用户select、insert权限同时创建用户 Mysql&gt; grant select,insert on hellodb.* to wang@’%’ identified by ‘centos’; Mysql&gt; select user,host,password from mysql.user where user=’wang’; 用户重命名：RENAME USER old_user_name TO new_user_name 示例： Mysql&gt; rename user wxlinux@’192.168.30.%’ to wangx@’192.168.30.%’; Mysql&gt; select user,host,password from user where user=’wangx’; 删除用户：DROP USER ‘USERNAME’@’HOST’ 示例： 删除匿名用户： MariaDB [mysql]&gt; select user,host,password from user; 删除指定用户： Mysql&gt; drop user wangx@’192.168.30.%’; Mysql&gt; select user,host,password from user where user=’wangx’; Empty set (0.00 sec) 修改密码：方法一： Mysql&gt; SET PASSWORD FOR ‘user’@’host’ = PASSWORD(‘password’); 方法二： Mysql&gt; UPDATE mysql.user SET password=PASSWORD(‘password’) WHERE clause; 此方法需要执行下面指令才能生效： Mysql&gt; FLUSH PRIVILEGES; 方法三： bash命令行修改 无密码新设密码： # mysqladmin -u root password ‘newpasswd’ 修改旧密码： #mysqladmin -u root –poldpasswd password ‘newpasswd’ 二、MySQL权限管理权限类别：数据库级别 表级别 字段级别 管理类 程序类 管理类：CREATE TEMPORARY TABLES CREATE USER FILE SUPER SHOW DATABASES RELOAD SHUTDOWN REPLICATION SLAVE REPLICATION CLIENT LOCK TABLES PROCESS 程序类： FUNCTION、PROCEDURE、TRIGGERCREATE ALTER DROP EXCUTE 库和表级别：DATABASE、TABLEALTER CREATE CREATE VIEW DROP INDEX SHOW VIEW GRANT OPTION：能将自己获得的权限转赠给其他用户 数据操作：SELECT INSERT DELETE UPDATE 字段级别：SELECT(col1,col2,…) UPDATE(col1,col2,…) INSERT(col1,col2,…) 所有权限：ALL PRIVILEGES 或 ALL 授权：参考：https://dev.mysql.com/doc/refman/5.7/en/grant.html GRANT priv_type [(column_list)],… ON [object_type] priv_level TO ‘user’@’host’ [IDENTIFIED BY ‘password’] [WITH GRANT OPTION]; priv_type：ALL [PRIVILEGES] object_type：TABLE | FUNCTION | PROCEDURE priv_level：*(所有库) | . | db_name.* | db_name.tbl_name | tbl_name(当前库 的表) | db_name.routine_name(指定库的函数,存储过程,触发器) with_option：GRANT OPTION | MAX_QUERIES_PER_HOUR count | MAX_UPDATES_PER_HOUR count | MAX_CONNECTIONS_PER_HOUR count | MAX_USER_CONNECTIONS count 回收授权：REVOKE priv_type [(column_list)] [, priv_type[(column_list)]] … ON [object_type] priv_level FROM user [, user] … 查看指定用户获得的授权： ​ Help SHOW GRANTS ​ SHOW GRANTS FOR ‘user’@’host’; ​ SHOW GRANTS FOR CURRENT_USER[()]; 注意：MariaDB服务进程启动时会读取mysql库中所有授权表至内存 (1) GRANT或REVOKE等执行权限操作会保存于系统表中，MariaDB的服务进 程通常会自动重读授权表，使之生效 (2) 对于不能够或不能及时重读授权表的命令，可手动让MariaDB的服务进程 重读授权表：mysql&gt; FLUSH PRIVILEGES; 示例： 授权同时创建用户 MariaDB [hellodb]&gt; grant select,insert on hellodb.* to mage@’%’ identified by ‘centos’; MariaDB [hellodb]&gt; select user,host,password from mysql.user; 只授权某个字段的操作权限 MariaDB [hellodb]&gt; grant select(stuid,name) on hellodb.students to zhang@’%’identified by ‘centos’; 查看指定用户的权限 MariaDB [hellodb]&gt; show grants for wang@’192.168.30.%’; 查看本机登录用户权限 current_user()是一个变量，特指本机 MariaDB [(none)]&gt; show grants for current_user(); 收回指定用户的select权限 MariaDB [hellodb]&gt; revoke select on hellodb.* from mage@’%’; 三、并发控制锁粒度： 表级锁 行级锁 锁： 读锁：共享锁，只读不可写，多个读互不阻塞， 写锁：独占锁,排它锁，一个写锁会阻塞其它读和它锁 实现 存储引擎：自行实现其锁策略和锁粒度 服务器级：实现了锁，表级锁；用户可显式请求 分类： 隐式锁：由存储引擎自动施加锁 显式锁：用户手动请求 锁策略：在锁粒度及数据安全性寻求的平衡机制 显示使用锁 LOCK TABLES tbl_name [[AS] alias] lock_type ​ [, tbl_name [[AS] alias] lock_type] … ​ lock_type: READ ， WRITE 解锁 UNLOCK TABLES FLUSH TABLES tb_name[,…] [WITH READ LOCK] 关闭正在打开的表（清除查询缓存），通常在备份前加全局读锁 SELECT clause [FOR UPDATE | LOCK IN SHARE MODE] 查询时加写或读锁 添加读锁： 效果：可查看但不可修改，本端会提示，其他客户端会卡住并且无提示 MariaDB [hellodb]&gt; lock tables teachers read; 添加写锁： 效果：自己可读，但别人无法读 MariaDB [hellodb]&gt; lock tables students write; 四、操作：破解Mysql数据库口令方法一： 适合干净环境，没有其他数据库： systemctl stop mariadb cd /var/lib/mysql/ rm -rf mysql/* systemctl start mariadb 方法二： vim /etc/my.cnf.d [mysqld] skip-grant-tables #忽略授权表 重启mysql服务 systemctl restart mariadb #mysql MariaDB [mysql] &gt; use mysql MariaDB [mysql] &gt; update user set password=(‘centos’)where user=’root’ and host=’localhost’ 最后再将忽略授权表那行删掉 重启mysql服务 systemctl restart mariadb]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之SQL语法介绍]]></title>
    <url>%2F2018%2F06%2F07%2FMySQL%E4%B9%8BSQL%E8%AF%AD%E6%B3%95%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[一、SQL语言简介：结构化查询语言(Structured Query Language)简称SQL，是一种特殊目的的编程语言，是一种数据库 查询和程序设计语言，用于存取数据以及查询、更新和管理关系数据库系统；同时也是数据库脚本文件 的扩展名 关系型数据库的常见组件数据库：database 表：table 行：row 列：column 索引：index 视图：view 用户：user 权限：privilege 存储过程：procedure，无返回值 存储函数：function，有返回值 触发器：trigger 事件调度器：event scheduler，任务计划 命名规则： 必须以字母开头 可包括数字和三个特殊字符（# _ $） 不要使用MySQL的保留字 同一database(Schema)下的对象不能同名 数据类型：(一)整型 tinyint(m) 1个字节 范围(-128~127) smallint(m) 2个字节 范围(-32768~32767) mediumint(m) 3个字节 范围(-8388608~8388607) int(m) 4个字节 范围(-2147483648~2147483647) bigint(m) 8个字节 范围(+-9.22*10的18次方) 取值范围如果加了unsigned，则最大值翻倍，如tinyint unsigned的取值范围为(0~255) (二)浮点型(float和double)，近似值 float(m,d) 单精度浮点型 8位精度(4字节) m总个数，d小数位 double(m,d) 双精度浮点型16位精度(8字节) m总个数，d小数位 设一个字段定义为float(6,3)，如果插入一个数123.45678,实际数据库里存 的是123.457，但总个数还以实际为准，即6位 (三)字符串(char,varchar,_text) char(n) 固定长度，最多255个字符 varchar(n)可变长度，最多65535个字符 inytext 可变长度，最多255个字符 ext 可变长度，最多65535个字符 mediumtext 可变长度，最多2的24次方-1个字符 ongtext 可变长度，最多2的32次方-1个字符 BINARY(M) 固定长度，可存二进制或字符，长度为0-M字节 VARBINARY(M) 可变长度，可存二进制或字符，允许长度为0-M字节 内建类型：ENUM枚举, SET集合 char和varchar： 1.char(n) 若存入字符数小于n，则以空格补于其后，查询之时再将空格去掉。 所以char类型存储的字符串末尾不能有空格，varchar不限于此。 2.char(n) 固定长度，char(4)不管是存入几个字符，都将占用4个字节，varchar 是存入的实际字符数+1个字节（n&lt; n&gt;255)，所以varchar(4),存入3个字符将 占用4个字节。 3.char类型的字符串检索速度要比varchar类型的快 varchar和text： 1.varchar可指定n，text不能指定，内部存储varchar是存入的实际字符数+1个 字节（n&lt; n&gt;255)，text是实际字符数+2个字节。 2.text类型不能有默认值 3.varchar可直接创建索引，text创建索引要指定前多少个字符。varchar查询速 度快于text (四)二进制数据：BLOB BLOB和text存储方式不同，TEXT以文本方式存储，英文存储区分大小写， 而Blob是以二进制方式存储，不分大小写 BLOB存储的数据只能整体读出 TEXT可以指定字符集，BLOB不用指定字符集 (五)日期时间类型 date 日期 ‘2008-12-2’ time 时间 ’12:25:36′ datetime 日期时间 ‘2008-12-2 22:06:44’ timestamp 自动存储记录修改时间 YEAR(2), YEAR(4)：年份 timestamp字段里的时间数据会随其他字段修改的时候自动刷新，这个数据类 型的字段可以存放这条记录最后被修改的时间 修饰符：NULL 数据列可包含NULL值 NOT NULL 数据列不允许包含NULL值 DEFAULT 默认值 PRIMARY KEY 主键 UNIQUE KEY 唯一键 CHARACTER SET name 指定一个字符集 AUTO_INCREMENT 自动递增，适用于整数类型 UNSIGNED 无符号 SQL语句分类：DDL：Data Defination Language 代表操作： CREATE 可用来创建数据库，表 DROP 可用来删除数据库，表 ALTER 可用来修改表的属性，字段的结构 DML：Data Manipulation Language 代表操作： INSERT 可用来添加表中的行 DELETE 可用来删除表中的行 UPDATE 可用来修改标准行的信息 DCL：Data Control Language 代表操作： GRANT REVOKE DQL：Data Query Language 代表操作： SELECT 二、数据定义语言(DDL)：CREATE, DROP, ALTER数据定义语言(DDL)：其语句包括动词CREATE和DROP。在数据库中创建新表或删除表（CREAT TABLE 或 DROP TABLE）；为表加入索引等。DDL包括许多与人数据库目录中获得数据 有关的保留字。它也是动作查询的一部分。 新建数据库：CREATE DATABASE|SCHEMA [IF NOT EXISTS] DB_NAME; CHARACTER SET ‘character set name’ COLLATE ‘collate name’ 删除数据库：DROP DATABASE|SCHEMA [IF EXISTS]’DB_NAME’ 新建表：CREATE TABLE (1) 直接创建 (2) 通过查询现存表创建；新表会被直接插入查询而来的数据 CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name [(create_definition,…)] [table_options] [partition_options] select_statement (3) 通过复制现存的表的表结构创建，但不复制数据 CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name { LIKE oldtblname | (LIKE oldtblname) } 示例：直接创建表 MariaDB [(db1)]&gt; create table emp ​ -&gt; ( id int unsigned primary key auto_increment, ​ -&gt; name varchar(30) not null , ​ -&gt; sex char(1) default ‘m’ , ​ -&gt; address varchar(100) ) engine=innodb charset=utf8; 示例：通过查询现存表创建 MariaDB [db1]&gt; create table user select user,host,password from mysql.user; MariaDB [db1]&gt; desc user; +———-+———-+——+—–+———+——-+ | Field | Type | Null | Key | Default | Extra | +———-+———-+——+—–+———+——-+ | user | char(16) | NO | | | | | host | char(60) | NO | | | | | password | char(41) | NO | | | | +———-+———-+——+—–+———+——-+ MariaDB [db1]&gt; select * from user; +——+—————+———-+ | user | host | password | +——+—————+———-+ | root | localhost | | | root | centos7.wangx | | | root | 127.0.0.1 | | | root | ::1 | | | | localhost | | | | centos7.wangx | | +——+—————+———-+ 示例：通过复制现存的表的表结构创建，但不复制数据 MariaDB [db1]&gt; create table user3 like mysql.user; 示例：创建表包含复合主键 MariaDB [db1]&gt; create table t1 ( name char(30),city char(30),sex char(1) primary key(name,city) ); 表操作：查看所有的引擎：SHOW ENGINES 查看表：SHOW TABLES [FROM db_name] 查看表结构：DESC [db_name.]tb_name 删除表：DROP TABLE [IF EXISTS] tb_name 查看表创建命令：SHOW CREATE TABLE tbl_name 查看表状态：SHOW TABLE STATUS LIKE ‘tbl_name’ 查看库中所有表状态：SHOW TABLE STATUS FROM db_name 示例：直接创建TABLE MariaDB [db1]&gt; CREATE TABLE students ( id tinyint unsigned not null primary key, name char(10) not null,phone char(11) not null ,sex char(1) ); MariaDB [db1]&gt; show tables; +—————+ | Tables_in_db1 | +—————+ | students | +—————+ 示例：查看表状态信息 MariaDB [db1]&gt; show table status like ‘students’\G *** 1. row *** Name: students Engine: InnoDB Version: 10 Row_format: Compact Rows: 0 Avg_row_length: 0 Data_length: 16384 Max_data_length: 0 Index_length: 0 Data_free: 10485760 Auto_increment: NULL Create_time: 2018-06-06 18:19:05 Update_time: NULL Check_time: NULL Collation: latin1_swedish_ci Checksum: NULL Create_options: Comment: 1 row in set (0.00 sec) 示例：查看数据库状态信息 MariaDB [db1]&gt; show table status from db1\G *** 1. row *** Name: students Engine: InnoDB Version: 10 Row_format: Compact Rows: 0 Avg_row_length: 0 Data_length: 16384 Max_data_length: 0 Index_length: 0 Data_free: 10485760 Auto_increment: NULL Create_time: 2018-06-06 18:19:05 Update_time: NULL Check_time: NULL Collation: latin1_swedish_ci Checksum: NULL Create_options: Comment: 1 row in set (0.00 sec) 表操作DROP TABLE [IF EXISTS] ‘tbl_name’; ALTER TABLE ‘tbl_name’ 字段： 添加字段：add ADD col1 data_type [FIRST|AFTER col_name] 删除字段：drop 修改字段： alter（默认值）, change（字段名）, modify（字段属性） 索引: 添加索引：add index 删除索引: drop index 表选项 修改: 查看表上的索引：SHOW INDEXES FROM [db_name.]tbl_name; 查看帮助：Help ALTER TABLE 示例： 修改表名 ALTER TABLE students RENAME s1; 添加表s1中phone列到name列后 ALTER TABLE s1 ADD phone varchar(11) AFTER name; 修改表s1中的phone字段属性为int ALTER TABLE s1 MODIFY phone int; 修改表s1中的phone字段名称为mobile ALTER TABLE s1 CHANGE COLUMN phone mobile char(11); 删掉表s1中的一个字段mobile ALTER TABLE s1 DROP COLUMN mobile; 在students表中新增加一列gender，只允许填入m，f ALTER TABLE students ADD gender ENUM(‘m’,’f’) 修改students表中的id字符变为sid字段 ALETR TABLE students CHANGE id sid int UNSIGNED NOT NULL PRIMARY KEY; 将students表中name字段设为唯一键 ALTER TABLE students ADD UNIQUE KEY(name); 将students表中age字段设为索引 ALTER TABLE students ADD INDEX(age); DESC students; SHOW INDEXES FROM students; 删掉students表中的age字段 ALTER TABLE students DROP age; 三、数据操作语言(DML)：INSERT,UPDATE,DELETE数据操作语言(DML)：其语句包括动词INSERT，UPDATE和DELETE。它们分别用于添加，修 改和删除表中的行。也称为动作查询语言。 INSERT功能：可用来添加表中的行 示例：添加表中的行第一种语法 MariaDB [db1]&gt; insert students values(1,’bai’,’10086′,’m’); MariaDB [db1]&gt; select * from students; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 1 | bai | 10086 | m | +—-+——+——-+——+ 示例：添加表中的行第二种语法 MariaDB [db1]&gt; insert students(name,id) value (‘wangx’,70); MariaDB [db1]&gt; select * from students; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 1 | bai | 10086 | m | | 70 | wangx| | NULL | +—-+——+——-+——+ 多行添加 MariaDB [db1]&gt; insert students(id,name,sex) values (2,’liu’,’m’),(3,’lin’,’f’); MariaDB [db1]&gt; select * from students; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 1 | bai | 10086 | m | | 2 | liu | | m | | 3 | lin | | f | | 70 | wang | | NULL | +—-+——+——-+——+ 示例：添加表中的行第三种语法 MariaDB [db1]&gt; insert students set id=4,name=’zhao’ ; MariaDB [db1]&gt; select * from students; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 1 | bai | 10086 | m | | 2 | liu | | m | | 3 | lin | | f | | 4 | zhao | | NULL | | 70 | wang | | NULL | +—-+——+——-+——+ UPDATE功能：可用来修改标准行的信息 UPDATE [LOW_PRIORITY] [IGNORE] table_reference SET col_name1={expr1|DEFAULT} [, col_name2={expr2|DEFAULT}] … [WHERE where_condition] [ORDER BY …] [LIMIT row_count] 注意：一定要有限制条件，否则将修改所有行的指定字段 限制条件： WHERE LIMIT Mysql 选项：–safe-updates| –i-am-a-dummy|-U MariaDB [db1]&gt; select * from students; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 1 | bai | 10086 | m | | 2 | liu | | m | | 3 | lin | | f | | 4 | zhao | | NULL | | 70 | wang | | NULL | +—-+——+——-+——+ 示例：修改表中行内容 MariaDB [db1]&gt; update students set name=’admin’,sex=’f’ where id=1; MariaDB [db1]&gt; select * from students; +—-+——-+——-+——+ | id | name | phone | sex | +—-+——-+——-+——+ | 1 | admin | 10086 | f | | 2 | liu | | m | | 3 | lin | | f | | 4 | zhao | | NULL | | 70 | wang | | NULL | +—-+——-+——-+——+ DELETE功能：可用来删除表中的行 生产环境一般用伪删除代替DELETE： DELETE [LOW_PRIORITY] [QUICK] [IGNORE] FROM tbl_name [WHERE where_condition] [ORDER BY …] [LIMIT row_count] 可先排序再指定删除的行数 注意：一定要有限制条件，否则将清空表中的所有数据 限制条件： WHERE LIMIT TRUNCATE TABLE tbl_name; 清空表，慎用！ MariaDB [db1]&gt; delete from students where id=1; MariaDB [db1]&gt; select * from students; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 2 | liu | | m | | 3 | lin | | f | | 4 | zhao | | NULL | | 70 | wang | | NULL | +—-+——+——-+——+ 为避免操作时忘加where可使用安全更新模式 mysql –safe-updates|-U 当执行修该操作未指定WHERE时就会进行报错提醒 MariaDB [db1]&gt; update user set user=’admin’ -&gt; ; ERROR 1175 (HY000): You are using safe update mode and you tried to update a table without a WHERE that uses a KEY column 方法一：添加别名 alias mysql=mysql -U 方法二：修改配置文件 vim /etc/my.cnf.d/mysql-clients.cnf [mysql] safe-updates 四、数据查询语言(DQL)：SELECT,LIKE,GROUP,ODER BY数据查询语言(DQL)：也称为“数据检索语句”，用以从表中获得数据，确定数据怎样在 应用程序给出。保留字SELECT是DQL（也是所有SQL）用得最多的动词，其他DQL常用的保 留字有WHERE，ORDER BY，GROUP BY和HAVING。这些DQL保留字常与其他类型的SQL语句一 起使用。 select语句执行顺序： SELECT[ALL | DISTINCT | DISTINCTROW ] [SQL_CACHE | SQL_NO_CACHE] select_expr [, select_expr …] [FROM table_references [WHERE where_condition] [GROUP BY {col_name | expr | position} [ASC | DESC], … [WITH ROLLUP]] [HAVING where_condition] [ORDER BY {col_name | expr | position} [ASC | DESC], …] [LIMIT {[offset,] row_count | row_count OFFSET offset}] [FOR UPDATE | LOCK IN SHARE MODE] 注意：select语句用法不同会造成性能消耗不同，性能差的写法甚至可能造成宕机 LIKE:%: 任意长度的任意字符 _：任意单个字符 RLIKE：正则表达式，索引失效，不建议使用 REGEXP：匹配字符串可用正则表达式书写模式，同上 逻辑操作符： ​ NOT ​ AND ​ OR ​ XOR 示例：单表操作 MariaDB [db1]&gt; select * from user; +——+—————+———-+ | user | host | password | +——+—————+———-+ | root | localhost | | | root | centos7.wangx | | | root | 127.0.0.1 | | | root | ::1 | | | | localhost | | | | centos7.wangx | | +——+—————+———-+ select也是一种语句： MariaDB [db1]&gt; select ‘hello world’; +————-+ | hello world | +————-+ | hello world | +————-+ 也可以进行运算 MariaDB [db1]&gt; select ‘1+2=’,1+2; +——+—–+ | 1+2= | 1+2 | +——+—–+ | 1+2= | 3 | +——+—–+ 有类似与sed的特性： MariaDB [db1]&gt; select ‘1+2=’,1+2 from user; +——+—–+ | 1+2= | 1+2 | +——+—–+ | 1+2= | 3 | | 1+2= | 3 | | 1+2= | 3 | | 1+2= | 3 | | 1+2= | 3 | | 1+2= | 3 | +——+—–+ MariaDB [db1]&gt; select user,password from user; +——+———-+ | user | password | +——+———-+ | root | | | root | | | root | | | root | | | | | | | | +——+———-+ 可添加自定义字符： MariaDB [db1]&gt; select ‘number’,user,password from user; +——–+——+———-+ | number | user | password | +——–+——+———-+ | number | root | | | number | root | | | number | root | | | number | root | | | number | | | | number | | | +——–+——+———-+ 限定条件select MariaDB [db1]&gt; select ‘number’,user,password from user where user=’root’; +——–+——+———-+ | number | user | password | +——–+——+———-+ | number | root | | | number | root | | | number | root | | | number | root | | +——–+——+———-+ MariaDB [db1]&gt; select * from students; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 2 | liu | | m | | 3 | lin | | f | | 4 | zhao | | NULL | | 70 | wang | | NULL | +—-+——+——-+——+ 判断条件，是否为空 搜索性别为空的学生信息 MariaDB [db1]&gt; select * from students where sex is null; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 4 | zhao | | NULL | | 70 | wang | | NULL | +—-+——+——-+——+ 搜索性别不为空的学生信息 MariaDB [db1]&gt; select * from students where sex is not null; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 2 | liu | | m | | 3 | lin | | f | +—-+——+——-+——+ 搜索id大于2小于5的学生信息 MariaDB [db1]&gt; select * from students where id &gt;=2 and id&lt;=5; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 2 | liu | | m | | 3 | lin | | f | | 4 | zhao | | NULL | +—-+——+——-+——+ 也可用between写法表示范围 MariaDB [db1]&gt; select * from students where id between 2 and 5; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 2 | liu | | m | | 3 | lin | | f | | 4 | zhao | | NULL | +—-+——+——-+——+ 字符范围搜索 MariaDB [db1]&gt; select * from students where sex in (‘f’,’m’); +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 2 | liu | | m | | 3 | lin | | f | +—-+——+——-+——+ 逻辑或关系搜索 MariaDB [db1]&gt; select * from students where sex in (‘f’,’m’) or sex is null; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 0 | 70 | | NULL | | 2 | liu | | m | | 3 | lin | | f | | 4 | zhao | | NULL | | 70 | wang | | NULL | +—-+——+——-+——+ 可对字段定义别名（as可省略） MariaDB [db1]&gt; select id as 编号,name 姓名 from students where sex in (‘f’,’m’) or sex is null; +——–+——–+ | 编号 | 姓名 | +——–+——–+ | 0 | 70 | | 2 | liu | | 3 | lin | | 4 | zhao | | 70 | wang | +——–+——–+ LIKE功能：支持模糊搜索 搜索名字以w开头学生信息 MariaDB [db1]&gt; select * from students where name like ‘w%’; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 70 | wang | | NULL | +—-+——+——-+——+ 搜索名字包含i的学生信息 MariaDB [db1]&gt; select * from students where name like ‘%i%’; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 2 | liu | | m | | 3 | lin | | f | +—-+——+——-+——+ “_”可用来表示单个字符，搜索名字为三个字符的学生信息 MariaDB [db1]&gt; select * from students where name like ‘___’; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 2 | liu | | m | | 3 | lin | | f | +—-+——+——-+——+ RLIKE功能：支持正则表达式，不建议使用，将导致索引生效！！！！！ 搜索名字以l开头的学员信息 MariaDB [db1]&gt; select * from students where name rlike ‘^l’; +—-+——+——-+——+ | id | name | phone | sex | +—-+——+——-+——+ | 2 | liu | | m | | 3 | lin | | f | +—-+——+——-+——+ GROUP功能：根据指定的条件把查询结果进行“分组”以用于做“聚合”运算 avg(), max(), min(), count(), sum() HAVING: 对分组聚合运算后的结果指定过滤条件 ORDER BY: 根据指定的字段对查询结果进行排序 升序：ASC 降序：DESC LIMIT [[offset,]row_count]：对查询的结果进行输出行数数量限制 对查询结果中的数据请求施加“锁” FOR UPDATE: 写锁，独占或排它锁，只有一个读和写 LOCK IN SHARE MODE: 读锁，共享锁，同时多个读 以下表为示例 MariaDB [db1]&gt; select * from students; +—-+——-+——-+——-+——+ | id | name | phone | score | sex | +—-+——-+——-+——-+——+ | 2 | liu | | 88 | m | | 3 | lin | | 84 | f | | 6 | zhang | 10010 | 76 | m | | 70 | wang | | 93 | f | +—-+——-+——-+——-+——+ 按性别分组统计最好成绩 MariaDB [db1]&gt; select sex,max(score) as 最好成绩 from students group by sex; +——+————–+ | sex | 最好成绩 | +——+————–+ | f | 93 | | m | 88 | +——+————–+ 按性别分组统计平均成绩 MariaDB [db1]&gt; select sex,avg(score) from students group by sex; +——+————+ | sex | avg(score) | +——+————+ | f | 88.5000 | | m | 82.0000 | +——+————+ 多行分组： MariaDB [db1]&gt; select * from students; +—-+——-+——-+——-+——+——-+ | id | name | phone | score | sex | class | +—-+——-+——-+——-+——+——-+ | 2 | liu | | 88 | m | 1 | | 3 | lin | | 84 | f | 1 | | 4 | abc | 11000 | 86 | f | 1 | | 6 | zhang | 10010 | 76 | m | 2 | | 70 | wang | | 93 | f | 2 | +—-+——-+——-+——-+——+——-+ 统计按班级，性别分组后的各组平均成绩 MariaDB [db1]&gt; select class,sex,avg(score) from students group by class,sex; +——-+——+————+ | class | sex | avg(score) | +——-+——+————+ | 1 | f | 85.0000 | | 1 | m | 88.0000 | | 2 | f | 93.0000 | | 2 | m | 76.0000 | +——-+——+————+ count()统计数量： MariaDB [db1]&gt; select class,sex,count(*) from students group by class,sex; +——-+——+———-+ | class | sex | count(*) | +——-+——+———-+ | 1 | f | 2 | | 1 | m | 1 | | 2 | f | 1 | | 2 | m | 1 | +——-+——+———-+ 统计数量时建议统计主键，可提高数率 MariaDB [db1]&gt; select class,sex,count(id) from students group by class,sex; +——-+——+———–+ | class | sex | count(id) | +——-+——+———–+ | 1 | f | 2 | | 1 | m | 1 | | 2 | f | 1 | | 2 | m | 1 | +——-+——+———–+ 统计学生人数 MariaDB [db1]&gt; select count(id) from students; +———–+ | count(id) | +———–+ | 5 | +———–+ 分组后过滤： 统计按班级，性别分组后的各组平均成绩，只显示平均成绩打印80的组统计信息 MariaDB [db1]&gt; select class,sex,avg(score) from students group by class,sex having avg(score) &gt;80; +——-+——+————+ | class | sex | avg(score) | +——-+——+————+ | 1 | f | 85.0000 | | 1 | m | 88.0000 | | 2 | f | 93.0000 | +——-+——+————+ 分组前过滤 只显示1班分组后的统计信息 MariaDB [db1]&gt; select class,sex,avg(score) from students where class=1 group by class,sex having avg(score) &gt;80; +——-+——+————+ | class | sex | avg(score) | +——-+——+————+ | 1 | f | 85.0000 | | 1 | m | 88.0000 | +——-+——+————+ ORDER BY正序排列： MariaDB [db1]&gt; select * from students order by score; +—-+——-+——-+——-+——+——-+ | id | name | phone | score | sex | class | +—-+——-+——-+——-+——+——-+ | 6 | zhang | 10010 | 76 | m | 2 | | 3 | lin | | 84 | f | 1 | | 4 | abc | 11000 | 86 | f | 1 | | 2 | liu | | 88 | m | 1 | | 70 | wang | | 93 | f | 2 | +—-+——-+——-+——-+——+——-+ 倒序排列： MariaDB [db1]&gt; select * from students order by score desc; +—-+——-+——-+——-+——+——-+ | id | name | phone | score | sex | class | +—-+——-+——-+——-+——+——-+ | 70 | wang | | 93 | f | 2 | | 2 | liu | | 88 | m | 1 | | 4 | abc | 11000 | 86 | f | 1 | | 3 | lin | | 84 | f | 1 | | 6 | zhang | 10010 | 76 | m | 2 | +—-+——-+——-+——-+——+——-+ 小技巧：利用-调整空字符NULL的位置 MariaDB [db1]&gt; select * from students order by score desc; +—-+——-+——-+——-+——+——-+ | id | name | phone | score | sex | class | +—-+——-+——-+——-+——+——-+ | 70 | wang | | 93 | f | 2 | | 2 | liu | | 88 | m | 1 | | 4 | abc | 11000 | 86 | f | 1 | | 3 | lin | | 84 | f | 1 | | 6 | zhang | 10010 | 76 | m | 2 | | 7 | zz | 10086 | 69 | m | 2 | | 8 | zhao | 10000 | NULL | m | 1 | +—-+——-+——-+——-+——+——-+ MariaDB [db1]&gt; select * from students order by -score desc; +—-+——-+——-+——-+——+——-+ | id | name | phone | score | sex | class | +—-+——-+——-+——-+——+——-+ | 7 | zz | 10086 | 69 | m | 2 | | 6 | zhang | 10010 | 76 | m | 2 | | 3 | lin | | 84 | f | 1 | | 4 | abc | 11000 | 86 | f | 1 | | 2 | liu | | 88 | m | 1 | | 70 | wang | | 93 | f | 2 | | 8 | zhao | 10000 | NULL | m | 1 | +—-+——-+——-+——-+——+——-+ LIMITMariaDB [db1]&gt; select * from students order by score limit 3; +—-+——-+——-+——-+——+——-+ | id | name | phone | score | sex | class | +—-+——-+——-+——-+——+——-+ | 8 | zhao | 10000 | NULL | m | 1 | | 7 | zz | 10086 | 69 | m | 2 | | 6 | zhang | 10010 | 76 | m | 2 | +—-+——-+——-+——-+——+——-+ 五、多表查询SQJ JOIN多表查询中主要的 SQL JOIN 类型：INNER JOIN：如果表中有至少一个匹配，则返回行 LEFT JOIN：即使右表中没有匹配，也从左表返回所有的行 RIGHT JOIN：即使左表中没有匹配，也从右表返回所有的行 FULL JOIN：只要其中一个表中存在匹配，则返回行 CROSS JOIN：用于生成两张表的笛卡尔集 本次示例，我们将使用 HELLODB 样本数据库。 下面是选自 “teachers” 表的数据： MariaDB [hellodb]&gt; select * from teachers; +—–+—————+—–+——–+ | TID | Name | Age | Gender | +—–+—————+—–+——–+ | 1 | Song Jiang | 45 | M | | 2 | Zhang Sanfeng | 94 | M | | 3 | Miejue Shitai | 77 | F | | 4 | Lin Chaoying | 93 | F | +—–+—————+—–+——–+ 以下是 “students” 表的数据 MariaDB [hellodb]&gt; select * from students; +——-+—————+—–+——–+———+———–+ | StuID | Name | Age | Gender | ClassID | TeacherID | +——-+—————+—–+——–+———+———–+ | 1 | Shi Zhongyu | 22 | M | 2 | 3 | | 2 | Shi Potian | 22 | M | 1 | 7 | | 3 | Xie Yanke | 53 | M | 2 | 16 | | 4 | Ding Dian | 32 | M | 4 | 4 | | 5 | Yu Yutong | 26 | M | 3 | 1 | | 6 | Shi Qing | 46 | M | 5 | NULL | | 7 | Xi Ren | 19 | F | 3 | NULL | | 8 | Lin Daiyu | 17 | F | 7 | NULL | | 9 | Ren Yingying | 20 | F | 6 | NULL | | 10 | Yue Lingshan | 19 | F | 3 | NULL | | 11 | Yuan Chengzhi | 23 | M | 6 | NULL | | 12 | Wen Qingqing | 19 | F | 1 | NULL | | 13 | Tian Boguang | 33 | M | 2 | NULL | | 14 | Lu Wushuang | 17 | F | 3 | NULL | | 15 | Duan Yu | 19 | M | 4 | NULL | | 16 | Xu Zhu | 21 | M | 1 | NULL | | 17 | Lin Chong | 25 | M | 4 | NULL | | 18 | Hua Rong | 23 | M | 7 | NULL | | 19 | Xue Baochai | 18 | F | 6 | NULL | | 20 | Diao Chan | 19 | F | 7 | NULL | | 21 | Huang Yueying | 22 | F | 6 | NULL | | 22 | Xiao Qiao | 20 | F | 1 | NULL | | 23 | Ma Chao | 23 | M | 4 | NULL | | 24 | Xu Xian | 27 | M | NULL | NULL | | 25 | Sun Dasheng | 100 | M | NULL | NULL | +——-+—————+—–+——–+———+———–+ 内连接：INNER JOIN效果：如果表中有至少一个匹配，则返回行 写法一：旧写法 MariaDB [hellodb]&gt; select s.name,t.name from students as s,teachers as t where s.teacherid=t.tid; +————-+—————+ | name | name | +————-+—————+ | Yu Yutong | Song Jiang | | Shi Zhongyu | Miejue Shitai | | Ding Dian | Lin Chaoying | +————-+—————+ MariaDB [hellodb]&gt; select s.name as 学生姓名,t.name as 讲师姓名 from students as s,teachers as t where s.teacherid=t.tid; +————–+—————+ | 学生姓名 | 讲师姓名 | +————–+—————+ | Yu Yutong | Song Jiang | | Shi Zhongyu | Miejue Shitai | | Ding Dian | Lin Chaoying | +————–+—————+ 写法二：SQL标准写法，适合其他类型数据库 MariaDB [hellodb]&gt; select s.name as 学生姓名,t.name as 讲师姓名 from students as s inner join teachers as t on s.teacherid=t.tid; +————–+—————+ | 学生姓名 | 讲师姓名 | +————–+—————+ | Yu Yutong | Song Jiang | | Shi Zhongyu | Miejue Shitai | | Ding Dian | Lin Chaoying | +————–+—————+ 交叉连接：CROSS JOIN效果：用于生成两张表的笛卡尔集，笛卡尔集的列数为每个表的列数之 和，笛卡尔集的行数为每个表的行数相乘。我们经常做的多表查询就是在笛卡 尔集中通过筛选条件得出的数据，所以笛卡尔集是多表查询的基础。 MariaDB [hellodb]&gt; select * from students cross join teachers; +——-+—————+—–+——–+———+———–+—–+—————+—–+——–+ | StuID | Name | Age | Gender | ClassID | TeacherID | TID | Name | Age | Gender | +——-+—————+—–+——–+———+———–+—–+—————+—–+——–+ | 1 | Shi Zhongyu | 22 | M | 2 | 3 | 1 | Song Jiang | 45 | M | | 1 | Shi Zhongyu | 22 | M | 2 | 3 | 2 | Zhang Sanfeng | 94 | M | | 1 | Shi Zhongyu | 22 | M | 2 | 3 | 3 | Miejue Shitai | 77 | F | | 1 | Shi Zhongyu | 22 | M | 2 | 3 | 4 | Lin Chaoying | 93 | F | | 2 | Shi Potian | 22 | M | 1 | 7 | 1 | Song Jiang | 45 | M | | 2 | Shi Potian | 22 | M | 1 | 7 | 2 | Zhang Sanfeng | 94 | M | | 2 | Shi Potian | 22 | M | 1 | 7 | 3 | Miejue Shitai | 77 | F | | 2 | Shi Potian | 22 | M | 1 | 7 | 4 | Lin Chaoying | 93 | F | | 3 | Xie Yanke | 53 | M | 2 | 16 | 1 | Song Jiang | 45 | M | | 3 | Xie Yanke | 53 | M | 2 | 16 | 2 | Zhang Sanfeng | 94 | M | | 3 | Xie Yanke | 53 | M | 2 | 16 | 3 | Miejue Shitai | 77 | F | | 3 | Xie Yanke | 53 | M | 2 | 16 | 4 | Lin Chaoying | 93 | F | | 4 | Ding Dian | 32 | M | 4 | 4 | 1 | Song Jiang | 45 | M | | 4 | Ding Dian | 32 | M | 4 | 4 | 2 | Zhang Sanfeng | 94 | M | | 4 | Ding Dian | 32 | M | 4 | 4 | 3 | Miejue Shitai | 77 | F | | 4 | Ding Dian | 32 | M | 4 | 4 | 4 | Lin Chaoying | 93 | F | | 5 | Yu Yutong | 26 | M | 3 | 1 | 1 | Song Jiang | 45 | M | ……. 左外连接：LEFT JOIN功能：即使右表中没有匹配，也从左表返回所有的行 注释：在某些数据库中，LEFT JOIN 称为 LEFT OUTER JOIN MariaDB [hellodb]&gt; select s.name as studentname,t.name as teachername from students as s left outer join teachers as t on s.teacherid=t.tid; +—————+—————+ | studentname | teachername | +—————+—————+ | Shi Zhongyu | Miejue Shitai | | Shi Potian | NULL | | Xie Yanke | NULL | | Ding Dian | Lin Chaoying | | Yu Yutong | Song Jiang | | Shi Qing | NULL | | Xi Ren | NULL | | Lin Daiyu | NULL | | Ren Yingying | NULL | | Yue Lingshan | NULL | | Yuan Chengzhi | NULL | | Wen Qingqing | NULL | | Tian Boguang | NULL | | Lu Wushuang | NULL | | Duan Yu | NULL | | Xu Zhu | NULL | | Lin Chong | NULL | | Hua Rong | NULL | | Xue Baochai | NULL | | Diao Chan | NULL | | Huang Yueying | NULL | | Xiao Qiao | NULL | | Ma Chao | NULL | | Xu Xian | NULL | | Sun Dasheng | NULL | +—————+—————+ 右外连接：RIGHT JOIN效果：即使左表中没有匹配，也从右表返回所有的行 注释：在某些数据库中，LEFT JOIN 称为 RIGHT OUTER JOIN MariaDB [hellodb]&gt; select s.name as studentname,t.name as teachername from students as s right outer join teachers as t on s.teacherid=t.tid; +————-+—————+ | studentname | teachername | +————-+—————+ | Shi Zhongyu | Miejue Shitai | | Ding Dian | Lin Chaoying | | Yu Yutong | Song Jiang | | NULL | Zhang Sanfeng | +————-+—————+ 联合查询：union效果：两张表上下连起来，类似cat a b的效果 MariaDB [hellodb]&gt; select name from students union select name from teachers; +—————+ | name | +—————+ | Shi Zhongyu | | Shi Potian | | Xie Yanke | | Ding Dian | | Yu Yutong | | Shi Qing | | Xi Ren | | Lin Daiyu | | Ren Yingying | | Yue Lingshan | | Yuan Chengzhi | | Wen Qingqing | | Tian Boguang | | Lu Wushuang | | Duan Yu | | Xu Zhu | | Lin Chong | | Hua Rong | | Xue Baochai | | Diao Chan | | Huang Yueying | | Xiao Qiao | | Ma Chao | | Xu Xian | | Sun Dasheng | | Song Jiang | | Zhang Sanfeng | | Miejue Shitai | | Lin Chaoying | +—————+ 29 rows in set (0.00 sec) 自连接功能：将一张表想象成两张表，自己连接自己 MariaDB [hellodb]&gt; select s1.name as emp,s2.name as leader from students as s1 inner join students as s2 on s1.teacherid=s2.stuid; +————-+————-+ | emp | leader | +————-+————-+ | Shi Zhongyu | Xie Yanke | | Shi Potian | Xi Ren | | Xie Yanke | Xu Zhu | | Ding Dian | Ding Dian | | Yu Yutong | Shi Zhongyu | +————-+————-+ 左自连接MariaDB [hellodb]&gt; select s1.name as emp,s2.name as leader from students as s1 left outer join students as s2 on s1.teacherid=s2.stuid; +—————+————-+ | emp | leader | +—————+————-+ | Shi Zhongyu | Xie Yanke | | Shi Potian | Xi Ren | | Xie Yanke | Xu Zhu | | Ding Dian | Ding Dian | | Yu Yutong | Shi Zhongyu | | Shi Qing | NULL | | Xi Ren | NULL | | Lin Daiyu | NULL | | Ren Yingying | NULL | | Yue Lingshan | NULL | | Yuan Chengzhi | NULL | | Wen Qingqing | NULL | | Tian Boguang | NULL | | Lu Wushuang | NULL | | Duan Yu | NULL | | Xu Zhu | NULL | | Lin Chong | NULL | | Hua Rong | NULL | | Xue Baochai | NULL | | Diao Chan | NULL | | Huang Yueying | NULL | | Xiao Qiao | NULL | | Ma Chao | NULL | | Xu Xian | NULL | | Sun Dasheng | NULL | +—————+————-+ 右自连接 MariaDB [hellodb]&gt; select s1.name as emp,s2.name as leader from students as s1 right join students as s2 on s1.stuid=s2.teacherid; +————-+—————+ | emp | leader | +————-+—————+ | Xie Yanke | Shi Zhongyu | | Xi Ren | Shi Potian | | Xu Zhu | Xie Yanke | | Ding Dian | Ding Dian | | Shi Zhongyu | Yu Yutong | | NULL | Shi Qing | | NULL | Xi Ren | | NULL | Lin Daiyu | | NULL | Ren Yingying | | NULL | Yue Lingshan | | NULL | Yuan Chengzhi | | NULL | Wen Qingqing | | NULL | Tian Boguang | | NULL | Lu Wushuang | | NULL | Duan Yu | | NULL | Xu Zhu | | NULL | Lin Chong | | NULL | Hua Rong | | NULL | Xue Baochai | | NULL | Diao Chan | | NULL | Huang Yueying | | NULL | Xiao Qiao | | NULL | Ma Chao | | NULL | Xu Xian | | NULL | Sun Dasheng | +————-+—————+ 子查询下表是内连接查询姓名和分数信息 MariaDB [hellodb]&gt; select students.name,scores.score from students inner join scores on students.stuid=scores.id; +—————+——-+ | name | score | +—————+——-+ | Shi Zhongyu | 77 | | Shi Potian | 93 | | Xie Yanke | 47 | | Ding Dian | 97 | | Yu Yutong | 88 | | Shi Qing | 75 | | Xi Ren | 71 | | Lin Daiyu | 89 | | Ren Yingying | 39 | | Yue Lingshan | 63 | | Yuan Chengzhi | 96 | | Wen Qingqing | 86 | | Tian Boguang | 83 | | Lu Wushuang | 57 | | Duan Yu | 93 | +—————+——-+ 取大于平均成绩的同学和成绩 MariaDB [hellodb]&gt; select students.name,scores.score from students inner join scores on students.stuid=scores.id and score &gt; (select avg(score) from scores); +—————+——-+ | name | score | +—————+——-+ | Shi Zhongyu | 77 | | Shi Potian | 93 | | Ding Dian | 97 | | Yu Yutong | 88 | | Lin Daiyu | 89 | | Yuan Chengzhi | 96 | | Wen Qingqing | 86 | | Tian Boguang | 83 | | Duan Yu | 93 | +—————+——-+ 六、视图VIEW视图：VIEW,虚表，保存有实表的查询结果 类似于shell中起个别名 视图不存数据，修改视图实际是修改了背后的表 物化视图：视图在磁盘上也占空间 示例:MariaDB [hellodb]&gt; create view view_students as select stuid,name from students; MariaDB [hellodb]&gt; select * from view_students; +——-+—————+ | stuid | name | +——-+—————+ | 1 | Shi Zhongyu | | 2 | Shi Potian | | 3 | Xie Yanke | | 4 | Ding Dian | | 5 | Yu Yutong | | 6 | Shi Qing | | 7 | Xi Ren | | 8 | Lin Daiyu | | 9 | Ren Yingying | | 10 | Yue Lingshan | | 11 | Yuan Chengzhi | | 12 | Wen Qingqing | | 13 | Tian Boguang | | 14 | Lu Wushuang | | 15 | Duan Yu | | 16 | Xu Zhu | | 17 | Lin Chong | | 18 | Hua Rong | | 19 | Xue Baochai | | 20 | Diao Chan | | 21 | Huang Yueying | | 22 | Xiao Qiao | | 23 | Ma Chao | | 24 | Xu Xian | | 25 | Sun Dasheng | +——-+—————+ 25 rows in set (0.00 sec) 判断一个表是否为视图：Comment状态 MariaDB [hellodb]&gt; show tables; +——————-+ | Tables_in_hellodb | +——————-+ | classes | | coc | | courses | | scores | | students | | teachers | | toc | | view_students | +——————-+ MariaDB [hellodb]&gt; show table status like ‘view_students’\G; *** 1. row *** Name: view_students Engine: NULL Version: NULL Row_format: NULL Rows: NULL Avg_row_length: NULL Data_length: NULL Max_data_length: NULL Index_length: NULL Data_free: NULL Auto_increment: NULL Create_time: NULL Update_time: NULL Check_time: NULL Collation: NULL Checksum: NULL Create_options: NULL ​ Comment: VIEW MariaDB [hellodb]&gt; show table status like ‘students’\G; *** 1. row *** Name: students Engine: InnoDB Version: 10 Row_format: Compact Rows: 25 Avg_row_length: 655 Data_length: 16384 Max_data_length: 0 Index_length: 0 Data_free: 9437184 Auto_increment: 26 Create_time: 2018-06-06 21:25:56 Update_time: NULL Check_time: NULL Collation: utf8_general_ci Checksum: NULL Create_options: Comment: 删除视图 MariaDB [hellodb]&gt; show tables; +——————-+ | Tables_in_hellodb | +——————-+ | classes | | coc | | courses | | scores | | students | | teachers | | toc | | view_goodstudent | | view_students | +——————-+ MariaDB [hellodb]&gt; drop view view_goodstudent;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实验：实现互联网的DNS架构]]></title>
    <url>%2F2018%2F06%2F07%2F%E5%AE%9E%E9%AA%8C%EF%BC%9A%E5%AE%9E%E7%8E%B0%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84DNS%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[实现互联网DNS分布式架构，当客户端访问时，经各级自建DNS解析，最终指向Web1或者Web2服务器httpd服务 实验拓扑图： 前期准备：准备8台虚拟机，操作系统及IP地址分别为 Root DNS Server： CentOS6.9 IP：192.168.30.15 Com DNS Server： CentOS6.9 IP：192.168.30.16 Master DNS Server： CentOS6.9 IP：192.168.30.12 Slave DNS Server： CentOS6.9 IP：192.168.30.17 Web1 Server： CentOS7.4 IP：192.168.30.10 Web2 Server： CentOS6.9 IP：192.168.30.11 ISP DNS Server： CentOS6.9 IP：192.168.30.18 Client： CentOS6.9 IP：192.168.30.19 关闭所有主机的SELinux安全策略，关闭iptables防火墙 实验预期：实现互联网DNS分布式架构，当客户端访问时，经各级DNS解析，最终指向Web1或者Web2服务器httpd服 务。 一、搭建**web**服务器：Web1 Server： echo welcome to magedu.com websrv1 &gt; /var/www/html/index.html systemctl start httpd Web2 Server: echo welcome to magedu.com websrv1 &gt; /var/www/html/index.html service httpd start 切换至Client确认web1，web2能够正常访问 Curl 192.168.30.10 Curl 192.168.30.11 二、搭建主**DNS**服务器： yum install bind vim /etc/named.conf vim /etc/named.rfc1912.zones vim /var/named/wxlinux.com.zone 切换到Client测试主DNS服务器： dig www.wxlinux.com @192.168.30.12 三、搭建从**DNS**服务器vim /etc/named.conf vim /etc/named.rfc1912.zones 启动named服务，确认slave文件生成： service named start 切换到Client测试从DNS服务器： dig www.wxlinux.com @192.168.30.17 四、搭建**com**服务器vim /etc/named.conf vim /etc/named.rfc1912.zones vim com.zone 切换到Client测试从Com服务器： dig www.wxlinux.com @192.168.30.16 五、搭建根**DNS**服务器vim /etc/named.conf vim /etc/named.rfc1912.zones vim root.zone 切换到Client测试根DNS服务器： dig www.wxlinux.com @192.168.30.15 六、搭建**ISP**服务器vim /etc/named.conf vim /var/named/named.ca 七、客户端进行最后测试修改DNS vim /etc/resolv.conf dig www.wxlinux.com 当访问www.wxlinux.com时，将随机指向两台web服务器之一 curl www.wxlinux.com]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库简介及安装实验]]></title>
    <url>%2F2018%2F06%2F05%2FMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%AE%89%E8%A3%85%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一、MySQL数据库简介MySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，目前 属于 Oracle 旗下产品。MySQL 是最流行的关系型数据库管理系统之一， 在 WEB 应用方面，MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件。 MySQL历史1979年：TcX公司 Monty Widenius，Unireg 1996年：发布MySQL1.0，Solaris版本，Linux版本 1999年：MySQL AB公司，瑞典 2003年：MySQL 5.0版本，提供视图、存储过程等功能 2008年：Sun 收购 2009年：Oracle收购sun 2009年：Monty成立MariaDB MySQL和MariaDB官方网址： https://www.mysql.com/ http://mariadb.org/ 官方文档 https://dev.mysql.com/doc/ https://mariadb.com/kb/en/ 版本演变： MySQL：5.1 –&gt; 5.5 –&gt; 5.6 –&gt; 5.7 MariaDB：5.5 –&gt;10.0–&gt; 10.1 –&gt; 10.2 –&gt; 10.3 MariaDB的特性插件式存储引擎：也称为“表类型”，存储管理器有多种实现版本，功能和特 性可能均略有差别；用户可根据需要灵活选择,Mysql5.5.5开始innoDB引擎是 MYSQL默认引擎 MyISAM ==&gt; Aria InnoDB ==&gt; XtraDB 单进程，多线程 诸多扩展和新特性 提供了较多测试组件 开源 下面我们以MariaDB为例，来介绍数据库在Linux系统上的安装 前期准备：操作系统：CentOS 7.4 环境准备：关闭SELinux安全策略，Iptables防火墙，确认当前主机未安装MySQL或MariaDB其他版本 准备对应的安装包： MariaDB 10.2.15官方下载页面：https://downloads.mariadb.org/mariadb/10.2.15/ mariadb-10.2.15.tar MariaDB源代码安装包 mariadb-10.2.15-linux-x86_64.tar MariaDB二进制格式安装包 ![LGPR5{YOL{5%HQZYA8@2 一、实验：使用yum源安装MariaDB 10.2.15去官网查询，复制yum源，yum install 1登录MariaDB官方网站：http://mariadb.org/ MariaDB 10.2.15下载界面：https://downloads.mariadb.org/mariadb/10.2.15/ 2 找到下图所示，点击Repository Configuration Tool. 3 根据自己的系统版本选择相应的选项，就会出现对应的yum源数据库配置 4.yum将数据库配置复制入库文件，并进行安装 安装MariaDB： yum install mariadb 5.添加安全加固 mysql_secure_installation 运行此脚本,交互式 是否设置root口令 y 是否删除匿名用户 y 是否允许root远程登录 n 是否删除test数据库 y privilege tables y 二、实验：通用二进制格式安装MariaDB 10.2.151.去官网下载： mariadb-10.2.15-linux-86_64.tar.gz 2.准备用户账号 useradd -r -d /data/mysqldb -s /sbin/nologin mysql 3.解压包到默认安装路径 安装包默认路径：configure –prefix=/usr/local tar -xvf mariadb-version.tar.gz -C /usr/local/ 4.修改文件权限 cd /usr/local ln -s mariabd-10.2.15-linux-x86_64/ mysql ll mysql/ chown -R root:root mysql/ 5.修改PATH变量，方便mysql目录下的二进制程序执行 ls /usr/local/mysql/bin echo PATH=/usr/local/mysql/bin:$PATH &gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh 6.创建数据库路径 mkdir /data/mysqldb chown mysql.mysql /data/mysqldb chmod 770 /data/mysqldb 7.生成系统自带数据库相关文件 cd /usr/local/mysql 必须在此目录下执行 scripts/mysql_install_db –datadir=/data/mysqldb –user=mysql ll /data/mysqldb/ 确认相关文件是否生成 8.生成mysql配置文件 ll /usr/local/mysql/support-files 可查看数据库自带的各种配置模板 cp /etc/my.cnf /etc/my.cnf.bak 建议备份配置文件 cp my-hug.cnf /etc/my.cnf vim /etc/my.cnf [mysqld] datadir = /data/mysqldb ##添加此行，指定数据库存放路径 9.添加mysql到服务 cp support-files/mysql.server /etc/init.d/mysqld chkcibfug –add mysqld service mysqld start 10.添加安全加固 mysql_secure_installation 三、实验：编译安装MariaDB 10.2.151.准备好源码安装包 mariadb-10.2.15.tar.gz 2.安装相关依赖包 yum install bison bison-devel zlib-devel libcurl-devel libarchive-devel boost-devel gcc gcc-c++ cmake ncurses-devel gnutls-devel libxml2-devel openssl-devel libevent-devel libaio-devel 3.创建用户 useradd -r -s /sbin/nologin mysql 4.解压缩源码包 tar -xvf mariadb-10.2.15.tar.gz 5.创建数据库路径 mkdir /data/mysqldb chown mysql.mysql /data/mysqldb chmod 770 /data/mysqldb 6.cmake编译 cd /mariadb-10.2.15/ cmake . \ -DCMAKE_INSTALL_PREFIX=/app/mysql \ -DMYSQL_DATADIR=/data/mysqldb/ \ -DSYSCONFDIR=/etc \ -DMYSQL_USER=mysql \ -DWITH_INNOBASE_STORAGE_ENGINE=1 \ -DWITH_ARCHIVE_STORAGE_ENGINE=1 \ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \ -DWITH_PARTITION_STORAGE_ENGINE=1 \ -DWITHOUT_MROONGA_STORAGE_ENGINE=1 \ -DWITH_DEBUG=0 \ -DWITH_READLINE=1 \ -DWITH_SSL=system \ -DWITH_ZLIB=system \ -DWITH_LIBWRAP=0 \ -DENABLED_LOCAL_INFILE=1 \ -DMYSQL_UNIX_ADDR=/app/mysql/mysql.sock \ -DDEFAULT_CHARSET=utf8 \ -DDEFAULT_COLLATION=utf8_general_ci 7．编译安装 make -j 4 &amp;&amp; make install 8.准备环境变量 echo ‘PATH=/app/mysql/bin:$PATH’ &gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh 9.生成数据库文件 cd /app/mysql/ scripts/mysql_install_db –datadir=/data/mysqldb/ –user=mysql –basedir=/app/mysql setfacl -R -m u:mysql:rwx /app/mysql/ 10.准备配置文件 cp /app/mysql/support-files/my-huge.cnf /etc/my.cnf 11.准备启动脚本 cp /app/mysql/support-files/mysql.server /etc/init.d/mysqld 12.启动服务 chkconfig –add mysqld service mysqld start 四、实验：实现多实例安装实验预期：在一台虚拟机上安装三套MariaDB数据库，数据库版本5.5 思路：三套配置文件（日志文件，配置文件，数据库文件），三个不同的端口 1.安装第一个实例 yum install mariadb-server 2.规划目录 mkdir /mysqldb/{3306,3307,3308}/{etc,socket,pid,log,data} –pv 目录结构如下： [root@CentOS7 ~]#tree /mysqldb/ /mysqldb/ ├── 3306 │ ├── data │ ├── etc │ ├── log │ ├── pid │ └── socket ├── 3307 │ ├── data │ ├── etc │ ├── log │ ├── pid │ └── socket └── 3308 ├── data ├── etc ├── log ├── pid └── socket 3.修改目录及文件权限 chown -R mysql.mysql /mysql 4.创建各自数据库文件 mysql_install_db –datadir=/mysqldb/3306/data –user=mysql [–basedir=/usr/ 二进制安装] mysql_install_db –datadir=/mysqldb/3307/data –user=mysql mysql_install_db –datadir=/mysqldb/3308/data –user=mysql 5.创建各自配置文件 cp /etc/my.cnf /mysqldb/3306/etc/ 6.修改各自配置文件 vim my.cnf [mysqld] port=3306 datadir=/mysqldb/3306/data socket=/mysqldb/3306/socket/mysql.sock [mysqld_safe] log-error=/mysqldb/3306/log/mariadb.log pid-file=/mysqldb/3306/pid/mariadb.pid #!includefir /etc/my.cnf.d 添加此行注释 参照3306配置文件，将3307,3308配置文件也生成 cp /mysqldb/3306/etc/my.cnf /mysqldb/3307/etc/my.cnf cp /mysqldb/3306/etc/my.cnf /mysqldb/3308/etc/my.cnf 7.准备启动服务脚本 chmod 700 mysqld 添加执行权限 cp mysqld /mysqldb/3306 / cp mysqld /mysqldb/3307/ cp mysqld /mysqldb/3308 / 注意修改启动服务脚本中的不同的参数 #!/bin/bash port=3306 mysql_pwd=”” cmd_path=”/usr/bin” 8.确认系统自带示例停止服务 systemctl stop mariadb 9.启动多实例服务 /mysqldb/{3306,3307,3308}/mysqld start ss -ntl 10.测试多实例 mysql -S /mysqldb/3308/socket/mysql.sock MariaBD [(none)]&gt; show variables like ‘%port%’;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS服务及相关实验]]></title>
    <url>%2F2018%2F06%2F02%2FDNS%E6%9C%8D%E5%8A%A1%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一、DNS服务相关介绍DNS：Domain Name Service 应用层协议 C/S,53/udp, 53/tcp BIND：Bekerley Internat Name Domain ISC （www.isc.org） 名字解析服务：将全称域名解析为IP地址 FQDN：Fully Qualified Domain Name,完整主机名 www.magedu.com 完整主机名(FQDN) www 主机名，或者别名 magedu.com domain域名 分散式解决方案：小环境，特定应用内部集群 /etc/hosts 集中式解决方案：NIS，适合中小型环境 分布式（既分散又集中）解决方案：DNS 本地名称解析配置文件：hosts Linux： /etc/hosts Windows：%WINDIR%/system32/drivers/etc/hosts ​ 122.10.117.2 www.magedu.com ​ 93.46.8.89 www.google.com 权威DNS服务器：查询FQDN所在的DNS服务器 13组服务器，13个IP地址存放根域 IPv6,25组跟服务器 DNS查询类型： 递归查询：负责到底 迭代查询：不负责到底 解析类型： 正向解析：FQDN –&gt; IP 反向解析：IP –&gt; FQDN 注意：正反向解析是两个不同的名称空间是两棵不同的解析树 DNS服务器的类型： 主DNS服务器 从DNS服务器 缓存DNS服务器（转发器） 主DNS服务器：管理和维护所负责解析的域内解析库的服务器 从DNS服务器：从主服务器或从服务器“复制”（区域传输）解析库副本 序列号：解析库版本号，主服务器解析库变化时，其序列递增 刷新时间间隔： 服务器从主服务器请求同步解析的时间间隔 重试时间间隔：从服务器请求同步失败时，再次尝试时间间隔 过期时长：从服务器联系不到主服务器时，多久后停止服务 “通知”机制：主服务器解析库发生变化时，会主动通知从服务器 bind相关文件： /etc/named.conf 主配置文件 /usr/sbin/named 主程序 /usr/lib/systemd/system/named.service 服务 /var/named 存放数据库 /var/named/named.localhost 区域解析库参考文件 cat /var/named/named.localhost $TTL 1D 一天作为缓存期 @ IN SOA @ rname.invalid. ( 第一个@表示当前域名，第二个@表示主DNS服务器,rname.invalid表示管理员邮箱 0 ; serial 版本序列号，序列号越大表示数据越新，需手动更改 1D ; refresh 刷新时间 1H ; retry 重试时间 1W ; expire 过期时间 3H ) ; minimum 否定答案的TTL值 NS @ A 127.0.0.1 AAAA ::1 资源记录：区域解析库：由众多RR组成： 资源记录：Resource Record, RR 记录类型：A, AAAA, PTR, SOA, NS, CNAME, MX SOA：Start Of Authority，起始授权记录；一个区域解析库有且仅能有一个SOA记录， 必须位于解析库的第一条记录，定义了谁是主DNS服务器，管理员邮箱及刷新时间(从属DNS服务器拉取 主DNS服务器数据的时间)、重试时间、过期时间及否定答案的TTL值 A：internet Address，作用，FQDN –&gt; IP AAAA：FQDN –&gt; IPv6 PTR：PoinTeR，IP –&gt; FQDN NS：Name Server，专用于标明当前区域的DNS服务器 CNAME：Canonical Name，别名记录，如www MX：Mail eXchanger，邮件交换器 资源记录定义的格式：语法：name [TTL] IN rr_type value 注意： (1) TTL可从全局继承 (2) @可用于引用当前区域的名字 (3) 同一个名字可以通过多条记录定义多个不同的值；此时DNS服务器会以轮询 方式响应 (4) 同一个值也可能有多个不同的定义名字；通过多个不同的名字指向同一个值 进行定义；此仅表示通过多个不同的名字可以找到同一个主机 二、实验：搭建正向主DNS服务器前期准备：主DNS服务器：192.168.30.10 web服务器：192.168.30.16 客户端：192.168.30.11 实验预期：客户端访问通过主DNS解析访问http服务器搭建的网页 具体步骤：1主DNS服务器安装bind包： yum install bind 2 备份主配置文件，注意保留属性 cp /etc/named.conf /etc/named.conf.bak -a 3.开启named服务 Systemctl start named Systemctl enable named 4.修改主配置文件： vim /etc/named.conf options { ​ listen-on port 53 { localhost; }; ​ allow-query { localhost;any; }; }; 5.修改区域配置文件： 6创建区域解析数据库文件 可参照named.localhost文件进行创建 cp named.localhost magedu.com.zone -a vim magedu.com.zone $TTL 1D @ IN SOA dns1.magedu.com. admin.magedu.com. ( ​ 0 ; serial ​ 1D ; refresh ​ 1H ; retry ​ 1W ; expire ​ 3H ) ; minimum magedu.com. NS dns1 dns1 A 192.168.30.10 www A 192.168.30.16 7重新加载named服务： Systemctl reload named 或 rndc reload 8如启动失败，可使用语法检查 named-checkconf 主配置文件语法检查 named-checkzone “magedu.com” /var/named/magedu.com.zone 解析库文件语法检查 9切换至客户端进行测试： dig www.magedu.com @192.168.30.10 指定从192.168.30.10解析www.magedu.com 10切换到web服务器： echo welcome to Magedu &gt; /var/www/html/html.index service httpd start 11.切换至客户端： 添加DNS到网卡配置文件 重启网络服务 Service httpd restart 12.测试访问www.magedu.com 我们看到，客户端已经由主DNS服务器解析成功访问到我们自己搭建的http网页！ 三、实验：泛域名解析，提高访问感受前期准备：实验环境承接上 实验预期：客户端访问网页时，即使将主机名输出，也可正常访问 具体步骤：1修改主DNS服务器端区域数据库解析文件： 增加此行：泛域名解析，如wwwww.magedu.com也可正常访问 A 192.168.30.7 2客户端测试： 我们看到即时主机名输出，也可正常访问到www.magedu.com的http页面 四、实验：利用DNS实现web服务器负载均衡前期准备：主DNS服务器：192.168.30.10 web服务器1：192.168.30.16 web服务器2：192.168.30.12 客户端：192.168.30.11 实验预期：当客户端访问网页时，由主DNS服务器随机指向一台web服务器 具体步骤：1修改区域解析库数据文件： 添加下列行： websrv A 192.168.30.17 websrv A 192.168.30.27 www CNAME websrv 重新加载named服务: rndc reload 2切换至客户端测试： 我们看到当ping测www.magedu.com时，将随机指向一台web服务器 五、实验：实现反向解析前期准备：DNS服务器：192.168.30.10 测试客户端：192.168.30.11 具体步骤：1修改DNS服务器区域配置文件，添加反向解析区域 2添加方向区域解析数据库文件 重启named服务 rcdn reload 3切换客户端建测试 dig -x IPaddr 是一个专门测试反向解析的命令 dig -x 192.168.30.16 我们看到192.168.30.16反向解析到了websrv.magedu.com dig -x 192.168.30.17 192.168.30.16反向解析到了appsrv.wxlinux.com dig -x 192.168.30.100 192.168.30.16反向解析到了mail.magedu.com 与DNS服务器区域解析文件对应关系相一致 六、实验：搭建正向从DNS服务器前期准备：主DNS服务器：192.168.30.10 从DNS服务器：192.168.30.12 web服务器：192.168.30.16 客户端：192.168.30.11 实验预期：搭建从DNS服务器，当主DNS服务器宕机时，由从DNS实现地址解析 具体步骤：1.修改主DNS服务器主配置文件， vim /etc/named.conf options { ​ listen-on port 53 { localhost; }; ​ allow-query { local;any; }; ​ allow-transfer { 从DNS的IP }; 加此行 }; 2修改主DNS服务器区域数据库解析文件 将从DNS服务器同步进去 3修改从DNS服务器主配置文件 vim /etc/named.conf allow-transfer { none; }; 加此行 4修改从DNS服务器区域配置文件 重启named服务 rndc reload 5确认从DNS服务器slave区域文件同步成功 6模拟主DNS服务器宕机，将虚拟机网卡断开连接 7添加从服务器地址到客户端的DNS列表中： 8.客户端测试 ping www.magedu.com 经过短暂的等待（dns切换时间），从DNS服务器解析地址成功！ 七、实验：实现子域实验预期：www.bj.magedu.com www.zz.magedu.com 使能正常访问 方法一：修改主DNS区域解析文件直接将子域指向子域web服务器： www.bj A 192.168.30.17 www.zz A 192.168.30.27 方法二：本机独立子域适用场景：访问量不大，较小规模，由同一个主DNS服务器管理 vim /etc/named.rfc1912.zones zone “bj.magedu.com” IN { ​ type master ​ file “bj.magedu.com.zone”; zone “zz.magedu.com” IN { ​ type master ​ file “zz.magedu.com.zone”; cp magedu.com.zone bj.magedu.com.zone -a vim bj.magedu.com.zone cp magedu.com.zone zz.magedu.com.zone -a vim zz.magedu.com.zone 方法三：委派给另一台主机维护子域，实现分布式DNS管理前期准备： 主域magedu.com: 192.168.30.10 子域bj.magedu.com: 192.168.30.16 web服务器1：www.magedu.com: 192.168.30.17 web服务器2：www.bj.magedu.com: 192.168.30.27 测试客户端：192.168.30.11 1关闭dnssec功能 vim /etc/named.conf dnssec-enable no; dnssec-validation no; 2修改主域DNS区域解析文件，主域web服务器指向192.168.30.17 vim /var/named/magedu.com.zone $TTL 1D @ IN SOA dns1.magedu.com. admin.magedu.com. ( ​ 0 ; serial ​ 1D ; refresh ​ 1H ; retry ​ 1W ; expire ​ 3H ) ; minimum ​ NS dns1.magedu.com. bj NS dns2.magedu.com. ##新增 dns1 A 192.168.30.10 dns2 A 192.168.30.17 ##新增 3切换至子域DNS服务器，添加bj.magedu.com的区域配置 vim /etc/named.rfc1912.zones 4添加子域DNS区域解析文件，将web服务器指向192.168.30.27 重启named服务 rndc reload 5切换客户端进行测试 dig www.bj.magedu.com @192.168.30.10 ping www.bj.magedu.com 我们看到www.bj.magedu.com将通过主域DNS转发至子域DNS，再经子域DNS解析指向web服务器 dig www.magedu.com @192.168.30.10 ping www.magedu.com 而www.magedu.com还是由主域DNS负责解析，这样就实现了主域和子域DNS简单的分布式管理 八、实验：forward转发（一）全局性转发：对非本机所负责解析区域的请求，全转发给指定的服务器 注意：被转发的服务器需要能够为请求者做递归否则转发请求不予进行 前期准备：DNS服务器1: 192.168.30.10 DNS服务器2: 192.168.30.16 Web服务器：192.168.30.100 测试访问端: 192.168.30.11 实验预期：当FQDN在DNS1服务器无法解析时，直接指向到DNS2服务器进行转发 1在DNS2服务器上建立www.wxlinux.com的区域文件及解析数据库文件，并将www.wxlinux.com指向web服务器：192.168.30.100 2切换到访问端用DNS2服务器解析www.wxlinux.com，可以解析成功 dig www.wxlinux.com @192.168.30.16 3切换至DNS1服务器修改主配置文件 vim /etc/named.conf options { ​ forward first|only; ##first优先在指向DNS服务器解析，only表示只在 ​ forwarders { 192.168.30.17; } ##指向的DNS服务器解析 }; 注意确定主配置文件recursion yes;并且关闭dnssec功能否则也将导致实验失败 重启named服务 rndc reload 4切换至客户端进行测试： 首先清除dns缓存记录 rndc flush 进行ping测，解析成功（由于未搭建web服务器，所以显示主机不可达） ping www.wxlinux.com 指定DNS1服务器解析地址，发现DNS1直接指向了DNS2服务器进行解析 dig www.wxlinux.com @192.168.30.10 （二）特定区域转发：仅转发对特定的区域的请求，比全局转发优先级高 前期准备：同全局转发实验 实验预期：只有在访问wxlinux.com域时，才优先指向DNS2服务器进行解析 1在DNS1删除刚才的全局配置，新增加区域配置文件内容如下： 只有当访问wxlinux.com域时，才优先转发DNS2服务器解析 vim /etc/named.rfc1912.zones zone “wxlinux.com” IN { ​ type forward; ​ forward first|only; ​ forwarders {192.168.30.16;}; 清理DNS1服务器的DNS缓存 rndc flush 2切换至客户端测试： 解析成功，只在访问wxlinu.com优先指向DNS2服务器进行解析 dig www.wxlinux.com @192.168.30.10 九、实验：实现智能DNS前期准备：DNS服务器：两块网卡地址分别为172.20.113.242和192.168.30.10 模拟192.168.30.0/24网段为北京地区地址段 模拟172.20.0.0/16 网段为上海地区地址段 实验预期：北京用户访问时返回192.168.30.1 上海用户访问时返回192.168.30.2 其他地区用户访问时防护192.168.30.3 1在主配置文件中添加ACL 2建立与ACL映射的数据库 3建立view，一但采用viwe，必须把所有区域信息放到view语句块中，否则将失效，为了便于管理，我们将主配置文件中此段内容剪切至/etc/named.rfc19212.zones中 vim /etc/named.conf 添加view：如图 4创建view对应的区域数据信息 cp /etc/named.rfc1912.zone /etc/named.rfc1912.zone.beijing –a cp /etc/named.rfc1912.zone /etc/named.rfc1912.zone.shanghai –a vim /etc/named.rfc1912.zone.beijing zone “wxlinux.com” IN { ​ type master ​ file “wxlinux.com.zone.beijing”; vim /etc/named.rfc1912.zone.shanghai zone “wxlinux.com” IN { ​ type master ​ file “wxlinux.com.zone.beijing”; 最终生成三个独立的区域数据信息 重启named服务 rndc reload 5切换到客户端进行测试： （1）192.168.30.0/24测试 dig www.wxlinux.com @192.168.30.10 当地址为192.168.30.0/24段时，web服务器指向192.168.30.1 （2）172.20.0.0/16测试 dig www.wxlinux.com @172.20.113.242 当地址为172.20.0.0/16段时，web服务器指向192.168.30.2 （3）其他网段测试 切换回DNS服务器端： dig www.wxlinux.com @127.0.0.1 由于127.0.0.1不属于上述两个网段之一，所以DNS服务器将web服务器地址指向192.168.0.3]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible使用介绍（三）templates及Roles角色]]></title>
    <url>%2F2018%2F05%2F31%2FAnsible%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D%EF%BC%88%E4%B8%89%EF%BC%89templates%E5%8F%8ARoles%E8%A7%92%E8%89%B2%2F</url>
    <content type="text"><![CDATA[一、环境搭建：前期准备：一台虚拟机作为ansible，三台虚拟机作为被控端node 主控端： 主机名：ansible 系统版本：CentOS6.9 被控端： 主机名：node1 CPU内核数：4 系统版本：CentSO7.4 主机名：node2 CPU内核数：2 系统版本：CentSO6.9 主机名：node3 CPU内核数：1 系统版本：CentSO6.9 /etc/ansible/hosts文件主机列表配置如下： 二、Playbook中模板templates的用法templates模板：功能：根据模块文件动态生成对应的配置文件 使用方法： （1）templates文件必须存放在templates目录下，且以.j2为后缀 （2）templates模块只能被playbook调用 （3）yam文件需和templates目录平级，目录结构如下： ./ ├── temnginx.yml └── templates └── nginx.conf.j2 templates使用形式：字符串：使用单引号或双引号 数字：整数，浮点数 列表：[item1, item2, …] 元组：(item1, item2, …) 字典：{key1:value1, key2:value2, …} 布尔型：true/false 算术运算：+, -, *, /, //, %, ** 比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;= 逻辑运算：and, or, not 流表达式：For If When 示例1：使用template传输配置文件cp /etc/nginx/nginx.conf templates/nginx.conf.j2 vim testtemplate.yml — – hosts: os6 remote_user: root tasks: ​ – name: install package ​ yum: name=nginx ​ – name: copy template ​ template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf ​ – name: start service ​ service: name=nginx state=started enabled=yes 执行结果：运行playbook后，我们发现work process进程数量与虚拟机cpu内核数量是一致的，接下来我 们将把配置模板中的work process进程数量与系统自带变量结合起来引用。 示例2：template引用系统变量ansible websrvs -m setup |grep ‘cpu’ vim templates/nginx.conf.j2 worker_processes NaN; vim testtemplate.yml — – hosts:os6 remote_user: root tasks: ​ – name: install package ​ yum: name=nginx ​ – name: copy template ​ template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf ​ notify: restart service ​ – name: start service ​ service: name=nginx state=started enabled=yes handlers: ​ – name: restart service ​ service:name=nginx state=restarted 执行结果：再次运行playbook后，我们发现worker process进程数量等于cpu核心数量加2，这样template 就能帮我们实现根据不同主机性能定制相应的配置。 示例3：hosts文件普通变量修改nginx服务端口vim /etc/ansible/hosts 192.168.30.101 httpd_port=81 192.168.30.102 httpd_port=82 vim templates/nginx.conf.j2 server { ​ listen default server ​ listen [::]: default server } 三、Playbook中逻辑语句的使用When：条件测试:如果需要根据变量、facts或此前任务的执行结果来做为某task执行与 否的前提时要用到条件测试,通过when语句实现，在task中使用，jinja2的语法 查看发行版本系统变量： ansible srv -m setup filter=”*distribution” 示例1：vim testtemplate.yml — – hosts: all remote_user: root tasks: ​ – name: install package ​ yum: name=nginx ​ – name: copy template for centos7 ​ template: src=nginx.conf7.j2 dest=/etc/nginx/nginx.conf ​ when: ansible_distribution_major_version == “7” ​ notify: restart service ​ – name: copy template for centos6 ​ template: src=nginx.conf6.j2 dest=/etc/nginx/nginx.conf ​ when: ansible_distribution_major_version == “6” ​ notify: restart service ​ – name: start service ​ service: name=nginx state=started enabled=yes handlers: ​ – name: restart service ​ service:name=nginx state=restarted 执行结果:当when语句不匹配时，将skipping直接跳过，仅执行与when语句匹配的语句内容，最终 CentOS6,7根据不同的版本号生成对应的配置并启动服务。 with_items：迭代迭代：当有需要重复性执行的任务时，可以使用迭代机制 对迭代项的引用，固定变量名为“item” 要在task中使用with_items给定要迭代的元素列表 列表格式： 字符串 字典 示例1：利用迭代一次创建多个文件，安装多个命令包vim testitem.yml — – hosts: all remote_user: root tasks: ​ – name: create some file ​ file: name=/data/ state=touch ​ when: ansible_distribution_major_version == “7” ​ with_items: ​ – file1 ​ – file2 ​ – file3 ​ – name: install some packages ​ yum: name= ​ with_items: ​ – htop ​ – sl ​ – hping3 执行结果：当系统为CentOS7版本时，在/data目录下创建file1-3文件，安装htop，sl，hping3命令 示例2：使用迭代创建组vim testitem2.yml — – hosts: all remote_user: root tasks: ​ – name: create some groups ​ group: name= ​ when: ansible_distribution_major_version == “7” ​ with_items: ​ – g1 ​ – g2 ​ – g3 执行结果：当系统版本为CentOS7时，创建g1,g2,g3组 示例3：使用迭代配合字典创建用户与组vim testitem2.yml — – hosts: all remote_user: root tasks: ​ – name: create some groups ​ group: name= ​ with_items: ​ – g1 ​ – g2 ​ – g3 ​ – name: create some users ​ user: name= group= ​ with_items: ​ – { name: ‘user1’,group: ‘g1’ } ​ – { name: ‘user2’,group: ‘g2’ } ​ – { name: ‘user3’,group: ‘g3’ } 执行结果：所有主机上创建user1，user2，user3用户，且主组为g1，g2，g3 for 与 if 示例1：template，forvim for1.conf.j2 vim testfor.yml — – hosts: websrvs remote_user: root vars: ​ ports: ​ – 81 ​ – 82 ​ – 83 tasks: ​ – name: copy conf ​ template: src=for1.conf.j2 dest=/data/for1.conf 执行结果：每台主机生成for1.conf文件，内容如下 示例2：template，for，引用字典vim for2.conf.j2 cp testfor.yml testfor2.yml vim testfor2.yml — – hosts: websrvs remote_user: root vars: ​ ports: ​ – listen_port: 81 ​ – listen_port: 82 ​ – listen_port: 83 tasks: ​ – name: copy conf ​ template:src=for2.conf.j2 dest/data/for2.conf 执行结果：每台主机生成for2.conf文件，内容如下 ### 示例3：for循环中调用字典vim for3.conf.j2 cp testfor2.yml testfor3.yml vim testfor3.yml — – hosts: websrvs remote_user: root vars: ​ ports: ​ – web1: ​ port: 81 ​ name: web1.magedu.com ​ rootdir: /data/website1 ​ – web2: ​ port: 82 ​ name: web2.magedu.com ​ rootdir: /data/website2 ​ – web3: ​ port: 83 ​ name: web3.magedu.com ​ rootdir: /data/website3 tasks: ​ – name: copy conf ​ template:src=for3.conf.j2 dest/data/for3.conf 执行结果：每台主机生成for3.conf文件，内容如下 示例4：for循环中调用ifvim for4.conf.j2 cp testfor3.yml testfor4.yml vim testfor4.yml — – hosts: websrvs remote_user: root vars: ​ ports: ​ – web1: ​ port: 81 ​ #name: web1.magedu.com ​ rootdir: /data/website1 ​ – web2: ​ port: 82 ​ name: web2.magedu.com ​ rootdir: /data/website1 ​ – web3: ​ port: 83 ​ #name: web3.magedu.com ​ rootdir: /data/website1 tasks: ​ – name: copy conf ​ template:src=for4.conf.j2 dest/data/for4.conf 执行结果：每台主机生成for3.conf文件，内容如下，web1与web3的name没赋值，所有跳过，web2的 name被赋值，文件中输出结果 四、Roles角色角色（roles）：角色集合 roles/ mysql/ httpd/ nginx/ memcached/ /roles/project/ :项目名称,有以下子目录 files/ ：存放由copy或script模块等调用的文件 templates/：template模块查找所需要模板文件的目录 tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件；其它的文 件需要在此文件中通过include进行包含 handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过 include进行包含 vars/：定义变量，至少应该包含一个名为main.yml的文件；其它的文件需要在此文件 中通过include进行包含 meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文 件，其它文件需在此文件中通过include进行包含 default/：设定默认变量时使用此目录中的main.yml文件 建议：roles创建在ansible目录 mkdir roles mkdir roles/{httpd,mysql,memcache,nginx} -pv 示例1：定义nginx角色思路： niginx 1.group:nginx 2.user:nginx 3.yum:nginx 4.template:nigin.conf.j2 5.service:nginx 目录结构如下： cd nginx mkdir tasks templates cd tasks vim group.yml – name: create group group: name=nginx gid=80 vim user.yml – name: create user user: name=nginx group=nginx uid=80 shell=/sbin/noligin vim yum.yml – name: install package yum: name=nginx vim start.yml – name: start service service: name=nginx state=started enabled=yes vim restart.yml – name: restart service service: name=nginx state=restarted cp /etc/nginx/nginx.conf template/nginx.conf.j2 vim template/nginx.conf.j2 worker_processes NaN; vim templ.yml – name: copy conf template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf vim main.yml – include: group.yml – include: user.yml – include: yum.yml – include: templ.yml – include: start.yml 调用角色的剧本要和roles目录在同一文件夹 vim nginx_roles.yml – hosts: websrvs romete_user: root roles: ​ – role: nginx ansible-playbook -C nginx_role.yml 执行结果如下： 示例2：增加httpd角色结构目录如下： cd httpd/ mkdir tasks cd tasks/ vim user.yml – name: create user user: name=apache system=yes shell=/sbin/nologin cd httpd/ mkdir files cp httpd.conf files/ cd /tasks/ 模拟编译安装yum vim copyfile.yml – name: copy files copy: src=httpd.conf dest=/data/ own=apache vim main.yml – incluse: user.yml – incluse: copyfile.yml vim httpd_role.yml – hosts: websrvs romete_user: root roles: ​ – role: httpd 执行结果如下： 示例3：同时调用两个roles角色目录结构： cp niginx_role.yml some_role.yml vim some_role.yml – hosts: websrvs romete_user: root roles: ​ – role: httpd ​ – role: nginx 执行结果如下： ### 示例4：一个roles角色调用另一个roles角色的task任务目标：nginx调用httpd的copyfile vim main.yml – include: group.yml – include: user.yml – include: yum.yml – include: templ.yml – include: start.yml – inclide: roles/httpd/tasks/copyfile.yml 示例5：roles playbook tags目录结构如下： cp -r nginx/ app/ 首先虚构一个app的role vim some_role2.yml – hosts: websrvs romete_user: root roles: ​ – { role: httpd,tags:[‘web’,’httpd’]} ​ – { role: nginx,tags:[‘web’,’nginx’]} ​ – { role: app,tags:’app’} ansible-playbook -t web some_role.yml 执行结果：只执行标签为web的role ### 示例6：roles playbook tags whencp -r nginx/ app/ 虚构一个role vim some_role3.yml – hosts: all romete_user: root roles: – { role: httpd,tags:[‘web’,’httpd’]} – { role: nginx,tags:[‘web’,’nginx’],when: ansible_distribution_major_version==”7″} – { role: app,tags:’app’} ansible-playbook -t web some_role.yml 执行结果：至执行tags标签为web的roles，当主版本号为7时，才执行nginx的role ### 示例7：综合演示结构目录： rm -rf /app mkdir app cd app mkdir tasks templates vars handlers files cd tasks/ vim group.yml – name: create group group: name=app system=yes gid=123 vim user.yml – name: create user user: name=app group=app system=yes shell=/sbin/nologin uid=123 vim yum.yml – name: install package yum: name=httpd cp /etc/httpd/conf/httpd.conf /templates/httpd.conf.j2 vim temlates/httpd.conf.j2 Listen NaN User Group vim /vars/main.yml username: app groupname: app vim templ.yml – name: copy conf temlplate: src=httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf notify: restart service vim start.yml – name: start service service: name=httpd state=started enabled=yes vim handlers/main.yml – name: restart service service: name=httpd state=restarted touch files/vhosts.conf vim copyfile.yml – name: copy config copy: src=vhosts.conf dest=/ect/httpd/conf.d/ vim main.yml – include: group.yml – include: user.yml – include: yum.yml – include: templ.yml – include: copyfile.yml – include: start.yml cd ansible/ vim app_role.yml – hosts: websrvs remote_user: root roles: ​ – role: app 执行结果如下： 示例8：部署memcached，占用内存为物理内存1/4 yum install memcached 目录结构： cp /etc/sysconfig/memcached templates/memcached.j2 vim memcached.j2 CACHESIZE=”NaN” vim tasks/yum.yml – name: install package yum: name=memcached vim templ.yum – name: copy conf template: src=memcached.j2 dest=/etc/sysconfig/memcached vim start.yml – name: start service service: name=memcached state=started enabled=yes vim main.yml – include: yum.yml – include: templ.yml – inculde: start.yml vim memcached_role.yml – hosts: os6 remote_user: root roles: ​ – role: memcached ansible-playbook memcached_role.yml 执行结果如下： 远程查看配置文件，确认生效：]]></content>
      <categories>
        <category>自动化运维</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible使用介绍（二）YAML语法及Playbook]]></title>
    <url>%2F2018%2F05%2F30%2FAnsible%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D%EF%BC%88%E4%BA%8C%EF%BC%89YAML%E8%AF%AD%E6%B3%95%E5%8F%8APlaybook%2F</url>
    <content type="text"><![CDATA[playbook是由一个或多个”play”组成的列表 play的主要功能在于将事先归并为一组的主机装扮成事先通过ansibe中的task定义好的角色。从根本上来 讲，所谓task无非是调用ansible的module。将多个play组织在一个playbook中，即可让它们联同起来按事 先编排的机制运行。 Playbook采用YAML语言编写每一个Ansible的Playbook都是一个YAML格式的文件，因此要学习编写剧 本(playbook)，我们先来了解YAML语法的基本用法 一、YAML介绍：YAML是一个可读性高的用来表达资料序列的格式。YAML参考了其他多种语言，包括：XML、 C语言、Python、Perl以及电子邮件格式RFC2822等。Clark Evans在2001年在首次发表了这种 语言，另外Ingy döt Net与Oren Ben-Kiki也是这语言的共同设计者 YAML Ain’t Markup Language，即YAML不是XML。不过，在开发的这种语言时，YAML的意 思其实是：”Yet Another Markup Language”（仍是一种标记语言） 特性：YAML的可读性好 YAML和脚本语言的交互性好 YAML使用实现语言的数据类型 YAML有一个一致的信息模型 YAML易于实现 YAML可以基于流来处理 YAML表达能力强，扩展性好 更多的内容及规范参见http://www.yaml.org YAML语法格式：1.在单一档案中，可用连续三个连字号(——)区分多个档案。另外，还有选择性的连续三个点号 ( … )用来表示档案结尾 2.次行开始正常写Playbook的内容，一般建议写明该Playbook的功能 3.使用#号注释代码 4.缩进必须是统一的，不能空格和tab混用 5.缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过缩进结 合换行来实现的 6.YAML文件内容和Linux系统大小写判断方式保持一致，是区别大小写的，k/v的值均需大小写敏 感 7.k/v的值可同行写也可换行写。同行使用:分隔 8.v可是个字符串，也可是另一个列表 9.一个完整的代码块功能需最少元素需包括 name: task 10.一个name只能包括一个task 11.YAML文件扩展名通常为yml或yaml YAML语法简介：[列表] List：列表，其所有元素均使用“-”打头 示例： # A list of tasty fruits – Apple – Orange – Strawberry – Mango [字典] Dictionary：字典，通常由多个key与value构成 示例： — # An employee record name: Example Developer job: Developer skill: Elite 也可以将key:value放置于{}中进行表示，用,分隔多个key:value 示例： — # An employee record {name: Example Developer, job: Developer, skill: Elite} 二、剧本PlaybookPlaybook核心元素：Hosts：执行的远程主机列表 Tasks：任务列表 Varniables：内置变量或自定义变量在playbook中调用 Templates：模板，可替换模板文件中的变量并实现一些简单逻辑的文件 Handlers：和notify结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行 tags：标签，指定某条任务执行，用于选择运行playbook中的部分代码。ansible具有幂等性。因此 会自动跳过没有变化的部分。此时，如果确信其没有变化，就可以通过tags跳过此些代码片段 下图展示的是Playbook的工作机制： Hosts：作用：playbook中的每一个play的目的都是为了让某个或某些主机以某个指定的用户 身份执行任务。hosts用于指定要执行指定任务的主机，须事先定义在主机清单中 可以是如下形式： one.example.com one.example.com:two.example.com 192.168.1.50 192.168.1.* websrvs:dbsrvs 两个组的并集 websrvs:&amp;dbsrvs 两个组的交集 webservers:!dbsrvs 在websrvs组，但不在dbsrvs组 示例: – hosts: websrvs：dbsrvs remote_user：作用：可用于Host和task中。也可以通过指定其通过sudo的方式在远程主机上执行任务， 其可用于play全局或某任务；此外，甚至可以在sudo时使用sudo_user指定sudo时切换的 用户 – hosts: websrvs remote_user: root tasks: ​ – name: test connection ​ ping: ​ remote_user: magedu ​ sudo: yes 默认sudo为root ​ sudo_user:wang sudo为wang tasks：作用：任务列表 格式：module: arguments 注意：shell和command模块后面跟命令，而非key=value 检查playbook： ansible-playbook -C file.yml 运行playbook的方式： ​ ansible-playbook &lt;filrname.yml&gt; …[options] ​ options： –check 只检测可能会发生的改变，但不真正的操作 –list-hosts 列出运行任务的主机 –limit 主机列表 只针对主机列表中的主机执行 -v,-vv,-vvv 显示详细过程 一个最简单的Playbook需包含的基础组件有host、remote_user、tasks 示例1： vim http.yml — – hosts: websrvs remote_user: root tasks: ​ – name: create new file ​ file: name=/data/newfile state=touch ​ – name: create new file ​ user: name=test2 system=yes shell=/sbin/nologin ​ – name: install package ​ yum: name=httpd ​ – name: copy index ​ copy: src=/var/www/html/index.html dest=/var/www/html/ ​ – name: start service ​ service: name=httpd state=started enabled=yes tags标签task**任务也可以通过”tags”打标签，而后可在ansible-playbook命令上使用-t指定进行调用** 示例2：使用tags vim http.yml — – host: websrvs remote_user: root tasks: ​ – name: install httpd package ​ yum: name=httpd ​ tags: inshttpd ​ – name: copy conf file ​ copy: src=files/httpd.conf dest=/etc/httpd/conf/ backup=yes ​ tags: cphttpd ​ – name: start service ​ service: name=httpd state=startd enable=yes ​ tags: rshttpd ansible-playbook -t rshttpd httpd.yml 单独执行rshttp 注：多个动作可共用一个tags标签 三、Playbook中handler的使用由于Ansible幂等性的特性，有时前一个task发生了变化，后续的task无变化并不会重新执行， 但后续的task却可能受前一个task变化而影响。使用hanlder和notify即可解决此问题，handler 用于当关注的资源发生变化时，才会采取一定的操作。在notify中列出的操作称为handler， 也即notify中调用handler中定义的操作 示例： vim http.yml — – host: websrvs remote_user: root tasks: ​ – name: install httpd package ​ yum: name=httpd ​ – name: copy conf file ​ copy: src=files/httpd.conf dest=/etc/httpd/conf/ backup=yes ​ – name: start service ​ service: name=httpd state=startd enable=yes vim /files/httpd.conf Listen 8080 ansible-playbook http.yml 此时无法重启服务，端口仍为80 vim http.yml — – host: websrvs remote_user: root tasks: ​ – name: install httpd package ​ yum: name=httpd ​ – name: copy conf file ​ copy: src=files/httpd.conf dest=/etc/httpd/conf/ backup=yes ​ notify: restart service ​ – name: start service ​ service: name=httpd state=startd enable=yes handlers: ​ – name: restart service ​ service: name=httpd state=restarted 由于httpd.conf发生了变化，触发了notify，执行相应的handler操作，httpd服务重启后 监听端口变为8080 四、Playbook中变量的使用变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量来源： 1.ansible all -m setup 远程主机的所有变量都可直接调用 2.在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 host分组变量：针对主机组中所有主机定义统一变量 3.通过命令行指定变量，优先级最高 例如：ansible-playbook –e varname=value 4.在playbook中定义 vars: – var1: value1 – var2: value2 5.在role中定义 变量定义：key=value 示例：http_port=80 变量调用方式： 通过 调用变量，且变量名前后必须有空格，有时用””才生效 变量调用优先级： 命令行-e &gt; playbook定义 &gt; hosts普通变量 &gt; host分组变量 示例1：命令行变量赋值 vim app.yml — – hosts: appsrvs remote_user: root tasks: ​ – name: install package ​ yum: name= ​ – name: start service ​ service: name= state=started enabled=yes 变量赋值并执行： ansible-playbook -e ‘pkname=vsftpd’ app.yml 示例2：playbook中赋值变量 vim app.yml — – hosts: appsrvs remote_user: root vars: ​ – pkname1: httpd ​ – pkname2: vsftpd tasks: ​ – name: install package ​ yum: name= ​ – name: install package ​ yum: name= ansible-playbook app.yml 示例3：hosts文件中定义普通变量 vim /etc/ansible/hosts 192.168.30.101 httpd_port=81 192.168.30.102 httpd_port=82 vim hostname.yml — – hosts: websrvs remote_user: root tasks: ​ – name: set hostname ​ hostname: name=www.magedu.com ansible-playbook -C hostname.yml 示例4：hosts文件中定义分组变量 vim /etc/ansible/hosts [websrv:vars] nodename=www domainname=wxlinux.com vim hostname2.yml — – hosts: websrvs remote_user: root tasks: ​ – name: set hostname ​ hostname: name=. ansible-playbook hostname.yml 示例5：引用系统自带变量 ansible all -m setup |grep ansible_fqdn 查看系统自带变量 vim var.yml — – hosts: websrvs remote_user: root tasks: ​ – name: create log file ​ file: name=/data/.log state=touch 示例6：定义变量到一个文件中 vim vars.yml var1: httpd var2: vsftpd vim testvar.yml — – hosts: websrvs remote_user: root vars_files: ​ – vars.yml tasks: ​ – name: install package ​ yum: name= ​ – name: create file ​ file: name=/data/.log state=touch]]></content>
      <categories>
        <category>自动化运维</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible使用介绍（一）基本概念及常用模块]]></title>
    <url>%2F2018%2F05%2F29%2FAnsible%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D%EF%BC%88%E4%B8%80%EF%BC%89%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[随着运维自动化经历了从本地部署到基础设施即服务（IaaS）、平台即服务（PaaS）在到软件即服务 （SaaS）的发展阶段，掌握多种自动化运维工具就成了运维人员必备技能之一，ansible就是目前国内使 用比较广泛的自动化运维工具之一。 一、ansible工具介绍：常用自动化运维工具：Ansible：python，中小型应用环境，300-500台 Saltstack：python，一般需部署agent，执行效率更高，大型环境1000台以上 Puppet：ruby，功能强大，配置复杂，重型，适合大型环境 Fabric：python，agentless Chef：ruby，国内应用少 Cfengine func Ansibleansible是新出现的自动化运维工具，基于Python开发，集合了众多运维工具（puppet、 cfengine、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量 运行命令等功能。 特性：模块化：调用特定的模块，完成特定任务 有Paramiko,PyYAML,Jinja2（模板语言）三个关机模块 支持自定义模块 基于Python语言实现 部署简单，基于python和SSH（默认已安装），agentless 安全，基于OpenSSH 支持playbook编排任务 幂等性：一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况 无需代理不依赖PKI（无需ssl） 可使用任何编程语言写模块 YAML格式，编排任务，支持丰富的数据结构 较强大的多层解决方案 Ansible主要组成部分：API：供第三方程序调用的应用程序编程接口 Inventory：Ansible管理主机清单，存放在/etc/ansible/hosts Modules：模块，Ansible执行命令的功能的模块，多个命令的组合 Playbook：剧本，多个模块的组合，编排定义Ansible任务集的配置文件，由Ansible顺序依次执行，通常是JSON格式的YML文件 Plugins：模块功能的补充，如连接类型的插件、循环插件、变量插件、过滤插件等，该功能不常用 Ansible：组合Inventory、API、Modules、Plugins的绿框，可以理解为是ansible命令工具，其为核心执行工具 相关文件：/etc/ansible/ansible.cfg 主配置文件，配置ansible工作特性 /etc/ansible/hosts 主机清单文件 /etc/ansible/rules 角色目录 程序： /usr/bin/ansible 主程序，临时命令执行工具 /usr/bin/ansible-doc 查看配置文档，模块功能查看工具 /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台 /usr/bin/ansible-playbook 定制自动化任务，编排剧本工具/usr/bin/ansible-pull 远 程执行命令的工具： /usr/bin/ansible-vault 文件加密工具 /usr/bin/ansible-console 基于Console界面与用户交互的执行工具 /etc/ansible/ansible.cfg ansible配置文件（一般保持默认） [defaults] #forks = 5 并发执行数量，默认5 #poll_interval = 15 拉取数据间隔时间，默认15秒 #sudo_user = root sudo命令默认用户 #remote_port = 22 连接远程端口号 #host_key_checking = False 检查对应服务器的host_key，##建议取消注释 #log_path=/var/log/ansible.log 日志文件，##建议取消注释 /etc/ansible/hosts主机清单inventory文件 inventory文件遵循INI文件风格，中括号中的字符为组名。可以将同一个主机 同时归并到多个不同的组中；此外，当如若目标主机使用了非默认的SSH端口， 还可以在主机名称之后使用冒号加端口号来标明 ntp.magedu.com [webservers] www1.magedu.com:2222 www2.magedu.com [dbservers] db1.magedu.com db2.magedu.com db3.magedu.com 如果主机名称遵循相似的命名模式，还可以使用列表的方式标识各主机 示例： [websrvs] www[01:100].example.com [dbsrvs] db-[a:f].example.com ansible**命令**功能：通过ssh实现配置管理、应用部署、任务执行等功能 建议：配置ansible端能基于密钥认证的方式联系各被管理节点 格式：ansible [-m module_name] [-a args] 常用选项： –version 显示版本 -m module 指定模块，默认为command -v 详细过程 –vv -vvv更详细 –list-hosts 显示主机列表，可简写—list -k, –ask-pass 提示连接密码，默认Key验证 -K, –ask-become-pass 提示输入sudo -C, –check 检查，并不执行 -T, –timeout=TIMEOUT 执行命令的超时时间，默认10s -u, –user=REMOTE_USER 执行远程执行的用户 -b, –become 代替旧版的sudo 切换 匹配主机的列表 ALL 表示列表中的所有主机 示例： ansible all -m ping * 支持通配符 示例： ansible “*” -m ping ansible 192.168.1.* -m ping ansible “*srvs” -m ping 或关系 示例： ansible “websrvs:appsrvs” -m ping ansible “192.168.1.10:192.168.1.20” -m ping 逻辑与： ansible “websrvs:&amp;dbsrvs” -m ping 在websrvs组，但不在dbsrvs组中的主机 逻辑非： ansible ‘websrvs:!dbsrvs’ -m ping 综合逻辑： ansible ‘websrvs:dbsrvs:&amp;appsrvs:!ftpsrvs’ -m -ping 正则表达式： ansible “websrvs:&amp;dbsrvs” -m ping ansible “~(web|db).*.magedu.com” -m ping ansible命令执行过程1.加载自己的配置文件 默认/etc/ansible/ansible.cfg 2.加载自己对应的模块文件，如command 3.通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程服务器 的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 4.给文件+x执行 5.执行并返回结果 6.删除临时py文件，sleep 0退出 执行状态： 绿色：执行成功并且不需要做改变的操作 黄色：执行成功并且对目标主机做变更 红色：执行失败 二、ansible常用模块：查看模块帮助： ansible-doc module 显示模块简要说明： ansible-doc -s module Command模块功能：默认模块，在远程主机执行命令，可忽略-m选项 ​ ansible srvs -m command -a ‘service vsftpd start’ ​ ansible srvs -m command -a ‘echo magedu |passwd –stdin wang’ 不成功 注意： （1）使用Command模块执行脚本时，要注意规范，shebang机制，否则将执行失败 （2）不支持管道“|”，变量“$”,以及重定向，需使用shell模块 Shell**模块**功能：和command相似，用shell执行命令 ​ ansible srv -m shell -a ‘echo magedu |passwd –stdin wang’ 注意： （1）调用bash执行命令 类似 cat /tmp/stanley.md | awk -F‘|’ ‘{print $1,$2}’ &amp;&gt; /tmp/example.txt 这些复杂命令，即使使用shell也可能会失败。 解决办法：写到脚本，copy到远程，执行，再把需要的结果拉回执行命令的机器 （2）可将默认模块替换为shell： ​ vim ansible.conf ​ module_name = shell ansible srvs -m command -a ‘echo magedu |passwd –stdin wang’ 成功 Script**模块**功能：运行脚本,不需要将脚本复制到被控端 ​ -a “/PATH/TO/SCRIPT_FILE” ​ snsible websrvs -m script -a f1.sh Copy**模块**功能：从服务器复制文件到客户端, ​ ansible srv -m copy -a “src=/root/f1.sh dest=/tmp/f2.sh owner=wang mode=600 ​ backup=yes” 如目标存在，默认覆盖，此处指定先备份 ansible srv -m copy -a “content=‘test content\n’ dest=/tmp/f1.txt” 利用内容，直接生成 目标文件 Fetch**模块**功能：从客户端取文件至服务器端，copy相反，目录可先tar ​ ansible srv -m fetch -a ‘src=/root/a.sh dest=/data/scripts’ 示例： 打包/var/log下所有日志文件并远程抓取 ​ ansible all -m shell -a ‘tar Jcf log.tar.xz /var/log/*.log’ ​ ansible all -m fetch -a ‘src=/root/log.tar.xz dest=/data’ File**模块**功能：设置文件属性 示例： 创建新文件： ​ ansible all -m file -a ‘name=/data/f3 state=touch’ 删除文件： ​ ansible all -m file -a ‘name=/data/f3 state=absent’ 创建目录： ​ ansible all -m file -a ‘name=/data/dir1 state=directory’ 删除目录： ​ ansible all -m file -a ‘name=/data/dir1 state=absent’ 创建软连接 ​ ansible all -m file -a ‘src=/etc/fstab dest /data/fstab.link state=link’ 删除软连接： ​ ansible all -m file -a ‘dest /data/fstab.link state=absent’ 创建文件指定所有者，权限： ​ ansible srv -m file -a “path=/root/a.sh owner=wang mode=755” ​ ansible web -m file -a ‘src=/app/testfile dest=/app/testfile-link state=link’ Hostname**模块**功能：管理主机名，生效同时更改文件永久生效 示例： 更改一个主机的主机名： ​ ansible node1 -m hostname -a “name=websrv” 注意： （1）Host模块不会修改/etc/hosts文件中的主机名解析，注意修改 （2）批量修改主机名时最好加变量，防止所有主机名一致 Cron**模块**功能：计划任务 支持时间：minute，hour，day，month，weekday 示例： 创建计划任务：每周1,3,5，每分钟打印，任务名称：warningcron ​ ansible all -m cron -a ‘minute=* weekday=1,3,5 job=”/usr/bin/wall FBI warning” name=warningcron’ 注释cronname=waringcron的计划任务： ​ ansible all -m cron -a ‘disabled=true job=”/usr/bin/wall FBI warning” name=warningcron’ 给cronname=waringcron的计划任务去掉注释： ​ ansible all -m cron -a ‘disabled=true job=”/usr/bin/wall FBI warning” name=warningcron’ 创建计划任务：每五分钟同步一次服务器时间，任务名称：syntime ​ ansible srv -m cron -a “minute=*/5 job=’/usr/sbin/ntpdate 172.16.0.1 &amp;&gt;/dev/null’ name=Synctime” 删除计划任务：Synctime ​ ansible srv -m cron -a ‘state=absent name=Synctime’ Yum**模块**功能：管理包 示例： yum安装vsftpd包：（默认state=installd） ​ ansible all -m yum -a ‘name=vsftpd’ 安装多个包用逗号隔开： ​ ansible all -m yum -a ‘name=vsftpd，httpd’ 显示所有已安装的包： ​ ansible all -m yum -a ‘name=vsftpd list=installd’ 卸载vsftpd包： ​ ansible all -m yum -a ‘name=vsftpd state=removed’ 安装从互联网下载的包： ​ ansible srv -m copy -a ‘src=/root/package.rpm dest=/data/package’ ​ ansible srv -m yum -a ‘name=/data/package.rpm’ 更新缓存： ​ ansible srv -m yum -a ‘update_cache=yes’ 更新缓存同时安装dstat包 ​ ansible srv -m yum -a ‘name=dstat update_cache=yes’ Service**模块**功能：管理服务 示例： 停止httpd服务： ​ ansible srv -m service -a ‘name=httpd state=stopped’ 开启httpd服务： ​ ansible srv -m service -a ‘name=httpd state=started’ 重新加载httod服务： ​ ansible srv -m service -a ‘name=httpd state=reloaded’ 重启httpd服务： ​ ansible srv -m service -a ‘name=httpd state=restarted’ 开启ftp服务，同时设置开机自动启动： ​ ansible srv -m service -a ‘name=vsftpd state=started enabled=yes’ 重启ftp服务： ​ ansible srv -m service -a ‘name=vsftpd state=restarted’ User**模块**功能：管理用户 示例： 添加用户，指定uid、家目录、主组及注释： ​ ansible srv -m user -a ‘name=user1 comment=”test user” uid=2048 home=/app/user1 group=root’ 添加一个系统用户： ansible srv -m user -a ‘name=sysuser1 system=yes home=/app/sysuser1’ 删除用户： ansible srv -m user -a ‘name=user1 state=absent’ 添加一个nginx用户： ​ ansible srv -m user -a ‘name=nginx shell=/sbin/nologin system=yes home=/var/nginx groups=root,bin uid=80 comment=”nginx service” 删除nginx用户同时删除家目录： ​ ansible srv -m user -a ‘name=nginx state=absent remove=yes’ Group**模块**功能：管理组 示例： 创建一个系统组： ​ ansible srv -m group -a “name=testgroup system=yes” 删除一个组： ​ ansible srv -m group -a “name=testgroup state=absent” 创建nginx组： ​ ansible srv -m group -a ‘name=nginx system=yes gid=80’ 删除nginx组： ​ ansible srv -m group -a ‘name=nginx state=absent’ 三、ansible系列命令：ansible系列命令包括： ansible ansible-doc ansible-playbook ansible-vault ansible-console ansible-galaxy ansible-pull ansible-doc功能：显示模块帮助 格式：ansible-doc [options] [module…] -a 显示所有模块的文档 -l 列出可用模块 -s 显示指定模块的playbook片段 示例： ansible-doc ping 查看ping模块帮助 ansible-doc -s ping 查看ping模块的简单说明 Ansible-vault功能：管理加密解密yml文件 格式：ans**ible-vault [create|decrypt|edit|encrypt|rekey|view]** ansible-vault encrypt hello.yml 加密yml文件 ansible-vault decrypt hello.yml 解密yml文件 ansible-vault view hello.yml 查看yml加密文件 ansible-vault edit hello.yml 编辑加密文件 ansible-vault rekey hello.yml 重新修改加密口令 ansible-vault create new.yml 创建新文件 Ansible-console功能：ansible控制台，可交互执行命令，支持tab root@test (2)[f:10] $ 执行用户@当前操作的主机组 (当前组的主机数量)[f:并发数]$ 设置并发数： forks n 例如： forks 10 切换组： cd 主机组 例如： cd web 列出当前组主机列表： list 列出所有的内置命令： ?或help 示例： 列出主机列表中所有主机： root@all (2)[f:5]$ list 切换至appsrvs组： root@all (2)[f:5]$ cd appsrvs 列出appsrvs组下所有主机： root@appsrvs (2)[f:5]$ list 安装httpd： root@appsrvs (2)[f:5]$ yum name=httpd state=present 开启httpd服务： root@appsrvs (2)[f:5]$ service name=httpd state=started ansible-galaxy功能：连接https://galaxy.ansible.com下载相应的roles 列出所有已安装的galaxy： ansible-galaxy list 安装galaxy： ansible-galaxy install geerlingguy.redis 删除galaxy： ansible-galaxy remove geerlingguy.redis ansible-pull功能：推送命令至远程，效率无限提升，对运维技术要求较高 当前应用还较少]]></content>
      <categories>
        <category>自动化运维</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cobbler自动化安装系统相关实验]]></title>
    <url>%2F2018%2F05%2F26%2Fcobbler%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一、cobbler简介：cobbler 功能：用来快速建立 Linux 网络安装环境 特性： 1.基于PXE的二次封装，将多种安装参数封装到一个菜单，更加方便，自动化 2.Python编写 3.支持UEFI+GPT cobbler工作流程：1.client裸机配置了从网络启动后，开机后会广播包请求DHCP服务器（cobbler server） 发送其分配好的一个IP 2.DHCP服务器（cobbler server）收到请求后发送responese，包括其ip地址 3.client裸机拿到ip后再向cobbler server发送请求OS引导文件的请求 4.cobbler server告诉裸机OS引导文件的名字和TFTP server的ip和port 5.client裸机通过上面告知的TFTP server地址通信，下载引导文件 6.client裸机执行执行该引导文件，确定加载信息，选择要安装的os，期间会再向 cobbler server请求kickstart文件和os image 7.cobbler server发送请求的kickstart和os iamge 8.client裸机加载kickstart文件 9.client裸机接收os image，安装该os image cobbler介绍：安装包： 系统默认未安装，需手动安装（epel源） cobbler服务集成： PXE ​ DHCP ​ rsync ​ Http ​ DNS ​ Kickstart ​ IPMI 电源管理 检查cobbler环境： cobbler check 1）指定server地址 2）指定tftp服务器地址 3）需要关闭SELinux 4）使用cobbler get-loaders下载必要文件 5）rsync服务，忽略不做 6）忽略不做 7）要求debian框架下安装debmirror包，忽略不做 8）要求加密口令 9）集群与电源相关 cobbler相关术语：发行版： 表示一个操作系统版本，它承载了内核和 initrd 的信息，以及内核参数等其他数据 配置文件： 包含一个发行版、一个 kickstart 文件以及可能的存储库，还包含更多特定的内核参 数等其他数据 系统： 表示要配置的主机，它包含一个配置文件或一个镜像，还包含 IP 和 MAC 地址、电源 管理（地址、凭据、类型）以及更为专业的数据等信息 存储库： 保存一个 yum 或 rsync 存储库的镜像信息 镜像： 可替换一个包含不属于此类别的文件的发行版对象（例如，无法分为内核和 initrd 的 对象） 相关配置文件：配置文件目录 /etc/cobbler /etc/cobbler/settings : cobbler 主配置文件 /etc/cobbler/iso/: iso模板配置文件 /etc/cobbler/pxe: pxe模板文件 /etc/cobbler/power: 电源配置文件 /etc/cobbler/user.conf: web服务授权配置文件 /etc/cobbler/users.digest: web访问的用户名密码配置文件 /etc/cobbler/dhcp.template : dhcp服务器的的配置末班 /etc/cobbler/dnsmasq.template : dns服务器的配置模板 /etc/cobbler/tftpd.template : tftp服务的配置模板 /etc/cobbler/modules.conf : 模块的配置文件 数据目录 /var/lib/cobbler/config/: 用于存放distros，system，profiles 等信息配置文件 /var/lib/cobbler/triggers/: 用于存放用户定义的cobbler命令 /var/lib/cobbler/kickstart/: 默认存放kickstart文件 /var/lib/cobbler/loaders/: 存放各种引导程序 镜像目录 /var/www/cobbler/ks_mirror/: 导入的发行版系统的所有数据 /var/www/cobbler/images/ : 导入发行版的kernel和initrd镜像用于远程网络启动 /var/www/cobbler/repo_mirror/: yum 仓库存储目录 日志目录 /var/log/cobbler/installing: 客户端安装日志 /var/log/cobbler/cobbler.log : cobbler日志 cobbler命令：cobbler commands 介绍 cobbler check 核对当前设置是否有问题 cobbler list 列出所有的cobbler元素 cobbler report 列出元素的详细信息 cobbler sync 同步配置到数据目录,更改配置最好都要执行下 cobbler reposync 同步yum仓库 cobbler distro 查看导入的发行版系统信息 cobbler system 查看添加的系统信息 cobbler profile 查看配置信息 二、实验：模拟搭建cobbler服务器，实现cobbler自动化安装系统1.开启各类服务 systemctl enable cobblerd dhcpd httpd tftp systemctl start cobblerd httpd tftp 2.检查 cobbler check 3.指定cobbler服务器地址： 养成好习惯，记得备份 vim /etc/cobbler/settings（备份） server:192.168.30.10 line384 4.重启服务 systemctl restart cobblerd 5.指定tftp服务器 next_server:192.168.30.10 line272 6.关闭SELinux 7.下载必要文件 cobbler get-loaders 8.同步必要文件到/var/lib/tftpboot目录 cobbler sync 同步后的目录结构如下： 9.加密口令替换setting文件中的默认口令 #openssl passwd -1 交互式生成加密口令 default_password_crytped line101 10.使用cobbler自动配置dhcp服务器 manage_dhcp:1 line242 11.重启cobbler服务 systemctl restart cobblerd 12.修改DHCP默认配置文件 vim /etc/cobbler/dhcp.template subnet 192.168.30.0 netmask 255.255.255.0 range dynamic-bootp 192.168.30.10 192.168.30.200; 按需修改 13.同步dhcp设置 cobbler sync 14.确保dhcp服务已启动（67端口） ss -ntlu 15.重启httpd cobbler服务 systemctl restart httpd cobblerd 16.挂载6,7磁盘 mount /dev/sr0 /mnt/cdrom0 mount /dev/sr1 /mnt/cdrom1 17.光盘导入 cobbler import –path=/mnt/cdrom0/ –name=CentOS-6.9-x86_64 –arch=x86_64 cobbler import –path=/mnt/cdrom1/ –name=CentOS-7.4-x86_64 –arch=x86_64 18.光盘导入完成后会自动生成对应版本最小化安装应答文件 cobbler distro list 列出有几套系统 CentOS-6.9-x86_64 CentOS-7.4-x86_64 cobbler profile list 列出有几套应答文件配置 CentOS-6.9-i386 CentOS-6.9-x86_64 CentOS-7.4-x86_6 19.可以删除不需要的应答文件 cobbler profile remove –name=CentOS-6.9-i386 cobbler distro remove –name=CentOS-6.9-i386 20.关联自己的应答文件 修改应答文件路径： vim ks.cfg url –url=$tree 修改路径（必要） 放置对应目录下： cp ks6_mini.cfg /var/lib/cobbler/kickstarts/ cp ks7_desktop.cfg /var/lib/cobbler/kickstarts/ cobbler profile add –name=CentOS-6.9-x86_64_Mini –distro=CentOS-6.9-x86_64 –kickstart=/var/lib/cobbler/kickstarts/ks6_mini.cfg cobbler profile add –name=CentOS-7.4-x86_64_Desktop –distro=CentOS-7.4-x86_64 –kickstart=/var/lib/cobbler/kickstarts/ks7_desktop.cfg 21.安装测试，新开一台虚拟机，网卡设置为仅主机 三、实验：实现基于web的cobbler前期准备：cobbler-web安装包，epel源 服务器：CentOS7:192.168.30.10 1.yum install cobbler-web 2.重启httpd服务 systemctl restart httpd 3.测试cobbler网页 https://192.168.30.10/cobbler_web/ 4.添加cobbler管理员账户 /etc/cobbler/modules.conf 定义了管理员账户的添加方式 可以看到默认认证方式定义在/etc/cobbler/users.digest文件中 方法一：默认方式创建用户test1 htdigest -c /etc/cobbler.users.digest Cobbler test1 要求输入口令 使用test1账户登录：登录成功： 就可以在页面上更改cobbler配置了 方法二：pam模块验证方法module = authn_pam cat /etc/cobbler/users.conf useradd -s /sbin/nologin test2 echo magedu | passwd –sdtin test2 vim /etc/cobbler/users.conf [admins] admin = test2 重启cobbler服务 systemctl restart cobblerd 使用test2账户登录：登录成功]]></content>
      <categories>
        <category>自动化运维</category>
      </categories>
      <tags>
        <tag>cobbler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PXE自动化安装系统相关实验]]></title>
    <url>%2F2018%2F05%2F26%2FPXE%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一、PEX简介：PXE(Preboot Execution Environment)：预启动执行环境 PXE是由Intel设计的协议，它可以使计算机通过网络而不是从本地硬盘、光驱等设备启动。 基于Client/Server的网络模式，支持远程主机通过网络从远端服务器下载 映像，并由此支持通过网络启动操作系统 PXE可以引导和安装Windows,linux等多种操作系统 PXE的工作原理：1)Client向PXE Server上的DHCP发送IP地址请求消息，DHCP检测Client是否合法（主要是检 测Client的网卡MAC地址），如果合法则返回Client的IP地址，同时将启动文件pxelinux.0的 位置信息一并传送给Client 2)Client向PXE Server上的TFTP发送获取pxelinux.0请求消息，TFTP接收到消息之后再向Client 发送pxelinux.0大小信息，试探Client是否满意，当TFTP收到Client发回的同意大小信息之后， 正式向Client发送pxelinux.0 3)Client执行接收到的pxelinux.0文件 4)Client向TFTP Server发送针对本机的配置信息文件（在TFTP 服务的pxelinux.cfg目录下）， TFTP将配置文件发回Client，继而Client根据配置文件执行后续操作。 5)Client向TFTP发送Linux内核请求信息，TFTP接收到消息之后将内核文件发送给Client 6)Client向TFTP发送根文件请求信息，TFTP接收到消息之后返回Linux根文件系统 7)Client启动Linux内核 8)Client下载安装源文件，读取自动化安装脚本 由此可见，要想实现PXE安装系统，首先要先搭建DHCP以及tftp服务器，我们接下来先介绍如何搭 建**一台DHCP以及tftp服务器。** 二、实验：模拟搭建DHCP服务器前期准备：准备一台CentOS7虚拟机作为DHCP服务器；网卡设为仅主机模式，设置固定IP地址， 关闭虚拟机的DHCP服务 1.关闭iptables，selinux服务 2.安装DHCP服务包 yum install dhcp 3.尝试启动dhcp服务 systemctl start dhcpd.service 我们发现dhcpd服务启动失败，原因是未配置dhcp.conf文件 4.系统自带的dhcp.conf是空文件，我们找到安装包自带的example进行修改 rpm –ql dhcp | grep example cp /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example /etc/dhcp/dhcp.conf 5.修改dhcp配置文件 vim dhcp.conf 其中全局语句块和subnet语句块均可使配置生效，subnet语句块优先级高于全局语句块 全局语句块： # option definitions common to all supported networks… option domaim-name “wxlinux.com” 指定获取主机域后缀 option domain-name-servers 114.114.114.114,8.8.8.8 指定DNS，可选 default-least-time 86400 结合生产环境，ip越充足，租期越大越好 max-lease-time 100000 最大租期时间 subnet语句块： # This is a very basic subnet declaration. subnet 192.168.30.0 netmask 255.255.255.0 { ​ range 192.168.30.10 192.168.30.100; 指定ip地址范围 ​ option router 192.168.30.1 指定网关 } 6.再次尝试启动dhcpd服务，并设置开机自启动 systemctl start dhcpd.service systemctl enable dhcpd.service 发现这次没有报错，dhcpd服务顺利启动 7.切换到另外一台CentOS6虚拟机 我们看到现在的ip地址为：192.168.30.158 执行命令重新获取ip地址： dhclient –d 新获取的地址为192.168.30.11，证明dhcp服务已搭建成功 利用systemctl status dhcpd 命令可观察dhcp分发地址的全过程 三、实验：模拟搭建tftp服务器前期准备：关闭服务器端，客户端的SELinux，以及防火墙 tftp服务器端：CentOS7:192.168.30.10 tftp客户端：CentOS6:192.168.30.11 tftp服务器端操作： 1.安装tftp服务 yum install tftp yum install tftp-server 2.开启服务 CentOS6: chkconfig tfcp on service xinted restart chkconfig tfcp enable CentOS7: systemctl start tftp.socket systemctl enable tftp.socket 3测试tftp服务 拷贝mbr7.bak文件到tftp目录下 cp mbr7.bak /var/lib/tftpboot/ 客户端： tftp 192.168.30.10 get menu.c23 文件通过tftp传输成功 ![1%Y5[PKHF}VCZB9PHN74UB 至此，dhcp及tfcp已在CentOS7上搭建完成，下面来实验用PEX安装CentOS系统四、实验：实现CentOS7的PXE安装前期准备：关闭SELinux策略，firewall防火墙 事先准备好应答文件ks7_mini.cfg，**ks7_desktop.cfg** 服务器端：CentOS7:192.168.30.10 1 安装必要包，并开启httpd服务 yum install dhcp tftp-server httpd syslinux systemctl enable dhcpd httpd tftp.socket systemctl start httpd 2.准备yum源 mkdir /var/www/html/centos/7 -pv 添加开机自动挂载光盘 vim /etc/fstab /dev/sr0 /var/www/html/centos/7 iso9660 defaults 0 0 挂载磁盘 mount dev/sr0 /var/www/html/centos/7 重新读取磁盘挂载 mount -a 2.制作ks.cfg文件 mkdir /var/www/html/ksdir/7 -pv cp /root/ ks7_desktop.cfg /var/www/html/ksdir/7/ks7_desktop.cfg cp /root/ ks7_mini.cfg /var/www/html/ksdir/7/ks7_mini.cfg chmod +r /var/www/html/ksdir/7/ks7_desktop.cfg 浏览器确认ks7.cfg能正常访问 3.修改ks.cfg文件 #Use CDROM installation media url –url=http://192.168.30.7/centos/7 #Use graphical install text #网卡 onboot=on 我们还可以在此添加ssh基于key的认证，使得新系统安装后可直接ssh连接 添加ssh基于key验证： %post mkdir /root/.ssh cat &gt; /root/.ssh/authorized_keys &lt;&lt; EOF ssh-rsa AAABBB…（服务器自授权公钥） EOF 4.配置dhcp服务 subnet 192.168.30.0 netmask 255.255.255.0 { ​ range 192.168.30.10 192.168.30.100; ​ option routers 192.168.30.254; ​ option domain-name-servers 8.8.8.8; ​ next-server 192.168.30.7; ​ filename “pxelinux.0”; } syetemctl dhcpd start 5.准备PXE相关文件 cd /var/lib/tftpboot/ mkdir pxelinux.cfg/ cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot rpm -ql syslinux|grep menu.c32 cp /usr/share/syslinux/menu.c32 /var/lib/tftpboot cp /misc/cd/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot cp /misc/cd/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default 最终目录树如下： 6.制作菜单 vim /var/lib/tftpboot/pxelinux.cfg/default default menu.c32 删掉背景，修改title等 menu title Auto Install System CentOS7: 见图 设置启动菜单： menu title Auto Install CentOS label desktop menu label Install ^Desktop CentOS 7 kernel vmlinuz append initrd=initrd.img ks=http://192.168.30.7/ksdir/7/ks7_desktop.cfg label mini menu label Install ^Mini CentOS 7 kernel vmlinuz append initrd=initrd.img ks=http://192.168.30.7/ksdir/7/ks7_mini.cfg label local menu default menu label Boot from ^local drive localboot 0xffff menu end 7.测试安装，新开一台虚拟机： 网卡设置为仅主机，正常启动将出现安装界面 我们选择Desktop安装 五、实验：在CentOS7实现PXE安装CentOS6,7双系统前期准备：关闭SELinux安全策略，关闭防火墙； 事先准备好应答文件ks6_mini.cfg，**ks7_desktop.cfg** 服务器：CentOS7:192.168.30.10 1 安装必要服务包 yum install dhcp tftp-server httpd syslinux systemctl enable dhcpd httpd tftp.socket systemctl start httpd 2 准备YUM源 mkdir /var/www/html/centos/{6,7}/ -pv vim /etc/fstab 加下面行 /dev/sr0 /var/www/html/centos/6 iso9660 defaults 0 0 /dev/sr1 /var/www/html/centos/7 iso9660 defaults 0 0 mount -a 3 准备ks文件 mkdir /var/www/html/ksdir/{6,7} -pv cp /root/ks6_mini.cfg /var/www/html/ksdir/7/ks6_mini.cfg cp /root/ks7_desktop.cfg /var/www/html/ksdir/7/ks7_desktop.cfg chmod +r /var/www/html/ksdir/7/ks7_desktop.cfg [root@centos7 tftpboot]#tree /var/www/html/ksdir/ /var/www/html/ksdir/ ├── 6 │ └── ks6_mini.cfg └── 7 ​ └── ks7_desktop.cfg 最好确认下应答文件是否可以httpd正常访问 4 配置dhcp服务 cp /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example /etc/dhcp/dhcpd.conf vim /etc/dhcp/dhcpd.conf [root@centos7 tftpboot]#cat /etc/dhcp/dhcpd.conf option domain-name “magedu.org”; option domain-name-servers 114.114.114.114,1.1.1.1; option routers 192.168.30.200; default-lease-time 86400; max-lease-time 100000; subnet 192.168.30.0 netmask 255.255.255.0 { ​ range 192.168.30.10 192.168.30.100; ​ option routers 192.168.30.254; ​ option domain-name-servers 8.8.8.8; ​ next-server 192.168.30.17; ​ filename “pxelinux.0”; } systemctl start dhcpd 5 准备PXE相关文件 rpm -ql syslinux mkdir /var/lib/tftpboot/pxelinux.cfg/ cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/ cp /usr/share/syslinux/menu.c32 /var/lib/tftpboot/ mkdir /var/lib/tftpboot/centos{6,7} cp /var/www/html/centos/7/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot/centos7/ cp /var/www/html/centos/6/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot/centos6/ cp /var/www/html/centos/7/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default 最终目录结构如下： 6.修改启动菜单 vim /var/lib/tftpboot/pxelinux.cfg/default default menu.c32 timeout 600 menu title AUTO Install CentOS6 or 7 label centos7 menu label ^Install Desktop CentOS 7 kernel centos7/vmlinuz append initrd=centos7/initrd.img ks=http://192.168.30.17/ksdir/ks7_desktop.cfg label centos6 menu label install ^Mini CentOS 6 menu default kernel centos6/vmlinuz append initrd=centos6/initrd.img ks=http://192.168.30.17/ksdir/ks6_mini.cfg label local menu label Boot from ^local drive localboot 0xffff menu end 6 客户端测试安装 一般能到达安装包界面就证明安装没问题了 登录成功：]]></content>
      <categories>
        <category>自动化运维</category>
      </categories>
      <tags>
        <tag>PXE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统日志管理]]></title>
    <url>%2F2018%2F05%2F25%2FLinux%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Linux系统中的日志记录了系统每天发生的各种各样的事情，你可以通过它来检查错误发生的原因， 或者受到攻击时攻击者留下的痕迹。日志对于安全来说，非常重要。 一、日志介绍日志主要包含以下内容：历史事件：时间，地点，人物，事件 日志级别：事件的关键性程度，Loglevel 系统中常见日志及说明： 系统日志服务：CentOS 5之前版本 syslogd syslogd: system application 记录应用日志 klogd: linux kernel 记录内核日志 事件记录格式： 日期时间 主机 进程[pid]: 事件内容 C/S架构：通过TCP或UDP协议的服务完成日志记录传送，将分布在不同主 机的日志实现集中管理 CentOS 6和7 rsyslog特性： 多线程 UDP, TCP, SSL, TLS, RELP MySQL, PGSQL, Oracle实现日志存储 强大的过滤器，可实现过滤记录日志信息中任意部分 自定义输出格式 ELK：elasticsearch, logstash, kibana 非关系型分布式数据库 基于apache软件基金会jakarta项目组的项目lucene Elasticsearch是个开源分布式搜索引擎 Logstash对日志进行收集、分析，并将其存储供以后使用 kibana 可以提供的日志分析友好的 Web 界面 日志常见术语参见man logger facility：设施，从功能或程序上对日志进行归类 auth, authpriv, cron, daemon,ftp,kern, lpr, mail, news, security(auth), user, uucp, local0-local7, syslog Priority： 优先级别，从低到高排序 debug, info, notice, warn(warning), err(error), crit(critical), alert, emerg(panic) 参看帮助： man 3 syslog 二、日志配置程序包：rsyslog 主程序：/usr/sbin/rsyslogd CentOS 6：service rsyslog {start|stop|restart|status} CentOS 7：/usr/lib/systemd/system/rsyslog.service 配置文件：/etc/rsyslog.conf，/etc/rsyslog.d/*.conf 库文件： /lib64/rsyslog/*.so 配置文件格式：由三部分组成 MODULES：相关模块配置 GLOBAL DIRECTIVES：全局配置 RULES：日志记录相关的规则配置 日志格式：RULES配置格式： facility.priority; facility.priority… target facility： *：所有的facility facility1,facility2,facility3,…：指定的facility列表 priority： ：所有级别；如：”authpriv.”表示authpriv认证信息服务产生的所有等级日志都记录 none：没有级别，即不记录 PRIORITY：指定级别（含）以上的所有级别 =PRIORITY：仅记录指定级别的日志信息，其他等级都不记录。如：”*.emerg”表示任何日志 服务产生的日志，只要等级为emerg就记录；此用法较少见，了解即可 target： 文件路径：通常在/var/log/，文件路径前的-表示异步写入 用户：将日志事件通知给指定的用户，* 表示登录的所有用户 日志服务器：@host，把日志送往至指定的远程服务器记录 管道： | COMMAND，转发给其它命令处理 /etc/rsyslog.conf#### RULES #### # Log all kernel messages to the console. 内核产生的任何日志 # Logging much else clutters up the screen. #kern.* /dev/console # Log anything (except mail) of level info or higher. 定义了系统中除邮箱，身份验证，计划任务以外的其他日志 # Don’t log private authentication messages! *.info;mail.none;authpriv.none;cron.none /var/log/messages 定义身份验证授权相关的日志文件路径 # The authpriv file has restricted access. authpriv.* /var/log/secure 定义邮件日志文件路径，”-“代表异步传输 # Log all the mail messages in one place. mail.* -/var/log/maillog 定义计划任务日志文件路径 # Log cron stuff cron.* /var/log/cron 系统出现严重问题时，每个人都会收到提示 # Everybody gets emergency messages .emerg :omusrmsg: 新闻相关服务日志文件 # Save news errors of level crit and higher in a special file. uucp,news.crit /var/log/spooler 本地预留定制日志 # Save boot messages also to boot.log local7.* /var/log/boot.log ################################## 三、日志管理Journalctl工具Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用 journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件 /etc/systemd/journald.conf journalctl用法 查看所有日志（默认情况下 ，只保存本次启动的日志） journalctl 查看内核日志（不显示应用日志） journalctl -k 查看系统本次启动的日志 journalctl -b journalctl -b -0 查看上一次启动的日志（需更改设置） journalctl -b -1 查看指定时间的日志 journalctl –since=”2017-10-30 18:10:30″ journalctl –since “20 min ago” journalctl –since yesterday journalctl –since “2017-01-10” –until “2017-01-11 03:00” journalctl –since 09:00 –until “1 hour ago” 显示尾部的最新10行日志 journalctl -n 显示尾部指定行数的日志 journalctl -n 20 实时滚动显示最新日志 journalctl -f 查看指定服务的日志 journalctl /usr/lib/systemd/systemd 查看指定进程的日志 journalctl _PID=1 查看某个路径的脚本的日志 journalctl /usr/bin/bash 查看指定用户的日志 journalctl _UID=33 –since today 查看某个 Unit 的日志 journalctl -u nginx.service journalctl -u nginx.service –since today 实时滚动显示某个 Unit 的最新日志 journalctl -u nginx.service -f 合并显示多个 Unit 的日志 journalctl -u nginx.service -u php-fpm.service –since today 查看指定优先级（及其以上级别）的日志，共有8级 0: emerg 1: alert 2: crit 3: err 4: warning 5: notice 6: info 7: debug journalctl -p err -b 日志默认分页输出，–no-pager 改为正常的标准输出 journalctl –no-pager 以 JSON 格式（单行）输出 journalctl -b -u nginx.service -o json 以 JSON 格式（多行）输出，可读性更好 journalctl -b -u nginx.serviceqq -o json-pretty 显示日志占据的硬盘空间 journalctl –disk-usage 指定日志文件占据的最大空间 journalctl –vacuum-size=1G 指定日志文件保存多久 journalctl –vacuum-time=1years Logrotate工具logrotate 程序是一个日志文件管理工具。用来把旧的日志文件删除，并创建新 的日志文件，称为日志转储或滚动。可以根据日志文件的大小，也可以根据其 天数来转储，这个过程一般通过 cron 程序来执行 配置文件：/etc/logrotate.conf 四、远程日志Linux系统中的日志不仅可以在本地存储，还可以远程发送至指定的主机，设置指定的Mysql数据库中。 启用远程日志服务： 通常的日志格式： 事件产生的日期时间 主机 进程(pid)：事件内容 如： /var/log/messages,cron,secure等 配置rsyslog成为日志服务器 #### MODULES #### # Provides UDP syslog reception $ModLoad imudp $UDPServerRun 514 # Provides TCP syslog reception $ModLoad imtcp $InputTCPServerRun 514 五、实验：实现远程日志前期准备：虚拟机三台 发送日志端：192.168.30.10 远程接收端：192.168.30.17 访问端：192.168.30.11 发送日志端：修改sshd默认日志为local2，记录等级至少为INFO vim /etc/ssh/sshd_config vim /etc/rsyslog.d/ssh.conf local2.* @192.168.30.17 #若使用tcp协议，格式：@@IP local2.* /var/log/local2.log #若要本机和远程都记录日志可添加此行 重启日志及SSH服务 systemctl restart rsyslog sshd 远程接收端：开启514端口 #$ModLoad imudp ==&gt; 去掉注释 #$UDPServerRun 514 ==&gt; 去掉注释 # Save boot messages also to boot.log local2.* /var/log/local2.log #添加此行 重启日志服务 systemctl restart rsyslog 查看514端口是否已开启 ss -untl 测试：切换到访问端ssh连接192.168.30.10 ssh 192.168.30.10 切换到远程接收端，已收到日志发生端发送过来的日志 六、实验：实现基于MySQL的远程日志前期准备：虚拟机三台 发送日志端：192.168.30.10 远程接收端：192.168.30.17 访问端：192.168.30.11 发送日志端：安装rsyslog-mysql包 yum install rsyslog-mysql rpm -ql rsyslog-mysql 将mysql- createDB.sql发送到远程接收端 scp /usr/share/doc/rsyslog-8.24.0/mysql-createDB.sql 192.168.30.17:/root/ 切换到远程接收端： 导入数据库 mysql &lt; mysql-createDB.sql mysql &gt; use Syslog mysql &gt; show tables; 创建一个syslog授权用户 mysql &gt; grant all on Syslog.* to syslog@’192.168.30.%’ identified by ‘centos’; musql &gt; flush privileges; 日志发送端：vim /etc/rsyslog.conf #### MODULES #### $ModLoad ommysql #添加ommysql模块 #### RULES #### *.info;mail.none;authpriv.none;cron.none :ommysql:192.168.30.17,Syslog,syslog,centos 重启日志服务 systemctl restart rsyslog 模拟一条日志信息 logger “this is a test log” 切换回远程接收端 能看到刚刚发送的模拟日志信息 Mysql&gt; select * from SystemEvents\G; 七、实验：通过loganalyzer展示数据库中的日志前期准备：承接基于MySQL远程日志的实验环境 具体步骤：在rsyslog服务器上准备amp或nmp组合 yum install httpd php php-mysql php-gd 安装LogAnalyzer tar xvf loganalyzer-4.1.5.tar.gz cp -a loganalyzer-4.1.5/src /var/www/html/loganalyzer cd /var/www/html/loganalyzer touch config.php chmod 644 config.php 重启httpd服务 systemctl start httpd 打开浏览器: http://192.168.30.17/loganalyzer/,出现下图页面，进行一些数据库的配置后，就可以进入 loganlyzer管理数据库中的日志了]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>日志管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH端口转发及相关实验]]></title>
    <url>%2F2018%2F05%2F18%2FSSH%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一、SSH端口转发相关概念 在上一节我们知道，SSH会自动加密和解密所有SSH客户端和服务器之间的网络数据。但是，SSH还同时 提供了一个非常有用的功能，这就是端口转发。它能够将其他TCP端口的网络数据通过安全的SSH协议 转发，例如：Telnet，SMTP等这些TCP应用都能从中受益，避免了用户名，密码以及隐私信息的明文传 输。而与此同时，如果在你的工作环境中防火墙限制了一些网络端口的使用，但是允许SSH的连接，那么 端口转发功能也能够将TCP端口转发来使用SSH进行通信。 SSH端口转发提供的功能主要有：1.加密SSH Client端至SSH Server端之间的数据 2.突破防火墙的限制完成一些之前无法建立的TCP连接 SSH端口转发提供的类型有：本地转发 远程转发 动态转发 X协议转发 本地转发：当外网用户想要临时访问公司内部的不安全TCP协议服务器时，由于防火墙限制无法直接访问，但可利用 先SSH连接至公司内网的SSH服务器在转发至不安全的TCP协议服务器。由于作为转发的SSH服务器与要访 问的不安全TCP协议服务器在同一网络环境内，故这种连接就叫本地转发。 格式： ssh -L localprot:remotehost:remotehostport sshserver localprot：指定本机端口 remotehost：指定远程不安全协议的服务器地址 remotehostport：远程不安全协议的服务器地址端口 sshserver：SSH服务器地址 options： -f 后台启用 -N 不打开远程shell，处于等待状态 -g 启用网关功能 示例： ssh -L 9527:telnetsrv:23 -N sshsrv telnet 127.0.0.1 9527 当访问本机的9527端口时，被加密后转发到sshsrv的ssh服务，再解密被转发到telnetsrv:23 大致流程： Data &lt;–&gt; localhost:9527 &lt;–&gt;localhost:xxxxx &lt;–&gt; sshsrv:22 &lt;–&gt;sshsrv:yyyyy &lt;–&gt; telnetsrv:23 远程转发：与本地端口转发相比，我们将SSH服务器与Client访问端的位置对调，将与不安全TCP协议服务器同一内网 的主机作为Client，将外部网络主机作为SSH服务器做为端口转发。由于作为转发的SSH服务器处在外部网 络环境中，故这种连接就叫远程转发。 格式：ssh -R sshserverport:remotehost:remotehostport sshserver sshserverport：指定SSH服务器端口 remotehost：指定远程不安全协议的服务器地址 remotehost:remotehostport：指定远程不安全协议的服务器端口 sshserver：SSH服务器地址 示例： ssh -R 9527:telnetsrv:23 -N sshsrv 让sshsrv侦听9527端口的访问，如有访问，就加密后通过ssh服务转发请求到本机ssh客户端，再由本机解密后转发到telnetsrv:23 大致流程： Data &lt;–&gt; sshsrv:9527 &lt;–&gt; sshsrv:22 &lt;–&gt; localhost:xxxxx &lt;–&gt; localhost:yyyyy &lt;–&gt; telnetsrv:23 动态端口转发：在之前我们已经了解了本地转发，以及远程转发，但它们实现的前提都是要求有一个固定的应用服务端端 口号。但在某些场景下，例如用浏览器浏览网页，是没有固定端口的，这时就需要利用到动态的端口转 发。比如说，当用firefox访问Internet时，本机的1080端口作为代理服务器，firefox的访问请求被转发到 sshserver上，由sshserver替代访问Internet ssh -D 1080 root@sshserver 在本机firefox设置socketproxy:127.0.0.1:1080 curl –socks5 127.0.0.1:1080 http://www.qq.com X协议转发：所有图形化应用程序都是X客户程序 能够通过tcp/ip连接远程X服务器 数据没有加密机，但是它通过ssh连接隧道安全进行 ssh -X user@remotehost gedit remotehost主机上的gedit工具，将会显示在本机的X服务器上 传输的数据将通过ssh连接加密 相关文件：/var/log/secure 存放日志 /etc/ssh/sshd_config SSH服务配置文件 #Port 22 端口 ​ 生产中一般第一步先改端口号 ​ 如Port 9527 定义公钥、私钥存放文件名，位置 HostKey /etc/ssh/ssh_host_rsa_key #HostKey /etc/ssh/ssh_host_dsa_key HostKey /etc/ssh/ssh_host_ecdsa_key HostKey /etc/ssh/ssh_host_ed25519_key 日志设置选项，日志存放在/var/log/secure # Logging #SyslogFacility AUTH SyslogFacility AUTHPRIV #LogLevel INFO #LoginGraceTime 2m 不输入密码最大时间端口 #PermitRootLogin yes 生产中一般改成no，普通用户连接su切换 #StrictModes yes 检查文件权限 #MaxAuthTries 6 密码登录最大验证次数 #MaxSessions 10 单个会话能开的最大克隆数 PasswordAuthentication yes 是否允许基于口令登录方式，no表示禁止 #ClientAliveInterval 0 连接后不操作最大时间，单位：秒 #ClientAliveCountMax 3 连接环不操作最大时间次数 ​ 生产中一般要修改AliveInterval 30 ​ AliveCountMax 3 ​ 表示连接后不进行任何操作30S，3次后自动断开连接 #ShowPatchLevel no UseDNS no 是否使用DNS反向解析，关闭可提高连接速度 #MaxStartups 10:30:100 最大并发连接数，默认10 限制可登录用户的办法： AllowUsers user1 user2 user3 DenyUsers AllowGroups DenyGroups SSH服务的最佳实践配置：建议使用非默认端口 禁止使用protocol version 1 限制可登录用户 设定空闲会话超时时长 利用防火墙设置ssh访问策略 仅监听特定的IP地址 基于口令认证时，使用强密码策略 tr -dc A-Za-z0-9_ &lt; /dev/urandom | head -c 30| xargs 使用基于密钥的认证 禁止使用空密码 禁止root用户直接登录 限制ssh的访问频度和并发在线数 经常分析日志 二、实验：模拟SSH本地端口转发应用场景：当外部客户端想要访问公司内网的Telnet服务器时，由于防火墙限制无法直接访问，可使用 SSH本地端口转发实现： 前期准备： 以三台CentOS模拟机作为服务器及主机，主机名网络配置如下： 客户端：192.168.30.133 SSH服务器：192.168.30.158 telnet服务器：192.168.30.160 telnet服务器端操作： 一、安装telnet-server包，系统默认未安装 二、防火墙禁止远程客户端访问： iptables -A INPUT -s 192.168.30.133 -j REJECT 为了防止之前防火墙策略干扰，最好先清空下防火墙策略： iptables -K 此时作为Clinet的192.168.30.133已经ping不通作为telnet服务器的192.168.30.160 三、开启telnet-server服务 CentOS6： service xinted start 开启xinted进程 chkconfig telnet on 开启telnet服务 service xinted restart 重启xinted服务 CentOS7： systemctl start telnet-scoket 客户端操作： ssh -L 9527:192.168.30.17:23 [-Nf] 192.168.30.6 加-Nf选项将后台执行，关闭时只能通过kill关闭进程 telnet 127.0.0.1 9527 提示输入用户名，密码；默认不让root账户使用SSH端口转发登录 三、实验：模拟SSH远程端口转发应用场景：当外部有工程师想要临时访问内部telnet服务器时，作为系统管理员，我们可以将对方主机作 为SSH服务器进行端口转发，让其临时可访问公司的telnet服务器。 前期准备： 以三台CentOS模拟机作为服务器及主机，主机名及网络配置如下： Internet：192.168.30.133 lanserver：192.168.30.158 telnet服务器：192.168.30.160 lanserver端操作： ssh -R 9527:192.168.30.17:23 [-Nf] 192.168.30.7 加-Nf选项将后台执行，关闭时只能通过kill关闭进程 Internet端操作： telnet 127.0.0.1 9527 四、实验：模拟SSH动态端口转发应用场景：在某些场景中，用浏览器浏览网页，是没有固定端口的，这时就需要利用到动态的端口转 发。下面我们模拟用一台虚拟机模拟google网站，用Internet主机通过代理服务器proxy访问google模拟机 前期准备： 以三台CentOS模拟机作为服务器及主机，主机名及网络配置如下： Internet：192.168.30.133 proxy：192.168.30.158 google：192.168.30.160 google模拟服务器操作： 开启http服务，模拟网页内容： CentOS6： service httpd start CentOS7： systemctl start httpd echo www.google.com &gt; /var/www/html/index.html 此时访问192.168.30.160，正常网页内容显示如下: Internet端操作： 此时在Internet端我们是无法访问google服务器的 使用proxy的1080端口作为动态转发： ssh -D 1080 root@192.168.30.158 接下来我们可以通过图形界面或者字符界面来尝试访问： 图形界面： 打开firefox浏览器，按以下顺序操作： –&gt;preferences–&gt;advanced–&gt;network–setting–manual proxy configuration –&gt;SOCKS Host:127.0.0.1 现在再次尝试访问192.168.30.160的google模拟服务器，发现可以正常访问了！ 字符界面： 在字符界面我们可执行下面的命令来进行访问： curl -socks5 127.0.0.1:1080 192.168.30.17]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH协议及基于SSH集群key认证实验]]></title>
    <url>%2F2018%2F05%2F18%2FSSH%E5%8D%8F%E8%AE%AE%E5%8F%8A%E5%9F%BA%E4%BA%8ESSH%E9%9B%86%E7%BE%A4key%E8%AE%A4%E8%AF%81%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[一、SSH协议相关概念SSH：secure shell，protocal，22/tcp，安全的远程登录； 利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题，用来代替早期不安全的telnet 具体的软件实现： OpenSSH：ssh协议的开源实现。CentOS默认安装 dropbear：另一个开源实现 SSH协议版本： v1: 基于CRC-32做MAC，不安全；man-in-middle v2：双方主机协议选择安全的MAC方式 基于DH算法做密钥交换，基于RSA或DSA实现身份认证 相关包： openssh openssh-clients openssh-server 工具： 基于C/S结构： Client： ​ Linux：ssh，scp，sftp，slogin ​ Windows：xshell，putty，securecrt，sshsecureshellclient Server：sshd 客户端组件： ssh, 配置文件：/etc/ssh/ssh_config Host PATTERN StrictHostKeyChecking no 首次登录不显示检查提示 格式： ssh [user@]host [COMMAND] ssh [-l user] host [COMMAND] -p port 远程服务器监听的端口 -b 指定连接的源IP -v 调试模式 -C 压缩方式 -X 支持x11转发，跨网络的图形界面显示；例如：xclock -Y 支持信任x11转发 ForwardX11Trusted yes -t 强制伪tty分配；堡垒机可用 ssh -t remoteserver1 ssh remoteserver2 两种方式的用户登录认证：基于password： 只要你知道自己帐号和口令，就可以登录到远程主机。所有传输的数据都会被加密，但是不能保证你正在连接的服务器就是你想连接的服务器。可能会有别的服务器在冒充真正的服务器，也就是受到“中间人”这种方式的攻击。 大致流程： 1.客户端发起ssh请求，服务器会把自己的公钥发送给用户 2.用户会根据服务器发来的公钥对密码进行加密 3.加密后的信息回传给服务器，服务器用自己的私钥解密，如果密码正确，则用户登录成功 基于key： 需要依靠密匙，也就是你必须为自己创建一对密匙，并把公用密匙放在需要访问的服务器上。如果你要连接到SSH服务器上，客户端软件就会向服务器发出请求，请求用你的密匙进行安全验证。服务器收到请求之后，先在该服务 器上你的主目录下寻找你的公用密匙，然后把它和你发送过来的公用密匙进行比较。如果两个密匙一致，服务器就用公用密匙加密“质询”（challenge）并把它发送给客户端软件。客户端软件收到“质询”之后就可以用你的 私人密匙解密再把它发送给服务器。 大致流程： 1.首先在客户端生成一对密钥 2.并将客户端的公钥ssh-copy-id拷贝到服务器端 3.当客户端再次发送一个连接请求，包括ip、用户名 4.服务端得到客户端的请求后，会到authorized_keys中查找，如果有响应的IP和用户，服务器就会发出“质询”（challenge）表现为一串随机字符，如：acdf。 5.服务端将使用客户端拷贝过来的公钥对“质询”进行加密，然后发送给客户端 6.得到服务端发来“质询”后，客户端会使用私钥进行解密，然后将解密后的字符串发送给服务端 7.服务端接受到客户端发来的字符串后，跟之前的字符串进行对比，如果一致，就允许免密码登录 两种登录认证的对比： 基于key的认证方式，用户必须指定自己密钥的口令。但是，与第一种级别相比，第二种级别不需要在网络上传送口令。 第二种级别不仅加密所有传送的数据，而且“中间人”这种攻击方式也是不可能的（因为他没有你的私人密匙）。但是整个登录的过程会比基于passwd认证稍长，可能需要10秒 相关文件： ~/.ssh/authorized_keys 存放已授权基于key登录的主机的公钥 ~/.ssh/know_hosts 存放本机SSH连接过的主机的公钥 操作：加快ssh服务访问速度 /etc/ssh/sshd_config文件 GSSAPIAuthentication yes–&gt;no 关闭api验证 #UseDNS yes|no–&gt;UseDNS no 去掉注释，启用DNS 重启sshd服务 CentOS6： service sshd restart CentOS7： systemctl restart sshd 二、实验：实现基于key登录认证一、在客户端生成一对钥匙： ssh-keygen -t rsa 交互式输入： 默认路径 输入口令 二、发送公钥给服务器端： ssh-copy-id wang@192.168.30.7 再次连接： ssh wang@192.168.30.7 不提示输入密码 ssh wang@192.168.30.7 ‘id’ 远程执行命令 利用基于key不需输入口令登录的特性，我们可小批量的执行一些任务： 先把需要执行任务的服务器IP放入一个文件中： cat ip.txt 192.168.30.7 192.168.30.12 192.168.30.17 …… 编写一个脚本显示主机名： vim hostname.sh hostname chmod +x hostname.sh 执行命令： 批量传送脚本 for ip in cat ip.txt;do scp -p f1.sh $ip:/data/;done 批量执行脚本显示主机名 for ip in cat ip.txt;do ssh $ip “/data/f1.sh”;done 可结合expect实现批量密钥登录方式 三、实验：实现多台机器间互相基于key登录认证思路：多台机器公用一套钥匙 一、在A机器上生成一对密钥，并对自己执行ssh-copy-id命令 ssh-keygen ssh-copy-id A 二、将本机.ssh目录发送给其他所有机器 scp -rp /root/.ssh B:/root/ scp -rp /root/.ssh C:/root/ 即可实现多台机器间互相基于key登录 当然，如果我们觉得私钥不加密不安全，我们还可以给私钥重新加密 重设私钥口令： ssh-keygen -p 私钥加密后，每次连接都要求输入私钥口令，我们可采取代理托管方式省去输入口令这一环节： 注：代理托管重启后失效，需重新设置 启用代理托管口令 ssh-agent bash ssh-add 四、实验：实现100台机器基于key登录验证一、准备ip列表 先把需要执行任务的服务器IP放入一个文件中： cat ip.txt 192.168.30.x 192.168.30.xx 192.168.30.xxx …… 二、编写将公钥推送到其他100台机器上的脚本 #!/bin/bash #安装expect包 rpm -q expect &amp;&gt; /dev/null || yum install expect -y #生成一对密钥，如需加密密钥可在-P之后写上密码 ssh-keygen -P “” -f “/root/.ssh/id_rsa” #服务器登录密码 password=centos while read ipaddr;do expect &lt;&lt;EOF set timeout 10 spawn ssh-copy-id $ipaddr expect { “yes/no” { send “yes\n”;exp_continue } “password” { send “$password\n” } } expect eof EOF done &lt; ip.txt 三、运行脚本，将公钥推送到其他100台机器上 四、实现基于密钥验证无密码登录 五、利用pssh工具实现集群管理注：系统默认未安装pssh工具，需使用epel源安装，使用pssh需先建立服务器端到用户端的基于 key验证才可以正常使用 pssh工具：pssh是一个python编写可在多台服务器上执行命令的工具，也可实现文件复制 options： –version 查看版本 -h 指定主机文件列表，内容格式”[user@]host[:port]” -H 指定主机，内容格式”[user@]host[:port]” -l 登录使用的用户名 -p 并发的线程数[可选] -o 输出的文件目录[可选] -e 错误输入文件[可选] -t TIMEOUT超过时间设置。0代表无限制[可选] -O SSH的选项 -v 查看过程 -A 手动输入密码模式 -x 额外的命令行参数使用空白符号，引号，反斜线处理 -X 额外的命令行参数，单个参数模式，同-x -i 显示每个服务器执行结果输出信息，默认不显示 -P 打印出服务器返回信息 未建立基于key验证将显示[FAILURE]失败 已建立基于key验证将显示[SUCCESS]成功 远程连接某主机执行hostname，显示主机名 pssh -H USER@192.168.x.x -i “hostname” 批量远程执行命令 一、将需要连接的主机写入一个文件 cat ip.txt 192.168.30.x 192.168.30.xx 192.168.30.xxx …… 二、批量显示文件中包含的主机名 pssh -h ip.txt -i “hostname”]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux网络安全技术]]></title>
    <url>%2F2018%2F05%2F18%2FLinux%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[一、网络安全基本概念信息安全防护的目标有：保密性 Confidentiality 信息不泄露给非授权用户、实体或过程，或供其利用的特性。 完整性 Integrity 数据未经授权不能进行改变的特性。即信息在存储或传输过程中保持不被修改、不被破坏和丢失的特性。 可用性 Usability 可被授权实体访问并按需求使用的特性。即当需要时能否存取所需的信息。例如网络环境下拒绝服务、破坏网络和有关系统的正常运行等都属于对可用性的攻击； 可控制性Controlability 对信息的传播及内容具有控制能力。 不可抵赖性 Non-repudiation 不可抵赖性包括对自己行为的不可抵赖及对行为发生的时间的不可抵赖。通过进行身份认证和数字签名可以避免对交易行为的抵赖，通过数字时间戳可以避免对行为发生的抵赖。 对于运维工程师最关键的两个工作职责：保证数据安全性、保证高可用性 安全防护环节物理安全：各种设备/主机、机房环境 系统安全：主机或设备的操作系统 应用安全：各种网络服务、应用程序 网络安全：对网络访问的控制、防火墙规则 数据安全：信息的备份与恢复、加密解密 管理安全：各种保障性的规范、流程、方法 生产环境中可能遇到的安全攻击Spoofing 假冒 假冒指的是某个实体（人或系统）发出含有其他实体身份信息的数据信息，假扮成其他实体，从而以欺骗方式获取一些合法用户的权利和特权。 Tampering 篡改 篡改消息是指一个合法消息的某些部分被改变、删除，消息被延迟或改变顺序，通常用以产生一个未授权的效果。如修改传输消息中的数据，将“允许甲执行操作”改为“允许乙执行操作”。 Repudiation 否认 Information Disclosure 信息泄漏 窃听是网络攻击中最常用的手段。目前应用最广泛的局域网上的数据传送是基于广播方式进行的，这就使一台主机有可能受到本子网上传送的所有信息。 Denial of Service 拒绝服务 拒绝服务即常说的DoS（Deny of Service），会导致对通讯设备正常使用或管理被无条件地终端。通常是对整个网络实施破坏，以达到降低性能、终端服务的目的。这种攻击也可能有一个特定的目标，如到某一特定目的地（如安全审计服务）的所有数据包都被组织。 Elevation of Privilege 提升权限 黑客可能通过一些漏洞来执行一些远程代码，来在你的系统中得到权限，当黑客得到管理者权限之后，就会通过一些特权命令或者提全程序来得到root权限。来达到控制你的系统的目的。 二、加密技术加密技术是电子商务采取的基本安全措施，交易双方可根据需要在信息交换的阶段使用。加密技术分为两 类，即对称加密和非对称加密。 ### 1.对称加密对称加密：加密key1与解密key2用的是用一把密钥 优势：速度快、效率高，适合加密大量的数据 特性：将原始数据分割成固定大小的块，逐个进行加密 缺点：密钥过多；密钥分发；数据来源无法确认 算法：DES、3DES、AES、Blowfish、Twofish、IDEA、RC6、CAST5等 对称加密命令：1）gpg命令： 对称加密file文件 ​ gpg -c file ​ ls file.gpg 在另一台主机上解密file ​ gpg -o file -d file.gpg 2）openssl命令： 对称加密： 工具：openssl enc, gpg 算法：3des, aes, blowfish, twofish enc命令： 帮助：man enc 加密： ​ openssl enc -e -des3 -a -salt -in testfile ​ -out testfile.cipher 解密： ​ openssl enc -d -des3 -a -salt –in testfile.cipher ​ -out testfile ​ openssl ? 2.非对称加密使用一对密钥来分别完成加密和解密操作，其中一个公开发布（即公钥），另一个由用户自己秘密保存（即私钥） 举例来讲，Alice要与Bob进行通信： Alice —&gt; Bob Alice：public-A（公钥），secret-A（私钥） Bob：public-B（公钥），secret-B（私钥） 公钥公开，私钥不可公开，只有自己有 公钥加密—&gt;需要对应私钥解密 优点：解决了对称加密无法确认数据来源，密钥过多的缺点 缺点：加密效率低、速度慢、密码长，适合加密较小的数据 算法：RSA（加密、数字签名），DSA（数字签名），ELGamal data—加密Pb（data）—解密Sb{Pb（data）}—data 加密功能 data—加密Sa（data）—解密Pa{Sa（data）}—data 数据来源功能 非对称算法DES和**对称算法RSA**和大概对应关系： 加密算法 文件大小 加密后大小 加密所需时间 解密所需时间 DES 1G 2G 4m 8m RSA 1G 1G 1m 64hour 非对称加密命令：1）gpg命令： 在hostB主机上用公钥加密，在hostA主机上解密 在hostA主机上生成公钥/私钥对 注：此步骤必须在图形界面下进行 ​ gpg –gen-key rng_tools 在hostA主机上查看公钥 ​ gpg –list-keys 在hostA主机上导出公钥到wang.pubkey ​ gpg -a –export -o wang.pubkey 从hostA主机上复制公钥文件到需加密的B主机上 ​ scp wang.pubkey hostB: 在需加密数据的hostB主机上生成公钥/私钥对 ​ gpg –list-keys ​ gpg –gen-key 在hostB主机上导入公钥 ​ gpg –import wang.pubkey ​ gpg –list-keys 用从hostA主机导入的公钥，加密hostB主机的文件file,生成file.gpg ​ gpg -e -r wangx file ​ file file.gpg 复制加密文件到hostA主机 ​ scp fstab.gpg hostA: 在hostA主机解密文件 ​ gpg -d file.gpg ​ gpg -o file -d file.gpg 删除公钥和私钥 ​ gpg –delete-keys wangx ​ gpg –delete-secret-keys wangx 2）openssl命令： 生成密钥对：man genrsa 生成私钥 ​ openssl genrsa -out /PATH/TO/PRIVATEKEY.FILE NUM_BITS ​ (umask 077; openssl genrsa –out test.key –des 2048) openssl rsa -in test.key –out test2.key 将加密key解密 从私钥中提取出公钥 ​ openssl rsa -in PRIVATEKEYFILE –pubout –out PUBLICKEYFILE ​ openssl rsa –in test.key –pubout –out test.key.pub 三、认证技术认证技术是用电子手段证明发送者和接收者身份及其文件完整性的技术，即确认双方的身份信息在传送或存储过程中未被篡改过。 要想解释数字签名的原理，先来了解hash单向散列和digest摘要概念： 单向散列：将任意数据缩小成固定大小的“指纹” 特性： 任意长度输入 固定长度输出 若修改数据，指纹也会改变（“不会产生冲突”） 法从指纹中重新生成数据（“单向”） 功能：数据完整性 常见hash算法： md5: 128bits、sha1: 160bits、sha224 sha256、sha384、sha512 常用工具： md5sum | sha1sum [ –check ] file openssl、gpg rpm -V digest摘要=hash（data） 经过hash算法得出的结果我们称为摘要，摘要单向不可推，即只拿到摘要digest是无法反推出数据的 特性：数据不变，摘要不变；数据有小变化，则摘要完全改变，雪崩效应 digest长度固定大小 md5：128 shal：160 1.数字签名数字签名：对数据进行hash计算后的摘要进行私钥加密。 也称电子签名，如同出示手写签名一样，能起到电子文件认证、核准和生效的作用。 即：Sa{hash（data）} 数字证书完整流程： 客户端： 1.对原文进行hash运算得到摘要digest hash（data） 2.将摘要用本方私钥加密得到数字签名 Sa{hash（data）} 3.连同原文同签名一起发送 data+Sa{hash（data）} 服务器端： 1.接收到原文与签名后，用客户端公钥解锁摘要 pa–&gt;hash（data） 2.再对原文进行hash计算 hash（data） 3.计算后的摘要与解锁摘要对比；如相同，则未被篡改；如不同，则发生过篡改 pa–&gt;hash（data）对比 hash（data） 2.数字证书数字证书是一个经证书授权中心（CA）数字签名的包括公钥拥有者信息以及公钥的文件。 数字证书的最主要构成包括一个用户公钥，加上密钥所有者的用户身份标识符，以及用户信任的证书权威机构（CA）签名 数字证书相关概念： 签证机构：CA（Certificate Authority） 注册机构：RA 证书吊销列表：CRL X.509：定义了证书的结构以及认证协议标准 版本号 序列号 签名算法 颁发者 有效期限 主体名称 根CA：普通CA上端还有其他CA认证，一个CA认证链的最顶端称为根CA或Root CA，Root CA自己给自己签名。 数字证书类型： 普通域名证书：www.tmall.com 只签名一个网站地址 泛域名证书：*.tmall.com 签名一类网站地址 数字证书获取： a）使用证书授权机构 生成签名请求（csr） 将csr发送给CA 从CA处接收签名 b）自签名的证书 自己签发自己的公钥 适用于公司内部网络加密，互联网中不认可 四、安全套接层协议SSL与OpenSSLSSL协议位于传输层和应用层之间，由SSL记录协议、SSL握手协议和SSL警报协议组成的。 SSL握手协议被用来在客户与服务器真正传输应用层数据之前建立安全机制。当客户与服务器第一次通信时，双方通过握手协议在版本号、密钥交换算法、数据加密算法和Hash算法上达成一致，然后互相验证 对方身份，最后使用协商好的密钥交换算法产生一个只有双方知道的秘密信息，客户和服务器各自根据此秘密信息产生数据加密算法和Hash算法参数。 SSL记录协议根据SSL握手协议协商的参数，对应用层送来的数据进行加密、压缩、计算消息鉴别码MAC，然后经网络传输层发送给对方。 SSL警报协议用来在客户和服务器之间传递SSL出错信息。 Record 协议：包括对消息的分段、压缩、消息认证和完整性保护、加密等 HTTPS 协议：就是“HTTP 协议”和“SSL/TLS 协议”的组合。HTTP over SSL”或“HTTP over TLS”，对http协议的文本数据进行加密处理后，成为二 进制形式传输 OpenSSL：OpenSSL 是一个安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。 三个组件： openssl：多用途的命令行工具，包openssl libcrypto：加密算法库，包openssl-libs libssl：加密模块应用库，实现了ssl及tls，包nss openssl命令： 两种运行模式：交互模式和批处理模式 openssl version：程序版本号 标准命令、消息摘要命令、加密命令 标准命令： enc, ca, req, … 对称加密与非对称加密命令上面已经提到，介绍下openssl的其他功能： 单向加密： 工具：md5sum, sha1sum, sha224sum,sha256sum… openssl dgst dgst命令： 帮助：man dgst ​ openssl dgst -md5 [-hex默认] /PATH/SOMEFILE ​ openssl dgst -md5 testfile ​ md5sum /PATH/TO/SOMEFILE MAC: Message Authentication Code，单向加密的一种延伸应用，用于实现 网络通信中保证所传输数据的完整性机制 CBC-MAC HMAC：使用md5或sha1算法 生成用户密码： passwd命令: 帮助：man sslpasswd ​ openssl passwd -1 -salt SALT(最多8位) ​ openssl passwd -1 –salt centos 生成随机数： 帮助：man sslrand ​ openssl rand -base64|-hex NUM NUM: 表示字节数；-hex时，每个字符为十六进制，相当于4位二进制，出现的字符数为NUM*2 随机数生成器：伪随机数字 键盘和鼠标，块设备中断 /dev/random：仅从熵池返回随机数；随机数用尽，阻塞 /dev/urandom：从熵池返回随机数；随机数用尽，会利用软件生成伪随机数,非阻塞 五、操作：搭建私有根CA，并向CA申请证书一、建立Root CA 1.生成私钥 ​ vim /etc/pki/tls/openssl.conf ​ (umask 066;openssl genrsa -out /etc/pki/CA/private/cakey.pem 4096) 2.自签名证书 ​ openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3650 -x509代表自己给自己前面 交互式填写： 国家：CN 省份：beijing 城市：beijing 公司名称：magedu 部门：M30 Common name：Magedu.com 查看生成的签名证书 ​ openssl x509 -in cacert.pem -noout -text ​ 二、用户或服务器 1.生成私钥 ​ （umask 066；openssl genrsa -out app.key 1024） 2.生成证书申请 ​ openssl req -new -key app.key -out app.csr 交互式填写： 国家：CN 省份：beijing 城市：beijing 公司名称：magedu 部门：M30 Common name：app.Magedu.com 注：国家，省份，公司必须一致才能申请成功 3.将申请文件发给CA ​ scp app.csr CA:IP 三、CA颁发证书 touch /etc/pki/CA/index.txt 建立已颁发证书信息列表文件；V：生效；R：吊销； echo 0F &gt; /etc/pki/CA/serial 建立证书序列号 openssl ca -in app.csr -out /etc/pki/CA/certs/app.crt -days 100 四、证书发送给客户端 ​ scp app.crt Client:IP 五、应用软件使用证书]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本三剑客之awk]]></title>
    <url>%2F2018%2F05%2F17%2F%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bawk%2F</url>
    <content type="text"><![CDATA[awk介绍：awk的名称来源于三个开发者的姓名：Aho, Weinberger, Kernighan，报告生成器，格式化文本输出， Linux文本处理三剑客之一。 有多种版本：New awk（nawk），GNU awk（gawk） 现在默认linux系统下日常使用的是gawk，用命令可以查看正在应用的awk的来源（ls -l /bin/awk ） Linux文本处理三剑客：grep：文本过滤工具（ sed： 文本编辑工具 awk：Linux上的实现gawk，文本报告生成 Awk编程语言用于处理文本文件。Awk在默认情况下，Awk文件的每一行都被视为一个记录。然后Awk记 录进一步分解成一系列的字段。Awk程序就是一系列作用在记录和字段上的”识别-执行”操作语句。 行row：记录record 列column：字段，域field，属性 awk工作原理：awk 程序通常由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块，共3部分组成 第一步：执行BEGIN{action；…}语句块中的语句 第二步：从文件或标准输入读取一行，然后执行pattern{action;…}语句块，它逐行扫描文件， ​ 从第一行到最后一行重复这个过程，直到文件全部被读取完毕。 第三步：当读至输入流末尾时，执行END{action;…}语句块 BEGIN语句块: 在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输入表格的表头等语句通常可以写在BEGIN语句块中， END语句块: 在awk从输入流中读取完所有的行后才被执行，比如打印所有所有行的分析结果，这里信息汇总都在END语句块中完成，它也是一个可选语句块 pattern语句块: 中的同用命令是最重要的部分，也是可选的。如果没有提供pattern语句块，则默认执行{print}，即打印每一个读取到的行，awk读取的每一行都会执行该语句块 BEGIN语句常用于打印表头 END语句往往用来做汇总 awk基本用法：awk基本用法： ​ awk [options] ‘program’ var=value file… ​ awk [options] -f programfile var=value file… ​ awk [options] ‘BEGIN{ action;… } pattern{ action;… } END{ action;… }’ file … option： 123-F 指明输入时用到的字段分隔符-v var=value: 自定义变量 基本格式：awk [options] ‘program’ var=value file… program：pattern{action statement} 其中 pattern 表示 AWK 在数据中查找的内容，而 action 是在找到匹配内容时所执行的一系列命令。 pattern和action： pattern部分决定动作语句何时触发及触发事件 如：BEGIN，END action statements对数据进行处理，放在{}内指明 如：print，printf 分隔符、域和记录 awk执行时，由分隔符分隔的字段（域）标记$1,$2…$n成为标识域。$0表示所有域，即整行 文件的每一行成为记录（record） 省略action,则默认执行print $0的操作 awk pattern根据pattern条件，过滤匹配到的行，再做处理 如果未指定：空模式，匹配每一行 /regular expression/：仅处理能够模式匹配到的行，需要用/ /括起来 123awk &apos;/^UUID/&#123;print $1&#125;&apos; /etc/fstab 取出包含UUID的行的第一个域awk &apos;！/^UUID/&#123;print $1&#125;&apos; /etc/fstab 取出不包含UUID的行的第一个域 relational expression：关系表达式，结果为”真”才会被处理 ​ 真：结果为非0值，非空字符串 ​ 假：结果为空字符串或0值 示例： 12345678910111213awk &apos;i=1&apos; /etc/passwd 结果为非零值，显示/etc/passwd内容awk &apos;i=0&apos; /etc/passwd 结果为零值，不显示/etc/passwd内容awk &apos;i=&quot;&quot;&apos; /etc/passwd 结果为空，不显示/etc/passwd内容awk &apos;!(i=&quot;&quot;)&apos; /etc/passwd 结果不为空，显示/etc/passwd内容awk -F: &apos;$NF==&quot;/bin/bash&quot;&#123;print $1$NF&#125;&apos; /etc/passwd 显示/etc/passwd文件中Shell为/bin/bash行的用户名和Shell类型awk -F: &apos;$NF~/bash$/&#123;print $1$NF&#125;&apos; /etc/passwd 显示/etc/passwd文件中以bash结尾行的用户名和Shell类型 line ranges：行范围 起始行，结尾行：/pat1/,/pat2/不支持直接给出数字格式 12# 显示root开头的行到nobody开头的行之间的用户名awk -F: &apos;/^root\&gt;/,/^nobody\&gt;/&#123;print $1&#125;&apos; /etc/passwd 12# 显示第10行到第20行，标准行号并显示用户名awk -F: &apos;(NR&gt;=10&amp;&amp;NR&lt;=20)&#123;print NR,$1&#125;&apos; /etc/passwd BEGIN/END模式 BEGIN{}：仅在开始处理文件中的文本之前执行一次 END{}：仅在文本处理完成之后执行一次 示例： 1234567891011121314151617181920# 在/etc/passwd文件每一行上都添加USER USERID，并在处理完文本后打印end fileawk -F: &apos;&#123;print &quot;USER USEID\n&quot;$1&quot;:&quot;$3&#125;END&#123;print &quot;end file&quot;&#125;&apos; /etc/passwdawk -F: &apos;&#123;print &quot;USER USEID&quot;;print $1″:&quot;$3&#125;END&#123;print&quot;end file&quot;&#125;&apos; /etc/passwd# 结果为0，条件为假，不显示seq 10|awk &apos;i=0&apos;# 结果不为0，条件为真，显示所有数字seq 10|awk &apos;i=1&apos;# 显示奇数，第一行i为空，!i则为非空，打印该行，第二行i为非空，!i为空则不打印，以此类推seq 10|awk &apos;i=!i&apos;# 显示1,0,1,0…即上例工作原理seq 10 | awk &apos;&#123;i=!i;print i&#125;&apos;# 显示偶数seq 10|awk &apos;!(i=!i)&apos;# 显示偶数，第一行i已赋值，所以!i为空，不显示seq 10 |awk -v i=1 &apos;i=!i&apos; awp操作符：输出操作符：print、printfprint格式： print item1，item2，… 要点： 逗号分隔符 输出的各item可以是字符串，也可以是数值；当前记录的字段、变量或awk的表达式 如省略item，相当于打印整行print $0 printf格式： 格式化输出：print “FORMAT”,item1,item2,… 要点： 必须指定FORMAT（格式） 不会自动换行，需要显示给出换行控制符，\n FROMAT中需要分别为后面每个item指定格式符 格式符：与item一一对应 12345678%c 显示字符的ASCII码%d,%i 显示十进制整数%e,%E 显示科学计数法数值%f 显示为浮点数%g,%G 以科学计数法或浮点形式显示数值%s 显示字符串%u 无符号整数%% 显示%自身 修饰符： 123#[.#] 第一个#控制显示的宽度；第二个#表示小数点后精度，%3.1f– 左对齐（默认右对齐）%-15s+ 显示数值的正负符号 %+d 示例： 123456789101112131415161718# 将/etc/passwd文件中所有用户名作为一个字符串输出 awk -F: &apos;&#123;printf &quot;%s&quot;,$1&#125;&apos; /etc/passwd awk -F: &apos;&#123;printf &quot;%s\n&quot;,$1&#125;&apos; /etc/passwd效果等同于awk -F: &apos;&#123;print $1&#125;&apos; /etc/passwd# 显示用户名左对齐，UID以十进制数显示且宽度为10 awk -F: &apos;&#123;printf &quot;%-20s %10d\n&quot;,$1,$3&#125;&apos; /etc/passwd awk -F: &apos;&#123;printf &quot;Username: %s\n&quot;,$1&#125;&apos; /etc/passwd效果等同于awk -F: &apos;&#123;print &quot;Username: &quot;$1&#125;&apos; /etc/passwdawk -F: &apos;&#123;printf &quot;Username: %s,UID:%d\n&quot;,$1,$3&#125;&apos; /etc/passwd显示结果如： Username: basher,UID:504awk -F: &apos;&#123;printf &quot;Username: %15s,UID:%d\n&quot;,$1,$3&#125;&apos; /etc/passwd显示结果如： Username: basher,UID:504 awk变量：变量：内置和自定义变量 内置变量： FS：输入字段分隔符，默认为空白字符 OFS：输出字段分隔符，默认为空白字符 RS：输入记录分隔符，指定输入时的换行符 ORS：输出记录分隔符，输出时用指定符号代替换行符 NF：字段数量 NR：记录号，相当于行号 FNR：同时针对多个文件时，分别计数，添加记录号 FILENAME：当前文件名 ARGC：命令行参数的个数 ARGV：数组，保存的是命令行所给定的各参数，参数标号默认从0开始，且第一个参数为awk命令本身 注：引用内置变量不需要加$ 示例： 1234567891011121314151617181920212223242526272829303132333435# 以：作为分隔符，显示每行的第一和第三个域，即用户名和UIDawk -F: &apos;&#123;print $1″:&quot;$3&#125;&apos; /etc/passwd 等价于awk -v FS=&apos;:&apos; &apos;&#123;print $1FS$3&#125;&apos; /etc/passwd# 以：作为分隔符，取出用户名，UID，shell类型，并以：分隔awk -v FS=&quot;:&quot; -v OFS=&quot;:&quot; &apos;&#123;print $1,$3,$7&#125;&apos; /etc/passwd没# 有记录分隔符，文件被看做一个整体记录，取$2即为第二行awk -v RS=&quot; &apos;&#123;print$2&#125;&apos; /etc/passwd# 没有记录分隔符，文件被看做一个整体的记录，文件尾添加###awk -v RS=&quot; -v ORS=&apos;###&apos; &apos;&#123;print&#125;&apos; /etc/passwd# 显示以：为分隔符，每一个行的字段数量awk -F: &apos;&#123;print NF&#125;&apos; /etc/passwd# 打印/etc/passwd每行的倒数第二个字段awk -F: &apos;&#123;print $(NF-1)&#125;&apos; /etc/passwd# 显示/etc/fstab文件每行行号，总行号awk &apos;&#123;print NR&#125;&apos; /etc/fstab ; awk END&apos;&#123;print NR&#125;&apos; /etc/fstab# 对/etc/fstab和/etc/inittab文件分别计数，显示行号awk &apos;&#123;print FNR&#125;&apos; /etc/fstab /etc/inittab# 在/etc/fstab文件每一行显示文件名awk &apos;&#123;print FILENAME&#125;&apos; /etc/fstab# 显示每行参数的个数awk &apos;&#123;print ARGC&#125;&apos; /etc/fstab /etc/inittab# 显示第一个和第二个参数：awk /etc/fstabawk &apos;BEGIN&#123;print ARGV[0],ARGV[1]&#125;&apos; /etc/fstab /etc/inittab 自定义变量（区分字符大小写）： -v var=value 在program中直接定义 注：{}内赋值变量要用；隔开； ​ {}外赋值变量时，每个变量前都要加-v选项； 示例： 12345678910111213141516# 在/etc/fstab文件每一行打印helloawk -v test=&apos;hello&apos; &apos;&#123;print test&#125;&apos; /etc/fstab # 打印helloawk -v test=&apos;hello&apos; &apos;BEGIN&#123;print test&#125;&apos;# 打印hello，&#123;&#125;内赋值变量后加；awk &apos;BEGIN&#123;test=&quot;hello&quot;;print test&#125;&apos; # 取出每行用户名，并在用户名后，打印male 18awk -F: &apos;&#123;age=18;sex=&quot;male&quot;;print $1,sex,age;&#125;&apos; /etc/passwd# 取出每一行的用户名和UID并在每行前面打印awkcat awkscript &#123;print script$1$3&#125;awk -F: -f awkscript script=&quot;awk&quot; /etc/passwd 算术操作符：x+y 加法运算 x-y 减法运算 x*y 乘法运算 x/y 除法运算（可精确到小数点） x^y 乘方运算 x%y 取余运算 示例： 12345计算9/2.2的结果为4.09091awk &apos;BEGIN&#123;print 9/2.2&#125;&apos;计算2的10次方显示1024awk &apos;BEGIN&#123;print 2^10&#125;&apos; 字符串操作符：没有符合的操作符，字符串连接 赋值操作符： =，+=，-=，*=，/=，%=，^=，++，– 示例： 12345678awk &apos;BEGIN&#123;i=0;print ++i,i &#125;&apos;显示：1 1awk &apos;BEGIN&#123;i=0;print i++,i &#125;&apos;显示：0 1awk &apos;BEGIN&#123;i=0;print i+=5,i&#125;&apos;显示：5 5 比较操作符： ==，!=，&gt;，&gt;=，&lt;，&lt;= 模式匹配符： ~ ：左边是否和右边匹配包含!~：是否不匹配 示例： 1234567891011# 取/etc/passwd文件中包含root的行中以：为分隔符的第一个域awk -F: &apos;$0 ~ /root/&#123;print $1&#125;&apos; /etc/passwd# 取/etc/passwd文件中以root开头的行awk &apos;$0 ~ &quot;^root&quot;&apos; /etc/passwd取/etc/passwd文件中不包含root的行awk &apos;$0 !~ &quot;root&quot;&apos; /etc/passwd# 取/etc/passwd文件中UID=0的行awk -F: &apos;$3==0&apos; /etc/passwd 逻辑操作符：&amp;&amp; 与 || 或 ！ 非 注意：这里的&amp;&amp;和||不是shell中的短路与和短路或，而是类似于[test]判断中的-a和-e 示例： 12345678# 取出/etc/passwd文件中UID大于0且小于1000的用户名awk -F: &apos;$3&gt;=0 &amp;&amp; $3&lt;=1000&#123;print $1&#125;&apos; /etc/passwd# 取出/etc/passwd文件中UID等于0或小于1000的用户名awk -F: &apos;$3==0 || $3&lt;=1000&#123;print $1&#125;&apos; /etc/passwd# 取出/etc/passwd文件中UID不等于0的用户名awk -F: &apos;!($3==0)&#123;print $1&#125;&apos; /etc/passwd 函数调用：function_name（argu1，argu2…） 条件表达式（三目表达式）：格式： 条件判断式？if-true-expression:if-false-expression 示例： 123456# 判断/etc/passwd文件中如果UID大于1000，在用户名后标注普通用户，如果UID小于1000，则标注root或系统用户awk -F: &apos;&#123;$3&gt;=1000?usertype=&quot;Common User&quot;:usertype=&quot;Sysadmin or SysUser&quot;;printf&quot;%15s:%-s\n&quot;,$1,usertype&#125;&apos; /etc/passwd显示：rpcuser:Sysadmin or SysUser nfsnobody:Common User awk循环判断：if-else语句语法：if（condition）{statement;…}[else statement] ​ if（condition1）{statement1;…}else if（condition2）{statement2;…}else{statement3} 使用场景：对awk取得的整行或某个字段做条件判断 示例： 1234567891011121314151617181920# 打印UID大于等于1000的用户名和UIDawk -F: &apos;&#123;if($3&gt;=1000)print$1,$3&#125;&apos; /etc/passwd# 打印shell类型为/bin/bash的用户名和UIDawk -F: &apos;&#123;if($NF==&quot;/bin/bash&quot;)print$1,$3&#125;&apos; /etc/passwd# 显示/etc/fstab文件中字段大于5的行awk &apos;&#123;if(NF&gt;5)print$0&#125;&apos; /etc/fstab# 取出UID大于等于1000用户名，并在前面加Common user：其他用户名前加System or root：awk -F: &apos;&#123;if($3&gt;=1000)&#123;printf &quot;Common user: %s\n&quot;,$1&#125;else&#123;printf &quot;System or root: %s\n&quot;,$1&#125;&#125;&apos; /etc/passwd# 等同于上例，在只有两种条件时，可用此格式替换awk -F: &apos;&#123;if($3&gt;=1000)printf &quot;Common user: %s\n&quot;,$1;else printf &quot;System or root: %s\n&quot;,$1&#125;&apos; /etc/passwd# 取出磁盘利用率大于80的磁盘名称和磁盘利用率df -h|awk -F% &apos;/^\/dev/&#123;print $1&#125;&apos;|awk &apos;$NF&gt;80&#123;print $1,$NF&#125;&apos;# 如果test打印90显示very good，大于60小于90显示good，小于60显示no passawk &apos;BEGIN&#123;test=100;if(test&gt;90)&#123;print &quot;very good&quot;&#125;else if(test&gt;60)&#123; print &quot;good&quot;&#125;else&#123;print &quot;no pass&quot;&#125;&#125;&apos; while循环语句语法：while（condition）{statement} 条件为”真”，进入循环；条件为”假”，退出循环 使用场景： a）对一行内的多个字段之一类似处理时使用 b）对数组中的各元素逐一处理时使用 示例： 12345# 取出grub2文件中空白开头跟linux16的行，并显示每个字段和每个字段的字符数awk &apos;/^[[:space:]]*linux16/&#123;i=1;while(i&lt;=NF) &#123;print $i,length($i); i++&#125;&#125;&apos; /etc/grub2.cfg# 取出grub2文件中空白开头跟linux16的行，并显示字符数大于10个的字段和对应字段的字符数awk &apos;/^[[:space:]]*linux16/&#123;i=1;while(i&lt;=NF)&#123;if(length($i)&gt;=10) &#123;print $i,length($i)&#125;; i++&#125;&#125;&apos; /etc/grub2.cfg do-whlie循环语句语法：do{statement;…}while（condition） 意义：无论真假，至少执行一次循环体 示例： 1234计算1到100的数字之和：awk &apos;BEGIN&#123;i=1;sum=0;do&#123;sum+=i;i++;&#125;while(i&lt;=100);print sum&#125;&apos;对比awk &apos;BEGIN&#123;i=1;sum=0;while(i&lt;=100)&#123;sum+=i;i++&#125;;print sum&#125;&apos; for循环语句语法：for(expr1;expr2;expr3) {statement;…} 常见用法： for(variable assignment;condition;iteration process) {for-body} 特殊用法：能够遍历数组中的元素 语法：for(var in array) {for-body} 示例： 12345计算1到100数字之和awk &quot;BEGIN&#123;for(i=0;i&lt;=100;i++)sum+=i;print sum&#125;&quot;与shell语言for循环第二种风格很类似：for ((i=1,sum=0;i&lt;=100;i++));do let sum+=i;done;echo $sum break和continue用于循环体中 break：提前结束本轮循环 continue：提前结束本轮循环，而直接进入下一轮判断； break[N]：提前结束第N层循环，最内层为第一层 continue[N]：提前结束第N层的本轮循环，而直接进入下一轮判断；最内层为第1层 示例： 12345# 计算1到100奇数之和，数字为偶数时跳过，奇数时相加awk &apos;BEGIN&#123;sum=0;for(i=1;i&lt;=100;i++)&#123;if(i%2==0)continue;sum+=i&#125;print sum&#125;&apos;# 数字加到66时，break退出循环，结果为1到66的数字之和awk &apos;BEGIN&#123;sum=0;for(i=1;i&lt;=100;i++)&#123;if(i==66)break;sum+=i&#125;print sum&#125;&apos; next语句提前结束对本行处理而直接进入下一行处理（awk自身循环） awk -F: ‘{if($3%2!=0) next; print $1,$3}’ /etc/passwd awk数组：关联数组：array[#] 下标： ​ a. 可使用任意字符串；字符串要使用双引号括起来 ​ b. 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化为”空串” 示例： 12345weekdays[&quot;mon&quot;]=&quot;Monday&quot;awk &apos;BEGIN&#123;weekdays[&quot;mon&quot;]=&quot;Monday&quot;;weekdays[&quot;tue&quot;]=&quot;Tuesday&quot;;print weekdays[&quot;mon&quot;]&#125;&apos;awk !arr[$0]++ dupfile 取出文件内容重复行 遍历数组：使用for循环可遍历数组中的每个元素 格式：for(var in array) {for-body} 注意：var会遍历array的每个索引 示例： 12345678# 显示weekdays[]数组中的每个元素awk &apos;BEGIN&#123;weekdays[&quot;mon&quot;]=&quot;Monday&quot;;weekdays[&quot;tue&quot;]=&quot;Tuesday&quot;;for(i in weekdays) &#123;print weekdays[i]&#125;&#125;&apos;# 显示网络连接每种状态的数量netstat -tan|awk &apos;/^tcp/&#123;state[$NF]++&#125;END&#123;for(i in state)&#123;print i,state[i]&#125;&#125;&apos;# 统计网络访问ip和访问次数awk &apos;&#123;ip[$1]++&#125;END&#123;for(i in ip) &#123;print i,ip[i]&#125;&#125;&apos; /var/log/httpd/access_log awk函数：系统内置函数： 数组处理： rand（）：返回0和1之间一个随机数，只有和srand（）函数配合才生效 示例： 12345# 返回0和1之间一个随机数awk &apos;BEGIN&#123;srand();print rand()&#125;&apos;# 返回10个0到100之间的随机数awk &apos;BEGIN&#123;srand();for(i=1;i&lt;=10;i++)print rand()*100&#125;&apos; 字符串处理： length([s])：返回指定字符串的长度 sub(r,s,[t])：对t字符串进行搜索r表示的模式匹配的内容，并将第一个匹配的内容替换为s 12示例：替换字符第一个出现的&quot;：&quot;为&quot;-&quot;；echo &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,&quot;-&quot;,$1)&apos; gsub(r,s,[t])：对t字符串进行搜索r表示的模式匹配的内容，并全部替换为s所表示的内容 12示例：全局替换字符第一个出现的&quot;：&quot;为&quot;-&quot;；echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos; split(s,array,[r])：以r为分隔符，切割字符串s，并将切割后的结果保存至array所表示的数组中， 第一个索引值为1,第二个索引值为2,… 自定义函数： 格式： function name ( parameter, parameter, … ) { ​ statements ​ return expression } 示例： 编写一个awk函数，比较两个数字的大小 123456789cat fun.awk function max(v1,v2) &#123; v1&gt;v2?var=v1:var=v2 return var &#125; BEGIN&#123;a=3;b=2;print max(a,b)&#125;# 文件调用函数awk –f fun.awk awk中调用shell命令：123awk BEGIN&apos;&#123;system(&quot;hostname&quot;) &#125;&apos;awk &apos;BEGIN&#123;score=100; system(&quot;echo your score is &quot; score) &#125;&apos;]]></content>
      <categories>
        <category>文本三剑客</category>
      </categories>
      <tags>
        <tag>akw</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SELinux简介]]></title>
    <url>%2F2018%2F05%2F15%2FSELinux%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[一、SELinux介绍：SELinux(Security-Enhanced Linux) 是美国国家安全局（NSA）对于强制访问控制的实现，是 Linux历史上最杰出的新安全子系统。NSA是在Linux社区的帮助下开发了一种访问控制体系，在 这种访问控制体系的限制下，进程只能访问那些在他的任务中所需要文件。 SELinux是一种基于 域-类型 模型（domain-type）的强制访问控制（MAC）安全系统，它由NSA 编写并设计成内核模块包含到内核中，相应的某些安全相关的应用也被打了SELinux的补丁，最 后还有一个相应的安全策略。任何程序对其资源享有完全的控制权。假设某个程序打算把含有潜 在重要信息的文件扔到/tmp目录下，那么在DAC情况下没人能阻止他。SELinux提供了比传统的 UNIX权限更好的访问控制。 传统UNIX系统使用的安全系统：自由访问控制（DAC：Discretionary Access Control） SELinx采用的安全系统：强制访问控制（MAC：Mandatory Access Control） DAC环境下进程是无束缚的 MAC环境下策略的规则决定控制的严格程度 MAC环境下进程可以被限制的 策略被用来定义被限制的进程能够使用那些资源（文件和端口） 默认情况下，没有被明确允许的行为将被拒绝 SElinux的工作类型：使用cat /etc/selinux/config 可以查看当前SELinux类型和系统支持的所有SELinux类型，不同系统版本支持类型有所不同 SELinux共有四种工作类型： （1）strict：centos5,每个进程都受到selinux的控制，不识别的进程将拒绝 （2）targeted： 用来保护常见的网络服务,仅有限进程受到selinux控制，只监控容易 被入侵的进程，centos4只保护13个服务，centos5保护88个服务，不识别的服务将允许 （3）minimum：centos7,修改的targeted，只对选择的网络服务 （4）mls：提供MLS（多级安全）机制的安全性 targeted现为CentOS系统默认SElinux类型，minimum和mls稳定性不足，未加以应用，strict现已不存在 SELinux的优点与缺点：优点： （1）通过MAC对访问的控制彻底化 （2）对于进程只赋予最小的权限 （3）防止权限升级 （4）对于用户只赋予最小的权限 缺点： （1）存在特权用户root （2）对于文件的访问权划分不够细 （3）SUID程序的权限升级 （4）DAC（Discretionary Access Control）问题 二、SELinux安全上下文传统Linux，一切皆文件，由用户，组，权限控制访问 在SELinux中，一切皆对象（object），由存放在inode的扩展属性域的 安全元素所控制其访问 所有文件和端口资源和进程都具备安全标签：安全上下文（security context） 安全上下文有五个元素组成： user:role:type:sensitivity:category user_u:object_r:tmp_t:s0:c0 user：指示登录系统的用户类型 role：定义文件，进程和用户的用途 type：指定了数据类别，type类别改变可能导致进程无法访问文件 sensitivity：限制访问的需要，由组织定义的分层安全级别。s0最低，Target策略默认使用s0 category：对于特定组织划分不分层的分类，Target策略默认不使用category 其中最重要的一项为文件的type标签，如httpd进程只能在httpd_t 里运行，/etc/passwd只有type 为passwd_file_t才能起作用，/var/log/messages文件如果不是var_log_t类型将无法记录日志等， 在SELinux安全策略中，修改了type类型，可能导致文件无法正常使用。 三、SElinux相关操作：1.SELinux启用、禁用SElinux共有三种运行模式： SELINUX=enforcing 启用SELinux SELINUX=disabled 彻底禁用SELinux SELINUX=permissive 禁用，但违反SELinux策略会产生告警 getenforce 显示当前SEliunx运行模式 a）利用命令临时修改： setenforce 0 临时切换到permissive setenforce 1 临时切换到enforcing b）修改配置文件： /etc/selinux/config /etc/sysconfig/selinux SELINUX={disabled|enforcing|permissive} /boot/grub/grub.conf 使用selinux=0禁用SElinux 注：grub.conf优先级高于/etc/selinux/config 2.修改SELinix安全标签：给文件重新打安全标签： chcon [OPTION]… [-u USER] [-r ROLE] [-t TYPE] FILE… chcon [OPTION]… –reference=RFILE FILE… -R：递归打标； 恢复目录或文件默认的安全上下文： restorecon [-R] /path/to/somewhere SELinux端口标签： semanage port -l|grep http 查看http允许使用的端口 semanage port -a -t http_port_t -t tcp 9527 添加http允许使用的端口包含9527 3.SELinux默认数据库查询与修改查看SELinux默认数据库： semanage fcontext -l 查看某文件放入默认SElinux类型： semanage fcontext -l | grep /path/file 添加到SELinux默认数据库： semanage fcontext -a –t httpd_sys_content_t ‘/testdir(/.*)?’ restorecon –Rv /testdir 从SElinux默认数据库中删除：（type类型将变回default_t） semanage fcontext -d –t httpdsyscontentt ‘/testdir(/.*)?’ 4.SELinux端口标签在SELinux安全策略中，定义了服务具体可使用的端口号，如果服务未使用对应的端口号，将会 导致无法使用，semanage命令也可以用来修改这些默认端口。 查看端口标签： semanage port –l 添加指定端口到指定服务： semanage port -a -t port_label -p tcp|udp PORT semanage port -a -t http_port_t -p tcp 9527 从指定服务删除指定端口： semanage port -d -t port_label -p tcp|udp PORT semanage port -d -t http_port_t -p tcp 9527 修改现有端口为新标签： semanage port -m -t port_label -p tcp|udp PORT semanage port -m -t http_port_t -p tcp 9527 5.SElinux布尔值布尔型规则： getsebool setsebool 查看bool命令： getsebool [-a] [boolean] semanage boolean –l semanage boolean -l –C 查看修改过的布尔值 设置bool值命令： setsebool [-P] boolean value（on,off） 不加-P只修改内存，临时生效 setsebool [-P] Boolean=value（0，1） 加-P同时修改内存和配置bool 6.SELinux日志管理：将错误的信息写入/var/log/message yum install setroubleshoot（重启生效） 查看安全事件日志说明 grep setroubleshoot /var/log/messages sealert -l UUID 扫描并分析日志 sealert -a /var/log/audit/audit.log 7.SELinux帮助：yum –y install selinux-policy-devel ( centos7.2) yum –y install selinux-policy-doc （centos7.3/7.4） mandb | makewhatis man -k _selinux 四、操作：SELinux环境下迁移httpd服务默认目录将默认目录/var/www/html迁移至/data/website/html目录 一、创建/data/html目录： mkdir /data/html 二、修改httpd服务配置文件 cat /etc/httpd/conf/httpd.conf #DocumentRoot “/var/www/html” 加上注释 DocumentRoot “/data/website/html” #&lt;Directory “/var/www/html”&gt; 加上注释 &lt;Directory “/data/website/html”&gt; 三、修改目录type类型： semanage fcontext -l |grep /var/www/html 查看默认目录的文件type类型 chcon -R -t httpd_sys_content_t /data/website/html 或： 修改安全上下文数据库 semanage fcontext -a -t httpd_sys_content_t /data/html（/.*）? restorecon -R /data/html 同步数据库type类型]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>SELINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统网络管理]]></title>
    <url>%2F2018%2F05%2F15%2FLinux%E7%B3%BB%E7%BB%9F%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[一、基本网络配置：将Linux主机接入网络，需要配置网络相关设置 一般包括以下内容： 主机名 IP/netmask 路由：默认网关 DNS服务器： 主DNS服务器 次DNS服务器 网络配置文件：IP、MASK、GW、DNS相关配置文件：/etc/sysconfig/networkscripts/ifcfg-IFACE： DEVICE=eth0 针对网卡名称（必须有） ONTBOOT=yes yes表示开机自动启动网卡，默认yes BOOTPROTO=dhcp 自动获取，生产中一般改为手动配置static|none（必须有） IPADDR=172.20.0.6 设置IP（必须有） NETMASK=255.255.0.0 传统方式配置掩码（必须有） PREFIX=16 CIDR法设置掩码（必须有） DEFROUTE=yes 是否将此配置的网关设为默认路由 GATEWAY=172.20.0.1 设置网关 DNS1=114.114.114.114 设置DNS1 DNS2=8.8.8.8 设置DNS2 TYPE 接口类型，常见有Ethernet，Bridge UUID 设备唯一表示 路由相关的配置文件：/etc/sysconfig/network-scripts/route-IFACE 注意：需service network restart生效 两种风格： (1) TARGET via GW 如：10.0.0.0/8 via 172.16.0.1 (2) 每三行定义一条路由 ​ ADDRESS#=TARGET ​ NETMASK#=mask ​ GATEWAY#=GW 网络配置方式：静态指定： ifconfig，route，netstat ip：object{link，addr，route}，ss，tc system-config-network-tui，setup 图形工具 直接修改配置文件 动态分配： DHCP： Dynamic Host Configuration Protocol 二、主机、网卡名称管理CentOS6网卡名称 接口命名方式： 以太网：eth[0,1,2…] ppp：ppp[0,1,2…] 网络接口识别并命名相关的udev配置文件： /etc/udev/rules.d/70-persistent-net.rules 查看网卡： dmesg |grep –i eth ethtool -i eth0 卸载网卡驱动： modprobe -r e1000 rmmod e1000 装载网卡驱动： modprobe e1000 修改主机名：hostname [NEWNAME] 临时生效，重启恢复 永久生效： CentOS6： 修改/etc/sysconfig/network CentOS7： 修改/etc/hostname 或：hostnamectl set-hostname [NEWNAME] hostname [NEWNAME] 使配置文件生效 修改CentOS7网卡命名为传统命名方式，实现自动化运维(1) 编辑/etc/default/grub配置文件 GRUB_CMDLINE_LINUX=”rhgb quiet net.ifnames=0″ 或：修改/boot/grub2/grub.cfg linux 16 行尾添加 net.ifnames=0 (2) 为grub2生成其配置文件 grub2-mkconfig -o /etc/grub2.cfg (3) 重启系统 修改本地解析器：/etc/hosts 本地主机名数据库和IP地址的映像 对小型独立网络有用 通常，在使用DNS前检查 一般建议在127.0.0.1的行尾加上本机的hostname 注：如果hostname发生更改，一定要记得同时更改/etc/hosts里的原添加内容 搭建网站也建议将网站地址与网页名称对应写入到/etc/hosts文件中，避免解析出错 设置DNS： /etc/resolv.conf nameserver DNS_SERVER_IP1 nameserver DNS_SERVER_IP2 nameserver DNS_SERVER_IP3 三、网卡别名对虚拟环境有用，可将多个IP地址绑定到一个网卡上 eth0：1、eth0：2、eth0：3 ifconfig命令： ifconfig eth0:0 192.168.1.100/24 up ifconfig eth0:0 down ip命令： ip addr add 172.16.1.2/16 dev eth0 ip addr add 172.16.1.1/16 dev eth0 label eth0:0 ip addr add 172.16.1.2/16 dev eth0 label eth0:0 ip addr del 172.16.1.1/16 dev eth0 label eth0:0 ip addr flush dev eth0 label eth0:0 为别名设备添加配置文件，永久生效 （1）service NetworkManager stop 关闭图形界面网络管理 （2）ifctg-ethX：xxx （3）必须使用静态IP配置 DEVICE=eth0：0 IPADDR=10.10.10.10 NETMASK=255.0.0.0 ONPARENT=yes （4）最后重启网络服务 service network restart 四、网络接口配置bondingBonding是将多个网卡绑定同一IP地址对外提供服务，可以实现高可用或者负载均衡。直接给两块网卡 设置同一IP地址是不可以的。通过bonding，虚拟一块网卡对外提供链接，物理网卡被修改为相同的MAC 地址 Bonding工作模式： Mode 0 (balance-rr) 轮转（Round-robin）策略：从头到尾顺序的在每个slave接口上发送数据包。提供负载均衡和容错的能力 Mode 1 (active-backup) 活动-备份（主备）策略：只有一个slave被激活，当且仅当活动的slave接口失败时才会激活其他slave。 为了避免交换机发生混乱此时绑定的MAC地址只有一个外部端口上可见 Mode 3 (broadcast) 广播策略：在所有的slave接口上传送所有的报文,提供容错能力 查看bond0主备状态：/proc/net/bonding/bond0 创建bonding设备的配置文件 /etc/sysconfig/network-scripts/ifcfg-bond0 DEVICE=bond0 BOOTPROTO=none BONDING_OPTS= “miimon=100 mode=0” /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 BOOTPROTO=none MASTER=bond0 SLAVE=yes USERCTL=no 也可使用nmcli实现bonding 添加bonding接口 nmcli con add type bond con-name mybond0 ifname mybond0 mode active-backup 添加从属接口 nmcli con add type bond-slave ifname ens7 master mybond0 nmcli con add type bond-slave ifname ens3 master mybond0 注：如无为从属接口提供连接名，则该名称是接口名称加类型构成，要启动绑定，则必须 首先启动从属接口 nmcli con up bond-slave-eth0 nmcli con up bond-slave-eth1 启动绑定 nmcli con up mybond0 取消bonding 1.卸载驱动模块 lsmod 显示所有已加载的驱动模块 lsmod | grep bond ifconfig bond0 down 禁用网卡 modproble -r bonding 2.删除和修改文件 rm -r ifcfg-bond0 vim ifcfg-eth{0,1} service network restart 重启网络服务 五、实现网络组代替bonding的一种技术 网络组：将多个网卡聚合在一起的方法，从而实现冗错和提高吞吐量 多种方式运行： broadcast 广播模式 roundrobin 轮播模式 activebackup 主备模式 loadbalance 负载均衡模式 lacp (implements the 802.3ad Link Aggregation Control Protocol) 创建网络组Network Teaming（RHCE） nmcli con add type team con-name team0 ifname team0 config ‘{“runner”: {“name”: “loadbalance”}}’ nmcli con mod team0 ipv4.addresses 192.168.1.100/24 nmcli con mod team0 ipv4.method manual nmcli connection show nmcli con add con-name team0-eth1 type team-slave ifname eth1 master team0 nmcli con add con-name team0-eth2 type team-slave ifname eth2 master team0 nmcli con up team0 nmcli con up team0-eth1 nmcli con up team0-eth2 nmcli connection show teamdctl team0 state 删除网络组： 第一种方法：删除network-scripts下配置文件 第二种方法：nmcli connection delete team0 team0-eth1 team0-eth2 六、Linux网络管理常用命令：ifconfig 命令 配置网络接口-a 查看所有接口信息 interface up|down 禁用|启用接口 设置IP地址 ifconfig IFACE IP/netmask 支持两种掩码设置IP IP netmask 注意：此命令执行将立即生效 route 命令 路由管理命令-n 查看路由表 添加路由： route add [-net|-host] target [netmask Nm] [gw Gw] [[dev] if] 添加目标：192.168.1.3 网关：172.16.0.1到路由表 route add -host 192.168.1.3 gw 172.16.0.1 dev eth0 添加目标：192.168.0.0 网关：172.16.0.1到路由表 route add -net 192.168.0.0 netmask 255.255.255.0 gw 172.16.0.1 dev eth0 route add -net 192.168.0.0/24 gw 172.16.0.1 dev eth0 添加默认路由，网关：172.16.0.1到路由表 route add -net 0.0.0.0 netmask 0.0.0.0 gw 172.16.0.1 route add default gw 172.16.0.1 删除路由： route del [-net|-host] target [netmask Nm] [gw Gw] [[dev] if] 配置动态路由 通过首行进程获取动态路由 安装quagga包 支持多种路由协议：RIP（根据跳数）、OSPF（综合带宽、跳数等）和BGP 命令vtysh配置 netstat 命令 查看网络连接，路由表，接口统计等信息option： -t tcp协议相关 -u udp协议相关 -w raw socket相关 -l 处于监听状态 -a 所有状态 -n 以数字显示所有IP和端口 -e 扩展格式 -p 显示相关进程及PID 常用组合选项： -nr 查看路由表 -nt 查看TCP进程 -ntu 查看TCP及UDP进程 -ntul 查看处于监听状态LISTEN的服务 -tul 端口程序不进行名称解析显示 -ntua 查看所有状态的服务 -ntuap 查看哪个进程打开的此端口 -ntuape 扩展信息，包括使用用户UID 统计端口数据 -i 查看网卡收发包信息 -I=eth0 只显示eth0网卡收发包信息等同于ifconfig -s eth0 ss 命令格式：ss [option]…[FILTER] 用来代替netstat的新命令，netstat通过遍历proc来获取socket信息，ss使用netlink与内核tcp_diag 模块通信获取socket信息。 option： -t tcp协议相关 -u udp协议相关 -w 裸套接字相关 -x unix sock相关 -l listen状态的链接 -a 所有链接 -n 以数字格式显示 -p 相关的程序及PID -e 扩展的信息 -m 内存用量 -o 计时器信息 TCP常见状态： LISTEN 监听 ESTABLISHED 已建立的链接 FIN_WAIT_1 FIN_WAIT_2 SYN_SENT CLOSED 支持EXPRESSION： dport= 目标端口 sport= 源端口 常用组合用法与netstat类似 -tan，-tanl等 常见用法： ss -l 显示本地打开的所有端口 ss -pl 显示每个进程具体打开的socket ss -t -a 显示所有tcp socket ss -u -a 显示所有的UDP Socekt ss -o state established ‘( dport = :ssh or sport = :ssh )’ 显示所有已建立的ssh连接 ss -o state established ‘( dport = :http or sport = :http )’ 显示所有已建立的HTTP连接 ss -s 列出当前socket详细信息 ip 命令 配置Linux网络属性格式：ip [OPTIONS] OBJECT {COMMAND|help} ​ OBJECT={link|addr|route} 网络设备配置： ip link set IFACE down|up 禁用|启用网卡 ip link show [up] 显示数据链路层信息[仅显示处于激活状态接口] ip地址设置： ip addr {add|del} IP dev IFACE ip address add IP dev IFACE label ALIASIFACE 添加地址时指定网卡别名 ip address add IP dev IFACE scpe{global|link|host} 指明作用域 global：全局可用 link：仅链接可用 host：本机可用 ip address flush dev IFACe 清空IP地址 路由管理： ip r|route [show|list] 查看路由表 ip route add|del TARGET via GW dev IFACE 添加|删除路由 ip route flush dev IFACE 清空路由表 常用命令： ip help 查看ip命令使用帮助 ip link 查看数据链路层信息 ip link set eth1 up|down 设置eth1网卡启用|禁用 ip address|a 查看网卡信息 ip route|r 查看路由信息 ip route add|del IP/24 via gateway 添加路由 ip address add 2.2.2.2/24 dev eth0 添加IP地址 ip address add 2.2.2.2/24 dev eth0 label eth0：2添加别名网卡IP地址 ip address flush dev eth0 清空eth0网卡上所有ip地址 nmcli 管理网络管理器的命令行工具格式：nmcli [OPTIONS] OBJECT COMMAND OBJECT： device 显示和管理网络接口 connection|con 管理网络连接 修改IP地址等属性： nmcli connection modify IFACE [+|-]setting.property value setting.property： ipv4.addresses ipv4.gateway ipv4.dns1 ipv4.method manual | auto 修改配置文件执行生效： systemctl restart network nmcli con reload 设备即网络接口，连接是对网络接口的配置。一个网络接口可有多个连接配置， 但同时只有一个连接配置生效 使连接配置生效|失效： nmcli con up|down eth0 显示所有包括不活动连接 nmcli con show 显示所有活动连接 nmcli con show –active 显示网络连接配置 nmcli con show “System eth0“ 显示设备状态 nmcli dev status 显示网络接口属性 nmcli dev show eth0 创建新连接default，IP自动通过dhcp获取 nmcli con add con-name default type Ethernet ifname eth0 删除连接 nmcli con del default 创建新连接static ，指定静态IP，不自动连接 nmcti con add con-name static ifname eth0 autoconnect no type Ethernet ipv4.addresses 172.25.X.10/24 ipv4.gateway 172.25.X.254 启用static连接配置 nmcli con up static 启用default连接配置 nmcli con up default 查看帮助 nmcli con add help 修改连接设置 nmcli con mod“static” connection.autoconnect no nmcli con mod “static” ipv4.dns 172.25.X.254 nmcli con mod “static” +ipv4.dns 8.8.8.8 nmcli con mod “static” -ipv4.dns 8.8.8.8 nmcli con mod “static” ipv4.addresses “172.25.X.10/24 172.25.X.254” nmcli con mod “static” +ipv4.addresses 10.10.10.10/16 DNS设置，存放在/etc/resolv.conf文件中 PEERDNS=no 表示当IP通过dhcp自动获取时，dns仍是手动设置，不自动获取。等价于下 面命令： nmcli con mod “system eth0” ipv4.ignore-auto-dns yes 修改连接配置后，需要重新加载配置： nmcli con reload nmcli con down “system eth0” 可被自动激活 nmcli con up “system eth0” nmcli dev dis eth0 禁用网卡，访止被自动激活 图形工具 nm-connection-editor 字符工具 nmtui nmtui-connect nmtui-edit nmtui-hostname 测试网络在命令行下测试网络的连通性 显示主机名 hostname 测试网络连通性 ping mtr 显示正确的路由表 ip route 确定名称服务器使用： nslookup host dig 跟踪路由 traceroute tracepath 网络客户端工具ftp，lftp：子命令：get、mget、ls、help ftp [-p port] [-u user[,password]] SERVER lftpget URL 直接跟URL地址下载 wget [option]… [URL]… -q: 静默模式 -c: 断点续传 -P：保存在指定目录 -O: 保存为指定的文件名 –limit-rate=: 指定传输速率，单位K,M等，生产中最好限速 links URL 图形界面浏览器 –dump 只显示文字 –source 查看网页源码]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>网络管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统计划任务]]></title>
    <url>%2F2018%2F05%2F13%2FLinux%E7%B3%BB%E7%BB%9F%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[在生活、生产环境中，我们可能遇到这样的场景，想在某个时刻，或者固定某个时间周期的在Linux系统中 执行某项任务，例如，定时关机，定期自动清理垃圾文件等，at，crontab等命令就是帮你实现这样功能的。 一、同步服务器时间在进行计划任务之前，一定要确保服务器的时间是准确无误的，否则将造成计划任务失败或者无法达到 预期效果，尤其是在大规模的集群环境中，更显得尤为重要，所以我们首先要学会的就是同步服务器时 间。 CentOS6： ntpdata 172.x.x.x 将时间与服务器同步 vim /etc/ntp.conf 修改此文件 server 172.x.x.x iburst 加上此行 chkconfig ntpd on 下次启动自动打开ntpd服务 service ntpd start 打开ntpd服务 service ntpd status 检查ntpd服务状态 CentOS7： ntpdata 172.x.x.x 将时间与服务器时间同步 vim /etc/chrony.conf 修改此文件 server 172.x.x.x iburst 加上此行 systemctl enable chronyd 下次启动自动打开chronyd服务 systemctl start chronyd 打开chronyd服务 systemctl status chronyd 检查chronyd服务状态 至此，服务器时间同步就算是完成了！ 二、执行一次性计划任务——atLinux任务计划、周期性任务执行 未来的某时间点执行一次任务 at batch：系统自行选择空闲时间去执行此处指定的任务 周期性运行某任务 cron 使用at命令前，先确认at服务是否处于运行状态 Centos6： 确认当前运行级别处于on状态 run level chkconfig –list atd 如果服务未开启，请开启atd服务 service atd start centos7： 确认处于active（running）状态 systemctl status atd 如果服务未开启，请开启atd服务 systemctl start atd at格式：at [options] TIME 最后Ctrl+d结束输出 options： -l 显示所有计划任务列表,同atq命令 -d # 删除第#个计划任务，同atrm命令 -c # 查看具体作用任务 -m 强制发邮件 -f /path/from/somefile 草丛指定文件中读取任务 TIME： HH：MM [YYYY-mm-dd] noon,midnight,teatime （4pm） tomorrow now+#{minute，hours，days，weeks} HH：MM 02：00 在今日HH：MM进行，若该时刻已过，则明天此时执行任务 HH：MM YYYY-mm-dd 规定在某年某月某一天的某时刻执行任务 HH：MM[am|pm][month][date] 04pm March 17 17:20 tomorrow HH：MM[am|pm]+number[minutes|hours|days|weeks] 在某个时间点再加几个时间后才执行任务 now + 5minutes 02pm + 3days 注意：计划任务中的标准输出不显示在终端，将会以邮件方式发送至邮箱，所以执行计划任务最好 将标准输出全部重定向到/dev/null，否则会产生大量垃圾邮件 at执行方式： 方法1：交互式 例：at at 15:00 创建一个15:00的计划任务 poweroff 输入计划命令 Ctrl+d 结束输出 方法2：输入重定向 例：at 18:00 &lt;&lt; EOF shutdown EOF 方法3：at -f 文件 例：echo “hello” &gt; /data/f1 at 19:00 -f /data/f1 at任务队列存放在/var/spool/at目录中，任务执行后消失。 at任务的黑名单（deny）、白名单（allow）文件： 系统默认只有黑名单文件/etc/at.deny，没有白名单文件/etc/at.allow /etc/at.deny 黑名单文件，放入文件中的用户将不能执行at任务计划 /etc/at.allow 白名单文件，当白名单文件存在时，只有白名单中的用户才能使用at。 白名单文件需手动创建，优先级高于黑名单 如果黑、白名单文件包含同一用户，将优先看白名单，可以使用at计划任务 如果黑、白名单文件都删除，将只有root账号可以使用at计划任务。 三、执行周期性的计划任务——crond使用crond周期任务计划前，先确认crond服务是否处于运行状态 Centos6： 确认处于active（running）状态 service crond status 如果服务未开启，请开启crond服务 service crond start centos7： 确认处于active（running）状态 systemctl status crond 如果服务未开启，请开启crond服务 systemctl start crond 相关文件： /etc/crontab 系统周期性任务计划文件（root only） /var/spool/cron/ 给用户创建周期计划的目录 /etc/cron.d/ 给存储系统创建周期计划的目录 /var/log/cron 日志文件，可利用日志中的信息恢复误操作内容 注意： （1）在/etc/crontab和/etc/cron.d/的文件中刚创建周期计划任务时，需要比普通用户周期计划目 录的格式多添加一个用户名，位于时间和命令之间。 （2）周期计划任务中的标准输出不显示在终端，将会以邮件方式发送至邮箱，所以执行计划任务建议 将标准输出全部重定向到/dev/null，否则会产生大量垃圾邮件 crontab格式： crontab [options] file crontab [options] options： -u 指定一个用户 -e 创建计划任务 -l 列出计划任务列表 -r 删除计划任务 -i 删除前进行交互式提示 例： crontab -l -u wang 查看wang用户的计划任务 crontab -r -u wang 删除wang用户的计划任务 crontab计划任务同at命令一样，也有自己的黑、白名单文件，并且他们的作用是相类似的： /etc/cron.deny 黑名单文件，放入文件中的用户将不能执行周期任务计划 /etc/cron.allow 白名单文件，只有白名单中的用户才能使用cron，需手动创建，优先级高于黑名单 如果黑、白名单文件都删除，将只有root账号可以使用周期计划任务。 创建周期任务的两种方法：第一种方法：修改/etc/crontab （rootonly） /etc/crontab 计划任务参考格式 # Example of job definition: # .—————- minute (0 – 59) # | .————- hour (0 – 23) # | | .———- day of month (1 – 31) # | | | .——- month (1 – 12) OR jan,feb,mar,apr … # | | | | .—- day of week (0 – 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * user-name command to be executed *表示每次都执行 */10表示每10分钟执行一次 例如： # run five minutes after midnight, every day 每五分钟执行一次： 5 0 * $HOME/bin/daily.job &gt;&gt; $HOME/tmp/out 2&gt;&amp;1 # run at 2:15pm on the first of every month — output mailed to paul 每个月第一天的14:15分执行一次，并发送邮件 15 14 1 $HOME/bin/monthly # run at 10 pm on weekdays, annoy Joe 每个工作日晚上22：00，发送邮件给Joe 0 22 1-5 mail -s “It’s 10pm” joe%Joe,%%Where are your kids?% 每间隔2小时的23分钟，打印一次，am0:23，am2:23，am4:23…，每天 23 0-23/2 * echo “run 23 minutes after midn, 2am, 4am …, everyday” 每个星期日的04:05，打印一次 5 4 sun echo “run at 5 after 4 every sunday” 注意： 30 4 1,15 * 5 表示每月1,15日加每周五执行，或关系 若想执行且关系，加脚本判断 特殊的时间格式： 这些特殊的时间规范可以用来代替一些时段和日期，用@字符作为前缀 @reboot Run once after reboot 下次启动会执行，包括poweroff @yearly 0 0 1 1 * 每年执行一次 @annually 0 0 1 1 * 每年执行一次 @monthly 0 0 1 每月执行一次 @weekly 0 0 0 每周执行一次 @daily 0 0 * 每天执行一次 @hourly 0 每小时执行一次 第二种方法：crontab命令创建 crontab -e 将以vi打开一个空白文件 # Example of job definition: # .—————- minute (0 – 59) # | .————- hour (0 – 23) # | | .———- day of month (1 – 31) # | | | .——- month (1 – 12) OR jan,feb,mar,apr … # | | | | .—- day of week (0 – 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * command to be executed 不需写用户名，将以当前用户执行周期计划任务 创建成功后周期计划文件自动放入/var/spool/cron目录 at和crontab对比： 一次性作业使用at 重复性作业使用crontab at crontab 创建任务： at time crontab -e 任务列表： at -l crontab -l 查看信息： at -c # N/A 删除任务： at -d # crontab -r 修改任务： N/A crontab -e 注意：（1）默认不显示标准输出和标准错误，会以邮件方式邮寄给用户 a.COMMAND &gt; /dev/null b.COMMAND &amp;&gt; /dev/null （2）根用户能够修改其他用户的作业]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>计划任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统启动流程详解]]></title>
    <url>%2F2018%2F05%2F10%2FLinux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[inux系统从按下电源键开始到系统启动要求用户输入用户名，中间究竟发生什么？了解Linux系统的启动 流程，不仅有助于我们更加深入的理解linux底层设计理念，更能帮助我们再出现系统启动故障时，迅速排 查出故障原因。 ## 一、Linux系统启动流程以下是CentOS6版本系统启动流程图： （注：下文中启动流程主要适用于CentOS6之前的版本，7版本变动较大，暂不加入讨论） CentOS6启动流程：1.加载BIOS的硬件信息，进行POST加电自检 2.读取第一个启动设备MBR的引导加载程序(grub)的启动信息 3.加载核心操作系统的核心信息，核心开始解压缩，并尝试驱动所有的硬件设备 4.核心执行init程序，并获取默认的运行信息 5.init程序执行/etc/rc.d/rc.sysinit文件 6.启动核心的外挂模块 7.init执行运行的各个批处理文件(scripts) 8.init执行/etc/rc.d/rc.local 9.执行/bin/login程序，等待用户登录 10.登录之后开始以Shell控制主机 接下来我们对每一项流程详细讲解 1.POST：Power-On-Self-Test，加电自检，是BIOS功能的一个主要部分。负责完成对CPU、主板、内 存、硬盘子系统、显示子系统、串并行接口、键盘、CD-ROM光驱等硬件情况检测。 2.加载MBR：MBR：Master Boot Record，主引导记录 0磁道0扇区：512bytes 446bytes：boot loader 64bytes：分区表 16bytes：标识一个分区（最多4个分区） 2bytes：55AA（分区标识位） bootloader：引导加载器，引导程序 主要功能有： a）识别、加载操作系统中的核心文件，并提交到内存中运行，进而来启动对应操作系统。 b）提供菜单信息，并将启动管理功能转交给其他加载程序。 Linux：GRUB，可引导多种操作系统 windows：ntloader，只能引导windows系统 因此建议：同一台电脑装多个操作系统，先装windows，后装Linux 3.GRUB：grub0.97（老版本） 第一阶段：MBR的前446字节 1.5阶段：MBR后续的27个扇区，加载/boot分区文件系统驱动 第二阶段：识别文件系统，加载/boot/grub目录下的文件（备份gurb的文件） 注：grup 修复命令依赖于/boot/grub下的文件 grub-install修复命令不依赖，将自动生产gurb文件下文件， 一旦用grub命令修复后，grub-install也将依赖这些文件。 /boot/grub/grub.conf grub配置文件 default=0 定义了默认启动项 timeout=5 定义了菜单超时时长 splashimage=(hd0,0)/grub/splash.xpm.gz 定义了菜单背景图片 password –md5 口令 默认无此行，添加此行后需输入正确口令才能以但用户模式破解root口令 可用grub-md5-crypt生产md5口令 hiddenmenu 默认隐藏菜单 title 定义了启动菜单，有几个title就有几个启动菜单 root（hd0,0） krenel 定义了内核文件位置，挂载目录 initrd 定义了initramfs文件位置 4.加载内核Kernel：探测可识别到的所有硬件设备 加载硬件驱动程序（借助于ramdisk加载驱动） 以只读方式挂载根文件系统： /boot/initramfs-VERSION-release.img文件加载根目录文件系统驱动 /boot/grup/grup.conf文件定义了根的位置 运行用户空间的第一个应用程序：/sbin/init 内核的核心文件： /boot/vmlinuz-VERSION-release ramdisk：辅助的伪根系统，存放辅助性的驱动模块 CentOS 5: /boot/initrd-VERSION-release.img ramdisk虚拟磁盘 CentOS 6,7: /boot/initramfs-VERSION-release.img ramfs虚拟文件系统 mkinitrd /boot/initramfs-uname -r.img uname -r 生成新的ramfs文件 5.启动init进程：CentOS5： SycV：init，redhat开发 特点：启动服务程序时，有依赖的服务将被串行启动，因此centos5系统启动很缓慢 配置文件：/etc/inittab CentOS6： Upstart：init，ubantu开发 特点：守护进程间通信依赖于D-Bus进行，因此可基本实现类似并行启动 配置文件：/etc/inittab，/etc/init/*.conf CentOS7： Systemd：systemd–&gt;init redhat开发 特点：服务只有在第一次被访问到才会启动，因此centos7系统启动过程非常快 配置文件：/usr/lib/systemd/system ​ /etc/systemd/system /sbin/init CentOS6版本之前 运行级别：为系统运行或维护等目的而设定；0-6：7个级别 0：关机 1：单用户模式(root自动登录), single, 维护模式 2: 多用户模式，启动网络功能，但不会启动NFS；维护模式 3：多用户模式，正常模式；文本界面 4：预留级别；可同3级别 5：多用户模式，正常模式；图形界面 6：重启 默认级别： 3, 5 切换级别：init # 查看级别：runlevel ; who -r 6.读取/etc/inittab文件CentOS5： 1.定义默认启动运行级别为3 2.定义了使用/etc/rc.d/rc.sysinit进行系统初始化 3.定义了每个运行级别执行的rc#文件 4.定义Ctrl-Alt-Delete组合键重启 5.配置不断电系统pf、pr两种机制 6.定义了终端数量，默认6个 7.如果是5级别，则会启动图形化界面 注意：可利用#加注释方法减少5选项中的终端数量，也可复制增加可登陆终端数量 建议：生产中建议关闭6选项组合键重启功能，防止误操作 CentOS6： 仅定义了系统默认启动运行级别，其他项分割为单个文件执行，原来与5版本一致。 /etc/init/control-alt-delete.conf /etc/init/tty.conf /etc/init/start-ttys.conf /etc/init/rc.conf /etc/init/prefdm.conf 7.读取/etc/rc.d/rc.sysinit 系统初始化文件(1) 设置主机名 (2) 设置欢迎信息 (3) 激活udev和selinux (4) 挂载/etc/fstab文件中定义的文件系统 (5) 检测根文件系统，并以读写方式重新挂载根文件系统 (6) 设置系统时钟 (7) 激活swap设备 (8) 根据/etc/sysctl.conf文件设置内核参数 (9) 激活lvm及software raid设备 (10) 加载额外设备的驱动程序 (11) 清理操作 /etc/init.d/ 存放对应服务脚本 是rc.d文件软连接的源文件 通过执行init.d脚本，确定运行级别开启和关闭的服务 8.运行/etc/rc.d/ rc[0-6].d/对应级别目录下服务K##*：运行级别为N时，关闭K开头的服务；##运行次序；数字越小，越先运行；数字越小的服务，通常 为依赖到别的服务 S##*：运行级别为S时，打开S开头的服务；##运行次序；数字越小，越先运行；数字越小的服务，通常 为被依赖到的服务 /var/lock/subsys 存放已启动的服务名称 9.运行/etc/rc.d/rc.local文件rc.local会在所有服务启动后作为一个兜底的服务进行启动 注意：（1）正常级别下，最后启动一个服务S99local没有链接至/etc/rc.d/init.d一个 服务脚本，而是指向了/etc/rc.d/rc.local脚本 （2）不便或不需写为服务脚本放置于/etc/rc.d/init.d/目录，且又想开机时自动运行 的命令，可直接放置于/etc/rc.d/rc.local文件中 （3）/etc/rc.d/rc.local在指定运行级别脚本后运行 （4）可以根据情况，进行自定义修改 10、执行/bin/login程序此时，系统完成启动，显示请输入用户名、密码 二、制定自己的init服务脚本：方法1：第一步：编写服务脚本 #！/bin/bash #chkconfig: 345/- 95 5 关键一行 生效模式:345或all S编号 K编号 #description:test service source /etc/init.d/functions 调用函数库 case $1 in start） [ -f /var/lock/subsys/testsrv ] &amp;&amp; action “testsrv is started ” touch /var/lock/subsys/testsrv action starting testsrv ;; stop） rm -f /var/lock/subsys/testsrv action testsrv is stopped ;; status) [ -f /var/lock/subsys/testsrv ]&amp;&amp;echo testsrv is starting||echo testsrv is stopped *) echo “Usage:service testsrv start|stop|status” esac 第二步：放入服务目录 /etc/init.d/ 放入服务目录 第三步：添加脚本至服务 chkconfig –add testsrv 将testsrv脚本添加至服务 方法2：也可以将开机启动服务代码添加到： /etc/rc.d/rc[0-6]/99Slocal中执行 三、服务相关命令chkconfig 服务状态控制 查看服务状态： –list 列出所有独立服务 –list [name] 列出指定服务各运行模式状态 添加脚本到服务： –add name 添加脚本到服务 注：SysV服务脚本要放置于/etc/rc.d/init.d（/etc/init.d） #!/bin/bash #LLLL 表示初始在哪个级别下启动，-表示都不启动 # chkconfig: LLLL nn nn 删除服务： –del name 删除指定服务 修改服务状态： –level 35 atd off|on 将3,5模式atd服务默认开机关闭服务，不添加模式：默认2,3,4,5 ntsysv 查看当前模式服务启动状态，*代表开机启动 –level=3 修改指定运行模式的启动服务 service 手动管理服务 [name] start|stop|restart 管理服务状态 –status-all 当前所有服务状态]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本编程基础（3）——循环用法]]></title>
    <url>%2F2018%2F05%2F10%2Fshell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94%E5%BE%AA%E7%8E%AF%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[在前面的基础编程内容中，我们已经学习了shell脚本的顺序执行及选择执行，通过这两种方式，可 以帮我们解决一些简单需求，但要想在更复杂的场景中使用的话，就需要掌握循环执行的方式了。 一、if、case条件判断条件判断if语句：if语句 是指编程语言中用来判定所给定的条件是否满足，根据判定的结果（真或假）决定执行给出的两种操作之一。 格式： 123456789if 判断条件1；then # 条件1为真的分支代码elif 判断条件2；then # 条件2为真的分支代码elif 判断条件3；then # 条件3为真的分支代码else # 以上条件都不满足的分支代码fi # if语句结束标记位 if语句会逐条件的进行判断，当第一次遇到为”真”的条件时，就会执行其分支代码，而后结束整个if语句。 条件判断case语句：case语句是实现选择结构程序设计的一种语句，比较适合处理离散型变量。 格式： 123456789101112131415case 变量引用 in1|2|3)cmd1;;4|5|6) cmd2;;7|8|9)cmd3;;*) cmd4esac 注意：case支持glob风格的通配符： 如：* 表示任意长度任意字符 ？ 表示任意单个字符 [] 指定范围内的任意单个字符 a|b a或者b 二、for、while及until循环循环执行 将某代码段重复运行多次 重复运行多少次 次数已知 次数未知 有进入条件和退出条件 循环主要语句有：for、whlie、until for循环for语句将循环一个列表中的每一个元素执行一次循环体代码，直到列表中元素全部执行过一次。 一般用于次数预先知道的循环。 格式1： 12345for 变量名 in 列表；do循环体done 其中列表的生成方式有多种： 直接给出列表 整数列表： （a）{start..end[..step]} （b）$（seq[start[step]end]） 返回列表的命令： $（COMMAND） 使用glob，如：*.sh 变量引用： $@,$*等 执行机制： 依次将列表中的元素赋值给”变量名”，每次赋值后即执行一次循环体；直到列表中的元素全部被执行，循环结束 格式2：C语言风格 123456789101112131415for ((: for (( exp1; exp2; exp3 )); do COMMANDS; doneArithmetic for loop.Equivalent to(( EXP1 ))while (( EXP2 )); doCOMMANDS(( EXP3 ))done 例：利用for循环依次读取列表{1..100}中的内容，并相加，得出1到100的数字之和 while循环while结构循环为当型循环(when type loop)，一般用于不知道循环次数的情况。维持循环的是一个条件表达式，条件成立执行循环体，条件不成立退出循环。 格式： 123while 循环控制条件；do循环体done 循环控制条件：进入循环之前，先做一次判断；每次循环之后会再次做判断；当条件为True时，则继续执行循环；直到条件测试状态为false时终止循环。 例：利用while循环，定义变量i=0，当i小于100时，执行循环，并让变量i每执行一次循环加1，直到i=100时停止循环，得出数字1到100之和 while循环的特殊用法（遍历文件的每一行）： while read line； do 循环体 done &lt; /PATH/FROM/SOMEFILE 依次读取/PATH/FROM/SOMEFILE文件中的每一行，且将行赋值给变量line for循环与while循环的区别：for循环与while循环是可以相互替代的；比如： 123for i in &#123;1..10&#125;；doecho &quot;OK&quot;done 用while语句来写的话： 12345i=1while [ $i -le 10 ];doecho &quot;OK&quot;let i++done 两者意思都是打印10次”OK”，那什么时候用for循环，什么时候又用while循环呢？ for循环用于针对集合中的每个元素的一个代码块，而while循环不断的运行，直到指定的条件不满足为止。 一般来说： for循环比较适合循环次数确定的情况 while循环适合循环次数不确定的情况 until循环维持循环的也是一个条件表达式，但与while用法正好相反，条件不成立时执行循环体，条件成立时退出循环。 123until 循环控制条件；do 循环体done until语句和while语句可相互转化： 如：until [ test ]；do 等价于 while [ ! test ]；do 三、循环控制语句continue、break、shiftcontinue语句用于循环体中 continue[N]：提前结束第N层的本轮循环，而直接进入下一轮判断；最内层为第1层 格式： 123456789while 循环控制条件；do CMD1 … if 判断条件；then continue fi CMDn …done 例：依次打印数字1至10，当continue出现在5循环中时，直接跳过，继续执行6循环； 当continue出现在嵌套循环中时，continue 2，提前结束第二次本轮循环，并打印3次 break语句用于循环体中 break[N]：提前结束第N层循环，最内层为第一层 123456789while 循环控制条件；do CMD1 … if 判断条件；then break fi CMDn …done 例：break语句将直接结束本轮循环 shift命令shift[n]：将参量列表list左移指定次数，缺省为左移一次，适合用于处理位置参数 参量列表list一旦被移动，最左端的那个参数就从列表中删除。while循环遍历位置参量列表时， 常用到shift 例1：利用shifit，每次位置变量向左移动1位，并打印本次全部位置变量，直到位置变量为0个 例2：利用shifit，每次变量向左移动一位，并打印本次第一个位置变量，直到位置变量小于1时停止执行 避免出现无限循环：1234567while true；do 循环体doneuntil false；do 循环体done 每个程序员都会偶尔不小心而编写出无限循环，在循环退出条件比较微妙时尤其如此，如果程序陷入无限循环，可按ctrl+c退出 要避免编写无限循环，务必对每个while、until循环进行测试，确保它按预期那样结束。 select循环与菜单123select 变量 in list；do 循环体命令done select循环主要用于创建菜单，常与case语句搭配使用，用户输入菜单列表中的某个数字，执行相应的命令 select是个无限循环，因此要记住用break命令退出循环，或用户exit命令终止脚本。可按ctrl+c退出循环 与for循环类似，可以省略in list，此时使用位置变量。 相关变量： $PS3 menu菜单提示符 $REPLY 保存用户的输入信息 四、信号捕捉traptrap ‘触发指令’信号 自定义进程收到系统发出的指定信号好，将执行触发指令，而不会执行原操作 trap “ 信号 忽略信号的操作 trap ‘-‘ 信号 恢复原信号的操作 trap -p 列出自定义信号操作 例：打印数字1到10的过程中，trap -p显示自定义信号操作，由于trap “int捕获了int信号，ctrl+c无法中断显示，且显示自定义输入：press ctrl+c； 打印数字11到20的过程中，由于trap “int捕获了int信号，ctrl+c无法中断显示 打印数字21到30的过程中，trap ‘-‘恢复了原信号操作，顾ctrl+c又可中断显示]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP/IP协议详解]]></title>
    <url>%2F2018%2F05%2F06%2FTCP-IP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[在前面的网络基础内容中我们了解了TCP/IP协议的定义以及TCP/IP模型的分层结构即： 应用层，传输层，Internet层以及网络访问层。 今天我来带大家详细了解下TCP/IP协议栈中的典型协议： 传输层的TCP、UDP协议，网络层的IP协议。 一、TCP协议TCP是面向连接的通信协议，通过三次握手建立连接，通讯完成时要拆除连接，由于TCP是面向连 接的，所有只能用于端到端的通讯。 TCP协议的工作特性：工作在传输层 面向连接协议：先协商确保网络状态正常稳定 全双工协议 半关闭：支持一端关闭，一端传输的半关闭状态 错误检查 将数据打包成段，排序 确认机制：保证数据包可靠 数据恢复，重传 流量控制，滑动窗口 拥塞控制，慢启动和拥塞避免算法 TCP协议报文格式：为何TCP协议具有上述工作特性呢，这就要结合TCP报文格式来讲起。 下图是TCP报文格式图： 具体含义如下： 1.源端口、目标端口：计算机上的进程要和其他进程通信需要通过计算机端口，而一个计算机端口 某个时刻只能被一个进程占用，所以通过指定源端口和目标端口，就可以制度哪两个进程通信。 2.序列号：seq序号，占32位，用来标识从TCP源端口向目的端口发送的字节流，发起方发送数据时 对此进行标记。 3.确认序号：ack序号，占32位，只有ACK标志位为1时，确认序号字段才有效，ack=seq+1 4.数据偏移：表示TCP报文段的首部长度，共4位，由于TCP首部包含一个长度可变的选项部 分，需要指定这个TCP报文段到底有多长。它指出 TCP 报文段的数据起始处距离 TCP 报文 段的起始处有多远。该字段的单位是32位(即4个字节为计算单位），4位二进制最大表示 15，所以数据偏移也就是TCP首部最大60字节。 5.标志位：共6个，URG、ACK、PSH、RSH、SYN、FIN，具体含义如下： （1）URG：紧急指针位，0表示无效，1表示有效 （2）ACK：确认序号有效 （3）PSH：收到数据包后是否直接传给应用程序使用，或传到buffer （4）RST：重置位，0表示正常，1表示异常需要重传 （5）SYN：同步位，代表发起一个新连接 （6）FIN：代表释放一个连接 6.窗口大小：表示现在允许对方发送的数据量，从本报文段的确认号开始允许对方发送数据量 7.校验和：提供额外的可靠性 8.紧急指针：标记紧急数据在数据字段的位置 9.选项部分：其最大长度可根据TCP首部长度进行推算。TCP首部长度用4位标识，选项部分最长 为：（2^4-1）*4-20=40字节 TCP协议端口号：传输层通过port号，确认应用层协议 tcp：传输控制协议，面向连接的协议；通信前需要建立虚拟链路；结束后拆除链路 port number：0-65535 其中： 0-1023：系统端口或特权端口（仅管理员可用），总所周知，永久的分配给固定的系统应用使用； 如：22/tcp（ssh），80/tcp（http），443/tcp（https）等 1024-49151：用户端口或注册端口，要求并不严格，分配给程序注册为某应用使用； 如：1433/tcp（SqlServer），1521/tcp（oracle） 3306/tcp（mysql），11211/tcp/udp（memcached） 49152-65535：动态端口或私有端口，客户端程序随机使用的端口； 其范围的定义：/proc/sys/net/ipv4/iplocalportrange 二、TCP协议三次握手及四次挥手TCP协议三次握手：所谓的三次握手即建立TCP连接，是指建立一个TCP连接时，需要客户端和服务端总共发送3个包以 确认连接的建立。 整个流程如下图所示： 第一次握手：客户端将标志位SYN置为1，随机产生一个序列值seq=x，并将该数据包发送给服务器， 客户端进入SYN_SENT状态，等待Server确认。 第二次握手：服务器收到数据包后由标志位SYN=1指定客户端请求建立连接，服务器端将标志位SYN 和ACK都置为1，ack=x+1，随机产生一个序列值seq=y，并将该数据包发送给客户端以确认连接请求， 此时，服务器进入SYN_RCVD状态。 第三次握手：客户端收到确认后，检查ack是否为x+1，ACK是否为1，如果正确则将标志位ACK置为1， ack=y+1，发送数据包给服务器端，客户端进入ESTABLISHED状态；服务器端收到对端发来的确认数据 包后也转入ESTABLISHED状态，此时三次握手完成，客户端与服务器已建立通讯连接。 SYN攻击在三次握手过程中，服务器发送SYN-ACK之后，收到客户端的ACK之前的TCP连接称为半连接，此时服务 器处于SYN_RCVD状态，当收到ACK后，服务器转入ESTABLISHED状态。SYN攻击就是Client在短时间 内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认， 由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接 队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。SYN攻击时一种典 型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的， 则可以断定遭到SYN攻击了，使用如下命令可以让之现形： #netstat -nap | grep SYN_RECV TCP协议四次挥手：所谓四次挥手即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务器端总共发送4个包以确认 连接的端开。 整个流程如下图所示： 由于TCP连接是全双工工作，因此，每个方向都必须要单独进行关闭。即当一方完成数据发送任务后， 发送一个FIN来终止这一方向的连接，收到一个FIN只是代表这一方向上没有数据流动了，即不再接收到 数据，但在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。 第一次挥手：客户端发送一个FIN，用来关闭客户端到服务器端的数据传送，客户端进入FIN_WAIT_1 状态。 第二次挥手：服务器端收到FIN后，发送一个ACK给客户端，确认序号+1，服务器进入CLOSE_WAIT状态。 第三次挥手：服务器端发送一个FIN，用来关闭服务器到客户端的数据传送，服务器进入LAST_WAIT状态。 第四次挥手：客户端收到FIN后，进入TIME_WAIT状态，在等待2个报文最大生产时限后会转入 CLOSED状态，客户端发送ACK确认，服务器收到ACK确认报文后由LAST_ACK状态转为CLOSED状态。 此时四次挥手完成。 三、UDP协议UDP是非面向连接的通讯协议，UDP数据包括目的端口号和源端口号信箱，由于通讯不需要连接，所有可 以实现广播发送。 UDP与TCP位于同一层，但它不管数据包的顺序、错误或重发。因此，UDP不被应用于那些使用面向连 接的服务，UDP主要用于那些面向查询—应答的服务，例如NFS。相对于FTP或Telnet，这些服务需 要交换的信息量较小。使用UDP的服务包括NTP（网络时间协议）和DNS（DNS也使用TCP）。 UDP通讯时不需要接收方确认，属于不可靠的传输，可能会出现丢包现象。 UDP协议的工作特性：工作在传输层 提供不可靠的网络访问 非面向连接协议 有限的错误检查 传输性能高 无数据恢复特性 UDP协议报文格式： 16-bit source port：占16位，源端口 16-bit destination port：占16位，目的端口 16-bit UDP length：占16位，定义数据报长度 16-bit UDP checksum：占16位，校验和 通过UDP协议报文格式，我们可以发现，欺骗UDP包比欺骗TCP包更容易，因为UDP没有建立初始化连 接（也可以称为握手），也就是说，与UDP相关的服务面临着更大的危险。 四、IP协议IP协议（Internet Protocol）是将多个包交换网络连接起来，它在源地址和目的地址之间传送一种 称之为数据包的东西，它还提供对数据大小的重新组装功能，以适应不同网络对包大小的要求。 IP协议的工作特性：运行于 OSI 网络层 面向无连接的协议 独立处理数据包 分层编址 尽力而为传输 无数据恢复功能 IP协议报头格式：如下图所示： 版本：占4位，指IP协议版本，目前IP协议版本号为4，即IPv4。 首部长度：占4位，定义了IP首部长度最大值是60字节。 区分服务：占8位，用来获取更好的服务，一般情况下不使用。 总长度：占16位，指首部和数据之和的长度，单位为字节，因此数据包的最大长度为65535字节。总 长度不可超过最大传送单元MTU。 标识：占16位，它是一个计数器，每发送一个报文，该值会加1，也用于数据包分片，在同一个包的若干 分片中，该值相同。 标志（flag）：占3位，目前只有后两位有意义。 （1）DF：Don’t Fragment，中间的一位，只有DF=0时才允许数据包分片。 （2）MF：More Fragment，最高位，MF=1表示后面还有分片。MF=0表示这是数据包最后一个分 片。 片偏移：占12位，值较长的分组在分片后，该分片在原分组中的相对位置，片偏移以8个字节为偏移单 位。 生存时间：占8位，TTL（Time To Live），数据包在网络中可通过的路由器数最大值。 协议：占8位，指出该数据包携带的数据使用何种协议，以便目的主机的IP层将数据不符上交给哪个处理 进程。其中：1表示为 ICMP 协议, 2表示为 IGMP 协议, 6表示为TCP 协议, 17表示为 UDP 协议。 首部校验和：占16位，只检验数据包的首部不检验数据不符。采用简单计算的方法。 源地址和目的地址：各占4字节，分别记录源IP地址和目的IP地址。 五、IP地址：IP地址用来唯一标识IP网络中的每台设备 每台主机（计算机、网络设备、外围设备）必须具有唯一的地址 IP地址由两部分组成： 网络ID： 标识网络 每个网段分配一个网络ID 主机ID： 标识单个主机 由组织分配给各设备 IP地址分类：A类地址 0XXXXXXX.XXXXXXXX.XXXXXXXX.XXXXXXXX 8位网络ID，24位主机ID 0-127.x.x.x 主机数：1600万左右 网段数：2^7-2=126 抛去特殊0开头127开头（本地回环） 1-126.x.x.x 共有126个A类可用网段 B类地址 10XXXXXX.XXXXXXXX.XXXXXXXX.XXXXXXXX 16位网络ID，16位主机ID 128-191.x.x.x 开头 主机数：65534 网段数：2^14=16384 C类地址 110XXXXX.XXXXXXXX.XXXXXXXX.XXXXXXXX 24位网络ID，8位主机ID 192-223.x.x.x 开头 主机数：2^8-2=254 D类地址 1110XXXX.XXXXXXXX.XXXXXXXX.XXXXXXXX 224-239.x.x.x 开头 E类地址（保留） 11110XXX.XXXXXXXX.XXXXXXXX.XXXXXXXX 239-255.x.x.x 开头 特殊地址 0.0.0.0 表示一个集合：所有不清楚的主机和目的网络 255.255.255.255 广播地址。对本机来说，这个地址指本网段内（同一广播域）所有主机 127.0.0.1—127.255.255.254 本机回环地址，主要用于测试。 224.0.0.0到239.255.255.255 组播地址，224.0.01特指所有主机，224.0.0.2特指所有路由器。 169.254.x.x 公有IP地址： A：1.0.0.0 到 9.255.255.255 11.0.0.0 到 126.255.255.255 B：128.0.0.0 到 172.15.255.255 172.32.0.0 到 191.255.255.255 C：192.0.0.0 到 192.167.255.255 192.169.0.0 到 223.255.255.255 私有IP地址：局域网用 A：10.0.0.0 到 10.255.255.255 B：172.16.0.0 到 172.31.255.255 C：192.168.0.0 到 192.168.255.255 子网掩码子网掩码(subnet mask)又叫网络掩码、地址掩码、子网络遮罩，它是一种用来指明一个IP地址的哪些位标 识的是主机所在的子网，以及哪些位标识的是主机的位掩码。子网掩码不能单独存在，它必须结合IP地址 一起使用。子网掩码只有一个作用，就是将某个IP地址划分成网络地址和主机地址两部分。 传统表示法： XXXXXXXX.XXXXXXXX.XXXXXXXX.XXXXXXXX 00000000 0 10000000 128 11000000 192 11100000 224 11110000 240 11111000 248 11111100 252 11111110 254 11111111 255 CIDR表示法： IP/网络ID位数 如192.168.10.132/30]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程监控管理工具详解]]></title>
    <url>%2F2018%2F05%2F05%2FLinux%E8%BF%9B%E7%A8%8B%E7%9B%91%E6%8E%A7%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[一、top——进程监控工具相对于ps而言，ps显示的是某个时间点的进程状态信息，top命令工具类似于windows系统的任务管理器， 可以动态的持续监控进程的运行状态 每一行的代表的含义为： 第一行： 1.当前系统时间 2.系统已启动的时间 3.当前登录用户数 4.系统平均负载（1min、5min、15min），超过1表示负载过高 第二行： 当前进程的总量，以及处于各种状态的进程的数量，要注意最后的zombie，不为0 要及时查看哪个进程处于僵死状态 第三行：CPU的整体负载，多核CPU可按1切换不同CPU的负载率 us：user space 用户运行程序占用CPU百分比 sy：system 用于运行内核占用CPU百分比 ni：nice用户进程空间所改变过优先级的进程占用CPU百分比 id：idle 空闲CPU百分比 wa：wait to 等待I/O花费时间 hi：hardware interrupt 硬件中断占用CPU的百分比 si：software interrupt 软件中断占用CPU的百分比 st：stolen 被偷走的CPU百分比，一般为虚拟机占用 第四行：表示物理内存的使用情况 第五行：表示交换分区的使用情况 第六行：这里默认显示空白，可以输入指令，包括： P 以占据的CPU百分比大小排序 M 以内存占比大小排序 T CPU累加占用时间排序 l 是否显示系统负载行 t 是否显示进程摘要信息及CPU负载状态 1 数字1，平均或单独显示各CPU负载信息 m 是否显示内存相关状态信息 q 退出 s 修改延迟时长 k 终止指定进程 top输出下面的部分： PID 进程ID USER 进程所有者 PR 进程优先级，越小优先级越高 NI nice优先级，越小优先级越高 VIRT 进程需要占用的内存大小 RES 进程当前实际占用内存大小 SHR 进程与其他进程恭喜的内存大小 S 进程状态 %CPU CPU占有率 %MEM 内存使用率 TIME+ 进行CPU使用时间累加 COMMAND 进程或命令名称 二、htop——top增强版进程监控工具htop是top命令工具的增强版，系统默认没有按照，需epel源进行安装 交互式命令： u 选择显示指定用户的进程 l 显示光标所在进程缩打开的文件列表 s 显示光标所在进程执行的系统调用 a 绑定进程到指定cpu（退出htop失效） # 快速定位光标至PID为#的进程上 htop支持的一些信息 -d # 延迟时长 -u USERNAME：显示指定用户的进程 -s COLUMN：根据指定字段进行排序 三、iotop、iostat——磁盘读写监控工具iotop命令是一个用来监视磁盘I/O使用状况的top类工具iotop具有与top相似的UI，其 中包括PID、用户、I/O、进程等相关信息，可查看每个进程是如何使用IO 每一行的代表的含义为： 第一行：Read和Write速率总计 第二行：实际的Read和Write速率 第三行：参数如下： TID 线程ID（按p切换为进程ID） PRIO 优先级 USER 用户 DISK READ 磁盘读速率 DISK WRITE 磁盘写速率 SWPIN swap交换百分比 IO&gt; IO等待所占的百分比 COMMAND 线程/进程命令 交互按键 left和right方向键：改变排序 r：反向排序 o：切换至选项–only p：切换至–processes选项 a：切换至–accumulated选项 q：退出 i：改变线程的优先级 iotop支持的选项： -o, –only 只显示正在产生I/O的进程或线程，除了传参，可以在运行过程中按o生效 -b, –batch 非交互模式，一般用来记录日志 -n NUM, –iter=NUM 设置监测的次数，默认无限。在非交互模式下很有用 -d SEC, –delay=SEC 设置每次监测的间隔，默认1秒，接受非整形数据例如1.1 -p PID, –pid=PID 指定监测的进程/线程 -u USER, –user=USER 指定监测某个用户产生的I/O -P, –processes 仅显示进程，默认iotop显示所有线程 -a, –accumulated 显示累积的I/O，而不是带宽 -k, –kilobytes 使用kB单位，而不是对人友好的单位。在非交互模式下，脚本编程有用 -t, –time 加上时间戳，非交互非模式 -q, –quiet 禁止头几行，非交互模式，有三种指定方式 -q 只在第一次监测时显示列名 -qq 永远不显示列名 -qqq 永远不显示I/O汇总 iostat 统计cpu和设备IO信息 第一段显示：内核版本（主机名） 当前日期 架构类型 核心数 第二段显示：cpu平均利用率 第三段显示：磁盘读写速度（kb/s） 四、vmstat——虚拟内存统计工具通过top、htop我们可以获得一些进程对系统资源的使用情况，而vmstat则可以通过 内存、磁盘、网络、CPU来动态显示系统资源的使用情况。 格式：vmstat [options][delay [count]] 选项： -s 显示内存的统计数据 -d 显示磁盘的统计数据 vmstat输出含义： procs： r：可运行进程的个数，和核心数有关 b：处于不可终端睡眠状态 memory： swpd：交换内存的使用总量 free：空闲物理内存总量 buffer：用于buffer的内存总量 cache：用于cache的内存总量 swap： si：从磁盘交换进内存的数据速率（kb/s） so：从内存交换至磁盘的数据速率（kb/s） io： bi：从块设备读入数据到系统的速率（kb/s） bo：保存数据至块设备的速率（kb/s） system： in：interrupts 中断速率，包括时钟 cs：进程切换速率 cpu： us：user space 用户运行程序占用CPU百分比 sy：system 用于运行内核占用CPU百分比 id：idle 空闲CPU百分比 wa：wait to 等待I/O花费时间 st：stolen 被偷走的CPU百分比，一般为虚拟机占用 五、glances——可跨平台系统监控工具glances是一款系统监视工具，能够监视CPU、负载、内存、磁盘I/O、网络流量、文件 系统、系统温度等信息。centos系统默认不安装glances工具，需手动安装（epel源） glances可提供的监视和分析性能数据功能包括： 1.CPU使用率 2.内存使用情况 3.内核统计信息和运行队列信息 4.磁盘I/O速度、传输和读/写比率 5.文件系统中的可用空间 6.磁盘适配器 7.网络I/O速度、传输和读/写比率 8.页面空间和页面速度 9.消耗资源最多的进程 10.计算机信息和系统资源 常用选项： -b： 以Byte为单位显示网卡数据速率 -d： 关闭磁盘I/O模块 -f： /path/to/somefile: 设定输入文件位置 -o： {HTML|CSV}：输出格式 -m： 禁用mount模块 -n： 禁用网络模块 -t #： 延迟时间间隔 -1： 每个CPU的相关数据单独显示 支持远程模式，可在C/S模式下运行glances命令： 注：glances版本最好一样 服务器模式： glances -s -B IPADDR IPADDR: 指明监听的本机哪个地址 客户端模式： glances -c IPADDR IPADDR：要连入的服务器端地址 六、dstat——多功能整合系统监控工具dstat是一个多功能工具，他包含了vmstat，iostat，netstat这些命令的功能，并 增加了监控项，变得更加灵活。dstat可用于基准测试和排除故障。 默认情况下，dstat每秒刷新一次并显示结果，可按ctrl+c退出 每一区列代表的含义： total-cpu-usage CPU使用率 dsk/total 磁盘读写总数 net/total 网络设备发送和接收数据的总数 paging 系统的分页活动，大多数情况我们希望此处两项为0 system 显示中断和上下文切换。只在有比较基线时才有意义。这一栏较高 的统计值通常表示大量进程造成拥塞 dstat支持的选项： -c 显示cpu性能指标相关统计数据 -d 显示磁盘disk相关速率 -g 显示page相关速率数据 -m 显示内存memory相关统计数据 -n 显示网络network相关统计数据 -p 显示进程process相关统计数据 -r 显示io请求相关统计数据 -s 显示swap的相关数据 长选项： –top-cpu 显示最占用CPU的进程 –top-io 显示最占用io的进程 –top-mem 显示最占用内存的进程 –top-latency 显示延迟最大的进程 –tcp 显示tcp套接字相关数据 –udp 显示udp套接字相关数据 –unix 显示unix sock接口相关统计数据 –raw 显示raw套接的相关数据 –socket 显示套接相关数据 –ipc 显示进程间通信相关的速率数据]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>进程监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统进程管理及作业操作]]></title>
    <url>%2F2018%2F05%2F05%2FLinux%E7%B3%BB%E7%BB%9F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%8F%8A%E4%BD%9C%E4%B8%9A%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[一、进程相关概念：进程是正在运行的程序实体，并且包括这个运行的程序中占据的所有系统资源，比如说CPU，IO,内存，网 络资源等。通过学习Linux系统进程管理来协调多道程序之间的关系，使CPU得到充分的利用。 进程和程序的区别是什么？ 进程是一个动态的概念，当用户把一个程序或命令执行起来的时候，才有进程的概念， 系统会自动分配一个编号PID给进程。 程序是一个静态的概念，表现为一个文件 进程的分类：根据进程与系统终端的关系： （1）守护进程：在系统引导过程中启动的进程，即跟终端无关的进程。 （2）前台进程：跟终端相关，通过终端启动的进程； 注：守护进程和前台进程可相互转化 根据进程占用资源的多少分为： （1）CPU密集型：对cpu占用率高的进程 （2）IO密集型：占用磁盘读写高的进程 进程的状态：进程在被内核调度过程中的状态可分为很多种： 1.运行态：running 进程正在运行中 2.就绪态：ready 3.睡眠态：sleeping 可中断睡眠：interruptible 大部分进程处于此状态，随时可唤醒 不可中断睡眠：uninterruptible 4.僵尸态：zombie 找不到归属的进程，或父进程已不存在 5.停止态：stopped 不可被调度并运行 进程优先级进程优先级： 系统优先级：数字越小，优先级越高 0-139（CentOS4,5） 各有140个运行队列和过期队列 0-98，99（CentOS6） 实时优先级: 99-0 值最大优先级最高 nice值：-20到19，对应系统优先级100-139或99 Big O：时间复杂度，用时和规模的关系（越往左越好） O(1), O(logn), O(n)线性, O(n^2)抛物线, O(2^n) 进程内存：Page Frame: 页框，用存储页面数据，存储Page 4k LRU：Least Recently Used 近期最少使用算法,释放内存 物理地址空间和线性地址空间 MMU：Memory Management Unit负责转换线性和物理地址 TLB:Translation Lookaside Buffer 翻译后备缓冲器,用于保存虚拟地址和物理地址 映射关系的缓存 IPC: Inter Process Communication 同一主机: signal:信号 shm: shared memory semaphore:信号量，一种计数器 不同主机：socket: IP和端口号 RPC: remote procedure call 远程过程调用 MQ：消息队列，Kafka，ActiveMQ 二、信号操作管理我们指定同一主机间的程序是通过信号来进行通讯的，那么我们也可以通过发送信号的方式对进程进行管 理。 使用kill -l 命令可以查看当前支持的信号类型： 信号的表示方式： （1）数字表示：1,2,9 （2）完整名称：SIGHUP （3）简写名称：HUP Linux系统支持的型号类型多达60余种，常用信号类型有： SIGHUP：1，无须关闭进程而让其重新读取配置文件，使新配置生效 SIGINT：2，打断正在运行中的进程，相当于Ctrl+c SIGQUIT：3，相当Ctrl+\ SIGKILL：9，强制杀死正在运行的进程 SIGTERN：15，终止正在运行的进程（kill命令默认信号） SIGCONT：18，继续运行指定进程 SIGSTOP：19，后台休眠 信号管理命令常用的信号管理命令有kill，killall，pkill： kill命令可用来向进程发送信号指令，以及显示当前系统可用的信号 kill发送信号格式： kill [-SIGNAL] PID 如：kill -9 123 强制杀死PID为123的进程 killall发送信号格式： killall [-SIGNAL] PROCESS 如：kill -9 sleep 强制杀死sleep进程 注意：kill命令跟PID，killall命令跟进程名 pkill发送信号格式： pkill [options] pattern options： -SIGNAL -u uid 生效者 -U uid 真正发起运行命令者 -t terminal 与指定终端相关的进程 -P pid 显示指定进程的子进程 如：pkill -9 -t tty2 强制杀死tty2终端下的所有进程 三、作业管理（job control）我们知道，在登录系统后每一个工作进程都是当前bash的子进程，通过作业管理我们可以 实现多个进程同时运行，这里我们要涉及到两个新的名词：前台作业和后台作业 前台作业：通过终端前，且启动后一直占据终端 后台作业：可通过终端启动，但启动后即转入后台运行（释放前端） 作业状态切换：作用运行一共有三种状态，分别为：前台执行、后台执行与后台休眠（stoped） jobs命令 显示当前作业编号以及作业状态 让作业运行于后台： （1）尚未启动的作业：COMMAND &amp; （2）运行中的作业：Ctrl+z，后台休眠状态 将后台休眠|运行作业调回前台运行： fg job_num 将作业在前台运行（foreground） 将后台休眠作业执行后台运行： bg job_num 将作业在后台运行（background） 关闭后台执行： （1）fg job_num；ctrl+c （2）kill %job_num 并行运行同时运行多个进程，提高效率 方法1： 利用脚本 vi all.sh ​ f1.sh&amp; ​ f2.sh&amp; ​ f3.sh&amp; 方法2： (CMD1&amp;);(CMD2&amp;);(CMD3&amp;) 方法3： { CMD1&amp; CMD2&amp; CMD3&amp; } 执行长时间任务时防止网络中断造成操作中断方法1：剥离命令与终端的联系，终端中断后进程将转移至1进程上，再恢复 nohup COMMAND &amp;&gt;/dev/null &amp; 方法2：开启一个screen会话，重新进入后screen -r即可恢复 screen；COMMAND；screen -r 恢复 四、Linux进程管理常用命令进程的管理命令有： pstree、ps、pidof、pgrep、pkill、pmap、kill、killall、job、bg、fg等 进程的管理工具： top、htop、vmstat、dstat、iostat、glances等（下节介绍） ps 显示进程状态 BSD选项： a 所有终端中的进程 x 不连接终端的进程 u 显示进程所有者的信息 f 显示进程树 k|–sort 属性 对属性排列，属性前加-表示倒序 L 显示支持的属性 显示PID,tty，cmd，cpu占用率，内存占用列表，并按%mem排序 ps xo pid,tty,cmd,%cpu,%mem –sort %mem ps xo pid,tty,cmd,%cpu,%mem k%mem 按%cpu排序，“-”表示倒序 ps xo pid,tty,cmd,%cpu,%mem –sort -%cpu 短选项： -e 显示所有进程 -f 显示完整格式程序信息 -F 显示更完整格式的进程信息 -C 查看指定CMD或脚本的进程，多个命令用“，”分开 显示PID，命令，pri优先级（数字越大，优先级越高），nice优先级，realtime优先级 ps xo pid,cmd,pri,nice,rtprio 根据进程编号查询CMD命令 ps -p 3245 -o comm= 查找PID3245对应的命令名称 ps -C sleep -o pid= 根据命令查找pid 常用组合： ps aux 显示所有进程的详细信息 ps -ef 类似于aux，缺少cpu%，mem% ps -eF pstree 显示进程树 -p 显示PID -h 高亮标注当前使用的进程 pgrep 进程搜索命令，支持正则表达式 格式：pgrep [options] pattern options： -u uid effective user,生效者 -U uid real user，真正发起运行命令者 -t terminal 与指定终端相关的进程 -l 显示进程名 -a 显示完整格式的进程名 -P pid 显示指定进程的子进程 pidof 查找正在运行进程的PID 如：pidof bash 显示bash进程的PID uptime 命令 显示当前时间，系统已启动时间，当前上线人数，系统平均负载（1、5、10分钟，一般不超过1） free 显示内存空间使用状态 options -b 以字节为单位 -m 以MB为单位 -g 以GB为单位 -h 人类已读格式 pmap 比较专业的查看内存与进程对应关系工具 pmap 12 查看进程号12的内存与进程对应关系 ​ -x 显示详细格式的信息]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>进程管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络基本概念及OSI参考模型、TCP/IP协议简介]]></title>
    <url>%2F2018%2F05%2F01%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8AOSI%E5%8F%82%E8%80%83%E6%A8%A1%E5%9E%8B%E3%80%81TCP-IP%E5%8D%8F%E8%AE%AE%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[当今时代，运行一台没有连接网络的计算机几乎是难以想象的，幸运的是，Linux从一开始就是为 网络开发的，并且网络也是Linux做的最好的事情之一。掌握网络知识，对于Linux学习而言，就显 得非常有必要了。本节我们将带大家了解一些网络的基本概念，以及OSI参考模型和TCP/IP协议。 一、网络概念什么是网络？ 网络是由节点和连线构成，表示诸多对象及其相互联系。在计算机领域中，网络是信息传输、接收、 共享的虚拟平台，通过它把各个点、面、体的信息联系到一起，从而实现这些资源的共享。 网络是人类发展史来最重要的发明，提高了科技和人类社会的发展。 网络应用程序： Web 浏览器（Chrome、IE、Firefox等） 即时消息（QQ、微信、钉钉等） 电子邮件（Outlook、foxmail 等） 协作（视频会议、VNC、Netmeeting、WebEx 等） web网络服务（apache,nginx,IIS） 文件网络服务（ftp,nfs,samba） 数据库服务（ MySQL,MariaDB, MongoDB) 中间件服务（Tomcat，JBoss） 安全服务（ Netfilter） 网络的特征： 速度 成本 安全性 可用性 可扩展性 可靠性 拓扑 拓扑结构： 网络拓扑可分为物理拓扑和逻辑拓扑 物理拓扑描述了物理设备的布线方式 逻辑拓扑描述了信息在网络中的流动方式 物理拓扑中又分为多种拓扑结构，常见类型有： 总线拓扑：所有设备均可接收信号 星型拓扑：通过中心点传输；单一故障点 拓展星型拓扑：比星型拓扑的复原能力更强 环拓扑：信号绕环传输；单一故障点 双环拓扑：信号沿相反方向传输；比单环复原能力更强 全网状拓扑：容错能力强；但实施成本高 部分网状拓扑：在容错能力与成本之间寻求平衡 三种通讯模式： 单播unicast 广播broadcast 组播multicast 非屏蔽式双绞线UTP：交叉线，直通线 UTP交叉线线序 T568B：橙白 橙 绿白 蓝 蓝白 绿 棕白 棕 T568A：绿白 绿 橙白 蓝 蓝白 橙 棕白 棕 网络通讯传输模式 单工：单词传播，如收音机，广播电台 双工：双向 全双工：同时双向，如手机 半双工：轮流双向，如对讲机 二、OSI参考模型OSI(Open System Interconnect）开放系统互连参考模型是国际标准化组织(ISO)和国际电 报电话咨询委员会(CCITT)联合制定的开放系统互连参考模型，为开放式互连信息系统提供了一种 功能结构的框架。它从低到高分别是：物理层、数据链路层、网络层、传输层、会话层、表示层 和应用层。 其目的是为异种计算机互连提供一个共同的基础和标准框架，并为保持相关标准的一致性和兼容性 提供共同的参考。OSI参考模型如下图所示： OSI模型的七层结构：下层为相邻的上层提供服务 应用层：作用：针对特定应用的协议 PDU：message 协议有：HTTP FTP TFTP SMTP SNMP DNS TELNET HTTPS POP3 DHCP 特性：网络进程访问应用层 为应用程序进行（如电子邮件、文件传输和终端仿真）提供网络服务 提供用户身份验证 表示层：作用：设备固有数据格式和网络标准数据格式的转换 PDU：message 格式有，JPEG、ASCll、DECOIC、加密格式等 特性：数据表示 确保接收系统可以读出该数据 格式化数据 构建数据 协商用于应用层的数据传输语法 提供加密 会话层：作用：通信管理。负责建立和断开通信连接（数据流动的逻辑通路）。管理传输层 以下的分层 PDU：message 对应主机进程，指本地主机与远程主机正在进行的会话 特性：主机间通信 建立、管理和终止在应用程序之间的会话 传输层：作用：管理两个节点之间的数据传输，负责可靠传输（确保数据被可靠的传送到目 的地址）。 PDU：段segment 协议有：TCP UDP，数据包一旦离开网卡即进入网络传输层 特性：传输问题 确保数据传输的可靠性 建立、维护和终止虚拟电路 通过错误检测和恢复 信息流控制来保障可靠性 网络层：作用：地址管理与路由选择 PDU：包packet 逻辑地址：IP地址 协议有：ICMP IGMP IP（IPV4 IPV6） ARP RARP 特性：数据传输 路由数据包 选择传递数据的最佳路径 支持逻辑寻址和路径选择 数据链路层：作用：互连设备之间传送和识别数据帧 PDU：帧frame 物理地址：MAC地址 特性：访问介质 定义如何格式化数据以便进行传输以及如何控制对网络的访问 支持错误检测 物理层：作用：以“0”、“1”代表电压的高低、灯光的闪灭。界定连接器和网线的规格 PDU：节bit 特性：二进制传输 为启动、维护已经关闭物流链路定义了电气规范、机械规范、过程规范和功能规范 单位：位bit PDU: Protocol Data Unit,协议数据单元是指对等层次之间传递的数据单位 物理层的 PDU是数据位 bit 数据链路层的 PDU是数据帧 frame 网络层的PDU是数据包 packet 传输层的 PDU是数据段 segment 其他更高层次的PDU是消息 message 三、TCP/IP协议TCP/IP也称”国际协议簇”， 即不仅指 TCP/IP协议本身，而且包括与其有关的协议。 TCP 为传输控制协议，IP为网际协议，是网络层最重要的协议。采用TCP/IP协议通过互联网传 送信息可减少网络中的传输阻塞，方便大批量的数据在网上传输，从而提高网络的传输效率。 TCP/IP协议簇的主要协议有TCP、IP、UDP、ICMP、RIP、TELNET、FTP、SMTP、ARP等 TCP/IP模型共定义了四层，分别是应用层，和OSI参考模型的分层有对应关系： 网络访问层(Network Access Layer)与OSI模型中的物理层以及数据链路层对应，在TCP/IP参考模 型中并没有详细描述，只是指出主机必须使用某种协议与网络相连。 Internet层(Internet Layer)是整个体系结构的关键部分，其功能是使主机可以把分组发往任何网 络，并使分组独立地传向目标。这些分组可能经由不同的网络，到达的顺序和发送的顺序也可能 不同。高层如果需要顺序收发，那么就必须自行处理对分组的排序。互联网层使用因特网协议(IP ，Internet Protocol)。TCP/IP参考模型的互联网层和OSI参考模型的网络层在功能上非常相似。 传输层(Tramsport Layer)使源端和目的端机器上的对等实体可以进行会话。 在这一层定义了两个端到端的协议：传输控制协议TCP和用户数据报协议UDP。 应用层(Application Layer)包含所有的高层协议，包括：虚拟终端协议(TELNET， TELecommunications NETwork)、文件传输协议(FTP，File Transfer Protocol)、电子邮件传输协议 (SMTP，Simple，Mail Transfer Protocol)、域名服务(DNS，Domain Name Service)、网上新闻传输协议 (NNTP，Net News Transfer Protocol)和超文本传送协议(HTTP，HyperText Transfer Protocol)等。 四、常见网络设备Hub集线器 Hub：多端口中继器，现已基本淘汰 Hub并不记忆该信息包是由哪个MAC地址发出，哪个MAC地址在Hub的哪个端口 Hub的特点： 共享带宽 半双工 以太网桥 交换式以太网的优势 扩展了网络带宽 分割了网络冲突域，使网络冲突被限制在最小的范围内 交换机作为更加智能的交换设备，能够提供更多用户所要 求的功能：优先级、虚拟网、远程检测… 学习时源MAC地址，转发时目的MAC地址 网桥是不能隔断广播的 同一广播域主机数量越多，网络性能越差 交换机（switch） 交换机是一种基于MAC（网卡的硬件地址）识别，能完成封装转发数据 包功能的网络设备。交换机可以“学习”MAC地址，并把其存放在内部地址表中， 通过在数据帧的始发者和目标接收者之间建立临时的交换路径，使数据帧直接由源 地址到达目的地址。 Hub和交换机区别 集线器属于OSI的第一层物理层设备，而网桥属于OSI的第二层数据链路层设备 从工作方式来看，集线器是一种广播模式，所有端口在一个冲突域里面。网桥 的可以通过端口隔离冲突 Hub是所有共享总线和共享带宽。网桥每个端口占一个带宽 路由器（router） 路由：把一个数据包从一个设备发送到不同网络里的另一个设备上去。这些工作 依靠路由器来完成。路由器只关心网络的状态和决定网络中的最佳路径。路由的实 现依靠路由器中的路由表来完成。为了实现路由,路由器需要做下列事情: 分隔广播域 选择路由表中到达目标最好的路径 维护和检查路由信息 连接广域网 双绞线物理层 wifi网络层 以太网数据链路层 搭建网络的分层网络架构：核心层、分布层、访问层 核心层Core Layer：企业级应用快速转发 分布层Distribution Layer：广播域，路由，安全，远程接入，访问层汇聚 访问层AccessLayer：终端接入]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实验：在软件RAID搭建LVM逻辑卷进行管理]]></title>
    <url>%2F2018%2F04%2F27%2F%E5%AE%9E%E9%AA%8C%EF%BC%9A%E5%9C%A8%E8%BD%AF%E4%BB%B6RAID%E6%90%AD%E5%BB%BALVM%E9%80%BB%E8%BE%91%E5%8D%B7%E8%BF%9B%E8%A1%8C%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[在我们了解到，RAID可以实现磁盘的高性能读写，并实现冗余，而LVM逻辑卷则可以实现磁盘的弹性扩展，那么如何将两者配合使用并将它们的优势充分发挥呢，今天我们来实验在软件RAID上搭建LVM逻辑卷 实验预期：在CentOS6.9系统上搭建两个RAID级别，分别为RAID0,及RAID5，将两个RAID合并为卷组并创建逻辑卷，实现冗余、性能提升、及弹性拓展。 实验准备环境：CentOS6.9服务器一台，3块硬盘，分别为40G,60G,80G，并在每块磁盘创建分区sdx1容量为1G，sdx2容 量为2G，创建挂载用空目录/test。 ## 实验一：在软件RAID创建LVM逻辑卷 1.mdadm -C /dev/md1 -a yes -l5 -n3 /dev/sd{b1,c1,d1} 将三个容量为1G的分区sdb1，sdc1，sdd1组成一个名称为md1的RAID5 2.mdadm -C /dev/md2 -a yes -l0 -n3 /dev/sd{b2,c2,d2} 将三个容量为2G的分区sdb2，sdc2，sdd2组成一个名称为md2的条形卷RAID0 3.mdadm -D /dev/md1 mdadm -D /dev/md2 查看RAID5、RAID0，确定已创建成功，md1设备可用容量为2G，md2设备可用容量为6G 4.pvcreate /dev/md1 /dev/md2 将md1、md2设备创建为物理卷 5.vgcreate vg_md /dev/md1 /dev/md2 创建由md1、md2组成的卷组vg_md，可用容量为8G 6.lvcreate -L 7G -n lv_md vg_md 在卷组vg_md上创建一个名称为lv_md，大小为7G的逻辑卷 7.mke2fs -t ext4 /dev/vg_md/lv_md 创建逻辑卷lv_md的文件系统为ext4 8.mount /dev/vg_md/lv_md /test/ 将逻辑卷lv_md挂载至提前准备好的空目录/test，这时我们看到逻辑卷lv_md已搭建在RAID0与RAID5共 同组成的分区上 9.vim /etc/fstab 将挂载信息写入/etc/fstab文件，实现开机自动挂载 10.dd if=/dev/zero of=/test/1G.file bs=1024k count=1000 dd if=/dev/zero of=/data/1G.file bs=1024k count=1000 测试磁盘写速度，可见/test目录下写性能相比普通磁盘挂载的/data目录确实有显著提升 实验二：扩展逻辑卷到15G由于原有卷组总容量只有8G，我们选择新创建一个10G分区sda6并添加至原卷组中 1.pvcreate /dev/sda6 创建卷组 2.vgextend vg_md /dev/sda6 将10G分区sda6添加至vg_md卷组 3.lvextend -r -L 15G /dev/vg_md/lv_md 拓展逻辑卷lv_md到15G 注：命令3中-r选项代表同步文件系统大小与逻辑卷大小相同，也可用resize2fs /dev/sda6命令代替 实验三：缩减逻辑卷到5G注意：只有ext4系列文件系统可进行LVM缩容，xfs文件系统无法缩减，缩容前先保证缩容后分区容量大于 数据容量，否则数据将被破坏，生产环境中一般不进行缩容LVM操作。 1.umount /test/ 卸载 resize2fs /dev/vg_md/lv_md 5G 缩减文件系统到5G 提示应先使用命令e2fsck -f检查文件系统 注意文件系统与逻辑卷的执行顺序，扩容时为先扩容逻辑卷再扩容文件系统，缩容时为先缩容文件 系统再**缩容逻辑卷，否则，执行e2fsck -f检查文件系统将失败** 2.e2fsck -f /dev/vg_md/lv_md 检查文件系统 3. resize2fs /dev/vg_md/lv_md 5G 缩减文件系统到5G 4.lvreduce -L 5G /dev/vg_md/lv_md 缩减逻辑卷到5G 5.lvdisplay 显示逻辑卷已缩减成功 总结：可见实验RAID和LVM配合使用，确实提升了磁盘的读写性能，实现了冗余，并且可弹性管理分区大小]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>raid lvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统中RAID及LVM管理]]></title>
    <url>%2F2018%2F04%2F26%2FLinux%E7%B3%BB%E7%BB%9F%E4%B8%ADRAID%E5%8F%8ALVM%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Linux系统中如何提高磁盘的读写性能，如何实现磁盘冗余，当磁盘快被占满时，又如何弹性拓展磁盘容量，RAID及LVM技术可以帮你轻松解决。 一、RAID概念及管理RAID 廉价（独立）磁盘冗余阵列使用多个磁盘合成一个“阵列”来提供更好的性能、冗余，或者两种都提供。 RAID的作用： 提高IO能力: 磁盘并行读写 提高耐用性: 磁盘冗余来实现 级别：多块磁盘组织在一起的工作方式有所不同 RAID实现的方式： 外接式磁盘阵列：通过扩展卡提供适配能力 内接式RAID：主板集成RAID控制器 安装OS前在BIOS里配置 软件RAID：通过OS实现（生产环境很少用，一般用来测试模拟） RAID级别RAID0 条带卷，读写能力提升，但无容错能力，最少需2块磁盘组成，磁盘利用率100% RAID1 镜像卷，具有一块硬盘的容错性，需要2,2N块磁盘组成，磁盘利用率50% RAID4 牺牲了1块硬盘实现冗余，至少3块磁盘组成，磁盘利用率（n-1）n RAID5 带奇偶校验的条带集，至少3块磁盘组成，磁盘利用率（n-1）n，一块硬盘损坏， ​ 将大幅消耗系统性能， 造成宕机，应及时更换硬盘，性价比高 RAID6 牺牲了2块硬盘实现冗余，至少4块磁盘组成，磁盘利用率（n-2）n RAID10 先做RAID1,再做RAID0，容错性相较于RAID01更强，至少4块磁盘组成，空间利用率50%。 ​ 生产中有条件情况下建议使用RAID10 RAID01 先做RAID0,再做RAID1，至少4块磁盘组成，容错性较RAID10稍弱，空间利用率50% RAID50 先做RAID5,再做RAID0，提供了接近RAID 10性能、可用性以及接近RAID 5成本的特性，具 有较好的整体性价比，至少6块磁盘组成，空间利用率（n-2）n JBOD 可用空间sum（S1,S2…），性能无提升，至少需要2块磁盘，磁盘利用率100% 注：目前RAID2-4已基本淘汰，RAID0生产中也少用，RAID1,RAID5,RAID10,RAID01常见 常见RAID图形示意RAID0 条带卷，读写能力提升，但无容错能力，最少需2块磁盘组成，磁盘利用率100% RAID1 镜像卷，读性能提升，写性能下降具有一块硬盘的容错性，需要2,2N块磁盘组成，磁盘利用率50% RAID5 带奇偶校验的条带集，与RAID4校验位固定在一个磁盘上相比，RAID5校验位在不同磁盘上不 断更替；至少3块磁盘组成，磁盘利用率（n-1）n，一块硬盘损坏，将大幅消耗系统性能，造成宕机，应 及时更换硬盘，性价比高 RAID01 先做RAID0,再做RAID1，至少4块磁盘组成，容错性较RAID10稍弱，空间利用率50% RAID10 先做RAID1,再做RAID0，容错性相较于RAID01更强，至少4块磁盘组成，空间利用率50%。 生产中有条件情况下建议使用RAID10 RAID50 先做RAID5,再做RAID0，提供了接近RAID 10性能、可用性以及接近RAID 5成本的特性，具有较好的整体性价比，至少6块磁盘组成，空间利用率（n-2）n JBOD 可用空间sum（S1,S2…），性能无提升，无冗余能力，至少需要2块磁盘，磁盘利用率100% RAID按实现方式的不同一般分为硬件RAID和软件RAID，生产环境中多数使用硬件RAID，在下面的实 验测试环境中我们使用软件RAID。 软件RAIDmdadm 命令 为软RAID提供管理界面 为空余磁盘添加冗余 结合内核中的md（multi devices） RAID设备可命名为/dev/md0、/dev/md1、/dev/md2、/dev/md3等 软件RAID的实现mdadm：模式化的工具 语法格式： 1mdadm [mode] &lt;raiddevice&gt; [options]&lt;component-devices&gt; 支持的RAID级别：LINEAR, RAID0, RAID1, RAID4,RAID5, RAID6, RAID10 模式： 12345678910111213创建：-C -C: 创建模式 -n #: 使用#个块设备来创建此RAID -l #：指明要创建的RAID的级别 -a &#123;yes|no&#125;：自动创建目标RAID设备的设备文件 -c CHUNK_SIZE: 指明块大小 -x #: 指明空闲盘的个数装配: -A监控: -F管理：-f, -r, -a -f: 标记指定磁盘为损坏 -a: 添加磁盘 -r: 移除磁盘 -D：显示raid的详细信息: mdadm -D /dev/md# 观察md的状态：cat /proc/mdstat 软RAID配置示例使用mdadm创建并定义RAID设备 12mdadm -C /dev/md0 -a yes -l 5 -n 3 -x 1 /dev/sdb1/dev/sdc1 /dev/sdd1 /dev/sde1 用文件系统对每个RAID设备进行格式化 1mke2fs -j /dev/md0 测试RAID设备 使用mdadm检查RAID设备的状况 1mdadm --detail|D /dev/md0 增加新的成员 1mdadm –G /dev/md0 –n4 -a /dev/sdf1 软RAID测试和修复模拟磁盘故障mdadm /dev/md0 -f /dev/sda1 移除磁盘mdadm /dev/md0 –r /dev/sda1 从软件RAID磁盘修复磁盘故障 替换出故障的磁盘然后开机 在备用驱动器上重建分区 mdadm /dev/md0 -a /dev/sda1 mdadm、/proc/mdstat及系统日志信息 软RAID管理生成配置文件：mdadm –D –s &gt;&gt; /etc/mdadm.conf 停止设备：mdadm –S /dev/md0 激活设备：mdadm –A –s /dev/md0 激活 强制启动：mdadm –R /dev/md0 删除raid信息：mdadm –zero-superblock /dev/sdb1 dd if=/dev/zero of=/dev/sdb1 破坏文件系统 mdadm -C /dev/md0 -a yes -l5 -n4 -x1 /dev/sd{b,c,d,e}1 创建一个RAID5,包含4块硬盘，一块空闲盘 mdadm -D /dev/md0 查看raid信息 mkfs.ext4 /dev/md0 -L raid 添加文件系统，添加卷标为raid umount /mnt/raid/ 停用 mdadm -S /dev/md0 禁用raid -A 启用raid mdadm /dev/md0 -f /dev/sdd1 模拟损坏硬盘 mdadm /dev/md0 -r /dev/sdd1 移除损坏硬盘 mdadm /dev/md0 -a /dev/sda1 更换一个新硬盘 mdadm -G /dev/md0 -n4 -a /dev/sdb3 拓展RAID一个硬盘 ll /etc/mdadm/conf mdadm -Ds /dev/md0 &gt; /etc/mdadm/conf 保存配置文件 将来重启或停止raid服务不会出现找不到配置文件的情况 二、LVM逻辑卷介绍及使用 logical Volumes 逻辑卷 lvcreae ↑ 创建逻辑卷 ↑ Volime Group 卷组 vgcreate ↑ 创建卷组 ↑ Physical Volumes 物理卷 pvcreate ↑ 创建物理卷 ↑ Linux Block Devices Linux块设备 pv管理工具显示物理卷 12pvs 简要pvdisplay 详细 创建卷组 1pvcreate /dev/DEVICE vg管理工具显示卷组 12vgs 简要vgdisplay 详细 创建卷组 1vgcreate [-s #[kKmMgGtTpPeE]] 卷组名 各分区物理路径 lv管理工具显示逻辑卷 12lvs 简要Lvdisplay 详细 创建逻辑卷 123lvcreate -L #[mMgGtT] -n 逻辑卷名 卷组名lvcreate -l 60%VG -n mylv testvglvcreate -l 100%FREE -n yourlv testvg lvcreate 常用选项 123456-c 指定chunk大小-l 指定PE数创建逻辑卷，或[%&#123;VG|FREE|ORIGIN&#125;]-L 指定大小创建逻辑卷-n 指定逻辑卷名称-p&#123;r|rw&#125; 指定逻辑卷权限-t 测试 删除逻辑卷 1lvremove /dev/VG_NAME/LV_NAME 重设文件系统大小 12fsadm [options] resize device [new_size[BKMGTEP]]resize2fs [-f][-F] [-M][-P] [-p] device [new_size] LVM快照快照是特殊的逻辑卷，它是在生成快照时存在的逻辑卷的准确拷贝 要注意快照不能替代备份作用，但可用于测试环境，在特殊情况下可代替备份效果。 快照生成时需要分配给它一定的空间，这些空间只有在原来的逻辑卷或者快照有所改变才会使用 这些空间，建立快照的卷大小只需要原始逻辑卷的15%-20%就可以了，也可以使用lvextend放大快照空 间要注意快照必须与被快照的LV在同一个卷组中，系统恢复时文件数量不能高于快照区的实际容量。 为现有逻辑卷创建快照与添加逻辑卷命令相同 lvcreate 创建快照常用选项： 1234-l 指定PE数创建快照，或[%&#123;VG|FREE|ORIGIN&#125;]-L 指定大小创建快照逻辑卷-n 指定快照名称-p&#123;r|rw&#125; 指定快照权限，一般设为只读 ext系列： 1234lvcreate -n centoslv0-snapshot -s -L 1G -p r /dev/centos6lv0lvdisplaymkdir /mnt/snapmount /dev/centos6vg0/centos6lv0-snapshot /mnt/snap xfs文件系统： 12345lvcreate -n centoslv0-snapshot -s -L 1G -p r /dev/lv0lvdisplaymkdir /mnt/snap 注：xfs文件系统不予许相同UUID设备进行挂载 1mount -o nouuid /dev/vg0/lv0-snopshot /mnt/lv0-snap 恢复快照 123umount /mnt/snap/umount /mnt/centos6lv0/lvconvert –merge /dev/centos6vg0/centos6lv0-snapshot 注：快照会在合并恢复后自动删除 删除快照 12umount /mnt/vg0/lv0lvremove /dev/mnt/lv0-snap]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>raid lvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手把手教你用VMware虚拟化软件安装CentOS 6系统]]></title>
    <url>%2F2018%2F04%2F26%2F%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8VMware%E8%99%9A%E6%8B%9F%E5%8C%96%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85CentOS%206%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[一、安装虚拟化软件： VMware Workstation是该公司出品的“虚拟 PC”软件（即：大家常说的“虚拟机”），通过它可在一台电脑上同时运行更多的Microsoft Windows、Linux、Mac OS X、DOS系统。此处我们以VMware14.1.1版本为例： 1.打开VMware软件后，选择创建新的虚拟机： 2.在类型配置选项选择典型配置，并点击下一步： 3.安装客户机操作系统选项选择稍后安装操作系统： 4.此处我们以安装CentOS6.9版本为例，选择Linux系统，版本选择CentOS6 64位： 5.下一步填写虚拟机名称和虚拟机想要放置的文件路径： 6.最大磁盘大小我们以200GB为例，虚拟磁盘选择存储为单个文件： 7.虚拟机配置完成后，我们可以进行配置修改，并将镜像ISO文件链接至虚拟机的CD/DVD下： 二、安装CentOS 6系统： 1.选择第一项：安装或升级系统（Install or upgrade an existing system）： 2.此处我们选择跳过（Skip），选择OK则进行检查IOS镜像是否完好： 3.选择适合自己的语言及键盘使用模式，我们以英文界面安装为例，选择English： 4.选择存储介质的类别,此处我们选择 Basic Storage Devices，如果安装到网络存储介质如SANS上，选择 Specialized Storage Devices： 5.提示新硬盘或硬盘上的数据是否已不再需要，选择Yes，discard any data： 6.输入主机名(hostname),在此界面也可选择Configure Network进行网络配置： 7.时区选择：我们以北京时间为例，在地图上选择中国上海，并将System clock uses UTC，否则将与格林尼治时间相同步。 8.输入管理员账户root的密码并重复输入确认： 9.分区管理我们选择Create Custom Layout,进行自定义分区： 10.点击Create进行分区创建，选择标准分区（Standard Partition），我们将sda1分区挂载至/boot目录，sda2分区挂载至“/”根目录,也可创建自己的个性化分区，如将sda3挂载至/data分区： 11.创建swap分区：swap分区功能类似于Windows系统下的虚拟内存功能，我们选择分区类型swap，分区大小一般设置为内存的2倍左右： 12.如图，我们已经将主要分区创建完成，点击NEXT，出现硬盘将被格式化提示，选择Format： 13.此处可添加启动菜单，无特别需要我们选择下一步： 14.进行服务器类型选择以及个性化初始软件安装，我们以Desktop（图形桌面）安装为例，选择Customize now可进行个性化初始软件安装： 15.点击NEXT，进入CentOS 6安装过程： 16.好啦，我们已经初步完成了CentOS 6.9版本的安装，进行简单的信息填写，就可以进入Linux的世界中了！]]></content>
      <categories>
        <category>手把手系列</category>
      </categories>
      <tags>
        <tag>手把手系列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手把手系列（四）教你用kickstart自动化安装CentOS系统]]></title>
    <url>%2F2018%2F04%2F25%2F%E6%89%8B%E6%8A%8A%E6%89%8B%E7%B3%BB%E5%88%97%EF%BC%88%E5%9B%9B%EF%BC%89%E6%95%99%E4%BD%A0%E7%94%A8kickstart%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85CentOS%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[一、KickStart安装简介KickStart是一种半自动化的安装方式。KickStart的工作原理是通过记录典型的安装过程中所需人工干预 填写的各种参数，并生成一个名为ks.cfg的文件；在其后的安装过程中（不只局限于生成KickStart安装 文件的机器）当出现要求填写参数的情况时，安装程序会首先去查找KickStart生成的文件，当找到合适 的参数时，就采用找到的参数，当没有找到合适的参数时，才需要安装者手工干预。这样，如果KickStart 文件涵盖了安装过程中出现的所有需要填写的参数时，安装者完全可以只告诉安装程序从何获取ks.cfg文件 ，然后去忙自己的事情。等安装完毕，安装程序会根据ks.cfg中设置的重启选项来重启系统，并结束安装。 KickStart文件的格式：KickStart文件格式与anaconda-ks.cfg文件格式十分类似，总体由三部分组成： 1）命令段：指明各种安装前配置，如键盘类型等 必备命令： authconfig：认证方式配置 authconfig –useshadow –passalgo=sha512 bootloader：bootloader的安装位置及相关配置 bootloader –location=mbr –driveorder=sda – append=”crashkernel=auto rhgb quiet” keyboard：设定键盘类型 lang：语言类型 part：创建分区 rootpw：指明root的密码 timezone：时区 可选命令： install OR upgrade text：文本安装界面 network firewall selinux halt poweroff reboot repo user：安装完成后为系统创建新用户 url: 指明安装源 key –skip 跳过安装号码,适用于rhel版本 2）程序包段：指明要安装的程序包组或程序包，不安装的程序包等 %packages @group_name package -package %end 3）脚本段： %pre：安装前脚本 运行环境：运行于安装介质上的微型Linux环境 %post：安装后脚本 运行环境：安装完成的系统 安装后脚本非常有用，我们可以在这里定义系统安装完成后自动安装yum源，创建一些普通用户等功能 生成ks应答文件方法：1.参照anaconda-ks.cfg文件修改（不常用） 2.利用system-config-kickstart图形工具制作（常用） 检查ks文件语法错误： ksvalidator /path/to/ks.cfg 在实验之前，我们还是先了解下系统安装程序anaconda以及光盘中isolinux目录的功能 anaconda：系统安装程序1）安装前配置阶段： 安装过程使用的语言 键盘类型 安装目标存储设备 Basic Storage：本地磁盘 特殊设备：iSCSI 设定主机名 配置网络接口 时区 管理员密码 设定分区方式及MBR的安装位置 创建一个普通用户 选定要安装的程序包 2）安装阶段： 在目标磁盘创建分区，执行格式化操作等 将选定的程序包安装至目标位置 安装bootloader和initramfs 3）图形模式首次启动： Iptables Selinux Core dump 系统在完成安装后，会在用户家目录自动生成一个anaconda-ks.cfg配置文件，记录了安装系统时选择的 各种参数，安装包等内容 系统光盘中isolinux目录列表文件：boot.cat 类似于系统启动时MBR的作用 grub.conf grub.conf文件镜像 initrd.img 是ramfs虚拟文件系统（先cpio，再gzip压缩） isolinux.bin 相当于grub的第二阶段 isolinux.cfg isolinux.bin的配置文件，当光盘启动，会自动去找isolinux.cfg文件 memtest 内存检测，这是一个独立程序 splash.jpg 光盘启动界面的背景图 vesamenu.c32 菜单风格，菜单图标 vmlinuz 内核镜像 二、实验：使用kickstart半自动化安装CentOS系统：CentOS6：一、系统默认未安装system-config-kickstart，先进行yum安装： yum install system-config-kickstart 二、配置kickstart 1.基本配置 这里我们选择语言、键盘模式、时区，设置root账户密码并且选择安装后自动重启以及字符界面安装。 2.选择安装方式，我们以http安装为例 3.Boot Loader设置 4.分区设置，与正常安装CentOS系统时设置分区类似，点击Add添加分区 5.网络配置界面，用来配置系统安装完成后的网络地址 6.用户加密方式设置，我们选择默认即可 7.防火墙设置，在这里我们可以关闭SELinux策略，防火墙等级选择默认 8.显示设置 9.自定义安装包，我们可以在这一项选择想要安装的安装包，比如mysql数据库等 10．安装前脚本 11.安装后脚本 我们可以在这里定义系统安装完成后自动安装yum源，创建一些普通用户等功能 三、保存ks.cfg文件 打开ks.cfg文件，可以看到刚才设置的参数已经保存在文件中，我们还可以直接修改ks.cfg文件，比如添加一些安装包等 四、在本机打开httpd服务，并将fs.cfg文件上传到网页 service httpd restart service iptables stop mv ks6_mini.cfg /var/www/html 浏览器：http://172.20.101.101/ks6_mini.cfg确认 五、开启一台新虚拟机： 网卡设置为桥接模式 在进入光盘引导界面后，按ESC，出现下图界面，输入： boot: linux ip=172.20.0.222 netmask=255.255.0.0 ks=http://172.20.0.223/ks6_mini.cfg 注：此处设置的ip地址是为了访问httpd服务设置的ip地址，与系统安装后的ip地址不同 六、自动化安装 如果ks.cfg文件没有设置出错的话，将进入自动安装界面 七、安装完成 我们可以看到，安装后脚本也执行成功，wang账户创建成功，分区创建成功！ CentOS7：7版本的kickstart安装与6基本一致，仅需修改个别版本参数 需要注意的是，在可选安装包这一项，获取不到安装包信息 解决方法：将yum的base源名称改为development即可 再次打开，我们发现可选安装包又出现了 其他流程与安装CentOS6版本基本一致： 三、实验：制作CentOS6的启动光盘boot.iso思路：参考ISO光盘内文件，制作boot6.iso 1.将光盘isoliux目录复制到/data/myiso目录下，ks.cfg文件复制到/data/myiso/ksdir下 目录结构如下： rm -rf /data/* cd /data mkdir myiso cp -r /misc/cd/isolinux /data/myiso/ mkdir /data/myiso/ksdir cp ks6_mini.cfg /data/myiso/ksdir cp ks6_desktop.cfg /data/myiso/ksdir 2.修改isolinux.cfg文件 cd isolinux/ vim isolinux.cfg 内存检测删掉 本地安装留下，且留作默认项（重要） 救援模式删掉 增加桌面安装 label desktop kernel vmlinuz append initrd=initrd.img ks=cdrom:/ksdir/ks6_desktop.cfg 增加最小化安装 label mini kernel vmlinuz append initrd=initrd.img ks=cdrom:/ksdir/ks6_mini.cfg 3.生成boot.iso文件 mkisofs -R -J -T -v –no-emul-boot –boot-load-size 4 –boot-info-table -V “CentOS 6.9 x86_64 boot” -b isolinux/isolinux.bin -c isolinux/boot. cat -o /root/boot.iso /data/myiso/ 4.将boot.iso文件导出系统，新开一台虚拟机，挂载boot.iso；并设置光盘引导启动 5.开机成功,显示我们通过isolinux.cfg修改过的菜单选项，默认本地安装，选择其他选项将进行对应系统的自动安装 四、实验：制作U盘自动安装盘思路：以实验三制作完成的boot.iso为启动文件，增加一块1G的虚拟硬盘/dev /sdc模拟U盘将iso转 1.为混合模式 isohybrid boot.iso 2.使用dd命令写入新硬盘 dd if=boot.iso of=/dev/sdc 3.开启一台新的虚拟机，插入刚才的硬盘，并设置新硬盘为启动项 4.启动成功 五、实验：制作不依赖网络的完整CentOS6系统ISO自动安装盘1.将CentOS6的第一张盘和第二张盘所有内容拷入centos6目录 mkdir /data/centos6 cp -rv /misc/cd/ /data/centos6 第一张盘 cp -rv /misc/cd/* /data/centos6 第二张盘 2.删除centos6/repodata/文件，只留下.*comps.xml一个文件 3.根据.*comps.xml生成新的repodata目录 cd centos6/ createrepo -g .*comps.xml 4.将准备好的ks.cfg文件拷入/data/centos6/ksdir目录 mkdir /data/centos6/ksdir cp ks6_mini.cfg /data/centos6/ksdir cp ks6_desktop.cfg /data/centos6/ksdir 5.删除/data/centos6目录下多余的文件，如TRANS.TBL文件 find /data/centos6 -name TRANS.TBL -exec rm {} \; 6.修改ks.cfg文件启动方式为光盘启动cdrom vim ksdir/ks6_mini.cfg #Use network installation cdrom 7.按照ks.cfg文件修改isoinux.cfg文件启动选项 cp /root/isolinux/isolinux.cfg . vim isolinux.cfg 注意设置本地启动为默认启动项 8.生成boot.iso mkisofs -R -J -T -v –no-emul-boot –boot-load-size 4 –boot-info-table -V “CentOS 6.9 x86_64 Everything” -b isolinux/isolinux.bin -c isolinux/boot.cat -o /root/CentOS-6.9-x86_64-Everything.iso /data/centos6/ 9.将CentOS-6.9-x86_64-Everything.iso文件导出，由于文件过大，推荐使用xftp导出 10.新开一台虚拟机，挂载CentOS-6.9-x86_64-Everything.iso，设置光盘为开机启动 如无错误，将弹出选项可进行自动安装]]></content>
      <categories>
        <category>手把手系列</category>
      </categories>
      <tags>
        <tag>手把手系列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[交换分区swap管理及特殊介质的使用]]></title>
    <url>%2F2018%2F04%2F25%2F%E4%BA%A4%E6%8D%A2%E5%88%86%E5%8C%BAswap%E7%AE%A1%E7%90%86%E5%8F%8A%E7%89%B9%E6%AE%8A%E4%BB%8B%E8%B4%A8%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[一、交换分区swap管理：交换分区是系统RAM的补充，相当于Windows系统中的虚拟内存，当系统RAM不够用的时候将使用交换分区来代替内存使用。 基本设置包括： 创建交换分区或者文件 使用mkswap写入特殊签名 在/etc/fstab文件中添加适当的条目 使用swapon -a激活交换分区 swapon 启用交换分区 格式：swapon [OPTION]…[DEVICE] 123-a 激活所有交换分区-p priority 指定优先级/etc/fstab:pri=value swapoff [OPTION]…[DEVICE] 禁用指定交换分区 swap的优先级可以指定swap分区0到32767的优先级，值越大优先级越高 系统默认会给没有指定的swap指定一个优先级，从-1开始，每加入一个新的没有指定优先级的swap，会给这个优先级减一。先添加的swap的缺省优先级比较高，除非用户自己指定一个优先级，而用户指定的优先级(是正数)永远高于核心缺省指定的优先级(是负数) 优化性能：分布存放，高性能磁盘存放 场景1：增加一个新的swap分区 fdisk /dev/sdb 创建新的swap分区，tyep=82=Linux swap 注：如果文件系统分区没有同步成功，需我们手动同步分区 CentOS5,7版本：partx -a /dev/sdb CentOS7版本： partprobe /dev/sdb mkswap /dev/sdb1 -L swap_sdb2 添加swap文件系统 vim /etc/fstab 1UUID=xxx swap swap defaults 0 0 swapon -a 使swap分区生效 swapon -s 查看是否生效 场景2：使用一个文件当做新的swap分区123456781. dd if=/dev/zero of=/swapfile bs=1024M count=2 创建一个2G文件2. mkswap /swapfile 添加文件的文件系统为swap blkid /swapfile 查看文件系统添加成功3. vim /etc/fstab 修改/etc/fstab文件 /swapfile swap swap defaults 0 0 注：挂载文件名，不能使用UUID 4. swapon -a5. swapon -s 二、Linux系统光盘使用光盘在Linux图形环境下将自动挂载 否则就必须手动进行挂 挂载命令： mount /dev/cdrom /mnt/ ejetc命令卸载或弹出光盘 创建ISO文件 12cp -a /dev/cdrom /root/centos7.isomkisofs -r -o /root/etc.iso /etc 刻录光盘 ​ wodim -v -eject centos.iso mkisofs -r -o /root/etc.iso /etc 这种制作光盘方法可作为yum源，但不可做启动光盘 centos官网https://wiki.centos.org 可搜索mkdvdiso.sh脚本 即可引导又可当yum源 三、Linux系统USB介质使用查看USB设备是否识别 lsusb 被内核探测为SCSI设备 /dev/sdaX、/dev/sdbX、或类似的设备文件 在图形环境中自动挂载 图标在[计算机]窗口中创建 挂载在/run/media// 手动挂载 mount /dev/sdb1 /mnt 四、强大的dd工具dd命令：convert and copy a file 用法： 12345678910111213dd if=/PATH/FROM/SRC of=/PATH/TO/DESTbs=#：block size, 复制单元大小count=#： 复制多少个bsof=file 写到所命名的文件而不是到标准输出if=file 从所命名文件读取而不是从标准输入bs=size 指定块大小（既是是ibs也是obs)ibs=size 一次读size个byteobs=size 一次写size个bytecbs=size 一次转化size个byteskip=blocks 从开头忽略blocks个ibs大小的块seek=blocks 从开头忽略blocks个obs大小的块count=n 只拷贝n个记录conv=conversion[,conversion…] 用指定的参数转换文件 转换参数: 12345678ascii 转换 EBCDIC 为 ASCIIebcdic 转换 ASCII 为 EBCDIClcase 把大写字符转换为小写字符ucase 把小写字符转换为大写字符nocreat 不创建输出文件noerror 出错时不停止notrunc 不截短输出文件sync 把每个输入块填充到ibs个字节，不足部分用空(NUL)字符补齐 备份MBR： 1dd if=/dev/sda of=/tmp/mbr.bak bs=512 count=1 破坏MBR中的bootloader： 1dd if=/dev/zero of=/dev/sda bs=64 count=1 seek=446 有一个大与2K的二进制文件fileA。现在想从第64个字节位置开始读取，需要读取的大小是128Byts。 又有fileB, 想把上面读取到的128Bytes写到第32个字节开始的位置，替换128Bytes，实现如下： 1dd if=fileA of=fileB bs=1 count=128 skip=63 seek=31 conv=notrunc 备份： 12345dd if=/dev/sdx of=/dev/sdy 将本地的/dev/sdx整盘备份到/dev/sdydd if=/dev/sdx of=/path/to/image 将/dev/sdx全盘数据备份到指定路径的image文件dd if=/dev/sdx | gzip &gt;/path/to/image.gz 备份/dev/sdx全盘数据，并利用gzip压缩，保存到指定路径 恢复： 123dd if=/path/to/image of=/dev/sdx 将备份文件恢复到指定盘gzip -dc /path/to/image.gz | dd of=/dev/sdx 将压缩的备份文件恢复到指定盘 拷贝内存资料到硬盘 1dd if=/dev/mem of=/root/mem.bin bs=1024 将内存里的数据拷贝到root目录下的mem.bin文件 从光盘拷贝iso镜像 1dd if=/dev/cdrom of=/root/cd.iso 拷贝光盘数据到root文件夹下，并保存为cd.iso文件 销毁磁盘数据，文件系统 1dd if=/dev/urandom of=/dev/sda1 利用随机的数据填充硬盘，在某些必要的场合可以用来销毁数据，执行此操作以后，/dev/sda1将无法挂载， 创建和拷贝操作无法执行。 得到最恰当的block size 123dd if=/dev/zero bs=1024 count=1000000 of=/root/1Gb.filedd if=/dev/zero bs=2048 count=500000 of=/root/1Gb.filedd if=/dev/zero bs=4096 count=250000 of=/root/1Gb.file 通过比较dd指令输出中命令的执行时间，即可确定系统最佳的block size大小 测试硬盘写速度 1dd if=/dev/zero of=/root/1Gb.file bs=1024 count=1000000 测试硬盘读速度 1dd if=/root/1Gb.file bs=64k | dd of=/dev/null 修复硬盘 1dd if=/dev/sda of=/dev/sda 当硬盘较长时间（比如1,2年）放置不使用后，磁盘上会产生消磁点。当磁头读 到这些区域时会遇到困难，并可能导致I/O错误。当这种情况影响到硬盘的第一 个扇区时，可能导致硬盘报废。上边的命令有可能使这些数据起死回生,且这个 过程是安全高效的]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>swap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统磁盘及文件系统管理]]></title>
    <url>%2F2018%2F04%2F24%2FLinux%E7%B3%BB%E7%BB%9F%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[一、磁盘基本概念设备文件：Linux中一切皆文件：open（），read（），write（），close（） 设备类型： 块设备：block，存储单位”块”，磁盘 字符设备：char，存储单位”字符”，键盘 设备文件：关联至一个设备驱动程序，进而能够跟与之对应硬件设备进行通信 设备号码： 主设备号：maj number，标识设备类型 次设备号：min number，标识同一类型下的不同设备 磁盘结构硬盘的接口类型： 并行： IDE：133MB/s SCSI：640MB/s 串口： SATA：6Gbps SAS：6Gbps USB：480MB/s 硬盘：机械硬盘（HDD）：传统普通硬盘，主要由：盘片，磁头，马达等组成 ​ 优势：相比固态硬盘，价格低，容量大，使用寿命长 固态硬盘（SSD）：用固态电子存储芯片阵列而制成的硬盘。 ​ 优势：相比机械硬盘，防震抗摔，传输速率，功率，噪音有优势 硬盘有价，数据无价，目前SSD不能完全取代HHD 磁盘设备的设备文件命名： /dev/DEV_FILE 硬盘接口命名如：SCSI,SATA,SAS,IDE,USB： /dev/sd 虚拟磁盘： /dev/vd 不同磁盘标识： a-z，aa，ab… ​ 例如： /dev/sda,/dev/sdb 同一设备的不同分区： 1,2，… ​ 例如：/dev/sda1,/dev/sda5 注：在脚本中，尽量避免使用磁盘设备文件名诸如sda，名称不稳定，应使用UUID 磁盘存储术语：head：磁头； 8bit寻址 2**8=256 track：磁道； ctlinder：柱面 10bit寻址 2**10=1024 sector：扇区 6bit寻址 2**6=64 CHS：磁盘三维。柱面、磁头、扇 采用24bit位寻址 其中前10位表示cylinder，中间8位表示head，后面6位表示sector。 最大寻址空间8GB LBA： 逻辑区块地址 LBA是一个整数，通过转换成CHS格式完成磁盘具体寻址 LBA采用48个bit位寻址 最大寻址空间128PB 二、磁盘分区管理我们知道使用磁盘有三个步骤： 创建分区 创建文件系统：格式化 挂载：分配目录名 为什么要对磁盘进行分区？ 优化I/O性能 实现磁盘空间配额限制 提高修复速度 隔离系统和程序 安装多个OS 采用不同的文件系统 分区类型两种分区方式：MBR，GPT MBR：Master Boot Record诞生于1982年，使用32位表示扇区数，分区不能超过2T MBR如何分区：按柱面 0磁道0扇区：512bytes ​ 446bytes：boot loader ​ 64bytes：分区表 ​ 16bytes：标识一个分区（最多4个分区） ​ 2bytes：55AA（分区标识位） 支持4个主分区；3个主分区+1扩展分区（N个逻辑分区） 注：生产中最好给MBR分区表进行备份 MBR分区结构: MBR的硬盘主引导记录MBR由4个部分组成 主引导程序（偏移地址0000H–0088H），它负责从活动分区中装载，并运行系统引导程序。 出错信息数据区，偏移地址0089H–00E1H为出错信息，00E2H–01BDH全为0字节。 分区表（DPT,Disk Partition Table）含4个分区项，偏移地址01BEH–01FDH,每个分区表项长16个字节，共64字节为分区项1、分区项2、分区项3、分区项4 结束标志字，偏移地址01FE–01FF的2个字节值为结束标志55AA BIOS+MBR 传统BIOS运行流程： ​ 开机–&gt;BIOS初始化–&gt;BIOS自检–&gt;引导操作系统–&gt;进入系统 GPT：GUID（Globals Unique Identifiers）支持128个分区，使用64位，支持8Z（512Byte/block）,64Z（4096Byte/block） 使用128位的通用唯一识别码UUID（Universally Unique Identifier）表示磁盘和分区表自动备份在头和尾两份，并有CRC校验位 UEFI（统一扩展固件接口）：硬件支持GPT，使操作系统启动 分区表 ​ MBR保护+GPT分区表+GPT划分数据+备份 UEFI+GPT UERI运行流程 ​ 开机–&gt;UEFI初始化–&gt;引导操作系统–&gt;进入系统 管理分区列出块设备： lsblk 创建分区使用： ​ fdisk 创建MBR分区 ​ gdisk 创建GPT分区 ​ parted 高级分区操作 partprobe： 重新设置内存中的内核分区表版本 parted命令 parted的操作都是实时生效的，小心使用 格式：parted[option]…[设备[命令[参数]…]…] 12345parted /dev/sdb mklabel gpt|msdos 设置分区类型GPT或MBRparted /dev/sdb print 打印sdb分区列表信息parted /dev/sdb mkpart primary 1 200 （默认M） 设置sdb分区大小parted /dev/sdb rm 1 删除sdb1分区parted -l 列出分区信息 分区工具fdisk和gdisk 查看分区: 1fdisk -l[-u][device…] 管理分区（交互式）: 12345678910fdisk /dev/sdb p 显示分区列表 t 更改分区类型（数据将丢失） n 创建新分区 d 删除分区 t 添加设备标签 v 校验分区 u 转换单位 w 保存并退出 q 不保存并退出 注：可使用重定向和多行重定向echo -e “n\np\n\n\n+2G\nw\n” | fdisk /dev/sdc 同步分区表1234cat/proc/partations 查看内核是否已经识别新的分区partprobe 同步分区表（centos5,7可用）partx -a /dev/sda 增加分区同步分区表（centos6可用）时使用；partx -d –nr M-N /dev/sda 删除分区同步分区表（centos6可用）时使用； 三、文件系统管理所谓文件系统，它是操作系统中藉以组织、存储和命名文件的结构。磁盘或分区和它所包括的文件系统的 不同是很重要的，大部分应用程序都基于文件系统进行操作，在不同种文件系统上是不能工作的。 文件系统类型Linux文件系统：ext2，ext3，ext4，xfs，btrfs，reiserfs，jfs，swap 光盘：iso9660 Windows：FAT32,exFAT,NTFS Unix：FFS（fast），UFS（unix），JFS2 网络文件系统：NFS，CIFS 集群文件系统：GFS2,OCFS2 分布式文件系统：fastfs,ceph,moosefs,mogilefs,glusterfs,Lustre RAW：未经处理或者未经格式化产生的文件系统（性能好，但不便于管理） 根据文件系统是否支持”journal（日志）”功能可分为： 日志型文件系统：ext3，ext4，xfs，…（牺牲读取性能，防止数据文件破坏） 非日志型文件系统：ext2，vfat（易造成数据文件破坏） 文件系统的组成部分： ​ 内核中的模块：ext4，xfs，vfat ​ 用户空间的管理工具：mkfs.ext4，mkfs.xfs，mkfs.vfat Linux的虚拟文件系统：VFS 查看支持的文件系统：cat /proc/filesystems 创建文件系统：mkfs命令两种用法： mkfs.FS_TYPE /dev/DEVICE 建议使用此用法，直观不易出错 1234ext4xfsbtrfsvfat mkfs -t FS_TYPE /dev/DEVICE 1-L &apos;LABEL&apos; 设定卷标（分区标签） mke2fs ext系统文件系统专用的管理工具 12345678910-t &#123;ext2|ext3|ext4&#125;-b &#123;1024|2048|4096&#125;-L &apos;LABEL&apos;-j: 相当于 -t ext3 mkfs.ext3 = mkfs -t ext3 = mke2fs -j = mke2fs -t ext3-i #: 为数据空间中每多少个字节创建一个inode；此大小不应该小于block的大小-N #：指定分区中创建多少个inode-I 一个inode记录占用的磁盘空间大小，128---4096-m #: 默认5%,为管理人员预留空间占总空间的百分比-O FEATURE[,...]：启用指定特性-O ^FEATURE：关闭指定特性 文件系统标签(LABEL): 它是指向设备的另一种方法，与设备无关 blkid 块设备属性信息查看 格式：blkid [option]… [DEVICE] 12-U UUID 根据指定UUID来查找对应设备-L LABEL 根据指定卷标来查找对应设备 e2label：管理ext系列文件系统的LABEL卷标 格式： 1e2label DEVICE [LABEL] findfs : 查找分区 格式： 12findfs [option] LABEL = &lt;label&gt; 根据卷标查找findfs [option] UUID = &lt;uuid&gt; 根据UUID查找 tune2fs 重新设定ext系列文件系统可调整参数的值 1234567-l 查看指定文件系统超级块信息-L&apos;LABEL&apos; 修改卷标-m # 修改预留给管理员空间的百分百-j 将ext2升级到ext3-O 文件系统属性启用或禁用，-O ^has_journal-o 调整文件系统的默认挂载选项，-o^acl-U UUID 修改UUID号 dumpe2fs 块分组管理，32768 1-h 查看超级块信息，不显示分组信息 超级块（superblock）dumpe2fs /dev/sda1 查看分区下所有超级块 12dumpe2fs -h 查看超级块信息tune2fs -l 查看超级块信息 超级块时存储文件系统的大小、有多少是空的和已经填满的占多少，以及它们各自的总数和其他诸如此类的信息。 要使用一个分区来进行数据访问，那么第一个要访问的就是超级块，由此可见超级块的重要性。 超级块占用第一号物理块，是文件系统的控制块。 超级块包括：文件系统的大小、空闲块数目、空闲块索引表、空闲i节点数目、空闲i节点索引表、封锁标记等。 超级块时系统为文件分配存储空间、回收存储空间的依据。 所以，为了防止超级块数据损坏，就需要对超级块数据进行备份，以便于损坏时进行修复。 文件系统检测和修复常发生于死机或者非正常关机之后 挂载为文件系统标记为”no clean” 注意：一定不要在挂载状态下修复或检测，否则数据将破坏！ 12345fsck 文件系统检查fsck.FS_typefsck -t FS_type-p 自动修复错误-r 交互式修复错误 注：FS_TYPE一定要与分区上已设置的文件系统类型相同 e2fsck ext系列文件专用的检测修复工具 12-y 自动回答为yes-f 强制修复 四、设备挂载管理挂载：把额外的文件系统与根文件系统现场的目录建立起关联关系，进而使得此目录作为其他文件访问入口的行为 一个挂载点只能挂载一个设备，但一个设备可挂载多个挂载点 挂载点建议要是空目录，否则该目录下原有文件将被隐藏，变为垃圾文件 把设备关联挂载点：mount Point monut 卸载：为解除此关联关系的过程 卸载时：可使用设备，也可使用挂载点 umount 挂载命令：mountcat /proc/mounts: 查看内核追踪到的已挂载的所有设备 格式： 1mount [-fnrsvw][-t vfstype] [-o options] device dir device 指明要挂载的设备 设备文件：例如dev/sda2 卷标：-L’LABEL’，例如-L’MYDATA’ UUID，-U’UUID’，例如-U ‘35bfb8f8-1c9a-4f67-b8fe-a7edb84c4780’ 伪文件系统名称：proc，sysfs，devtmpfs，configfs dir 挂载点 事先存在；建议使用空目录 进程正在使用中的设备无法被卸载 mount常用命令选项： 12345678-t 指定要挂载的设备上的文件系统类型-r readontlt，只读挂载-w r+w，读写挂载（默认）-n centos6隐藏挂载，不更新/etc/mtab,mount不可见，cat /proc/mounts可见-a 自动挂载所有支持自动挂载的设备-L&apos;LABEL&apos; 以卷标指定挂载设备-U&apos;UUID&apos; 以UUID指定要挂载的设备-B，–bind 绑定目录到另一个设备上。类似于软连接 -o options：(挂载文件系统的选项)，多个选项使用逗号分隔 1234567891011121314async 异步模式（默认模式）sync 同步模式,内存更改时，同时写磁盘atime/noatime 包含目录和文件（是否更新atime，默认更新）diratime/nodiratime 目录的访问时间戳auto/noauto 是否支持自动挂载,是否支持-a选项exec/noexec 是否支持将文件系统上运行应用程序dev/nodev 是否支持在此文件系统上使用设备文件suid/nosuid 是否支持suid和sgid权限remount 重新挂载ro 只读rw 读写user/nouser 是否允许普通用户挂载此设备，/etc/fstab使用acl 启用此文件系统上的acl功能loop 使用loop设备，把文件挂载目录，模拟设备 默认：rw，suid，dev，exec，auto，nouser，async 卸载命令：umount查看挂载情况： 1findmnt MOUNT_POINT|DEVICE 查看正在访问指定文件系统的进程： 12lsof MONUT_POINTfuser -v MOUNT_POINT 终止所有在正访问指定的文件系统的进程 1fuser -km MONUT_POINT 卸载： 12umount DEVICEumount MOUNT_POINT 挂载点和/etc/fstab配置文件系统体系 被mount、fsck和其他程序使用 系统重启时保留文件系统体系 可以在设备栏使用文件系统卷标 使用mount -a 命令挂载/etc/fstab中的所有文件系统 /etc/fstab 每行定义一个要挂载的文件系统设备或伪文件系统 挂载点 文件系统类型 挂载选项 备份间隔时间{0|1|2} 文件系统检查{0|1} 要挂载的设备或伪文件系统 设备文件 ​ LABEL：LABEL=” “ ​ UUID：UUID=” “ 伪文件系统名称：proc，sysfs 挂载点 文件系统类型 挂载选项：default 转储频率：0：不做备份 ； 1：每条转储 ； 2：每隔一天转储 ； 自检次序：0：不自检 ； 1：首先自检；一般只有rootfs才用1 一些特殊文件设备的挂载永久生效的设置：vim /etc/fstab /root/p1 /mnt/p1 ext4 loop 0 0 挂载普通文件 /mnt/cdrom /mnt/cdrom iso9660 defaults 0 0 挂载光盘 /boot /mnt/boot none bind 0 0 挂载目录到目录下]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>磁盘管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手把手系列（二）教你搭建自己的yum源服务器]]></title>
    <url>%2F2018%2F04%2F20%2F%E6%89%8B%E6%8A%8A%E6%89%8B%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84yum%E6%BA%90%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[一、前期准备准备两台Linux服务器，本文所用的服务器为CentOS6.9，及CentOS7.4服务器各一台，将演示CentOS7服 务器作为yum源服务器，用CentOS6服务器进行yum访问。 二、开启CentOS7自动挂载光盘服务我们知道在CentOS6版本系统中，有一个“神奇”的目录/misc可实现光盘的自动挂载，但在CentOS7版本中 默认并不支持此服务，需要我们进行手动安装autofs服务 yum install autofs 安装autofs包 systemctl start autofs 开启自动挂载 systemctl enable autofs 下次开机默认开启自动挂载 三、关闭防火墙要注意CentOS6版本与CentOS7版本关闭防火墙的命令有所不同： CentOS6： service iptables stop 关闭防火墙 chkconfig iptables off 下次启动时自动关闭防火墙 CentOS7： systemctl stop firewalld 关闭防火墙 systemctl disable firewalld 下次启动时自动关闭防火墙 四、安装httpd服务yum install httpd 五、开启httpd服务service httpd start 将本机ip地址输入浏览器，不出意外就能访问我们搭建的测试页面啦！ 六、创建网页目录打开httpd包的文件列表，我们看到/var/www/html的文件夹，这里就是存放网页内容的目录了 rpm -ql httpd 查看httpd包的文件列表 cd /var/www/html 进入html目录 mkdir -pv centos/{6,7}/os/x86_64/ 创建挂载6，7yum源的目录 七、挂载yum源mount /dev/sr0 /var/www/centos/7/os/x86_64/ 将6光盘挂载至6网络下 mount /dev/sr1 /var/www/centos/6/os/x86_64/ 将7光盘挂载至7目录下 此时，在浏览器输入：ipadress/centos/版本号/os/x86_64/ 就能看到我们挂载的yum源了 注：echo ‘- – -‘ &gt; /sys/class/scsi_host/host0/scan 热添加光盘时识别光盘 八、在CentOS搭建yum仓库[test] 仓库名 name=test 描述名，不设置不影响包的安装，但会报错 baseurl=http://172.20.102.79/centos/6/os/x86_64/ 设置仓库地址链接 gpgcheck=0 默认为1，表示数字密钥安全检查，0表示不进行安全检查 九、更新yum仓库yum clean all 清空全部yum缓存 yum repolist 显示yum仓库列表 此时我们看到test仓库下已经更新出有6706个包列表，现在我们就可以通过自己搭建的yum源服务器来安装 程序包了！]]></content>
      <categories>
        <category>手把手系列</category>
      </categories>
      <tags>
        <tag>手把手系列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统软件包管理介绍]]></title>
    <url>%2F2018%2F04%2F20%2FLinux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[一、软件包基础软件运行环境：程序员代码–&gt;预处理–&gt;编译–&gt;汇编–&gt;链接 静态编译：.a 动态编译：.so 包管理器：二进制应用程序的组成部分 二进制文件、库文件、配置文件、帮助文件 包命名：源代码：name-VERSION.tar.gz|bz2|xz 包之间：可能存在依赖性关系，甚至循环依赖 解决依赖包管理工具：yum：rpm包管理器的前端工具 apt-get：deb包管理器前端工具 zypper：suse上的rpm前端管理工具 dnf：Fedora 18+ rpm包管理器前端管理工具 程序包管理器：debian：deb文件，dpkg包管理器 redhat：rpm文件，rpm包管理器 rpm：Redhat Package Manager RPM Package Manager 二、RPM包管理RPM代表Redhat Packge Manager（Redhat包管理器）RPM现在已成为管理Redhat和UnitedLinux以及其他许多发行版本上的软件的标准。 RPM本质上就是一个包，包含可以立即在特定机器体系结构上安装和运行的Linux 软件。最初加载到发行版本中的所有软件都是通过一个RPM来安装的。 RPM剖析：RPM是文件包，它包括关于包及其功能和依赖关系（即在该包能够运行之前必须安装 其他哪些包）的信息。还包含包中的文件清单，指定这些文件必须加载到系统中的何 处，以及它们的初始权限如何。RPM还包含安装前脚本，这是由包开发人员编写的。 RPM其次还包含已编译的二进制文件。最后，RPM包含了安装后的脚本。 RPM数据库：/var/lib/rpm 包含了关于系统上已安装的每个RPM信息。这个数据库知道包之间的依赖关系，还知道每个包的 文档和配置文件的位置。在加载和卸载包时，RPM使用这个数据库来检查依赖关系。用户还可以 在这个数据库查询关于包的信息。 rpm常用选项： 1234567891011121314-i 安装包-h 输出哈希（#）符号提供安装进度更新-v 显示详细过程-ihv是常用配合选项；-e 删除已安装的包-V 验证开关-U 升级-q 查询-qc 显示包的配置文件-qd 显示包的文档文件-qi 显示包描述-ql 显示包的文件列表-qR 显示包的依赖关系 安装：rpm{-i|–install}[install-option]PACKAGE_FILE123-h 输出哈希（#）符号提供安装进度更新-v 显示详细过程-ihv是常用配合选项； [install-option]123456789101112131415161718192021–test 测试安装，但不真正执行安装–nodeps 忽略依赖关系–replacepkgs|replacefiles 覆盖包安装（可用来修复已安装的安装包）|覆盖文件安装–nosignature 不检查来源的合法性（不安全）RPM-GPG-KEY-CentOS-6–nodigest 不检查包完整性 （不安全）–noscripts 只装包不执行程序包脚本–nopre 不执行安装前脚本–nopost 不执行安装后脚本–nopreun 不执行卸载前脚本–nopostun 不执行卸载后脚本 升级：123rpm&#123;-U|–upgrade&#125;[install-option]PACKAGE_FILErpm&#123;-F|–freshen&#125;[install-option]PACKAGE_FILE upfrade 如果安装有旧版程序包，则升级 如果不存在旧版程序包，则安装 freshen 如果安装有旧版程序包，则升级 如果不存在旧版程序包，则不执行升级操作 123rpm -Uvh PACKAGE_FILE…rpm -Fvh PACKAGE_FILE… 注：内核升级不建议使用以上两种升级命令，建议使用-ivh重新安装另一个内核，Linux支持多内核版本共存。 123–oldpackage 降级–force 强制安装（可用来修复已安装的安装包） 查询：1rpm&#123;-q|–query&#125;[select-options][query-options] 注：包的名称必须精确匹配，不允许使用通配符。然而，如果记不住包的完整名称，您可以 使用 grep 工具来帮助找到它。可以使用 -qa 开关来查询所有已安装的包，并用 grep 来管道 输出您能记住的信息。例如：rpm -qa | grep name [select-option]12345-a 查看所有已安装的包-f 查看指定的文件由哪个程序包安装产生-p rpmfile 针对尚未安装的程序包文件做查询操作（配合文件名而不是包名）–whatprovides CAPABILITY 查询指定的关键字由哪个包所提供–whatrequires CAPABILITY 查询指定的关键字被哪个包所依赖 [query-options]12345678–changelog 查询rpm包的changelog-c 查询程序的配置文件-d 查询程序的文档-i 查看包描述information-l 查看指定的程序包安装后生成的文件–scripts 查看程序包自带的脚本–provides 列出指定程序包所提供的关键字-R 查询指定程序包所依赖的关键字CAPABILITY rpm2cpio 包文件|cpio -itv 预览包内文件 rpm2cpio 包文件|cpio -id “*.conf”释放包内文件 包校验：1rpm&#123;-V|–verify&#125;[select-options][verify-options]PACKAGE_FILE 注：只能查看已安装的包 导入所需要公钥1234567rpm -K|checksig rpmfile 检查包的完整性和签名rpm –import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7CentOS 7发行版光盘提供：RPM-GPG-KEY-CentOS-7rpm -qa &quot;gpg-pubkey*&quot; 三、YUM使用介绍Yellowdog Update Modifier，rpm的前端程序，可解决软件包相关依赖性，可在多个库之间定位软件包，up2date的替代工具。使用yum安装文件包出错一般都是下面2种情况： 配置文件的格式错误 缓存问题 注：yum不支持多个终端同时执行 yum repository: yum repo，存储了众多rpm包，以及包的相关的元数据文件（放置于特定目录repodata下） 文件服务器： ​ http:// ​ https:// ​ ftp:// ​ file:// 仓库位置： ​ /etc/yum.repos.d/*.repo 仓库默认设置： ​ /etc/yum.conf repo关键行 12345678910111213[base] 仓库名，不可以加空格name=centos cdrom 描述信息baseurl= file：///mnt/cdrom注：仓库路径为repodata目录的父目录gpgcheck=0 默认为1，0表示不进行数字签名完整性检查gpgkey=file：///mnt/cdrom/RPM-GPG-KEY-CentOS-7 自动导入秘钥enabled=0 默认为1,0表示仓库禁用 yum日志： ​ /var/log/yum.log 包含了使用yum安装与卸载的日志 yum的repo配置文件中可用的变量： ​ $releasever: 当前OS的发行版的主版本号 ​ $basearch：基础平台；i386, x86_64 例如： 12345http://server/centos/$releasever/$basearch/http://server/centos/7/x86_64http://server/centos/6/i384 yum格式：yum[option][command][package…]PACKAGE_FILE 显示仓库列表：1yum repolist[all|enabled|disabled] 显示程序包：12345yum listyum list[all|glob_exp1][glob_exp2][…]yum list&#123;available|installed|updates&#125;[glob_exp1][…] 安装程序包：123yum install package1 [package2][…]yum reinstall package1 [package2][…] (重新安装) 升级程序包：123yum update [package1][package2] […]（升级）yum downgrade package1 [package2][…] （降级） 检查可用升级：1yum check-update 卸载程序包：1yum remove | erase package1 [package2][…] 查看程序包information：1yum info […]  查看指定的特性(可以是某文件)是由哪个程序包所提供：1yum provides | whatprovides feature1 [feature2][…] 清理本地缓存：123清除/var/cache/yum/$basearch/$releasever缓存yum clean [ packages | metadata | expire-cache | rpmdb | plugins | all ] 构建缓存：12 搜索：1yum search string1 [string2][…] 以指定的关键字搜索程序包名及summary信息 查看指定包所依赖的capabilities： 1yum deplist package1 [package2][…] 查看yum执行历史：123456yum history [info|list|packages-list|packages-info| summary|addon-info |redo|undo|rollback|new|sync|stats]yum historyyum history info 6yum history undo 6 日志：/var/log/yum.log安装及升级本地程序包：123yum install rpmfile1 [rpmfile2][…]yum update rpmfile1 [rpmfile2][…] 包组管理的相关命令：123456789yum groupinstall group1 [group2][…]yum groupupdate group1 [group2][…]yum grouplist [hidden][groupwildcard] […]yum groupremove group1 [group2][…]yum groupinfo group1 […] 四、源代码安装C、C++：make项目管理器 configure脚本–&gt;Makefile.in–&gt;Makefile C语言源代码编译安装三步骤： 1、./configure​ –prefix= 指定目录安装 ​ –sysconfidir= 指定/etc目录独立安装 通过选项传递参数，指定启用特性，安装路径；执行会参考用户的指定已经Makefile.in文件生成Makefile 检查依赖到的外部环境，如依赖的软件包 2、make编译过程，根据Makefile文件，构建应用程序 3、make install复制文件到相应路径]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本三剑客之sed的高级用法]]></title>
    <url>%2F2018%2F04%2F16%2F%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed%E7%9A%84%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一、模式空间与保持空间：我们知道sed工作机制是每次读取一行文本至模式空间（pattern space）中，在模式空间中完成处理，将 处理结果输出至标准输出设备；在模式空间中处理一行内容后会继续处理下一行，那么对于处理过的行可 能还有其他的处理，因此可以把处理过的行传送至一个叫保持空间（hold space）中，然后在后续的处理中 再次传送回模式空间中。这就类似加工车间和仓库的概念，好比模式空间是加工车间，保持空间就是仓 库，不过这里的仓库存储的都是些半成品的产品。 二、sed高级用法：Sed工具支持一些高级的命令来运用到保持空间中，这些高级命令有： 123456789101112P：打印模式空间开端至\n内容，并追加到默认输出之前 h: 把模式空间中的内容覆盖至保持空间中 H：把模式空间中的内容追加至保持空间中 g: 从保持空间取出数据覆盖至模式空间 G：从保持空间取出内容追加至模式空间 x: 把模式空间中的内容与保持空间中的内容进行互换 n: 读取匹配到的行的下一行覆盖至模式空间 N：读取匹配到的行的下一行追加至模式空间 d: 删除模式空间中的行 D：如果模式空间包含换行符，则删除直到第一个换行符的模式空间中的文本， 并不会读取新的输入行，而使用合成的模式空间重新启动循环。如果模式空间 不包含换行符，则会像发出d命令那样启动正常的新循环。 三、示例分析：以下我们均以该文档为例： 例1：cat test2.sed |sed ‘G’ 解析：由于保持空间初始默认为空，所有将空行追加到每行的模式空间中输出，等同在每行的 后面添加一个空行。 例2：cat test2.sed |sed ‘g’ 解析：g和G的区别在，g为覆盖模式空间，G为追加至模式空间，由于g默认为空，将每行的模式空间都覆 盖为空行输出，所以表现为5个空行。 例3：cat test2.sed |sed ‘$!d’ 解析：$表示尾行，$!d则表示除了尾行都执行删除。 例4：cat test2.sed |sed ‘n;d’ 解析：n将第一行读入模式空间输出，并将下一行即第二行覆盖至模式空间并删除，如此循环，最终表现为 只显示文本的奇数行。 例5：cat test2.sed |sed ‘N;D’ 解析：N将第二行追加至第一行的模式空间中，D删除模式空间内的第一行；对第二行执行命令，将第三行追加至第二行的模式空间内，并删除模式中的第一行；如此循环，最后只输出最后一行文本。 例6：cat test2.sed |sed ‘$!N;$!D’ 解析:’$!N;$!D’即对文本中除了最后一行支持’N;D’操作，由例外5可知，除了最后一行执行’N;D’操作，得出 结果为只输出倒数第二行，最后一行文本不处理，默认输出，所有最后结果输出倒数两行的文本。 例7：cat test2.sed|sed -n ‘n;p’ 解析：对第一行执行操作，n选项将第二行覆盖至模式空间，在第一行和第二行的默认输出后追加打印出来，-n取消默认输出，如此循环，最后得出文本的偶数行。 例8：cat test2.sed|sed -n ‘1!n;p’ 解析：与例7相比，例8为对除了第一行的其他行执行例7的操作，则最后的结果也为得出文本的奇数行。 例9：cat test2.sed |sed ‘/^$/d;G’ 解析：^$为表示地址定界匹配到的空行，d将空行删除，G在每行的文本后添加一个空行；最后的输出结果即：删除文本内的空行，并在每行后追加一行空行。 例10：cat test2.sed |sed ‘1!G;h;$!d’ 解析：1!G表示除了第一行，都执行将保持空间的内容追加至模式空间并输出，h命令使上一个模式空间内容将G覆盖，最后$!d只保留对最后一行的执行结果，具体表现为： 对第1行只进入模式空间默认输出，第2行将上一个模式空间内容（即第1行文本）覆盖至保持空间，共同进入模式空间（包含第2至1行文本）并输出；第3行将上一个模式空间内容（即第2至1行文本）覆盖至保持空间，共同进入模式空间（包含第3至1行文本）并输出；如此循环…….对第5行将上一个模式空间内容（第4至1行）覆盖至保持空间，共同进入模式空间（包含5至1行）输出；最后$!d除了最后一行的其他行的模式空间内容都删除，最后只留最后一行的执行结果，即将文本倒序输出。 例11：cat test2.sed |sed -n ‘1!G;h;$p’ 解析：与例10相比，最后的$p只打印最后一行的模式空间内容（第5至1行），-n取消所有默认输出，得出的结果与例10相同，倒序将文本输出。]]></content>
      <categories>
        <category>文本三剑客</category>
      </categories>
      <tags>
        <tag>sed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本三剑客之sed]]></title>
    <url>%2F2018%2F04%2F15%2F%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed%2F</url>
    <content type="text"><![CDATA[强大的处理文本的工具sed我们知道，sed被称为Linux中被称为文本处理三剑客之一，相比于grep命令匹配内容的功能，sed则能够做到对匹配到的文本内容对其进行编辑。 Linux文本处理三剑客简介：grep：文本过滤工具 sed：文本编辑工具 awk：Linux上的实现gawk，文本报告生成器 sed用法：sed[option]…’script’ inputfile… 其中‘script’可表示为’地址定界+编辑命令’ option：12345-n 取消默认打印内容到屏幕-e 多点编辑,表达且关系，与grep的-e不同，grep -e表达或关系-f 从指定文件中读取编辑脚本-r 支持使用扩展正则表达式-i.bak 原处编辑，并备份文件file.bak 地址定界： 不给地址：对全文进行处理 单地址： #：指定的行，$：最后一行 /pattern/：支持正则表达式，被此模式所能匹配到的每一行 地址范围： #，# #，+# /pat1/,/pat2/ /pat1/, # ~：步进 1~2 奇数行 2~2 偶数行 编辑命令：1234567891011121314d 删除模式空间匹配的行p 打印当前模式空间内容，追加到默认输出之后a[\]text 在指定行后面追加文本 如要实现插入内容空格开头可先追加\再输入空格 支持使用\n实现多行追加i[\]text 在指定行前面插入文本c[\]text 替换指定行尾单行或多行文本w /path/somefile 保存模式匹配的行到指定文件r /path/somefile 读取指定文件的文本匹配的行后 注意：w，r后跟文件一定要加空格 可利用此命令定义别名到.bashrc= 为模式空间中的行打印行号！ 取反，！需加载地址定界和编辑命令中间，如&apos;2！d&apos;s///： 查找替换，支持使用其他分隔符；s###；s@@@ 示例以下我们创建文件test进行示例： 示例1：sed ‘1,10p’ /data/test.sed sed命令默认将文本内容打印到屏幕，由于执行命令p，文本内容被打印了两遍 sed -n ‘1,10p’ /data/test.sed sed -n选项将取消默认输出到屏幕，仅显示p的执行结果 示例2：sed -n -e ‘1p’ -e ‘3p’ 显示第一行和第三行，-e表示且的关系 示例3：sed -n -f sedscripts.txt /data/test.sed 将2,5p写入sedscripts.txt文件，-f选项读取sedscripts.txt，并执行文件中内容 示例4：sed -i ‘1,10a#’ /data/test.sed 表示在第1至第10行内容后插入#，-i选项直接编辑了test.sed的文本内容 sed -i ‘/#/d’ /data/test.sed 表示将所有带#的行删掉并编辑文本 示例5：sed -n ‘3p’ 打印第3行内容 sed -n ‘2,5p’ 打印第2至第五行 sed -n ‘2,+3p’ 打印第2至第5行 sed -n ‘1~2p’ 打印奇数行 sed -n ‘2~2p’ 打印偶数行 示例6：正则定界，表示ifconfig命令输出中开头eth2的行，至开头为lo的行 示例7：正则数字混合定界，表示ifconfig命令输出中，eth2开头的行到第12行的内容 示例8：多行插入，将aaa\nbbb插入到每行后面 示例9：sed ‘1,10i#’ /data/test.sed 在每一行上面插入# 示例10：sed ‘1,5c’ /data/test.sed 将test.sed文件中1到5行替换为一个# 示例11：sed ‘2,5w f1’ /data/test.sed 将test.sed文件中第2到第5行内容打印到f1文件中 示例12：sed ‘2,5r f1’ /data/test.sed 将f1的内容插入到第2至第5行 示例13：sed -n ‘2,5! p’ /data/test.sed 打印除了第2至第5行的内容 示例14：ifconfig |sed -n “2p”|sed -r “s@.addr:(.) Bcast.*@\1@” 利用搜索替代，我们可以将任意段字符串定义成方法，然后表示出整行，再利用后向引用即可取出该字符串。]]></content>
      <categories>
        <category>文本三剑客</category>
      </categories>
      <tags>
        <tag>sed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手把手系列（三）教你自制简单Linux系统]]></title>
    <url>%2F2018%2F04%2F13%2F%E6%89%8B%E6%8A%8A%E6%89%8B%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89%E6%95%99%E4%BD%A0%E8%87%AA%E5%88%B6%E7%AE%80%E5%8D%95Linux%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[CentOS启动相关最重要的几个文件有：内核vmlinuz文件、虚拟文件系统initramfs文件、grub文件以 及init启动程序，围绕这几个文件，我们来制作一个能够简单启动的自制Linux系统 实验思路：CentOS6的启动流程如下 1.加载BIOS的硬件信息，进行POST加电自检 2.读取第一个启动设备MBR的引导加载程序(grub)的启动信息 3.加载核心操作系统的核心信息，核心开始解压缩，并尝试驱动所有的硬件设备 4.核心执行init程序，并获取默认的运行信息 5.init程序执行/etc/rc.d/rc.sysinit文件 6.启动核心的外挂模块 7.init执行运行的各个批处理文件(scripts) 8.init执行/etc/rc.d/rc.local 9.执行/bin/login程序，等待用户登录 10.登录之后开始以Shell控制主机 其中与启动相关最重要的几个文件有：内核vmlinuz文件、虚拟文件系统initramfs文件、grub文件以 及init**启动程序**，接下来就围绕这几个重要文件，来制作一个能够简单启动的自制Linux系统 准备环境：CentOS6虚拟服务器1台，准备一个硬盘或者U盘，本实验我们以一块20G的虚拟硬盘为例制作一个简单的 Linux系统 具体步骤：第一步：针对新增加的20G硬盘创建两个分区dev/sdb1，dev/sdb2 fdisk /dev/sdb 第二步：创建文件系统，将/dev/sdb1，/dev/sdb2两个分区文件系统设置为ext4格式 mkfs.ext4 /dev/sdb1 mkfs.ext4 /dev/sdb2 第三步：挂载/boot目录 mkdir /mnt/boot 此处挂载子目录必须为boot mount /dev/sdb1 /mnt/boot 第四步：安装gurb grub-install –root-director=/mnt /dev/sdb hexdump -C /dev/sdb -n 512 -v 查看一阶段是否创建成功，446字节已生成 ls /mnt/boot 查看二阶段是否创建成功，grub目录已生成 第五步:拷贝内核vmlinuz文件及虚拟文件系统initramfs文件 cp /boot/vmlinuz-VERSION /mnt/boot/vmlinuz cp /boot/initramfs-VERSION.img /mnt/boot/initramfs.img 第六步:设置grub.conf文件 vim /grub.conf default=0 timeout=5 title linux kernel /vmlinuz-VERSION root=/dev/sda2 init=/bin/bash initrd /initramfs.img 第七步：挂载根目录 mkdir /mnt/rootfs mount /dev/sdb2 /mnt/rootfs 第八步：复制相关命令和库文件 如：ifconfig，insmod，ping，mount，ls cat，df，lsblk，blkid等 第九步：准备根目录下必要目录 mkdir /mnt/rootfs/{dev,etc,proco,sys,usr,var,lib,mnt.home,root,tmp,lib64} -v sync；sync；sync； 确保写入硬盘 第十步：安装必要的模块，如网络模块等 第十一步：关机此服务器，并将20G硬盘安装到一台无硬盘启动的虚拟机服务器上]]></content>
      <categories>
        <category>手把手系列</category>
      </categories>
      <tags>
        <tag>手把手系列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统文件查找与解压缩方法]]></title>
    <url>%2F2018%2F04%2F12%2FLinux%E7%B3%BB%E7%BB%9F%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E4%B8%8E%E8%A7%A3%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[如同我们平时在操作 Windows系统时，文件查找与解压缩文件是经常要使用到的操作，Linux系统中也要经常用到相同的操作，今天我们就来介绍Linux系统中的一些文件查找与解压缩时使用到的工具。 一、文件查找Linux系统中自带两个文件查找命令locate和find，那两个命令如何进行使用选择呢？各自又有什么优点和缺点呢，我们来详细看一下： （1）locate命令优点：搜索速度快，节省系统性能（生产环境适合使用locate） 缺点：不能即时更新（文件索引数据库在每次开机后更新），要想搜索最新文件需手动输入命令updatedb更新文件索引数据库，模糊搜索； Locate命令适合搜索不经常变化的文件，如系统文件 查询系统上预建的文件索引数据库： /var/lib/mlocate/mlocate.db locate -i 忽略大小写 -b 只搜索基名符合条件的文件 -n 只列出前几个 -r 支持扩展正则表达式 （2）find命令优点：精确查找；实时查找；搜索条件灵活 缺点：查找速度慢；占用系统性能 find [OPTION]…[查找路径] [查找条件] [处理动作] 指定搜索层级： 不指定情况下默认当前目录下搜索 -maxdepth level 最大搜索深度，默认为1层 -mindepth level 最小搜索深度 根据文件名和inode查找： -name “filename” 支持使用通配符glob；注意文件名一定加”” -iname “filename” 不区分字母大小写 -inum n 按节点号inode查找文件 -samefile name 查找相同inode的文件，即硬链接 -links n 查找链接数为n的文件 -regex “PATTERN” 使用正则表达式搜索 根据属主、属组查找： -user USERNAME：查找属主为指定用户（UID）的文件 -group GRPNAME：查找属组为指定组（GID）的文件 -uid UID： 查找属主为指定UID号的文件 -gid GID： 查找属组为指定GID号的文件 -nouser： 查找没有属主的文件 -nogroup： 查找没有属组的文件 -nouser -o -nogroup 查找没有属主或没有属组的文件 根据文件类型查找： -type TYPE： f： 普通文件 d： 目录文件 l： 符号链接文件 s： 套接字文件 b： 块设备文件 c： 字符设备文件 p： 管道文件 搜索空文件或目录： -empty 查找空文件或空目录 例：find/app -type d -empty 组合条件： -a 与 -o 或 -not,! 非 德摩根定律： ​ （非A）或（非B）=非（A且B） ​ （非A）且（非B）=非（A或B） 注意：使用（）表示组合条件时，括号内两边一定要加空格,且括号一定要加转义符”\”。 根据文件大小来查找： -size[+|-]#UNIT 常用单位：k，M，G，c（byte） 1024c (1024-1，1024] +1024c (1024,+) -1024c [0,1024-1] 根据时间戳查找： 以“天”为单位： -atime[+|-]# 3：[3,4) +3:[4,+] -4:[0,4) -mtime -ctime 以“分钟”为单位： -atime -mtime -ctime 根据权限查找： -perm[/|+|-]MODE MODE：精确权限匹配（数字法） /|+MODE：任何一类（u,g,o）对象的权限中只要能一位匹配即可，或关系； CentOS6使用“+”，CentOS7使用“/” -MODE：没类对象权限都有对应权限时，才会匹配，且关系； 处理动作： -print 默认的处理动作，显示到屏幕 -ls 类似于对查找的文件执行”ls -l”命令 -delete 删除查找到的文件，不进行提示 -fls file 查找到的所有文件的长格式信息保存至指定文件中 -ok COMMAND{}\； {}代表前面搜索到的结果，-ok后必须跟\；结尾，语法要求；对 查找到的每个文件执行COMMAND命令，每个文件执行命令时，会要求 用户确认 例：find -name “f*” -ok rm {} \； 将f开头的文件删除，每个文件删除时会要求确认。 -exec COMMAND{}\； 对每个搜索到的文件执行COMMAND命令，不要求用户确认 例：find -name “f*” -exec mv {} /data/ \; 将f开头的文件移动到data目录下，不要求用户确认 二、压缩和解压缩Linux系统中支持多种文件解压缩工具，不同压缩工具压缩比有所不同，压缩后的后缀名也不一样。要注意的是：前面我们说过在linux系统中，文件是不通过后缀判断的，但在解压缩中是个例外，不同的解压缩工具对后缀是有要求的。 Linux常见解压缩工具：file-roller 图形化解压缩工具（类似于windows系统winrar） compress/uncompress： .Z后缀 gzip/gunzip： .gz后缀（主流） bzip2/bunzip2： .bz2后缀（主流） xz/unxz： .xz后缀（主流，新兴） zip tar cpio (1)compress/uncompress -d 解压缩，相当于uncompress，压缩文件删除 -c 压缩结果输出至标准输出，不删除原文件 例：compress -c b &gt; b.Z 解压文件b并且不删除 -v 显示详情 uncompress 解压缩，同compress -d，压缩文件删除 zcat file.Z &gt; file 解压缩，原压缩文件不删除 (2)gzip/gunzip -d 解压缩，相当于gunzip -c 将压缩结果输出至标准输出，不删除原文件 -v 显示详情 zcat file.gz &gt; file 解压缩，原压缩文件不删除 (3)bzip2/bunzip -k 保留原文件 -d 解压缩 bunzip2 解压缩 bzcat 不解压缩前提查看文本内容，与gzip的zcat用法类似 (4)xz/unxz -k 保留原文件 -d 解压缩 unxz 解压缩，功能同xz -d xzcat 功能同zcat，bzcat 压缩比：xz &gt; bzip2 &gt; gzip &gt; compress (5)zip/unzip 打包压缩 zip -r /tsetdir/sysconfig /etc/sysconfig/ 解包解压缩 unzip sysconfig.zip cat /var/log/messages|zip messages – unzip -p message &gt; message 解压缩重定向 (6)tar工具：（Tape ARchive，磁带归档的缩写）打包工具，并不压缩 tar[OPTION]… -c 创建一个打包文件 -C 指定解压的目录 -p 保留属性 -v 查看过程 -f 对哪个进行文件归档或打包 -t 查看列表 1.创建文档（打包文件或目录） tar -cpvf /PATH/TO/SOMEFILE.tar FILE… 2.追加文件到归档：注：不支持对压缩文件追加 tar -r -f /PATH/TO/SOMEFILE.tar FILE… 3.查看归档文件中的文件列表 tar -t -f /PATH/TO/SOMEFILE.tar 4.展开归档（解包） tar -x -f /PATH/TO/SOMEFILE.tar tar -x -f /PATH/TO/SOMEFILE.tar -C /PATH/ 5.结合压缩工具实现：归档并压缩 -j：bizp2 -z：gzip -J：xz 6.-T选项指定输入文件，-X选项指定包含要排除的文件列表 例：tar zcvf myback.tgz -T /root/includefilelist -X /root/excludefilelist 7.分割打的tar文件为多份小文件： split -b Size -d tar-file-name prefix-name -b 1M –d mybackup.tgz mybackup-parts -b 1M mybackup.tgz mybackup-parts 8.合并tar分割的多个小文件： cat mybackup-parts* &gt; mybackup.tar.gz (7)cpio 功能：复制文件从或到归档 cpio命令是通过重定向的方式将文件进行打包备份，还原恢复的工具，他可以解压以 “cpio”或者”tar”结尾的文件 cpio[option] &gt; 文件名或者设备名 cpio[option] &lt; 文件名或者设备名 选项 -o 将文件拷贝打包成文件或者将文件输出到设备上 -i 解包，将打包文件解压或将设备上的备份还原到系统 -t 预览，查看文件内容或者输出到设备上的文件内容 -v 显示打包过程中的文件名称 -d 解包生产目录，在cpio还原时，自动的建立目录 -c 一种较新的存储方式 示例： 将etc目录备份 find ./etc -print |cpio -ov &gt;etc.cpio 内容预览 cpio -tv &lt; etc.cpio 解包文件 cpio -idv &lt;etc.cpio]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>文件查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本编程基础（2）——新手注意事项及技巧16条]]></title>
    <url>%2F2018%2F04%2F11%2Fshell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94%E6%96%B0%E6%89%8B%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%E5%8F%8A%E6%8A%80%E5%B7%A716%E6%9D%A1%2F</url>
    <content type="text"><![CDATA[总结了一些shell编程初学者常犯的错误、注意事项及技巧：1.判断变量是否加$：（1）赋值变量时不加$ （2）如果命令能识别变量就不加$,如果命令不能识别变量加$ 2.存放多行字符时”$name”变量外加双引号可保留换行格式 3.{}和（）中执行命令的区别： （）中使用的命令为一次性的，小括号中相当于在子进程中执行命令,小括号继承括号外变量，但不会影响括号外变量 注：小括号中所说的子进程与常规的子进程不是一回事 而{ }中使用命令是在当前shell环境中执行，不会不开启子进程，会影响当前shell环境 例1：x=1;echo $$;(echo $$;echo $x;x=2);echo $x 虽然括号内开启了一个子进程，但该子进程号和括号外进程号一致；此外括号外变量会影响括号内，但括号内变量更改不会影响括号外。 例2：（echo $$;exit） 执行此命令，显示当前所在进程号，exit退出（）内子进程 { }中使用命令是在当前shell环境中执行，不会不开启子进程，会影响当前shell环境 例3：x=1;echo $$;{ echo $$;echo $x;x=2; };echo $x {}内命令相当于当前shell执行，因此括号外和括号内进程号一致，此外{}内变量影响了{}外的变量。 例4：{ echo$$;exit; } 执行此命令，显示当前所在进程号，exit退出当前shell； 因此编写脚本时，想要使用括号利用exit命令退出脚本，一定要使用{}，而不能使用（） 4.短路与&amp;&amp;和短路或||嵌套连续命令时可使用大括号如&amp;&amp;{ cmd1 ；cmd2 ； }；||{ cmd1 ；cmd2 ；}； 测试或命令结果为假时，后跟连续多条命令，必须需采用此种格式： false || { echo cmd1 ; echo cmd2 ; } 表示测试或命令返回false时，执行cmd1，cmd2 测试或命令结果为真时，后跟连续多条命令，可写为： true &amp;&amp; echo cmd1 &amp;&amp; echo cmd2 也可写为： true &amp;&amp; { echo cmd1 ; echo cmd2 ; } 当条件测试或命令后同时出现短路且&amp;&amp;与短路或||有嵌套命令的情况时: 如：[ Test ] &amp;&amp; { echo cmd1 ; echo cmd2 ; } || { echo cmd3; echo cmd4 ; } 表示当Test为真时，执行命令cmd1，cmd2；当Test为假时，执行cmd3，cmd4； 5.引用超过10个以上的位置变量时，数字加{}；如$10要写为${10}不加{}时，默认将$10当作$1和0表示出来： 当给10加上大括号后，${10}才表示第10个位置变量： 6.位置变量$*与$@的区别两者都可表示传递给脚本的所有参数，但$*将每个参数合并为一个字符串； 而$@每个参数作为独立字符 注意：$@、$*只在被双引号包起来的时候才会有差异。 7.在使用[ ]和test引用变量时，最好加双引号””避免出问题不加引号也许不会出错，但加上引号肯定不会有错 8.脚本中进行变量的算术运算时，有空格尽量删除变量的算术运算，多一个空格就会导致出错，所以尽量将空格删除 9.进行条件测试过程中，能加空格地方尽量都加空格条件测试时，无论是括号两端还是字符两端少一个空格就会导致出错，所有尽量都加空格 10.使用=~进行PATTERN匹配时，需要加双括号[[ ]]，且正则表达式不能加引号，默认使用扩展正则表达式正则表达式加引号就会导致错误结果，这与我们在使用grep与sed等命令利用到正则表达式需要加引号正好相反，需要注意 11.用于字符串比较时的用到的操作应该都使用引号同上，不加引号也许不会出错，但加上引号肯定不会有错 12.[[ == ]]右侧可匹配类似于通配符glob的用法此种匹配类似于通配符，但不完全等同于通配符，注意格式双中括号，双等号 [[ == ]] 13.脚本里不支持别名14.文件测试后跟空字符时，也反馈为True。例如：/data/fstab为普通文件，用-f选项判断时，后跟fstab文件或者空时都判断为真 因此要保证一个文件存在且满足测试条件时， 可表示为：[ -n “file” -a –f “file” ] file文件是否存在且为普通文件 15.测试字符串是否为空除了-z及-n选项，还可用[ “$var” = “” ]；[ x”$var” = “x” ]来测试。例1：当$var为空时，使用[ “$var” = “” ]返回结果0 例2：当$var为空时，[ x”$var” = “x” ]返回结果为0 16.养成好习惯：变量一使用完后就用unset删掉。]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本编程基础（1）]]></title>
    <url>%2F2018%2F04%2F10%2Fshell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[要想玩转Linux系统，编写shell脚本是必须要掌握的技能。那什么是shell编程呢？简单来说，shell编程就是对多个Linux命令进行逻辑处理。 下面，我们从编程的基础开始讲起： 一、编程基础1.什么是程序？程序是指：指令+数据 程序编程风格可分为： ​ 过程式：以指令为中心，数据服务于指令（关注过程，小软件开发） ​ 对象式：以数据为中心，指令服务于数据（关注结果，适合开发大型软件） 2.程序的执行方式计算机：运行二进制命令 编程语言： 低级：汇编 高级： 编译：高级语言–&gt;编译器–&gt;目标代码 (由程序员完成编译器翻译过程，安全性相对好) java，C# 解释：高级语言–&gt;解释器–&gt;机器代码 （由电脑完成解释器翻译过程，安全性不如编译型） shell，perl，python shell程序：提供了编程能力，解释执行 3.编程基本概念编程逻辑处理方式： ​ 顺序执行 ​ 循环执行 ​ 选择执行 shell编程：过程式、解释执行 编程语言的基本结构： 各种系统命令的组合 数据存储：变量、数组 表达式：a+b 语句：if 二、脚本基本格式格式要求：首行shebang机制（即声明脚本使用哪种编程语言） 如： #！/bin/bash #！/bin/python shell脚本的用途有：自动化常用命令 执行系统管理和故障排除 创建简单的应用程序 处理文本或文件 运行脚本： 给予执行权限，执行 直接运行解释器，将脚本作为解释器程序的参数运行 脚本规范：脚本代码开头约定： 第一行一般为调用使用的语言 程序名，避免更改文件名为无法找到正确的文件 版本号 更改后的时间 作者相关信息 该程序的作用，及注意事项 最后是各版本的更新简要说明 脚本示例：1234567891011\#!/bin/bash\# ——————————————\# Filename: hello.sh # Revision: 1.1\# Date: 2018/04/01\# Author: wangx\# Email: wangx@gmail.com\# Website: www.donlihuoguo.cn\# Description: This is the first script\# ——————————————\# Copyright: 2018 wang\# License: GPL echo &quot;hello world&quot; 脚本调试： bash -n script 检查脚本的语法错误 bash -x script 调试脚本执行 三、变量定义变量时，变量名不加$符号，如： 1my_name=&quot;wangx&quot; 变量命名规则： 数字、字母、下划线，不能以数字开头 不能使用程序中的保留字：如if，for等 做到见名知意 注意： ​ 引用变量一般需加$ ​ 赋值变量： ​ name=” “ 要加引号 ​ 存放多行字符时”$name”变量外加双引号可保留换行格式 bash变量的种类局部变量、全局变量、本地变量、位置变量、特殊变量 局部变量：只在当前shell进程生效，对当前shell之外其他shell进程，包括父shell和子shell都无效 全局变量：生效范围在当前shell进程及其子进程；父进程变量可以传给子进程，子进程变量不可向上传给父进程 数字变量：$10以上的变量需要加花括号${10} 特殊变量：$1,$@,$*,$#,$0等、 $1,$2,…：对应第1、第2参数，shift[n]换位置 $0：命令本身 $*：传递给脚本的所有参数，每个参数合为一个字符串 $@：传递给脚本的所有参数，每个参数为独立字符串 $#：传递给脚本的参数的个数 $@$*只在被双引号包起来的时候才会有差异 set– 清空所有位置变量 注：怎么判断变量前加不加$符号？ 如果命令能识别变量就不加$,如果命令不能识别变量加$； 养成好习惯：编完脚本将变量用unset删掉； （）中使用的命令为一次性的，小括号中相当于在子进程中执行命令 注：小括号中所说的子进程与常规的子进程不是一回事 例如：x=1;echo $$;(echo $$)中显示进程号一致 { ；}中使用命令时在当前shell环境中执行，不开启子进程影响当前shell环境 变量运算bash中的算术运算：help let +，-，*，/，%取余，**乘方 实现算术运算： let var=算术表达式 var=$[算术表达式] var=$((算术表达式)) 注：算术运算过程中，空格尽量删除 条件测试过程中，能加空格地方尽量加空格 正则条件测试时，正则表达式不加引号 四、条件测试测试命令： test EXPRESSION [ EXPRESSION ] [[ EXPRESSION ]] 双括号一般用于左侧字符匹配右侧扩展正则表达式 注：EXPRESSION前后必须有空白字符 评估布尔声明，以便用在条件性执行中： ​ 若真，则返回0 ​ 若假，则返回1 例如： 12345678a=1;b=2[ $a -eq $b ]echo $?结果：1a=2;b=2[ $a -eq $b ]echo $结果： 0 条件性的执行操作符&amp;&amp;代表条件性的AND THEN，前面执行结果$?=0时，继续执行&amp;&amp;后命令 ||代表条件性的OR ELSE，前面执行结果$?不为0时，执行||后命令 test 与[ ]效果相同，注意括号里内容两边需加空格 -v VAR 变量VAR是否设置 数值测试：123456-gt 是否大于（greater-than）-ge 是否大于等于（greater-than-or-equal）-eq 是否等于（equal）-ne 是否不等于（not-equal）-lt 是否小于（less-than）-le 是否小于等于（less-than-or-equal） 字符串测试：123456789101112== 是否等于&gt; ascii码是否大于ascii码&lt; 是否小于!= 是否不等于=~ 左侧字符串是否能够被右侧的PATTERN所匹配注：使用PATTERN匹配时，需要加双括号[[ ]]；使用扩展的正则表达式，且正则表达式不能加引号-z 字符串是否为空，空为真，不空为假-n 字符串是否为不空，不空为真，空为假注：用于字符串比较时的用到的操作应该都使用引号字符串是否为空还可用[ &quot;$name&quot; == &quot;&quot; ]来测试。 文件相关测试：存在性测试： 12-a FILE 同-e-e FILE 文件存在性测试，存在为真，否则为假 存在性及类别测试： 12345678-b FILE 是否存在且为块设备文件-c FILE 是否存在且为字符设备文件-d FILE 是否存在且为目录文件-f FILE 是否存在且为普通文件-h FILE 同-L-L FILE 是否存在且为符号链接文件-p FILE 是否存在且为管道文件-S FILE 是否存在且为套接字文件 文件权限测试： 123-r FILE 是否存在且有可读权限-w FILE 是否存在且有可写权限-x FILE 是否存在且有可执行权限 文件特殊权限测试： 123-u FILE 是否存在且拥有suid权限-g FILE 是否存在且拥有sgid权限-k FILE 是否存在且拥有sticky权限 文件小测试： 1-s FILE 是否存在且非空 文件是否打开： 1234-t fd：fd 文件描述符是否在终端已经打开-N FILE 文件自从上一次被读取之后是否被修改过-O FILE 当前有效用户是否为文件属主-G FILE 当前有效用户是否文文件属组 注意：文件测试后跟空字符时，也反馈为True，如果要保证一个文件存在且满足测试条件时， 应表示为： 例：[ -n “file” -a -d “file” ] file文件是否存在且为目录文件 双目测试：123FILE1 -ef FILE2 FILE1是否是FILE2的硬链接FILE1 -nt FILE2 FILE1是否新于FILE2（mtime）FILE1 -ot FILE2 FILE1是否旧于FILE2 Bash的组合测试条件：第一种方式： 123COMMAND1 &amp;&amp; COMMAND2 并且COMMAND1 || COMMAND2 或者！COMMAND 非 第二种方式： 123[ EXPRESSION -a EXPRESSION ] 并且[ EXPRESSION -o EXPRESSION ] 或者[ ！EXPRESSION ] 非 注：优先级为：”!”最高，”-a”次之，”-o”最低 短路与&amp;&amp; 12340&amp;&amp;0=00&amp;&amp;1=01&amp;&amp;0=01&amp;&amp;1=1 cmd1 &amp;&amp; cmd2 如果cmd1为假，cmd2不需要执行，反之cmd1为真，需要cmd2执行 短路或|| 12340||0=00||1=11||0=11||1=1 cmd1 || cmd2 如果cmd1为真，cmd2不需要执行，反之cmd1为假，需要cmd2执行 异或 ^ 如果相同为假，反则为真 12340 ^ 1 = 11 ^ 0 = 11 ^ 1 = 00 ^ 0 = 0 注意：[ ]和test用变量时，最好加双引号””避免出问题 123false || &#123; echo cmd1 ; echo cmd2 ; &#125;false || (echo cmd1 ; echo cmd2) 使用read命令来接受输入read 使用read来把输入值分配给一个或多个shell变量 12345-p 指定要显示的提示-s 静默输出，一般用于密码-n N指定输入的字符长度N-d ‘字符’输入结束符，类型与输入重定向的&lt;&lt;EOF-t N TIMEOUT为N秒，N秒内无输入将自动退出 read命令从标准输入中读取单词，并给每个单词分配一个变量 例如： ​ read -p “Enter a filename:” FILE 标准输入将赋予变量$FILE ​ read命令从标准输入中读取单词，并给每个单词分配一个变量 read 给多个变量赋值的方法： 将多个变量输入一个文件中，用空格分开，输出重定向 1read a b c &lt; f 用”&gt;&gt;&gt;”分开： 1read a b c &lt;&lt;&lt; &quot;x y z&quot; 五、配置用户环境bash的配置文件按生效范围划分，存在两类： 全局配置： ​ /etc/profile ​ /etc/profile.d/*.sh ​ /etc/bashrc 个人配置： ​ ~/.profile ​ ~/.bashrc shell登录的两种方式： ​ 交互式登录： ​ 1. 直接输入账号密码登录 ​ 2. su – username 切换的用户 ​ 执行顺序：/etc/profile –&gt; /etc/profile.d/*.sh –&gt; ~/.bash_profile –&gt; ~/.bashrc–&gt; /etc/bashrc ​ 非交互式的登录： ​ 1. su usernme ​ 2. 图形界面打开的终端 ​ 3. 执行脚本 ​ 4. 任何其他的bash实例 ​ 执行顺序：~/.bashrc –&gt; /etc/bashrc –&gt; /etc/profile.d/*.sh 注：只在交互式登录生效：/etc/profile，~/.bash_profile 配置执行文件按功能划分，存在两类： profile类和bashrc类 Profile类：为交互式登录的shell提供配置 全局生效：/etc/profile ，/etc/profile.d/*.sh 个人生效：~/.bash_profile 功用： 用于定义环境变量 运行命令或脚本 Bashrc类：为非交互式和交互式登录的shell提供配置 全局生效：/etc/bashrc 个人生效：~/.bashrc 功用： 定义命令别名和函数 定义本地变量 修改profile和bashrc文件后使生效的两种方法： 重新启动shell进程 .或sourc；例：.~/.bashrc 注： .或source执行脚本表示将在当前进程运行，而不是开启一个子进程运行（配置文件一般用此方式执行） ​ bash执行脚本则是开启一个进程执行（运行脚本一般用此方式执行） Bash退出任务保存在~./.bash_logout文件中（用户） 在退出登录shell时运行 可用于： ​ 创建自动备份 ​ 清除临时文件 ​ 清除操作历史等 特殊的变量$-12345678\#echo $-\#hibBHh：hash缓存功能；set -h，关闭hash功能；set +h，开启hash功能i：代表交互式shellm：打开监控模式B：大括号扩展H：history，命令操作历史 bash展开命令的优先级：把命令行分成单个命令词 展开别名 展开大括号{} 展开波浪符~ 命令替换$()和 再次把命令行分成命令词 展开文件通配（*、？等） I/O重定向 运行命令]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim文本编辑器及文本处理常用命令]]></title>
    <url>%2F2018%2F04%2F08%2Fvim%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8%E5%8F%8A%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[一、文本编辑器简介： vi: Visual Interface，文本编辑器文本：ASCII, Unicode文本编辑种类： 行编辑器: sed 全屏编辑器：nano, vi vim - Vi Improved （vi文本编辑器的升级版）其他编辑器： gedit 一个简单的图形编辑器 gvim 一个Vim编辑器的图形版本 二、Vim文本编辑器相关命令：Vim是从 vi发展出来的一个文本编辑器。代码补全、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。 1.vim打开文件：vim[option]…FILE… 12345+# 打开文件后，让光标处于第#行行首-o 后跟多个文件可水平显示多个窗口-O 后跟多个文件可垂直显示多个窗口-b 以二进制方式打开文件-d file1 file2… 比较多个文件 注：当一个文件不存在时，用vim打开编辑存盘后会自动创建它 2.vim的三种主要模式：命令（normal）模式：默认模式，可移动光标，剪切/粘贴文本。左下角显示文本路径，行数，字符数，右下角显示光标位置 插入（insert）模式：也叫编辑模式，修改文本。左下角显示 –INSERT– 扩展命令（extended command）模式：保存、退出等。左下角显示 “：” 3.vim模式切换：命令模式—&gt;插入模式 123456i：在光标处输入I：在光标所在行首输入a：在光标所在处后输入A：在光标所在行行尾输入o：在光标所在行的下方打开一个新行O：在光标所在行的上方打开一个新行 插入模式—&gt;命令模式 ESC 命令模式—&gt;扩展命令模式 ： 扩展命令模式—&gt;命令模式 ESC，Enter 4. vim的其他一些模式：替换（replace）模式： 命令模式下R切换，可随意替换字符；右下角显示–REPALCE– 可视化（visual）模式： ​ v 切换面向字符的可视化模式;右下角显示–VISUAL– ​ V 切换面向行的可视化模式 ​ ctrl+v 面试块的可视化模式 5.vim关闭文件扩展模式: 12345678按”：”从命令模式进入Ex模式 wq 存盘退出 q 文本未修改，不存盘退出 q！ 文本已被修改，想不存盘退出 w file 文件另存为file r file 读取file文件内容到当前文件 ！command 直接在扩展模式下执行命令 r！command 读入命令的输入到当前文件光标处 命令模式下也可关闭文件（不推荐使用） 12ZZ 保存退出ZQ 不保存退出 6.命令模式常用命令：字符间跳转 12h: 左 l: 右 j: 下 k: 上#COMMAND：跳转由#指定的个数的字符 单词间跳转： 1234w：下一个单词的词首e：当前或下一单词的词尾b：当前或前一个单词的词首#COMMAND ：由#指定一次跳转的单词数 当前页跳转： 1H：页首 M：页中间行 L:页底 行首行尾跳转： 123^ 跳转至行首第一个非空白字符0 跳转至行首$ 跳转至行尾 行间移动： 123\#G 调至第#行；扩展模式下可执行 ：GG 最后一行1G，gg 第一行 句间移动： 1)：下一句 (：上一句 段落间移动： 1&#125;:下一段 &#123;：上一段 命令模式下字符操作: 1234567891011121314151617181920212223242526272829x：删除光标所在处字符\#x：删除从光标所在处开始#个字符xp：交换光标所在处字符和它后面字符的位置（原理是剪切粘贴）~：波浪符转换大小写J：删除当前行后的换行符r：替换光标所在处字符 d：删除命令d$ 当前光标删除至行尾d^ 当前光标删除到非空行首d0 当前光标删除到行首dw 删除单词dd 删除光标所在的行\#dd 多行删除，一下删除#行y：复制命令（用法类似d删除）y$ 复制当前光标到行尾y^ 复当前光标位置到非空行首yw 复制单词yy 复制光标所在的行p：粘贴p 粘贴至光标所在行下一行P 粘贴至光标所在行上一行u：撤销更改\#u 撤销之前多次修改U 撤销光标落在这行后所有此行的修改Ctrl+r 返回上次撤销 7.扩展命令模式常用命令：格式：地址定界+编辑命令 地址定界 12345678：# 跳到第#行：#，# 第左侧第#行，到右侧第#行；2,5表示第2到第5行：#，+# 从左侧第#行，加上右侧#的行；2，+3表示第2到5行：. 当前行$ 最后一行% 全文，相当于1，$：/pat1/,/pat2/ 从pat1匹配到的行开始，到第一次被pat2匹配到的行：/pat1/，# 可混用 使用方式：后跟一个编辑命令 1234d 删除y 复制w file 将范围内行另存至指定文件中r file 在指定位置插入匹配内容 查找字符 1234/PATTERN：从光标所在处向文件尾部查找？PATTERN：从光标所在处向文件首部查找n：与命令同方向N：与命令反方向 s：查找并替换 ​ 格式：s/要查找的内容/替换为的内容/修饰符 ​ 修饰符： 1234i：忽略大小写g：全局替换每一行的第一次出现的匹配gc：全局替换所有匹配，每次替换前询问查找替换的分隔符/可用其他分隔符代替：如#，@ 命令模式 1234u： 撤销更改ctrl+r: 恢复上一次撤销. 重复执行上一次操作#. 重复执行上一次操作n次 8.vim的剪贴板有26个命名剪贴板和一个无命名剪贴板，存放不同的剪切内容，可以不同会话间分享 例： 1234&quot;myy 表示复制光标所在行到m剪贴板&quot;mp 表示将m剪贴板内容粘贴3&quot;tyy 表示复制3行内容到t剪贴板&quot;tp 表示将t剪贴板内容粘贴 9.vim多文件模式vim FILE1 FILE2 FILE3 1234567：next 下一个文件：prev 上一个文件：first 第一个文件：last 最后一个文件：wall 保存所有文件：qall 退出所有：wqall 保存退出 单文件的窗口分隔：方便对照文件内容 1234ctrl+w放开后按s 水平分割ctrl+w放开后按v 垂直分割ctrl+w放开后按q 取消相邻窗口ctrl+w放开后按w 取消全部窗口；与：wqall相同 三、定制vim的工作特性扩展命令模式下执行：12set number 添加行号set nonumber 取消行号 此操作仅临时有效，退出重进vim后，操作失效，要想永久保存vim的工作特性，需写入配置文件中 配置文件：使vim工作特性永久有效全局：/etc/vimrc 个人：~/.vimrc 其他一些常用vim特性命令：忽略大小写 12set ic 忽略大小写set noic 取消忽略大小写 自动缩进 12set ai 自动和上一行对齐set noai 取消对齐 文件格式转换 12set fileformat=unix Windows文件转换Linux文件set fileformat=dos Linux文件转换Windows文件 设置光标所在行下划线 12set cursorline 启用set no cursorline 禁用 复制时保留格式： 12set paste 启用set nopaste 禁用 查看全部已配置的vim工作特性12：set 显示全部已配置set：help 查看帮助 四、文本处理常用命令 cut : 按列抽取文本 1234567-b： 仅显示行中指定直接范围的内容；-c： 仅显示行中指定范围的字符；-d： 指定字段的分隔符，默认的字段分隔符为“TAB”；-f： 显示指定字段的内容；-n： 与“-b”选项连用，不分割多字节字符；--complement： 补足被选择的字节、字符或字段；--out-delimiter=&lt;字段分隔符&gt;： 指定输出内容是的字段分割符； diff: 比较两个文件直接的差别，后跟file1，file2 head: 用于显示文件的开头的内容 12-n&lt;数字&gt;：指定显示头部内容的行数；-c&lt;字符数&gt;：指定显示头部内容的字符数； tail: 用于显示文件的结尾的内容 1234-n 显示最后n行-c 显示最后n个字节-f 跟踪文本的变化（追加内容），可写为tailf-F 跟踪文件名 sort: 将文件进行排序，并将排序结果标准输出 1234567-t 指定分隔符（类似cut -d）-k 指定第几列（类似cut -f）-n 以数字排序-r 倒序排列-f 忽略大小写-u 删除重复的行压缩到一行-R 随机排序 paste 合并两个文件同行号的列到一行 12-s 合并两个文件按一行显示-d 指定分隔符，类似cut -d的用法 grep: 基于行过滤的文本过滤工具 1234567891011121314-v 显示不被匹配到的行-i 忽略字符大小写-n 添加匹配到的行的行号-c 统计被匹配到的行数-o 仅显示匹配到的字符-q 静默模式-A# 包含此匹配行和后#行-B# 包含此匹配行和前#行-C# 包含此匹配行和前后#行-e 实现多个匹配字符的或者（or）关系 -e a -e b：a或b-w 匹配整个单词，数字、字母、下划线都算单词一部分-r 递归目录-E 使用ERE，扩展的正则表达式-F 相当于fgrep]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本三剑客之grep及正则表达式用法]]></title>
    <url>%2F2018%2F04%2F07%2F%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bgrep%E5%8F%8A%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[grep 是一种强大的文本搜索工具，它能使用特定模式匹配（包括正则表达式）搜索文本，并默认输出匹配行。 一、grep、文本过滤工具格式： ​ grep [OPTION]… PATTERN [FILE]… option： 1234567891011121314-v 显示不被匹配到的行-i 忽略字符大小写-n 添加匹配到的行的行号-c 统计被匹配到的行数-o 仅显示匹配到的字符-q 静默模式-A# 包含此匹配行和后#行-B# 包含此匹配行和前#行-C# 包含此匹配行和前后#行-e 实现多个匹配字符的或者（or）关系 -e a -e b：a或b-w 匹配整个单词，数字、字母、下划线都算单词一部分-r 递归目录-E 使用ERE，扩展的正则表达式-F 相当于fgrep grep工具之所以功能强大，是因为它支持正则表达式进行匹配，那什么又是正则表达式呢? 二、正则表达式的相关概念 正则表达式语言由两种基本字符类型组成：原义（正常）文本字符和元字符。元字符使正则表达 式具有处理能力。所谓元字符就是指那些在正则表达式中具有特殊意义的专用字符，可以用来规 定其前导字符（即位于元字符前面的字符）在目标对象中的出现模式正则表达式（REGEXP）： 由一类特殊字符及文本字符所编写的模式，其中有些字符（元字符）不表示字符表面意义， 而表示控制或通配功能 正则表达式与通配符的区别：通配符匹配的是文件名中的字符，不能匹配文件的文本内容的字符串， 这时候就需要用到正则表达式。 正则表达式分两类： 基本正则表达式：BRE；只承认的元字符有^$.[]*其他字符识别为普通字符：()需要转义 扩展正则表达式：ERE；则添加了（）{}?+|等 grep -E 等价于 egrep 正则表达式引擎： 采用不同算法，检查处理正则表达式的软件模块 基于PCRE语言（逐渐没落）兼容的正则表达式 元字符分类：字符匹配、匹配次数、位置锚定、分组（帮助文档：man 7 regex） 三、基本正则表达式（BRE）的元字符介绍：1. 字符匹配：12345678910. 匹配任意单个字符，放在[]中就表示点[] 匹配括号内任意单个字符[^] 匹配指定范围外的任意单个字符[:alnum:] 任意一个字母和数字[:alpha:] 任意一个字母[:lower:] 任意一个小写字母[:upper:] 任意一个大写字母[:digit:] 任意一个数字[:space:] 水平或垂直空白字符[:punct:] 标点符号 注意：正则表达式使用字符集作为搜索条件时，一定要加双引号，如”[[:digit:]]”； ​ 否则正则表达式会将字符集作为一个个字符进行识别 ​ 转义符“\”使正则表达式中具有特殊含义的字符显示其本身，如.只表示小数点 2. 匹配次数（某个字符出现的次数）12345678*- 匹配前面的字符任意次，包括0次（贪婪模式，尽可能长的匹配）.* 任意长度的任意字符\？ 匹配前面的字符0或1次，可看做 \&#123;0,1\&#125;\+ 匹配前面的字符至少1次，可看做\&#123;1，\&#125;（可实现懒惰模式）\&#123;m\&#125; 精确匹配前面的字符m次\&#123;m，\&#125; 至少匹配前面的字符m次\&#123;,m\&#125; 至多匹配前面的字符m次\&#123;m，n\&#125;匹配前面的字符m到n次 3. 位置锚定123456^ 行首锚定，用于模式最左侧$ 行尾锚定，用于模式最右侧^$ 表示空行\&lt;或\b 单词的词首锚定\&gt;或\b 单词的次尾锚定\&lt;word\&gt; 匹配整个单词，同grep -w 4. 分组()将一个或多个字符捆绑在一起，当做一个整体进行处理，如：(root)+ 分组括号中匹配到的内容会被正则表达式记录与内部变量中， 这些变量命名方式为：\1,\2,\3,… \1表示从左侧起第一个左括号以及与之匹配右括号之间的模式所匹配到的字符 后向引用：\1表示的是前面匹配的结果而不是前面匹配的模式 例：echo rootxxrbbt|grep ‘(r..t).*\1’ \1代表root，而不是r..t 5. 或者：|例：a|b：a或b； C|cat：C或cat \（C|c\）at：Cat或cat 四、扩展正则表达式（ERE）介绍：egrep 同grep -E扩展正则表达式（ERE）可理解为将基础正则表达式中的转义符全部去掉，其字符匹配与基础正则表达式（BRE）相同。 1. 字符匹配123. 任意单个字符[] 指定范围的字符[^] 不在指定范围的字符 2.次数匹配：12345* ：匹配前面字符任意次?: 0 或1次 次+ ：1 次或多次&#123;m&#125; ：匹配m次 次&#123;m,n&#125; ：至少m ，至多n次 3.位置锚定：1234^ : 行首$ : 行尾\&lt;, \b : 语首\&gt;, \b : 4.分组：12（）后向引用：\1,\2,… 5.或者：123a|b a或bC|cat C或catC|c）at Cat或cat 五、正则表达式中的元字符与通配符的区别作用不同：通配符匹配的是文件名中的字符，而正则表达式匹配的是文件的文本内容的字符串； 两者之间有很多相同之处，也有不同点，其中： 1.正则表达式元字符与通配符代表意义不同的有：通配符中： ​ * 表示任意长度的任意字符 ​ ? 表示任意一个单个字符 正则表达式： ​ *表示匹配前面的字符任意次 ​ . 表示匹配任意一个单个字符 ​ .*表示任意长度的任意字符 2. 正则表达式元字符与通配符含义相似的有：123456789[] 匹配括号内任意单个字符[^] 匹配指定范围外的任意单个字符[:alnum:] 任意一个字母和数字[:alpha:] 任意一个字母[:lower:] 任意一个小写字母[:upper:] 任意一个大写字母[:digit:] 任意一个数字[:space:] 水平或垂直空白字符[:punct:] 标点符号]]></content>
      <categories>
        <category>文本三剑客</category>
      </categories>
      <tags>
        <tag>grep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈几种IO重定向变形用法]]></title>
    <url>%2F2018%2F04%2F05%2F%E6%B5%85%E8%B0%88%E5%87%A0%E7%A7%8DIO%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%98%E5%BD%A2%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Linux给程序提供了三种I/O设备，即： 标准输入（STDIN） 0 默认接受来自键盘的输入 标准输出（STDOUT） 1 默认输出到终端窗口 标准错误（STDERR） 2 默认输出到终端窗口 同时linux中使用“&gt;”和“&gt;&gt;”将标准输出和标准错误重新定向到文件中： 后跟重定向文件，文件内容会被覆盖 123456789101112131415&gt; 把标准输出重定向到文件,文件内容会被覆盖2&gt; 把标准错误重定向到文件&amp;&gt; 把标准输出和错误都定向到文件1&gt;&amp;2 把标准输出定向到标准错误（简单来讲，对的变成错的）2&gt;&amp;1 把标准错误定向到标准标准输出（错的变成对的）&gt;&gt; 追加标准输出重定向到文件2&gt;&gt; 追加标准错误重定向到文件&amp;&gt;&gt; 追加标准输出和错误都定向到文件 那么下面我们来讨论下几种重定向的变形用法： 首先我们先建file1-6的6个空文件 这里我们看到: 123ll /data/f1 显示标准输出（f1文件详细信息）；ll /erorr显示标准错误（提示无此目录）； 接下来我们来进行几个小实验: 实验1. ll /data/f1 /erorr &gt; /data/file1 2&gt;&amp;1 结果:屏幕无显示，标准输出和标准错误输入到file1文件中 实验2.ll /data/f1 /erorr 2&gt;&amp;1 &gt; /data/file2 结果:屏幕显示标准错误，标准输出输入到file2文件中 实验3.ll /data/f1 /erorr 2&gt; /data/file3 1&gt;&amp;2 结果:屏幕无显示，标准输出和标准错误输入到file3文件中 实验4.ll /data/f1 /erorr 1&gt;&amp;2 &gt; /data/file4 结果:屏幕显示标准错误，标准输出输入到file4文件中 实验5.ll /data/f1 /erorr &gt; /data/file5 结果:屏幕显示标准错误，标准输出输入到file5文件中 实验6.ll /data/f1 /erorr &gt; /data/file6 1&gt;&amp;2 结果:屏幕显示标准输出和标准错误，file6文件为空 观察6个小实验我们发现: 实验1,3得出的结果完全相同，屏幕无显示，标准输出和标准错误输入到file文件中。得出此结果也有两种 执行顺序的可能性： 可能性1：实验1可看做，标准输出先重定向到file文件中，标准错误然后重定向为标准输出再次重定向 到file文件中；实验3可看做，标准错误先重定向到file文件中，标准输出然后重定向为标准错误再次重定 向到file文件中，所以file文件中既有标准输入又有标准输出。 可能性2：实验1可看做，标准输出和错误都经过2&gt;&amp;1的重定向后，全变为标准输出，再输入进file1件中； 实验3可看做，标准输出和错误都经过1&gt;&amp;2的重定向后，全变为标准错误，再输入file3文件中。 于是我们有了实验6，ll /data/f1 /erorr &gt; /data/file6 1&gt;&amp;2，得出结果屏幕显示标准输出和标准错误，file6 文件为空，由此可认为实验6执行了可能性2的执行过程。 结论1:当有1&gt;&amp;2或2&gt;&amp;1处于重定向组合命令结尾时，输出结果全部先执行1&gt;&amp;2或2&gt;&amp;1，再执行前面的重定向。 实验2,4,5得出的结果完全相同，即屏幕显示标准错误，标准输出输入到file5文件中 三条命令分别为： ​ ll /data/f1 /erorr 2&gt;&amp;1 &gt; /data/file2 ​ ll /data/f1 /erorr 1&gt;&amp;2 &gt; /data/file4 ​ ll /data/f1 /erorr &gt; /data/file5 我们是否可以这样认为: 结论2:当2&gt;&amp;1或1&gt;&amp;2处在重定向组合命令中间位置时，2&gt;&amp;1或1&gt;&amp;2是不起作用的，可以忽略掉（此结论待定）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>IO重定向</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件权限详解]]></title>
    <url>%2F2018%2F04%2F04%2FLinux%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Linux系统中不仅是对用户与组根据UID,GID进行了管理，还对Linux系统中的文件，按照用户与组进行分类，针对不同的群体进行了权限管理，用他来确定谁能通过何种方式对文件和目录进行访问和操作。 一、文件权限 文件的权限针对三类对象进行定义 owner 属主，缩写u group 属组，缩写g other 其他人，缩写o 每个文件针对每类访问者定义了三种主要权限 r：Read 读 w：Write 写 x：eXecute 执行 另 X：针对目录加执行权限，文件不加执行权限（因文件具备执行权限有安全隐患） 注意：root账户不受文件权限的读写限制，执行权限受限制 对于文件和目录来说，r，w，x有着不同的作用和含义： 针对文件： r：读取文件内容 w：修改文件内容 x：执行权限对除二进制程序以外的文件没什么意义 针对目录：目录本质可看做是存放文件列表、节点号等内容的文件 r：查看目录下的文件列表 w：删除和创建目录下的文件 x：可以cd进入目录，能查看目录中文件的详细属性，能访问目录下文件内容（基础权限） 用户获取文件权限的顺序：首先看是否为所有者，如果是，则后面权限不看；再看是否为所属组， 如果是，则后面权限不看。 二、修改文件访问权限的方法 chmod 修改权限 change mode 方法1：mode法 ​ 格式：chmod who opt per file ​ who：u g o a（all） ​ opt：+ – = ​ per：r w x X ​ 方法2：数字法 ​ 格式：chmod XXX file rwx rw- r– 111 110 100 7 6 4 ​ r：4 ​ w：2 ​ x：1 例：chmod 764 file 给file文件添加 rwxrw-r– 权限 ​ chmod -R +X dir 给dir目录添加X执行权限，dir目录下文件不添加执行权限 ​ （如果dir目录下有文件已具备执行权限，则添加该文件执行权限） 三、UMASK值umask值的作用：用来设置限制新建文件权限的掩码。当新文件被创建时，其最初的权限由文件创建掩码决定 对目录： umask+default=777（dir） 对文件： 666-umask：观察结果，如果有奇数，奇数位+1，偶数不变 四、三种特殊权限suid、sgid、sticky suid 作用：让本来没有相应权限的用户运行这个程序时，可以访问他没有权限访问的资源。 suid权限位 位于所有者的执行权限位上，如果一个文件具有suid权限，则所有者执行位为s，文件表现为红色背景 例： 12ll /usr/bin/passwd #查看/usr/bin/passwd文件的权限-rwsr-xr-x. 1 root root 30768 Nov 24 2015 /usr/bin/passwd 给file文件增加suid权限 12chmod u+s file # suid的mode法chmod 4755 file # suid数字法表示为4 注：suid只适合作用在二进制程序上 sgid 作用1：给一个用户继承二进制程序所有组拥有的权限 作用2：作用在目录上时，使一个目录下的新建的文件继承目录的所属组 sgid权限位 位于所有组的执行权限位，如果一个文件具有suid权限，则所有组的执行位为s，文件表现为黄色背景 例： 123ll `which cat`-rwxr-sr-x. 1 root root 48568 Mar 23 2017 /bin/cat 给file文件增加sgid权限 12chmod g+s file # sgid的mode法chmod 2755 file # sgid数字法表示为2 ​ sticky 作用：作用于目录上，此目录的文件只能被所有者删除 sticky权限位位于其他的执行权限位上，如果一个文件具有sticky权限，则其他的执行位为t，目录表现为绿色背景 如： 12ll -d /tmpdrwxrwxrwt. 17 root root 4096 Apr 4 10:02 /tmp 给dir目录添加sticky权限 12chmod o+t dir # sticky的mode法chmod 1777 dir # sticky数字法表示为1 ​ 五、ACL访问控制列表作用：实现更加灵活的权限管理，打破了三类用户的权限管理 添加ACL权限 1234567setfacl -m u:lpx:0 file # 使lpx账户对指定file文件无权限setfacl -m u:mage:rw file # 使mage账户对指定file文件有读写权限setfacl -m g:g1:rw file # 使g1组对指定file文件有读写权限getfacl file # 查看指定file文件的ACL权限 ACL权限执行顺序类似于用户获取文件权限的顺序，getfacl顺序从上到下执行，一旦生效，下面的将不再生效（如果属于多个组，权限累加） 删除ACL权限 123setfacl -x u:lpx file 删除lpx账户对指定file文件的ACL权限setfacl -x g:g1 file 删除g1组对指定file文件的ACL权限 ACL权限下的mask 1234567设置用户对指定文件所能拥有的最大权限（限高作用）setfacl -m mask::r file 使指定文件file所拥有的最大权限位读rsetfacl -x mask::r file 取消指定文件file的最大权限限制masksetfacl -b f1 取消f1文件所有的ACL权限 ACL生效顺序：所有者、自定义用户、自定义组、其他人 备份和恢复ACL权限 123getfacl -R /tmp/dir1&gt;acl.txt 将dir1目录下ACL权限备份setfacl -R –set-file=acl.txt /tem/dir 恢复dir1目录下ACL权限 六、文件权限操作的常用命令 chown 设置文件所有者（普通用户无法修改文件所有者） 1234-R 递归user：group 同时修改所有者，所有组chgrp 设置文件所属组（普通用户要想该所属组，前提是文件所有者为自己，自己在所属组中）-R 递归 chmod 设置指定文件权限 12-R 递归–reference=f1 f2 f3 参考f1文件权限设置f2，f3文件 chattr 给指定文件添加保护，避免root账户误操作 12345+i 锁定文件，不能删除，不能改名，不能更改内容-i 解锁+i-a 锁定文件，不能删除，不能改名，但可追加内容（追加重定向）-a 解锁+a+A 指定文件读时间atime不再更改 lsattr 查看指定文件是否有锁定状态 setfacl 设置文件ACL权限 1234-m mask::r file 使指定文件file所拥有的最大权限位读r-x mask::r file 取消指定文件file的最大权限限制mask-b f1 取消f1文件所有的ACL权限-R –set-file=acl.txt /tem/dir 恢复dir1目录下ACL权限 getfacl 查看文件ACL权限]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件系统简介]]></title>
    <url>%2F2018%2F04%2F04%2FLinux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Linux哲学思想讲“一切皆是文件”，包括硬件在linux系统中也表现为文件形式。 学好文件系统将为以后深入研究与学习Linux系统奠定良好的基础。 一、目录文件管理 / 根目录每个文件和目录都从这里开始 /bin 基本程序，一般为普通用户可执行的程序 /boot 静态文件，系统文件 /dev 存放硬件设备文件 /etc 存放配置文件 /lib64 库文件 /media 挂载点 /mnt 管理员手动挂载点 /opt 第三方软件包 /sbin 管理员运行的程序 /srv 服务器相关数据 /tmp 存放临时文件 /usr 第二层目录结构 /var 存放变化的文件，如/var/log存放日志 /home 家目录，存放用户信息 /root 管理员的家目录‘ /lost+found 分区为ext4具有（如centos6） /misc 实现光盘的自动挂载 /sys 硬件相关信息 /proc 存储内存中的状态信息 /selinux 安全策略（生产环境中一般禁用） 二、文件颜色 Linux系统通过不同的颜色来对文件进行区别，其中： ​ 蓝色 代表目录 ​ 绿色 可执行程序 ​ 红色 打包文件，压缩文件 ​ 浅蓝色 链接文件（快捷方式） ​ 粉色 套接字文件 ​ 浅黄色 管道文件 三、文件类型 12345678910111213– 普通文件d 目录文件b 块设备c 字符设备l 符号链接文件p 管道文件pipes 套接字文件socket 四、文件时间戳 通过stat file 命令查看file文件时间戳： ​ mtime 文件最后修改时间 ​ atime 文件最后读取时间 ​ ctime 文件元数据最后发生变化的时间，如权限，所有组的变化 五、常用文件通配符： 1234567891011121314151617181920212223\* 匹配零个或多个字符？ 匹配任何单个字符~ 当前用户家目录[0-9] 表示数字[^0-9] 除数字以外[a-z] 小写字母[A-Z] 大写字母[:digit:] 任意数字[:lower:] 任意小写字母[:upper:] 任意大写字母[:alpha:] 任意大小写字母[:alnum:] 任意数字或字母 六、节点编号inode Linux系统的文件数据都储存在块（block），此外还需有个地方来储存文件的元信息，比如文件权限、创建者、创建日期等。这种储存文件元信息的区域就叫做inode。 节点编号也是宝贵的资源，查看指针节点占用情况：df -i 每个节点编号占4字节 直接指针：前12个指针为直接指针 一级指针：可保存4096/4=1024个指针，可存储文件大小1024*4096=4MB 二级指针：可存储文件大小102410244096=4GB 三级指针：可存储文件大小102410241024*4096=4TB 七、常用文件管理命令： ls 显示文件信息 1234567-a 包含隐藏文件-l 显示文件详细信息，可写为ll-s 从大到小排列-r 倒序排列-d 只显示目录自身属性-d */ 只显示当前目录下文件夹-m MODE: 创建目录时直接指定权限 touch 创建文件 1234-a 仅改变atime和ctime-m 仅改变mtime和ctime-t[[CC]YY]MMDDhhmm[.ss] 指定atime和mtime的时间戳-c 如果文件不存在，则不予创建 mkdir 创建目录 12-p 存在于不报错，且可自动创建所需的各目录-v 显示过程 cp 复制 123456-a 复制全部信息，用于备份；可复制特殊文件如字符文件，块文件-i 覆盖前提示-r 递归复制-v 显示过程-u 只复制源比目标更新文件或目标不存在的文件–backup=numbered 目标存在，覆盖前先备份加数字后缀（建议加别名） mv 移动或重命名文件（mv只支持单个文件重命名，rename可批量改名） 123-i 移动前提示-r 递归-v 显示过程 rm 删除 123-f 不去询问直接删除-i 删除前交互提示-r 递归]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux用户与组管理命令的易混淆点和重合点]]></title>
    <url>%2F2018%2F04%2F03%2FLinux%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%E7%9A%84%E6%98%93%E6%B7%B7%E6%B7%86%E7%82%B9%E5%92%8C%E9%87%8D%E5%90%88%E7%82%B9%2F</url>
    <content type="text"><![CDATA[Linux用户与组的管理命令，对于初学者来说很容易造成混淆，此外，这些命令之间有很多相重合的用法，即：拥有多种命令可实现相同的需求的情况。 Linux用户与组的管理命令主要有useradd、usermod、userdel、groupadd、groupmod、groupdel、groupmems、gpasswd、passwd、newgrp等等，其中每条命令也都有很多的可选项，对于初学者来说很容易造成混淆；此外，这些命令之间有很多相重合的用法，即：拥有多种命令可实现相同的需求的情况。 接下来，我们来把这些混淆和重合点进行下梳理： 一、易混淆点：关于GID的改变 命令1：usermod -g 改变一个用户的gid 123456[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx)[root@CentOS6 ~]#usermod -g 4322 wangx[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=4322(mage) groups=4322(mage) 此条命令改变了用户的主组，需注意的是新改变的主组需已存在 命令2：newgrp 临时改变一个用户的gid 12345678910[wangx@CentOS6 ~]$iduid=1666(wangx) gid=1235(wangx) groups=1235(wangx),4322(mage) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023[wangx@CentOS6 ~]$newgrp mage[wangx@CentOS6 ~]$iduid=1666(wangx) gid=4322(mage) groups=4322(mage),1235(wangx) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023[wangx@CentOS6 ~]$id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx),4322(mage) 此条命令作用为切换当前登录用户的主组，注意是临时切换，重新登录后失效，使用id user命令看到的还是切换前的主组 命令3：groupmod -g 改变组的gid 12 此条命令仅仅是改变了组的ID，组成员还是原来的组成员，没有变化。 二、增、删辅助组的多种方式 1.为一个用户添加一个辅助组有三种方式：（这里暂以添加一个辅助组为例，暂不考虑添加多个辅助组的情况） 命令1：groupmems -a user -g group 指定用户user加入组group 1234567[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx)[root@CentOS6 ~]#groupmems -a wangx -g mage[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx),4322(mage) 命令2：gpasswd -a user group 将用户user添加至指定组group中: 12345[root@CentOS6 ~]#gpasswd -a wangx mageAdding user wangx to group mage[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx),4322(mage) 命令3：usermod -G 为user用户添加辅助组，注意：新的辅助组覆盖原辅助组: 1234567[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx)[root@CentOS6 ~]#usermod -G mage wangx[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx),4322(mage) 从一个辅助组中删除一个用户也有三种方式: 命令1：groupmems -d user -g group 从group组中删除用户user 1234567[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx),4322(mage)[root@CentOS6 ~]#groupmems -d wangx -g mage[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx) 命令2：gpasswd -d user group 将用户user从group组中删除 12345678[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx),4322(mage)[root@CentOS6 ~]#gpasswd -d wangx mageRemoving user wangx from group mage[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx) 命令3：usermod -G “” user 1234567usermod -G user user 两种方法均可删除所有辅助组[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx),4322(mage)[root@CentOS6 ~]#usermod -G wangx wangx[root@CentOS6 ~]#id wangxuid=1666(wangx) gid=1235(wangx) groups=1235(wangx) 三、其他的一些拥有多种命令可实现相同需求的情况： 修改一个用户的shell类型（2种方法）： 123命令1：chsh 修改用户的shell命令2：usermod -s 新的默认shell 修改一个用户的描述信息（2种方法）： 123命令1：chfn 修改用户描述信息命令2：usermod -c 新的用户描述信息 修改一个账号下次登录自动修改密码（2种方法）： 123命令1：chage -l wang 使wang账户口令立马失效，下次登录自动修改命令2：passwd -e wang 使wang账户口令立马失效，下次登录自动修改 给一个账号加锁（2种方法）： 123命令1：usermod -L命令2：passwd -l 给一个账号解锁（2种方法）： 123命令1：usermod -U命令2：passwd -u 给一个账号指定最短使用期限（mindays）（2种方法）： 123命令1：passwd -n命令2：chage -m 最大使用期限（maxdays）（2种方法）： 123命令1：passwd -x命令2：chage -M 设置一个账号提前多少天开始警告（warndays）（2种方法）： 123命令1：passwd -w命令2：chage -W 设置一个账号非活动期限（inactivedays）（3种方法）： 12345命令1：passwd -i命令2：usermod -f命令3：chage -I 设置一个账号的有效期（expiredate）（2种方法）： 123命令1：usermod -e YYYY-MM-DD 设置用户账号过期时间命令2：chage -E YYYY-MM-DD 设置用户账号过期时间]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux用户与组管理详解]]></title>
    <url>%2F2018%2F04%2F03%2FLinux%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[在linux系统上，用户管理是基于用户名和密码的方式进行资源的分配，了解和掌握用户与组的管理是从事运维工作所必须具备的能力，也是将来从事运维行业的重要工作之一。 Linux的安全模型 安全3A ​ Linux通过三个机制来保证用户的安全： ​ Authentication：认证 ​ Authorization：授权 ​ Accouting|Audition：审计 安全上下文 ​ Linux 安全上下文 运行中的程序：进程 (process) 以进程发起者的身份运行： root: /bin/cat mage: /bin/cat 进程所能够访问资源的权限取决于进程的运行者的身份 User and Grooup用户user令牌: token,identityLinux 用户：Username/UID管理员：root, 0普通用户：1-65535 系统用户：1-499, 1-999 （CentOS7） ） 对守护进程获取资源进行权限分配登录用户:500+, 1000+ （CentOS7） ） 交互式登录 组 group：Linux组：Groupname/GID 管理员组：root，GID=0 普通组： ​ 系统组：1-499,1-999（centos7） ​ 普通组：500+，1000+（centos7） 在创建用户不指定组的情况下，默认创建一个与该用户名相同的组作为该用户的主组 组的类别：用户的主要组(primary group) 用户必须属于一个且只有一个主组 组名同用户名，且仅包含一个用户，私有组用户的附加组(supplementary group) 一个用户可以属于零个或多个辅助组 用户和组的配置文件 /etc/passwd： 存用户及其属性信息( 名称、UID 、主组ID 等 /etc/shadow： 存放用户密码及其相关信息 /etc/group： 存放组及属性信息 /etc/gshadow： 存放组密码及其相关信息 /etc/default/useradd：新建账户模板信息 /etc/passwd 12345678name：password:UID:GID:GECEO:directory:shell1. login name ： 登录用名（lpx） ）2. passwd ： 密码 (x)3. UID号 ： 用户身份编号 (1000)4. GID ： 登录默认所在组编号 (1000)5. GECOS ： 用户全名或注释6. home directory录 ： 用户主目录 (/home/wang)7. shell ： 用户默认使用shell (/bin/bash) ​ /etc/shadow 123456781. 登录用名2. 用户密码: 一般用sha512 加密3. 从 从1970 年1 月1 日起到密码最近一次被更改的时间4. 密码再过几天可以被变更（0 表示随时可被变更）5. 密码再过几天必须被变更（99999 表示永不过期）6. 密码过期前几天系统提醒用户（默认为一周）7. 密码过期几天后帐号会被锁定8. 从1970 年1 月1 日算起，多少天后帐号失效 /etc/group 1234561. group_name:password:GID:user_list2. group_name 群组名称：就是群组名称3. password 群组密码：通常不需要设定，密码是被记录在 /etc/gshadow4. GID 群ID：就是群组的 ID5. user_list 以当前组为附加组的用户列表(分隔符为逗号) /etc/gshadow 123451. group_name:encrypted_password:administrators:members2. group_name:群组名称：就是群组名称3. encrypted_password:群组密码：4. administrators:组管理员列表：组管理员的列表，更改组密码和成员5. members :以当前组为附加组的用户列表：(分隔符为逗号) /etc/default/useradd 123456781. useradd defaults file 创建用户默认文件2. GROUP=100 创建用户无指定组时默认所属的组users3. HOME=/home 创建用户默认家目录路径4. INACTIVE=-1 创建用户时默认没有宽限时间5. EXPIRE= 创建用户时默认有效期6. SHELL=/bin/bash 创建用户时默认shell类型7. SKEL=/etc/skel 创建用户时家目录模板8. CREATE_MAIL_SPOOL=yes 创建用户时默认创建邮箱 文件操作​ vipw 等同于vi /etc/passwd ​ vigr 等同于vi /etc/group ​ pwck 检查passwd文件格式错误 ​ grpck 检查group文件格式错误 用户与组的管理命令用户管理命令及常用选项 useradd: 添加登录账号 123456789101112-u 指定uid（生产环境中多台服务器保证程序是同一UID）-o 不检查UID的唯一性，需配合-u使用（不建议UID一样）-g 创建用户时指定主组-c 创建用户时添加描述-d 创建用户时指定家目录路径，二层目录（生产环境中创建给服务用的账户可能会用到）-s 创建用户时指定shell类型/etc/shells-r 创建系统用户（默认不创建家目录）-m 强行创建家目录，用于系统用户，配合-r使用（生产环境中为服务生成系统用户）-M 强行不创建家目录，用于普通用户-G 创建用户时加入到多个辅助组里，多个辅助组用“，”分开-N 创建一个用户名和主组名不同的用户，默认users作为主组-p 创建用户添加密码（不建议此种方式添加口令，口令会在shadow文件中明文） usermod： 修改登录账号 123456789-u 修改UID-g 修改GID（组需存在）-G 修改辅助组（会将原来的辅助组覆盖），如果要保留原辅助组配合-a使用-s 新的默认shell-c 新的注释信息-d 新家目录不会自动创建；若要创建新家目录并移动原家数据，同时使用-m选项（-m -d有顺序）-l 新的用户名-L 用户加锁-U 用户解锁（centos6以后禁止此方式解锁） userdel： 删除登录账号 1-r 删除用户的所有文件，家目录及邮箱（工作中不建议用，建议保留数据） id： 可以显示真实有效的UID和GID 1234-u: 显示UID-g: 显示GID-G: 显示用户所属的组的ID-n: 显示名称，需配合ugG 使用 su: 切换用户或以其他用户身份执行命令 1234567示例： su UserName ：非登录式切换，即不会读取目标用户的配置文件，不改变当前工作目录 su - UserName ：登录式切换，会读取目标用户的配置文件，切换至家目录，完全切换 root su 至其他用户无须密码；非root 用户切换时需要密码换个身份执行命令：su [-] UserName -c &apos;COMMAND&apos; 选项：-l --loginsu -l UserName 于 相当于 su - UserName passwd: 修改自己的密码 12345678910passwd [OPTIONS] UserName: 修改指定用户的密码，仅root-l: 锁定指定用户-u: 解锁指定用户-e: 强制用户下次登录修改密码-n mindays: 指定最短使用期限-x maxdays ： 最大使用期限-w warndays ： 提前多少天开始警告-i inactivedays ： 非活动期限--stdin ： 从标准输入接收用户密码如： echo &quot; PASSWORD &quot; | passwd --stdin USERNAME newusers passwd： 格式文件 批量创建用户chpasswd： 批量修改用户口令 chage：修改用户密码策略 1234567891011-d LAST_DAY-E --expiredate EXPIRE_DATE-I --inactive INACTIVE-m --mindays MIN_DAYS-M --maxdays MAX_DAYS-W --warndays WARN_DAYS–l 显示示例：chage -d 0 tom 下一次登录强制重设密码chage -m 0 –M 42 –W 14 –I 7 tomchage -E 2016-09-10 tom chfn: 用来改变finger命令显示的信息 1234-f&lt;真实姓名&gt;或--full-name&lt;真实姓名&gt;：设置真实姓名；-h&lt;家中电话&gt;或--home-phone&lt;家中电话&gt;：设置家中的电话号码；-o&lt;办公地址&gt;或--office&lt;办公地址&gt;：设置办公室的地址；-p&lt;办公电话&gt;或--office-phone&lt;办公电话&gt;：设置办公室的电话号码； chsh: 修改指定shell 12-s&lt;shell 名称&gt;或--shell&lt;shell 名称&gt;：更改系统预设的shell环境。；-l或--list-shells：列出目前系统可用的shell清单； finger: 用于查找并显示用户信息。包括本地与远端主机的用户皆可 1234567-l：列出该用户的帐号名称，真实姓名，用户专属目录，登入所用的Shell，登入时间，转信地址，电子邮件状，还有计划文件和方案文件内容；-m：排除查找用户的真实姓名；-s：列出该用户的帐号名称，真实姓名，登入终端机，闲置时间，登入时间以及地址和电话；-p：列出该用户的帐号名称，真实姓名，用户专属目录，登入所用的Shell，登入时间，转信地址，电子邮件状，但不显示该用户的计划文件和方案文件内容。 组帐号维护命令及常用选项 groupadd： 添加组 12-g 指明GID号创建组-r 创建系统组group（centos6：ID&lt;500、centos7：ID&lt;1000） groupmod： 修改组信息 12-n 新的组名-g 新的GID groupdel： 删除组（前提没有用户以此组为主组） groupmems： 查看指定组的成员 12345-g 更改为指定组（只有root）-a 指定用户加入组-d 从组中删除用户-p 从组中清除所有成员-l 显示组成员列表（读取的/etc/group文件中对应组的最后一个字段的全部内容） gpasswd： 给组添加口令 123-a user 将user添加至指定组中-d user 从指定组中移除用户user-A user1，user2… 设置有管理权限的用户列表（设置组管理员）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[带你认识Linux中的通配符]]></title>
    <url>%2F2018%2F04%2F02%2F%E5%B8%A6%E4%BD%A0%E8%AE%A4%E8%AF%86Linux%E4%B8%AD%E7%9A%84%E9%80%9A%E9%85%8D%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[所谓的通配是指：显示以指定条件的文件，英文名为glob。通配符是一种特殊语句，用来模糊搜索文件。当查找文件夹时，可以使用它来代替一个或多个真正字符它使得文件管理更加快速，便捷，大大提升了工作效率。 常用的通配符有 * 、? 、[] 等（可通过man 7 glob的帮助文档来查看所有通配符） 表示任意长度的任意字符： 例：ls -d /etc/a* 显示/etc目录下所有以a开头的文件与目录： ? 表示任意单个字符： 例：ls a?b 显示当前目录下所有以a开头中间有一个字符b结尾的文件，a10b中间夹2个字符，因此不显示： [] 匹配指定范围内任意单个字符： 例：ls -d /etc/[mn]* 显示/etc目录下所有以m开头或者n开头的文件和目录： ​ [a-Z]：表示任意一个单个字母： ​ 例：ls -d*[a-Z] 显示目录下所有以字母开头的文件和目录 ​ [0-9]：表示任意单个数字： 例：ls -d f[0-9]显示当前目录下所有以f开头后跟任意一个数字的文件和目录，f16因含两个数字，则不予显示： [^]匹配除指定范围以外的任意单个字符： 例：ls -d [^a]* 显示当前目录下所有不是a开头的文件和目录： ​ 注意：对字符集或数字集取反时，托字符^加在括号内；如：[^0-9] 常用的字符集表示方法： [:alpha:]表示所有的字母（不区分大小写） 例：ls -d *[[:alpha:]] 显示当前目录下所有以字母结尾（不区分大小写）的文件和目录 ​ [:digit:]表示任意单个数字，效果同[0-9] ​ 例：ls f[[:digit:]] 显示当前目录下所有f开头，单个数字结尾的文件，值得注意的是： ​ [:digit:]只代表单个数，f16文件因为f后跟两个数字，则不予显示。 ​ [:lower:]表示任意单个小写字母 ​ 例：ls -d [[:lower:]]*[[:lower:]] ​ 显示所有当前目录下以小字字母开头且以小写字母结尾的文件和目录： ​ [:upper:]表示任意单个大写字母 ​ 例：ls -d a*[[:upper:]] 显示当前目录下 所有以a开头并以一个大写字母结尾的文件和目录： ​ [:alnum:]表示任意单个字母或数字 ​ 例：ls -d [[:alnum:]]显示当前目录下 所有以字母或数字结尾的文件和目录：]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux入门知识]]></title>
    <url>%2F2018%2F04%2F01%2Flinux%E5%85%A5%E9%97%A8%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Linux起源：1991 年的10 月5 日，Torvalds 在comp.os.minix新闻组上发布消息，正式向外宣布他自行编写的完全自由免费的内核诞生（Freeminix-likekernel sources for 386-AT ）———FREAX英文 含义是怪诞的、怪物、 异想天开类Unix 的内核，在GPL 下发布官网：www.kernel.orgLinux 操作系统 ： 完整的类UNIX 操作系统Linux 内核+ GNU 工具如：CentOS,Ubuntu,Android Linux主流发行版linux有三大主流源头发行版，分别为 slackware: 由Novell公司发布维护 SUSE Linux Enterprise Server (SLES) 企业版OpenSuse 个人版版 debian: 由Debian维护社区发布 Ubuntu 以桌面应用为主的开源GNU/Linux操作系统Linux Mint:为家庭用户和企业提供一个不花钱的，易用的，并且漂亮的桌面系统 redhat：由Redhat发布 RHEL: RedHat Enterprise Linux 企业版 每18个月发行一个新版本CentOS ：兼容RHEL的格式 企业版中标麒麟：中标软件Fedora ：个人版 每6个月发行一个新版本 ArchLinux ：轻量简洁Gentoo ：极致性能， 不提供传统意义的安装程序更多详情可参考 Linux 分支参考网站：http://futurist.se/gldt/ linux内核版本 linux哲学思想 一切都是一个文件（包括硬件）： linux系统是由各种类型不同的文件组成，但是操作文件的方法却是相同的 小型，单一用途的程序： 程序和可执行文件不要太复杂，这样才能保证了linux内核的高效运行 链接程序，共同完成复杂的任务： 复杂的功能可以通过连接多个用途单一的程序组合实现，在保证简单程序的高效性的同事，复杂程序也必然高效 避免令人困惑的用户界面： linux是开源系统的，无论什么问题都可以通过简洁的命令行实现 排错，修改系统的配置，一切都是简洁明了为基础。而图形化用户界面如果遇到问题，无法知道错误的原因，只能通过重启来解决问题，再不行就重装系统 配置数据存储在文本中： linux所有的配置文件都存放在文本配置文件当中，无论什么如何操作系统都只需修改其配置文件即可]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机系统组成及其功能]]></title>
    <url>%2F2018%2F04%2F01%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%8F%8A%E5%85%B6%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[计算机系统组成计算机系统由硬件 计算机系统由硬件(Hardware) 系统和软件(Software)系统两大部分组成 计算机的功能： 把需要的程序和数据送至计算机中。 必须具有长期记忆程序、数据、中间结果及最终运算结果的能力。 能够完成各种算术、逻辑运算和数据传送等数据加工处理的能力。 能够根据需要控制程序走向，并能根据指令控制机器的各部件协调操作。 能够按照要求将处理结果输出给用户。 冯诺依曼体系的五大基本部件： 运算器：用于完成各种算术运算、逻辑运算和数据传送等数据加工处理。 控制器：用于控制程序的执行，是计算机的大脑。 存储器：用于记忆程序和数据。分为只读存储器和随机存储器 输入设备：用于将数据或程序输入到计算机中，例如：鼠标、键盘。 输出设备：将数据或程序的处理结果展示给用户，例如：显示器、打印机。]]></content>
      <categories>
        <category>computer</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux的历史]]></title>
    <url>%2F2018%2F03%2F20%2FLinux%E7%9A%84%E5%8E%86%E5%8F%B2%2F</url>
    <content type="text"><![CDATA[Linux的历史Linux起源Multics计划&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上个世纪六十年代，那个计算机还没有很普及，只有少数人才能使用，而且当时的计算机系统都是批处理的，就是把一批任务一次性提交给计算机，然后就等待结果。并且中途不能和计算机交互。往往准备作业都需要花费很长时间，并且这个时候别人也不能用，导致了计算机资源的浪费。 为了改变这种情况，在1965年前后，贝尔实验室（Bell）、麻省理工学院（MIT）以及通用电气（GE）联合起来准备研发一个分时多任务处理系统，简单来说就是实现多人同时使用计算机的梦想，并把计算机取名为Multics（多路信息计算系统），但是由于项目太复杂，加上其他原因导致了项目进展缓慢，1969年贝尔实验室觉得这个项目可能不会成功，于是就退出不玩了。 Unix的诞生&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bell退出Multics计划之后，Bell实验室的那批科学家就没有什么事做了，其中一个叫做Ken Thompson的人在研发Multics的时候，写了一个叫做太空大战（Space Travel）的游戏，大概就是一个很简单的打飞机的游戏，但是这个游戏运行在Multics上。当Bell退出了Multics后，Thompson就没有了Multics的使用环境了，为了能够继续游戏，于是他花了一个月的时间写了一个小型的操作系统，用于运行Space Travel，当完成之后，Thompson怀着激动的心情把身边同事叫过来，让他们来玩他的游戏，大家玩过之后纷纷表示对他的游戏不感兴趣，但是对他的系统很感兴趣。 因为MULTICS是“Multiplexed informtion and Computing Service”的缩写（多路信息计算系统），于是他们命名这个系统为：“UNiplexed Information and Computing Service”，缩写为“UNICS”(没路信息计算系统，与Multics相反)。后来大家取其谐音，就称其为“UNIX”了。 这个时候已经是1970年了，于是就将1970年定为Unix元年，因此计算机上的时间就是从这一年开始计算的。 后来Unix这个小操作系统就在Bell实验室内部流行开，并经过不断地改良最终在1974年7月Unix发展到第5个版本，Bell实验室公开了Unix，结果引起了学术界的广泛兴趣并对其源码索取。所以，Unix第五个版本就以“仅用于教育目的”的协议，提供给各大学作为教学之用，成为当时操作系统课程的范例教材。各大学公司开始通过Unix源码对Unix进行了各种各样的改进和拓展。1978年学术界的老大伯克利大学，推出了一份以第六版为基础，加上一些改进和新功能而成的Unix。并命名为BSD（Berkeley Software Distribution伯克利分发版），开创了Unix的另一分支：BSD系列。 于是乎Unix就有了两个分支，一个就是BSD系列的分支，一个就是Bell本身发放的分支，当时因为Bell属于AT&amp;T，AT&amp;T受到了美国《谢尔曼反托拉斯法》的影响，不能销售除了电话机电报机等之外的商品，后来AT&amp;T分解，Bell可以卖Unix了，Unix走向了商业化，如果想继续使用就需要购买授权，一份授权4万美元。 Minix及Linux的诞生&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Unix昂贵的授权费用下，很多大学不得不停止对其研究，老师导致上课也不知道讲什么了。在1987年荷兰有个大学教授安德鲁写了一个Minix，类似于Unix，专用于教学。当Minix流传开来之后，世界各地的黑客们纷纷开始使用并改进，希望把改进的东西合并到Minix中，但是安德鲁觉得他的系统是用于教学的，不能破坏纯净性，于是拒绝了。 在1991年9y月17日，Linus Torvalds(林纳斯.托瓦兹)在互联网上公布了自己写的Linux，可能是表达对安德鲁的不满吧（为什么不接受大家的好意呢？你让大家的满腔热情往哪放呢？），于是Linus发布了一个帖子，大概就是说：我写了一个操作系统的内核，但是还不够完善，你们以任何姿势使用不收费，也可以帮助我一起修改。帖子发出后引起了强烈的反响。在大家的努力下，于1994年Linux的1.0版本正式发布。 为什么会引起这么强烈的反应呢？这就要从了另一个人说起，那就是Richard Stallman(自由软件之父)。Stallman是一个非常“激进”的人，因为Unix商业化的影响，他认为软件是全人类的智慧结晶，不应该为某一家公司服务。在八十年代，他发起了自由软件运动，吹起了共产主义的号角（发起了GUN运动），并发布了软件界的共产主义宣言（GPL协议），并且这一运动得到了很多人的认同。 所谓自由软件自由就是指：自由使用、自由学习和修改、自由分发、自由创建衍生版。 GUN的定义是一个递归缩写，就是GUN IS NOT UNIX。就是说Unix是流氓，我不是。有意思的是，GUN运动是上个世纪八十年代开始的，而那个时候Linux还没有诞生呢 ，所以Stallman宝宝心里苦啊，就在大家逐渐失去信心的时候，1991年Linus Torvalds带着他的Linux闪亮登场了，给GUN运动画了一个完美的句号。 Linux为什么会引起如此强烈的反响呢？因为Unix有版权，爱好编程的狂热分子在研究Unix的时候很容易吃上官司 ，而Linux是遵循GPL协议的，可以免费使用，让黑客们尽情的施展（这里的黑客指那些技术大牛，不是指那些利用计算机干坏事的人）。于是Linux提供内核（kernel），GUN提供外围软件，就这样GUN/Linux诞生了。 所以，看到这里你就会了解到Unix是1970年出现的，Linux是1991年发布的，但Linux是不同于Unix的操作系统。 Linux主流发行版linux有三大主流源头发行版，分别为 slackware: 由Novell公司发布维护 SUSE Linux Enterprise Server (SLES) 企业版 OpenSuse 个人版版 debian: 由Debian维护社区发布 Ubuntu 以桌面应用为主的开源GNU/Linux操作系统 Linux Mint:为家庭用户和企业提供一个不花钱的，易用的，并且漂亮的桌面系统 redhat：由Redhat发布 RHEL: RedHat Enterprise Linux 企业版 每18个月发行一个新版本 CentOS ：兼容RHEL的格式 企业版 中标麒麟：中标软件 Fedora ：个人版 每6个月发行一个新版本 其他版本的Linux发行版 ArchLinux：轻量简洁 Gentoo：极致性能，不提供传统意义的安装程序 LFS: Linux From scratch 自制Linux Android: kernel+busybox（工具集）+java虚拟机 更多详情可参考 Linux 分支参考网站：http://futurist.se/gldt/ Linux内核版本 Linux哲学思想 一切皆文件； 小型，单一用途的程序； 连接程序，共同完成复杂功能； 避免令人困惑的用户界面； 配置数据存储在文本中； 解释：一切皆文件： 是 Unix/Linux 的基本哲学之一。不仅普通的文件，目录、字符设备、块设备、 套接字等在 Unix/Linux 中都是以文件被对待；它们虽然类型不同，但是对其提供的却是同一套操作界面。 小型，单一用途的程序： 程序和可执行文件不要太复杂，这样才能保证了linux内核的高效运行 连接程序，共同完成复杂功能： 复杂的任务可以通过连接多个简单的程序实现复杂的功能。对于复杂的功能linux通过许多简单程序的组合等方式实现，在保证简单功能的高效性的同时，复杂的程序也必然是高效性的 避免令人困惑的用户界面： 如windows那样出了问题一般人选择的会是重启，实在是不行的话就是 重新 安装系统了，因为对于windows那样不是开源的，并且用户界面比较 复杂操作系统出了问题，一般的人是根本没有办法解决的。但是linux就不一样了，第一linux是开源的，无论什么问题都可以通过简洁的命令行实现 排错，修改系统的配置，一切都是简洁明了为基础。 配置数据存储在文本中： linux所有的配置文件都存放在文本配置文件当中，无论什么配置修改都只需修改其配置文件即可，配置文件时文本形式的只需任意一款文本编辑器修改即可而不是类似于windows那样将保存在注册表中，并且windows的注册表需要专门的二进制或十六进制的编辑器才可编辑，修改比较复杂]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
